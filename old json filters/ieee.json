  [
    {
      "Document Title": "A Machine Learning Based Approach to Identify SQL Injection Vulnerabilities",
      "Authors": "K. Zhang",
      "Author Affiliations": "Department of Computer Science, Wayne State University, Detroit, MI",
      "Publication Title": "2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "9-Jan-20",
      "Publication Year": "2019",
      "Start Page": "1286",
      "End Page": "1288",
      "Abstract": "This paper presents a machine learning classifier designed to identify SQL injection vulnerabilities in PHP code. Both classical and deep learning based machine learning algorithms were used to train and evaluate classifier models using input validation and sanitization features extracted from source code files. On ten-fold cross validations a model trained using Convolutional Neural Network(CNN) achieved the highest precision (95.4%), while a model based on Multilayer Perceptron(MLP) achieved the highest recall (63.7%) and the highest f-measure (0.746).",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-7281-2508-4",
      "DOI": "10.1109/ASE.2019.00164",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952467",
      "Author_Keywords": "Deep learning;prediction model;SQL injection;vulnerability",
      "IEEE_Terms": "Deep learning;SQL injection;Machine learning algorithms;Multilayer perceptrons;Training",
      "Article Citation Count": "27",
      "Reference Count": "18",
      "License": "IEEE",
      "Online Date": "9-Jan-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Toward Machine Learning Based Analyses on Compressed Firmware",
      "Authors": "S. Lee; J. -Y. Paik; R. Jin; E. -S. Cho",
      "Author Affiliations": "Dept. of Computer Science and Engineering, Chungnam National University, Daejeon, Republic of Korea; The School of Computer Science and Technology, Tianjin Polytechnic University, Tianjin, China; The School of Computer Science and Technology, Tianjin Polytechnic University, Tianjin, China; Dept. of Computer Science and Engineering, Chungnam National University, Daejeon, Republic of Korea",
      "Publication Title": "2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "9-Jul-19",
      "Publication Year": "2019",
      "Volume": "2",
      "Start Page": "586",
      "End Page": "591",
      "Abstract": "As Internet of Things (IoT) applications are getting attention these days, the importance of firmware security is also growing. However, it is not straightforward to analyze the bugs or vulnerabilities that reside in firmware. One of the major challenges is to detect information about hardware architectures of compressed firmware. Traditional analysis tools make use of static signatures embedded in the compressed binary code of firmware. However, signature extraction needs the careful elaboration of experts, and it is not always even possible. In this paper, we introduce our experience in analyzing the hardware information of compressed firmware. Since it is not possible to use the semantic information of compressed binary code, we adopt machine learning technologies for this purpose. Despite various difficulties, we have positive experimental results.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-7281-2607-4",
      "DOI": "10.1109/COMPSAC.2019.10271",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8754220",
      "Author_Keywords": "Firmware, Machine Learning, Firmware Type, Firmware Classification",
      "IEEE_Terms": "Microprogramming;Machine learning algorithms;Classification algorithms;Feature extraction;Hardware;Support vector machines;Machine learning",
      "Article Citation Count": "5",
      "Reference Count": "18",
      "License": "IEEE",
      "Online Date": "9-Jul-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Keep it simple: Is deep learning good for linguistic smell detection?",
      "Authors": "S. Fakhoury; V. Arnaoudova; C. Noiseux; F. Khomh; G. Antoniol",
      "Author Affiliations": "School of Electrical Engineering and Computer Science, Washington State University, Pullman, USA; School of Electrical Engineering and Computer Science, Washington State University, Pullman, USA; Department of Computer and Software Engineering, Polytechnique Montr√©al, Montr√©al, Canada; Department of Computer and Software Engineering, Polytechnique Montr√©al, Montr√©al, Canada; Department of Computer and Software Engineering, Polytechnique Montr√©al, Montr√©al, Canada",
      "Publication Title": "2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "5-Apr-18",
      "Publication Year": "2018",
      "Start Page": "602",
      "End Page": "611",
      "Abstract": "Deep neural networks is a popular technique that has been applied successfully to domains such as image processing, sentiment analysis, speech recognition, and computational linguistic. Deep neural networks are machine learning algorithms that, in general, require a labeled set of positive and negative examples that are used to tune hyper-parameters and adjust model coefficients to learn a prediction function. Recently, deep neural networks have also been successfully applied to certain software engineering problem domains (e.g., bug prediction), however, results are shown to be outperformed by traditional machine learning approaches in other domains (e.g., recovering links between entries in a discussion forum). In this paper, we report our experience in building an automatic Linguistic Antipattern Detector (LAPD) using deep neural networks. We manually build and validate an oracle of around 1,700 instances and create binary classification models using traditional machine learning approaches and Convolutional Neural Networks. Our experience is that, considering the size of the oracle, the available hardware and software, as well as the theory to interpret results, deep neural networks are outperformed by traditional machine learning algorithms in terms of all evaluation metrics we used and resources (time and memory). Therefore, although deep learning is reported to produce results comparable and even superior to human experts for certain complex tasks, it does not seem to be a good fit for simple classification tasks like smell detection. Researchers and practitioners should be careful when selecting machine learning models for the problem at hand.",
      "ISBNs": "978-1-5386-4969-5",
      "DOI": "10.1109/SANER.2018.8330265",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8330265",
      "Author_Keywords": "Antipattern Detection;Machine Learning;Con-volutional Neural Networks",
      "IEEE_Terms": "Neural networks;Machine learning;Support vector machines;Linguistics;Task analysis;Machine learning algorithms;Vegetation",
      "Article Citation Count": "19",
      "Reference Count": "29",
      "License": "IEEE",
      "Online Date": "5-Apr-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Method of Component Prediction for Crash Bug Reports Using Component-Based Features and Machine Learning",
      "Authors": "Y. Xu; C. Liu; Y. Li; Q. Xie; H. -D. Choi",
      "Author Affiliations": "SAP Labs China, Xi‚Äôan, China; SAP Labs China, Xi‚Äôan, China; SAP Labs China, Xi‚Äôan, China; SAP Labs China, Xi‚Äôan, China; SAP Labs Korea, Seoul, South Korea",
      "Publication Title": "2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "15-May-23",
      "Publication Year": "2023",
      "Start Page": "773",
      "End Page": "777",
      "Abstract": "In large-scale software with hundreds of components, assigning a bug report to a relevant component representing a group of developers who can analyze and solve the potential issue can be a challenging task. In such a practical environment, we observed that bug reports often get re-assigned multiple times because of incorrect root cause component identification. Each re-assignment considerably delays the bug fix time. Therefore, it is desirable to identify a suitable component correctly. We report on our experience with component prediction when call stacks are used as the primary data of bug reports. Our method extracts the component features by aggregating the frequency of component functions from the call stack after introducing the component name and position into the original call stack. By predicting the component position of the call stack using component features and machine learning, we can obtain a suitable component of the bug report from the call stack. Our method achieves 73% accuracy on crash bug reports for SAP HANA, a large industrial in-memory database system. It significantly reduces the time delay for assigning bug reports to suitable components.",
      "ISSN": "2640-7574",
      "ISBNs": "978-1-6654-5278-6",
      "DOI": "10.1109/SANER56733.2023.00089",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10123465",
      "Author_Keywords": "bug assignment;feature extraction;machine learning;crash failure;software evolution",
      "IEEE_Terms": "Training;Machine learning algorithms;Delay effects;Computer bugs;Machine learning;Feature extraction;Software",
      "Reference Count": "23",
      "License": "IEEE",
      "Online Date": "15-May-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Predicting Number of Bugs before Launch: An Investigation based on Machine Learning",
      "Authors": "S. Rajendren; S. Reddivari",
      "Author Affiliations": "School of Computing, University of North Florida, Jacksonville, FL; School of Computing, University of North Florida, Jacksonville, FL",
      "Publication Title": "2021 IEEE 45th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "9-Sep-21",
      "Publication Year": "2021",
      "Start Page": "1403",
      "End Page": "1404",
      "Abstract": "Identifying and minimizing the number of bugs before release is a high priority of any team working on software development. This can be achieved by Machine Learning (ML) models. By using particular aspects of the code, ML Models can predict the number of bugs that are possible post launch. We use a public dataset consisting of 15 Java projects from GitHub as our training and test dataset. We use five ML models for our investigation: Multilayer Perceptron, K-Nearest Neighbors, Linear Regression, Logistic Regression, and Decision Trees. We conduct a preliminary investigation to evaluate how these ML models perform in predicting bugs. The results show that Linear Regression outperforms the other four ML models in finding the number of bugs post release.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-6654-2463-9",
      "DOI": "10.1109/COMPSAC51774.2021.00205",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9529793",
      "Author_Keywords": "software;bugs;machine learning",
      "IEEE_Terms": "Training;Computational modeling;Computer bugs;Linear regression;Machine learning;Predictive models;Software",
      "Article Citation Count": "1",
      "Reference Count": "8",
      "License": "IEEE",
      "Online Date": "9-Sep-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "What do Developers Know About Machine Learning: A Study of ML Discussions on StackOverflow",
      "Authors": "A. A. Bangash; H. Sahar; S. Chowdhury; A. W. Wong; A. Hindle; K. Ali",
      "Author Affiliations": "Department of Computing Science, University of Alberta, Edmonton, AB, Canada; Department of Computing Science, University of Alberta, Edmonton, AB, Canada; Department of Computing Science, University of Alberta, Edmonton, AB, Canada; Department of Computing Science, University of Alberta, Edmonton, AB, Canada; Department of Computing Science, University of Alberta, Edmonton, AB, Canada; Department of Computing Science, University of Alberta, Edmonton, AB, Canada",
      "Publication Title": "2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "29-Aug-19",
      "Publication Year": "2019",
      "Start Page": "260",
      "End Page": "264",
      "Abstract": "Machine learning, a branch of Artificial Intelligence, is now popular in software engineering community and is successfully used for problems like bug prediction, and software development effort estimation. Developers' understanding of machine learning, however, is not clear, and we require investigation to understand what educators should focus on, and how different online programming discussion communities can be more helpful. We conduct a study on Stack Overflow (SO) machine learning related posts using the SOTorrent dataset. We found that some machine learning topics are significantly more discussed than others, and others need more attention. We also found that topic generation with Latent Dirichlet Allocation (LDA) can suggest more appropriate tags that can make a machine learning post more visible and thus can help in receiving immediate feedback from sites like SO.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-7281-3412-3",
      "DOI": "10.1109/MSR.2019.00052",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8816808",
      "Author_Keywords": "stackoverflow, machine learning, topic modeling",
      "IEEE_Terms": "Machine learning;Machine learning algorithms;Software;Classification algorithms;Training;Programming;Tagging",
      "Article Citation Count": "24",
      "Reference Count": "10",
      "License": "IEEE",
      "Online Date": "29-Aug-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "On the Impact of Multi-language Development in Machine Learning Frameworks",
      "Authors": "M. Grichi; E. E. Eghan; B. Adams",
      "Author Affiliations": "GIGL department, Polytechnique Montreal, Quebec, Canada; GIGL department, Polytechnique Montreal, Quebec, Canada; GIGL department, Polytechnique Montreal, Quebec, Canada",
      "Publication Title": "2020 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "2-Nov-20",
      "Publication Year": "2020",
      "Start Page": "546",
      "End Page": "556",
      "Abstract": "The role of machine learning frameworks in software applications has exploded in recent years. Similar to non-machine learning frameworks, those frameworks need to evolve to incorporate new features, optimizations, etc., yet their evolution is impacted by the interdisciplinary development teams needed to develop them: scientists and developers. One concrete way in which this shows is through the use of multiple programming languages in their code base, enabling the scientists to write optimized low-level code while developers can integrate the latter into a robust framework. Since multi-language code bases have been shown to impact the development process, this paper empirically compares ten large open-source multi-language machine learning frameworks and ten large open-source multi-language traditional systems in terms of the volume of pull requests, their acceptance ratio i.e., the percentage of accepted pull requests among all the received pull requests, review process duration i.e., period taken to accept or reject a pull request, and bug-proneness. We find that multi-language pull request contributions present a challenge for both machine learning and traditional systems. Our main findings show that in both machine learning and traditional systems, multi-language pull requests are likely to be less accepted than mono-language pull requests; it also takes longer for both multi- and mono-language pull requests to be rejected than accepted. Machine learning frameworks take longer to accept/reject a multi-language pull request than traditional systems. Finally, we find that mono-language pull requests in machine learning frameworks are more bug-prone than traditional systems.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-7281-5619-4",
      "DOI": "10.1109/ICSME46990.2020.00058",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240642",
      "Author_Keywords": "Machine learning;Framework;Open Source;Software engineering;Multi-language;Traditional systems",
      "IEEE_Terms": "Software maintenance;Computer languages;Conferences;Machine learning;Open source software;Optimization",
      "Article Citation Count": "5",
      "Reference Count": "36",
      "License": "IEEE",
      "Online Date": "2-Nov-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Machine Learning Regression Techniques for Test Case Prioritization in Continuous Integration Environment",
      "Authors": "E. A. Da Roza; J. A. P. Lima; R. C. Silva; S. R. Vergilio",
      "Author Affiliations": "Department of Computer Science, Federal University of Paran√°, Curitiba, PR, Brazil; Department of Computer Science, Federal University of Paran√°, Curitiba, PR, Brazil; Department of Computer Science, Federal University of Paran√°, Curitiba, PR, Brazil; Department of Computer Science, Federal University of Paran√°, Curitiba, PR, Brazil",
      "Publication Title": "2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "21-Jul-22",
      "Publication Year": "2022",
      "Start Page": "196",
      "End Page": "206",
      "Abstract": "Test Case Prioritization (TCP) techniques are a key factor in reducing the regression testing costs even more when Continuous Integration (CI) practices are adopted. TCP approaches based on failure history have been adopted in this context because they are more suitable for CI environment constraints: test budget and test case volatility, that is, test cases may be added or removed over the CI cycles. Promising approaches are based on Reinforcement Learning (RL), which learns with past prioritization, guided by a reward function. In this work, we introduce a TCP approach for CI environments based on the sliding window method, which can be instantiated with different Machine Learning (ML) algorithms. Unlike other ML approaches, it does not require retraining the model to perform the prioritization and any code analysis. As an alternative for the RL approaches, we apply the Random Forest (RF) algorithm and a Long Short Term Memory (LSTM) deep learning network in our evaluation. We use three time budgets and eleven systems. The results show the applicability of the approach considering the prioritization time and the time between the CI cycles. Both algorithms take just a few seconds to execute. The RF algorithm obtained the best performance for more restrictive budgets compared to the RL approaches described in the literature. Considering all systems and budgets, RF reaches Normalized Average Percentage of Faults Detected (NAPFD) values that are the best or statistically equivalent to the best ones in around 72% of the cases, and the LSTM network in 55% of them. Moreover, we discuss some implications of our results for the usage of the algorithms evaluated.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-6654-3786-8",
      "DOI": "10.1109/SANER53432.2022.00034",
      "Funding Information": "CAPES(grant numbers:88887.501291/2020-00,88882.382199/2019-01,88887.501314/2020-00); CNPq(grant numbers:305968/2018-1); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9825820",
      "Author_Keywords": "Recurrent Neural Networks;Machine Learning;Continuous Integration;Regression Testing",
      "IEEE_Terms": "Radio frequency;Machine learning algorithms;Recurrent neural networks;Software algorithms;Reinforcement learning;Software;History",
      "Article Citation Count": "2",
      "Reference Count": "43",
      "License": "IEEE",
      "Online Date": "21-Jul-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Debugging Support for Machine Learning Applications in Bioengineering Text Corpora",
      "Authors": "K. S. Cheng; T. -H. Ahn; M. Song",
      "Author Affiliations": "University of Nebraska at Omaha; Saint Louis University; University of Nebraska at Omaha",
      "Publication Title": "2022 IEEE 46th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "10-Aug-22",
      "Publication Year": "2022",
      "Start Page": "1062",
      "End Page": "1069",
      "Abstract": "Modeling in machine learning (ML) is becoming an essential part of software systems in practice. Validating ML applications is a challenging and time-consuming process for developers since the accuracy of prediction heavily relies on generated models. ML applications are written by relatively more data-driven programming based on the blackbox of ML frameworks. If all of the datasets and the ML application need to be individually investigated, the ML debugging tasks would take a lot of time and effort. To address this limitation, we present a novel debugging technique for machine learning applications, called MLDBUG that helps ML application developers inspect the training data and the generated features for the ML model. Inspired by software debugging for reproducing the potential reported bugs, MLDBUG takes as input an ML application and its training datasets to build the ML models, helping ML application developers easily reproduce and understand anomalies on the ML application. We have implemented an Eclipse plugin for MLDBUG which allows developers to validate the prediction behavior of their ML applications, the ML model, and the training data on the Eclipse IDE. In our evaluation, we used 23,500 documents in the bioengineering research domain. We assessed the MLDBUG's capability of how effectively our debugging technique can help ML application developers investi-gate the connection between the produced features and the labels in the training model and the relationship between the training instances and the instances the model predicts.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-6654-8810-5",
      "DOI": "10.1109/COMPSAC54236.2022.00166",
      "Funding Information": "NSF(grant numbers:OIA-1920954); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9842702",
      "Author_Keywords": "Machine Learning;Bioengineering;Debugging",
      "IEEE_Terms": "Training;Biological system modeling;Computational modeling;Training data;Debugging;Machine learning;Predictive models",
      "Article Citation Count": "2",
      "Reference Count": "22",
      "License": "IEEE",
      "Online Date": "10-Aug-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Quantum Machine Learning for Software Supply Chain Attacks: How Far Can We Go?",
      "Authors": "M. Masum; M. Nazim; M. J. H. Faruk; H. Shahriar; M. Valero; M. A. H. Khan; G. Uddin; S. Barzanjeh; E. Saglamyurek; A. Rahman; S. I. Ahamed",
      "Author Affiliations": "Analytics and Data Science Institute, Kennesaw State University, USA; Department of Computer Science, Kennesaw State University, USA; Department of Software Engineering and Game Development, Kennesaw State University, USA; Analytics and Data Science Institute, Kennesaw State University, USA; Department of Computer Science, Kennesaw State University, USA; Department of Computer Science, Kennesaw State University, USA; Electrical and Software Engineering, Institute for Quantum Science and Technology, University of Calgary, Canada; Electrical and Software Engineering, Institute for Quantum Science and Technology, University of Calgary, Canada; Electrical and Software Engineering, Institute for Quantum Science and Technology, University of Calgary, Canada; Department of Computer Science, Tennessee Tech University, USA; Department of Computer Science, Marquette University, USA",
      "Publication Title": "2022 IEEE 46th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "10-Aug-22",
      "Publication Year": "2022",
      "Start Page": "530",
      "End Page": "538",
      "Abstract": "Quantum Computing (QC) has gained immense popularity as a potential solution to deal with the ever-increasing size of data and associated challenges leveraging the concept of quantum random access memory (QRAM). QC promises-quadratic or exponential increases in computational time with quantum parallelism and thus offer a huge leap forward in the computation of Machine Learning algorithms. This paper analyzes speed up performance of QC when applied to machine learning algorithms, known as Quantum Machine Learning (QML). We applied QML methods such as Quantum Support Vector Machine (QSVM), and Quantum Neural Network (QNN) to detect Software Supply Chain (SSC) attacks. Due to the access limitations of real quantum computers, the QML methods were implemented on open-source quantum simulators such as IBM Qiskit and TensorFlow Quantum. We evaluated the performance of QML in terms of processing speed and accuracy and finally, compared with its classical counterparts. Interestingly, the experimental results differ to the speed up promises of QC by demonstrating higher computational time and lower accuracy in comparison to the classical approaches for SSC attacks.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-6654-8810-5",
      "DOI": "10.1109/COMPSAC54236.2022.00097",
      "Funding Information": "National Science Foundation(grant numbers:2100115,1723578); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9842669",
      "Author_Keywords": "Quantum Computing;Quantum Machine Learning;Software Supply Chain;Software Security;Source Code Vulnerability;Quantum Support Vector Machine;Quantum Neural Network",
      "IEEE_Terms": "Computers;Machine learning algorithms;Supply chains;Neural networks;Qubit;Software algorithms;Support vector machine classification",
      "Article Citation Count": "8",
      "Reference Count": "37",
      "License": "IEEE",
      "Online Date": "10-Aug-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Leveraging Feature Bias for Scalable Misprediction Explanation of Machine Learning Models",
      "Authors": "J. Gesi; X. Shen; Y. Geng; Q. Chen; I. Ahmed",
      "Author Affiliations": "Donald Bren School of ICS, University of California, Irvine, Irvine, USA; Donald Bren School of ICS, University of California, Irvine, Irvine, USA; Donald Bren School of ICS, University of California, Irvine, Irvine, USA; Donald Bren School of ICS, University of California, Irvine, Irvine, USA; Donald Bren School of ICS, University of California, Irvine, Irvine, USA",
      "Publication Title": "2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "14-Jul-23",
      "Publication Year": "2023",
      "Start Page": "1559",
      "End Page": "1570",
      "Abstract": "Interpreting and debugging machine learning models is necessary to ensure the robustness of the machine learning models. Explaining mispredictions can help significantly in doing so. While recent works on misprediction explanation have proven promising in generating interpretable explanations for mispredictions, the state-of-the-art techniques ‚Äúblindly‚Äù deduce misprediction explanation rules from all data features, which may not be scalable depending on the number of features. To alleviate this problem, we propose an efficient misprediction explanation technique named Bias Guided Misprediction Diagnoser (BGMD), which leverages two prior knowledge about data: a) data often exhibit highly-skewed feature distributions and b) trained models in many cases perform poorly on subdataset with under-represented features. Next, we propose a technique named MAPS (Mispredicted Area UPweight Sampling). MAPS increases the weights of subdataset during model retraining that belong to the group that is prone to be mispredicted because of containing under-represented features. Thus, MAPS make retrained model pay more attention to the under-represented features. Our empirical study shows that our proposed BGMD outperformed the state-of-the-art misprediction diagnoser and reduces diagnosis time by 92%. Furthermore, MAPS outperformed two state-of-the-art techniques on fixing the machine learning model's performance on mispredicted data without compromising performance on all data. All the research artifacts (i.e., tools, scripts, and data) of this study are available in the accompanying website [1].",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-5701-9",
      "DOI": "10.1109/ICSE48619.2023.00135",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172677",
      "Author_Keywords": "machine learning;data imbalance;rule induction;misprediction explanation",
      "IEEE_Terms": "Machine learning algorithms;Machine learning;Debugging;Predictive models;Prediction algorithms;Robustness;Data models",
      "Article Citation Count": "1",
      "Reference Count": "58",
      "License": "IEEE",
      "Online Date": "14-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Can a Machine Learn Through Customer Sentiment?: A Cost-Aware Approach to Predict Support Ticket Escalations",
      "Authors": "C. Werner; Z. S. Li; D. Damian",
      "Author Affiliations": "University of Victoria; University of Victoria; University of Victoria",
      "Publication Title": "IEEE Software",
      "Date Added To Xplore": "15-Aug-19",
      "Publication Year": "2019",
      "Volume": "36",
      "Issue": "5",
      "Start Page": "38",
      "End Page": "45",
      "Abstract": "Given the connection between customer happiness and support ticket escalation, we describe an approach that 1) analyzes the emotions in conversations between a customer and a support analyst and 2) provides organizations with a cost-based mechanism to evaluate machine-learning algorithms trained on emotion-related features to predict support ticket escalations.",
      "ISSN": "1937-4194",
      "DOI": "10.1109/MS.2019.2923408",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8737665",
      "Author_Keywords": "Sentiment analysis;Natural language;Affective Computing;Machine learning;Modeling and prediction;cost-sensitive learning;data mining;defect escalation;machine learning;software defect escalation prediction",
      "IEEE_Terms": "Training data;Software engineering;Sentiment analysis;Machine learning algorithms;Data mining;Emotion recognition",
      "Article Citation Count": "6",
      "Reference Count": "16",
      "License": "IEEE",
      "Online Date": "17-Jun-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Magazines"
    },
    {
      "Document Title": "Towards Robust Production Machine Learning Systems: Managing Dataset Shift",
      "Authors": "H. Abdelkader",
      "Author Affiliations": "Applied Artificial Intelligence Institute A2I2, Deakin University, Australia",
      "Publication Title": "2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "24-Dec-20",
      "Publication Year": "2020",
      "Start Page": "1164",
      "End Page": "1166",
      "Abstract": "The advances in machine learning (ML) have stimulated the integration of their capabilities into software systems. However, there is a tangible gap between software engineering and machine learning practices, that is delaying the progress of intelligent services development. Software organisations are devoting effort to adjust the software engineering processes and practices to facilitate the integration of machine learning models. Machine learning researchers as well are focusing on improving the interpretability of machine learning models to support overall system robustness. Our research focuses on bridging this gap through a methodology that evaluates the robustness of machine learning-enabled software engineering systems. In particular, this methodology will automate the evaluation of the robustness properties of software systems against dataset shift problems in ML. It will also feature a notification mechanism that facilitates the debugging of ML components.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-4503-6768-4",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9286084",
      "IEEE_Terms": "Focusing;Machine learning;Production;Debugging;Software systems;Robustness;Software engineering",
      "Article Citation Count": "3",
      "Reference Count": "30",
      "Online Date": "24-Dec-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Automated Testing of Software that Uses Machine Learning APIs",
      "Authors": "C. Wan; S. Liu; S. Xie; Y. Liu; H. Hoffmann; M. Maire; S. Lu",
      "Author Affiliations": "University of Chicago; University of Chicago; Whitney Young High School; University of Chicago; University of Chicago; University of Chicago; University of Chicago",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "212",
      "End Page": "224",
      "Abstract": "An increasing number of software applications incorporate machine learning (ML) solutions for cognitive tasks that statistically mimic human behaviors. To test such software, tremendous human effort is needed to design image/text/audio inputs that are relevant to the software, and to judge whether the software is processing these inputs as most human beings do. Even when misbehavior is exposed, it is often unclear whether the culprit is inside the cognitive ML API or the code using the API. This paper presents Keeper, a new testing tool for software that uses cognitive ML APIs. Keeper designs a pseudo-inverse function for each ML API that reverses the corresponding cognitive task in an empirical way (e.g., an image search engine pseudo-reverses the image-classification API), and incorporates these pseudo-inverse functions into a symbolic execution engine to automatically gener-ate relevant image/text/audio inputs and judge output correctness. Once misbehavior is exposed, Keeper attempts to change how ML APIs are used in software to alleviate the misbehavior. Our evalu-ation on a variety of open-source applications shows that Keeper greatly improves the branch coverage, while identifying many pre-viously unknown bugs.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3510068",
      "Funding Information": "NSF(grant numbers:CNSI764039,CNS1956180,CCF1837120,CCF2119184,CNS1952050,CCFI823032); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793999",
      "Author_Keywords": "software testing;machine learning;machine learning API",
      "IEEE_Terms": "Codes;Computer bugs;Web pages;Machine learning;Search engines;Software;Test pattern generators",
      "Article Citation Count": "5",
      "Reference Count": "108",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Detecting and Preventing ROP Attacks using Machine Learning on ARM",
      "Authors": "G. B. Welearegai; C. Hu; C. Hammer",
      "Author Affiliations": "Faculty of Informatics and Mathematics, University of Passau, Passau, Germany; Munich, Germany; Faculty of Informatics and Mathematics, University of Passau, Passau, Germany",
      "Publication Title": "2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "2-Aug-23",
      "Publication Year": "2023",
      "Start Page": "667",
      "End Page": "677",
      "Abstract": "As the ARM processor is receiving increased attention due to the fast growth of mobile technologies and the internet-of-things (IoT), it is simultaneously becoming the target of several control flow attacks such as return-oriented programming (ROP), which uses code present in the software system in order to exploit memory bugs. While some research can detect control flow attacks on architectures like x86, the ARM architecture has been neglected. In this paper, we investigate whether ROP attack detection and prevention based on hardware performance counters (HPC) and machine learning can be effectively transferred to the ARM architecture. Given the observation that ROP attacks exhibit different micro-architectural events compared to benign executions of a software, we evaluate whether and which HPCs, which track these hardware events, are indicative on ARM to detect control flow attacks. We collect data exploiting real-world vulnerable applications running on ARM-based Raspberry Pi machines. The collected data then serves as training data for different machine learning techniques. We also implement an online monitor consisting of a modified program loader, kernel module and a classifier, which labels a program‚Äôs execution as benign or under attack, and stops its execution once the latter is detected. An evaluation of our approach provides detection accuracy of 92% for the offline training and 75% for the online monitoring, which demonstrates that variations in the HPCs are indicative of attacks on ARM architectures. The performance overhead of online monitoring evaluated on 8 real-world vulnerable applications exhibits a moderate 6.2% slowdown on average. The result of our evaluation indicates that the behavioral changes in micro-architectural events of the ARM platform can play a vital role in detecting memory attacks.",
      "ISSN": "0730-3157",
      "ISBNs": "979-8-3503-2697-0",
      "DOI": "10.1109/COMPSAC57700.2023.00092",
      "Funding Information": "Ministry of Education; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10196911",
      "Author_Keywords": "ROP Detection;ARM;HPC;Machine Learning;Online Monitor",
      "IEEE_Terms": "Training;Support vector machines;Program processors;Training data;Machine learning;Computer architecture;Hardware",
      "Reference Count": "39",
      "License": "IEEE",
      "Online Date": "2-Aug-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Comprehensive Study of Real-World Bugs in Machine Learning Model Optimization",
      "Authors": "H. Guan; Y. Xiao; J. Li; Y. Liu; G. Bai",
      "Author Affiliations": "The University of Queensland, Brisbane, Australia; Southern University of Science and Technology, Shenzhen, China; Microsoft Software Technology Center Asia, Beijing, China; Southern University of Science and Technology, Shenzhen, China; The University of Queensland, Brisbane, Australia",
      "Publication Title": "2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "14-Jul-23",
      "Publication Year": "2023",
      "Start Page": "147",
      "End Page": "158",
      "Abstract": "Due to the great advance in machine learning (ML) techniques, numerous ML models are expanding their application domains in recent years. To adapt for resource-constrained platforms such as mobile and Internet of Things (IoT) devices, pre-trained models are often processed to enhance their efficiency and compactness, using optimization techniques such as pruning and quantization. Similar to the optimization process in other complex systems, e.g., program compilers and databases, optimizations for ML models can contain bugs, leading to severe consequences such as system crashes and financial loss. While bugs in training, compiling and deployment stages have been extensively studied, there is still a lack of systematic understanding and characterization of model optimization bugs (MOBs). In this work, we conduct the first empirical study to identify and characterize MOBs. We collect a comprehensive dataset containing 371 MOBs from TensorFlow and PyTorch, the most extensively used open-source ML frameworks, covering the entire development time span of their optimizers (May 2019 to August 2022). We then investigate the collected bugs from various perspectives, including their symptoms, root causes, life cycles, detection and fixes. Our work unveils the status quo of MOBs in the wild, and reveals their features on which future detection techniques can be based. Our findings also serve as a warning to the developers and the users of ML frameworks, and an appeal to our research community to enact dedicated countermeasures.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-5701-9",
      "DOI": "10.1109/ICSE48619.2023.00024",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172690",
      "Author_Keywords": "Machine Learning;Model Optimization;Bugs",
      "IEEE_Terms": "Training;Adaptation models;Analytical models;Systematics;Computer bugs;Machine learning;Internet of Things",
      "Article Citation Count": "2",
      "Reference Count": "54",
      "License": "IEEE",
      "Online Date": "14-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Standard Baseline for Software Defect Prediction: Using Machine Learning and Explainable AI",
      "Authors": "N. S. Bommi; A. Negi",
      "Author Affiliations": "School of Computer and Information Sciences, University of Hyderabad, Hyderabad, India; School of Computer and Information Sciences, University of Hyderabad, Hyderabad, India",
      "Publication Title": "2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "2-Aug-23",
      "Publication Year": "2023",
      "Start Page": "1798",
      "End Page": "1803",
      "Abstract": "The utility of ubiquitous computing systems drives large-scale software development with millions of lines of code (LOC). As there are vast code sets, it also increases the possibility of coding errors since it is difficult for even highly trained software engineers to write flawless code. Such flawed software can lead to severe issues once deployed. McCabe and Halstead proposed feature extractors for source code to define software quality. Based on the static features proposed by McCabe and Halstead, we run a series of feature engineering techniques and different machine learning models to detect code defects and use explainable algorithms to assess the prediction quality. We report different processing pipeline combinations to detect defects and compare the approaches. We conclude the paper with comments on the nature of the dataset and establish a baseline for further research.",
      "ISSN": "0730-3157",
      "ISBNs": "979-8-3503-2697-0",
      "DOI": "10.1109/COMPSAC57700.2023.00278",
      "Funding Information": "University of Hyderabad; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10196938",
      "Author_Keywords": "Machine Learning;Explainable AI;Software Defect Prediction;Software Engineering;Dataset Imbalance",
      "IEEE_Terms": "Codes;Source coding;Software algorithms;Machine learning;Software quality;Predictive models;Feature extraction",
      "Reference Count": "24",
      "License": "IEEE",
      "Online Date": "2-Aug-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Towards the generation of machine learning defect reports",
      "Authors": "T. D. Lai",
      "Author Affiliations": "Applied Artificial Intelligence Institute, Deakin University",
      "Publication Title": "2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "20-Jan-22",
      "Publication Year": "2021",
      "Start Page": "1038",
      "End Page": "1042",
      "Abstract": "Effective locating and fixing defects requires detailed defect reports. Unlike traditional software systems, machine learning applications are subject defects caused from changes in the input data streams (concept drift) and assumptions encoded into models. Without appropriate training, developers face difficulties understanding and interpreting faults in machine learning (ML). However, little research is done on how to prepare developers to detect and investigate machine learning system defects. Software engineers often do not have sufficient knowledge to fix the issues themselves without the help of data scientists or domain experts. To investigate this issue, we analyse issue templates and check how developers report machine learning related issues in open-source applied AI projects. The overall goal is to develop a tool for automatically repairing ML defects or generating defect reports if a fix cannot be made. Previous research has identified classes of faults specific to machine learning systems, such as performance degradation arising from concept drift where the machine learning model is no longer aligned with the real-world environment. However, the current issue templates that developers use do not seem to capture the information needed. This research seeks to systematically develop a two-way human-machine information exchange protocol to support domain experts, software engineers, and data scientists to collaboratively detect, report, and respond to these new classes of faults.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-6654-0337-5",
      "DOI": "10.1109/ASE51524.2021.9678592",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9678592",
      "IEEE_Terms": "Training;Knowledge engineering;Production systems;Protocols;Computer bugs;Machine learning;Software systems",
      "Reference Count": "20",
      "License": "IEEE",
      "Online Date": "20-Jan-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "SoK: Security and Privacy in Machine Learning",
      "Authors": "N. Papernot; P. McDaniel; A. Sinha; M. P. Wellman",
      "Author Affiliations": "Pennsylvania State University; Pennsylvania State University; University of Michigan; University of Michigan",
      "Publication Title": "2018 IEEE European Symposium on Security and Privacy (EuroS&P)",
      "Date Added To Xplore": "9-Jul-18",
      "Publication Year": "2018",
      "Start Page": "399",
      "End Page": "414",
      "Abstract": "Advances in machine learning (ML) in recent years have enabled a dizzying array of applications such as data analytics, autonomous systems, and security diagnostics. ML is now pervasive-new systems and models are being deployed in every domain imaginable, leading to widespread deployment of software based inference and decision making. There is growing recognition that ML exposes new vulnerabilities in software systems, yet the technical community's understanding of the nature and extent of these vulnerabilities remains limited. We systematize findings on ML security and privacy, focusing on attacks identified on these systems and defenses crafted to date.We articulate a comprehensive threat model for ML, and categorize attacks and defenses within an adversarial framework. Key insights resulting from works both in the ML and security communities are identified and the effectiveness of approaches are related to structural elements of ML algorithms and the data used to train them. In particular, it is apparent that constructing a theoretical understanding of the sensitivity of modern ML algorithms to the data they analyze, √† la PAC theory, will foster a science of security and privacy in ML.",
      "ISBNs": "978-1-5386-4228-3",
      "DOI": "10.1109/EuroSP.2018.00035",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8406613",
      "Author_Keywords": "security;privacy;machine learning",
      "IEEE_Terms": "Security;Machine learning;Data models;Training;Privacy;Computational modeling;Analytical models",
      "Article Citation Count": "217",
      "Patent Citation Count": "1",
      "Reference Count": "115",
      "License": "IEEE",
      "Online Date": "9-Jul-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Towards Comprehensible Representation of Controllers using Machine Learning",
      "Authors": "G. Balasubramaniam",
      "Author Affiliations": "Department of Informatics, Technical University of Munich, Germany",
      "Publication Title": "2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "9-Jan-20",
      "Publication Year": "2019",
      "Start Page": "1283",
      "End Page": "1285",
      "Abstract": "From the point of view of a software engineer, having safe and optimal controllers for real life systems like cyber physical systems is a crucial requirement before deployment. Given the mathematical model of these systems along with their specifications, model checkers can be used to synthesize controllers for them. The given work proposes novel approaches for making controller analysis easier by using machine learning to represent the controllers synthesized by model checkers in a succinct manner, while also incorporating the domain knowledge of the system. It also proposes the implementation of a visualization tool which will be integrated into existing model checkers. A lucid controller representation along with a tool to visualize it will help the software engineer debug and monitor the system much more efficiently.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-7281-2508-4",
      "DOI": "10.1109/ASE.2019.00163",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952374",
      "Author_Keywords": "Cyber Physical Systems, Controller Synthesis, Model Checking, Machine Learning, Inductive Logic Programming, Domain Knowledge, Strategy Representation",
      "IEEE_Terms": "Decision trees;Computer science;Machine learning;Mathematical model;Software;Tools;Probabilistic logic",
      "Article Citation Count": "1",
      "Reference Count": "17",
      "License": "IEEE",
      "Online Date": "9-Jan-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "You Are the Only Possible Oracle: Effective Test Selection for End Users of Interactive Machine Learning Systems",
      "Authors": "A. Groce; T. Kulesza; C. Zhang; S. Shamasunder; M. Burnett; W. -K. Wong; S. Stumpf; S. Das; A. Shinsel; F. Bice; K. McIntosh",
      "Author Affiliations": "School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon; Centre for HCI Design, School of Informatics, City University London, London, United Kingdom; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "31-Mar-14",
      "Publication Year": "2014",
      "Volume": "40",
      "Issue": "3",
      "Start Page": "307",
      "End Page": "323",
      "Abstract": "How do you test a program when only a single user, with no expertise in software testing, is able to determine if the program is performing correctly? Such programs are common today in the form of machine-learned classifiers. We consider the problem of testing this common kind of machine-generated program when the only oracle is an end user: e.g., only you can determine if your email is properly filed. We present test selection methods that provide very good failure rates even for small test suites, and show that these methods work in both large-scale random experiments using a ‚Äúgold standard‚Äù and in studies with real users. Our methods are inexpensive and largely algorithm-independent. Key to our methods is an exploitation of properties of classifiers that is not possible in traditional software testing. Our results suggest that it is plausible for time-pressured end users to interactively detect failures-even very hard-to-find failures-without wading through a large number of successful (and thus less useful) tests. We additionally show that some methods are able to find the arguably most difficult-to-detect faults of classifiers: cases where machine learning algorithms have high confidence in an incorrect result.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2013.59",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6682887",
      "Author_Keywords": "Machine learning;end-user testing;test suite size",
      "IEEE_Terms": "Testing;Software;Training;Training data;Electronic mail;Software algorithms;Machine learning algorithms",
      "Article Citation Count": "41",
      "Reference Count": "63",
      "License": "IEEE",
      "Online Date": "12-Dec-13",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Machine Learning for Web Vulnerability Detection: The Case of Cross-Site Request Forgery",
      "Authors": "S. Calzavara; M. Conti; R. Focardi; A. Rabitti; G. Tolomei",
      "Author Affiliations": "Universit√† Ca‚Äô Foscari Venezia; University of Padua; Universit√† Ca‚Äô Foscari Venezia; Universit√† Ca‚Äô Foscari Venezia; Sapienza University of Rome",
      "Publication Title": "IEEE Security & Privacy",
      "Date Added To Xplore": "13-May-20",
      "Publication Year": "2020",
      "Volume": "18",
      "Issue": "3",
      "Start Page": "8",
      "End Page": "16",
      "Abstract": "We propose a methodology to leverage machine learning (ML) for the detection of web application vulnerabilities. We use it in the design of Mitch, the first ML solution for the black-box detection of cross-site request forgery vulnerabilities. Finally, we show the effectiveness of Mitch on real software.",
      "ISSN": "1558-4046",
      "DOI": "10.1109/MSEC.2019.2961649",
      "Funding Information": "Universit√† Ca Foscari di Venezia(grant numbers:IRIDE program Machine learning for web security\"); \"",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8966601",
      "IEEE_Terms": "Security;Tools;Browsers;Supervised learning;Forgery;Social networking (online);Machine learning",
      "Article Citation Count": "12",
      "Reference Count": "18",
      "License": "IEEE",
      "Online Date": "22-Jan-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Magazines"
    },
    {
      "Document Title": "Automatically Tagging the ‚ÄúAAA‚Äù Pattern in Unit Test Cases Using Machine Learning Models",
      "Authors": "C. Wei; L. Xiao; T. Yu; X. Chen; X. Wang; S. Wong; A. Clune",
      "Author Affiliations": "School of Systems and Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA; School of Systems and Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA; Department of EECS, University of Cincinnati, Cincinnati, OH, USA; HSBC Software Development (Guangdong) Limited, Guangzhou, Guangdong Province, China; School of Systems and Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA; Envestnet, Inc., Berwyn, PA, USA; AGI, Ansys Company, Exton, PA, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "15-May-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "5",
      "Start Page": "3305",
      "End Page": "3324",
      "Abstract": "The AAA pattern (i.e., Arrange-Act-Assert) is a common and natural layout to create a test case. Following this pattern in test cases may benefit comprehension, debugging, and maintenance. The AAA structure of real-life test cases, however, may not be clear due to their high complexity. Manually labeling AAA statements in test cases is tedious. Thus, we envision that an automated approach for labeling AAA statements in existing test cases could benefit new developers and projects that practice collective code ownership and test-driven development. This paper contributes an automatic approach based on machine learning models. The ‚Äúsecret sauce‚Äù of this approach is a set of three learning features that are based on the semantic, syntax, and context information in test cases, derived from the manual tagging process. Thus, our approach mimics how developers may manually tag the AAA pattern of a test case. We assess the precision, recall, and F-1 score of our approach based on 449 test cases, containing about 16,612 statements, across 4 Apache open source projects. To achieve the best performance in our approach, we explore the usage of six machine learning models; the contribution of the SMOTE data balancing technique; the comparison of the three learning features; and the comparison of five different methods for calculating the semantic feature. The results show our approach is able to identify Arrangement, Action, and Assertion statements with a precision upwards of 92%, and recall up to 74%. We also summarize some experience based on our experiments‚Äîregarding the choice of machine learning models, data balancing algorithm, and feature engineering methods‚Äîwhich could potentially provide some reference to related future research.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2023.3252442",
      "Funding Information": "National Science Foundation(grant numbers:CCF-1909085,CCF-1909763); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10058578",
      "Author_Keywords": "AAA pattern;feature engineering;machine learning;natural language processing;software testing;unit testing",
      "IEEE_Terms": "Codes;Machine learning;Tagging;Debugging;Production;Maintenance engineering;Computer bugs",
      "Reference Count": "81",
      "License": "IEEE",
      "Online Date": "3-Mar-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Mitch: A Machine Learning Approach to the Black-Box Detection of CSRF Vulnerabilities",
      "Authors": "S. Calzavara; M. Conti; R. Focardi; A. Rabitti; G. Tolomei",
      "Author Affiliations": "Universit√† Ca‚Äô Foscari; Universit√† di Padova; Universit√† Ca‚Äô Foscari; Universit√† Ca‚Äô Foscari; Universit√† di Padova",
      "Publication Title": "2019 IEEE European Symposium on Security and Privacy (EuroS&P)",
      "Date Added To Xplore": "22-Aug-19",
      "Publication Year": "2019",
      "Start Page": "528",
      "End Page": "543",
      "Abstract": "Cross-Site Request Forgery (CSRF) is one of the oldest and simplest attacks on the Web, yet it is still effective on many websites and it can lead to severe consequences, such as economic losses and account takeovers. Unfortunately, tools and techniques proposed so far to identify CSRF vulnerabilities either need manual reviewing by human experts or assume the availability of the source code of the web application. In this paper we present Mitch, the first machine learning solution for the black-box detection of CSRF vulnerabilities. At the core of Mitch there is an automated detector of sensitive HTTP requests, i.e., requests which require protection against CSRF for security reasons. We trained the detector using supervised learning techniques on a dataset of 5,828 HTTP requests collected on popular websites, which we make available to other security researchers. Our solution outperforms existing detection heuristics proposed in the literature, allowing us to identify 35 new CSRF vulnerabilities on 20 major websites and 3 previously undetected CSRF vulnerabilities on production software already analyzed using a state-of-the-art tool.",
      "ISBNs": "978-1-7281-1148-3",
      "DOI": "10.1109/EuroSP.2019.00045",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8806728",
      "Author_Keywords": "Cross site request forgery;Machine learning;Web security",
      "IEEE_Terms": "Security;Tools;Browsers;Forgery;Machine learning;Manuals;Task analysis",
      "Article Citation Count": "14",
      "Reference Count": "38",
      "License": "IEEE",
      "Online Date": "22-Aug-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Characterizing and Understanding Software Security Vulnerabilities in Machine Learning Libraries",
      "Authors": "N. S. Harzevili; J. Shin; J. Wang; S. Wang; N. Nagappan",
      "Author Affiliations": "Lassonde School of Engineering, York University, Toronto, Canada; Lassonde School of Engineering, York University, Toronto, Canada; Institute of Software Chinese Academy of Sciences, Beijing, China; Lassonde School of Engineering, York University, Toronto, Canada; IIIT Delhi, New Delhi, India",
      "Publication Title": "2023 IEEE/ACM 20th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "12-Jul-23",
      "Publication Year": "2023",
      "Start Page": "27",
      "End Page": "38",
      "Abstract": "The application of machine learning (ML) libraries has tremendously increased in many domains, including autonomous driving systems, medical, and critical industries. Vulnerabilities of such libraries could result in irreparable consequences. However, the characteristics of software security vulnerabilities have not been well studied. In this paper, to bridge this gap, we take the first step toward characterizing and understanding the security vulnerabilities of seven well-known ML libraries, including TensorFlow, PyTorch, Scikit-learn, Mlpack, Pandas, Numpy, and Scipy. To do so, we collected 683 security vulnerabilities to explore four major factors: 1) vulnerability types, 2) root causes, 3) symptoms, and 4) fixing patterns of security vulnerabilities in the studied ML libraries. The findings of this study can help developers and researchers understand the characteristics of security vulnerabilities across the studied ML libraries.",
      "ISSN": "2574-3864",
      "ISBNs": "979-8-3503-1184-6",
      "DOI": "10.1109/MSR59073.2023.00018",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10173858",
      "Author_Keywords": "Security vulnerability;machine learning libraries;empirical study",
      "IEEE_Terms": "Industries;Machine learning;Debugging;Reliability engineering;Libraries;Software;Software reliability",
      "Article Citation Count": "3",
      "Reference Count": "52",
      "License": "IEEE",
      "Online Date": "12-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Balancing Effectiveness and Flakiness of Non-Deterministic Machine Learning Tests",
      "Authors": "C. S. Xia; S. Dutta; S. Misailovic; D. Marinov; L. Zhang",
      "Author Affiliations": "University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign",
      "Publication Title": "2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "14-Jul-23",
      "Publication Year": "2023",
      "Start Page": "1801",
      "End Page": "1813",
      "Abstract": "Testing Machine Learning (ML) projects is challenging due to inherent non-determinism of various ML algorithms and the lack of reliable ways to compute reference results. Developers typically rely on their intuition when writing tests to check whether ML algorithms produce accurate results. However, this approach leads to conservative choices in selecting assertion bounds for comparing actual and expected results in test assertions. Because developers want to avoid false positive failures in tests, they often set the bounds to be too loose, potentially leading to missing critical bugs. We present FASER - the first systematic approach for balancing the trade-off between the fault-detection effectiveness and flakiness of non-deterministic tests by computing optimal assertion bounds. FASER frames this trade-off as an optimization problem between these competing objectives by varying the assertion bound. FASER leverages 1) statistical methods to estimate the flakiness rate, and 2) mutation testing to estimate the fault-detection effectiveness. We evaluate FASER on 87 non-deterministic tests collected from 22 popular ML projects. FASER finds that 23 out of 87 studied tests have conservative bounds and proposes tighter assertion bounds that maximizes the fault-detection effectiveness of the tests while limiting flakiness. We have sent 19 pull requests to developers, each fixing one test, out of which 14 pull requests have already been accepted.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-5701-9",
      "DOI": "10.1109/ICSE48619.2023.00154",
      "Funding Information": "NSF(grant numbers:CCF-1763788); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172715",
      "IEEE_Terms": "Machine learning algorithms;Systematics;Limiting;Statistical analysis;Machine learning;Writing;Reliability",
      "Reference Count": "105",
      "License": "IEEE",
      "Online Date": "14-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Are SonarQube Rules Inducing Bugs?",
      "Authors": "V. Lenarduzzi; F. Lomio; H. Huttunen; D. Taibi",
      "Author Affiliations": "Lahti-Lappeenranta University, Lahti-Lappeenranta, Finland; Tampere University, Tampere, Finland; Tampere University, Tampere, Finland; Tampere University, Tampere, Finland",
      "Publication Title": "2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "2-Apr-20",
      "Publication Year": "2020",
      "Start Page": "501",
      "End Page": "511",
      "Abstract": "The popularity of tools for analyzing Technical Debt, and particularly the popularity of SonarQube, is increasing rapidly. SonarQube proposes a set of coding rules, which represent something wrong in the code that will soon be reflected in a fault or will increase maintenance effort. However, our local companies were not confident in the usefulness of the rules proposed by SonarQube and contracted us to investigate the fault-proneness of these rules. In this work we aim at understanding which SonarQube rules are actually fault-prone and to understand which machine learning models can be adopted to accurately identify fault-prone rules. We designed and conducted an empirical study on 21 well-known mature open-source projects. We applied the SZZ algorithm to label the fault-inducing commits. We analyzed the fault-proneness by comparing the classification power of seven machine learning models. Among the 202 rules defined for Java by SonarQube, only 25 can be considered to have relatively low fault-proneness. Moreover, violations considered as ‚Äúbugs‚Äù by SonarQube were generally not fault-prone and, consequently, the fault-prediction power of the model proposed by SonarQube is extremely low. The rules applied by SonarQube for calculating technical debt should be thoroughly investigated and their harmfulness needs to be further confirmed. Therefore, companies should carefully consider which rules they really need to apply, especially if their goal is to reduce fault-proneness.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-7281-5143-4",
      "DOI": "10.1109/SANER48275.2020.9054821",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054821",
      "Author_Keywords": "Technical Debt;SonarQube;coding style;code smells;architectural smells;static analysis;machine learning",
      "IEEE_Terms": "Fault diagnosis;Java;Machine learning algorithms;Conferences;Computer bugs;Machine learning;Companies",
      "Article Citation Count": "33",
      "Reference Count": "32",
      "License": "IEEE",
      "Online Date": "2-Apr-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Fairness-aware Configuration of Machine Learning Libraries",
      "Authors": "S. Tizpaz-Niari; A. Kumar; G. Tan; A. Trivedi",
      "Author Affiliations": "University of Texas at El Paso; Pennsylvania State University; Pennsylvania State University; University of Colorado Boulder",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "909",
      "End Page": "920",
      "Abstract": "This paper investigates the parameter space of machine learning (ML) algorithms in aggravating or mitigating fairness bugs. Data-driven software is increasingly applied in social-critical applications where ensuring fairness is of paramount importance. The existing approaches focus on addressing fairness bugs by either modifying the input dataset or modifying the learning algorithms. On the other hand, the selection of hyperparameters, which provide finer controls of ML algorithms, may enable a less intrusive approach to influence the fairness. Can hyperparameters amplify or suppress discrimination present in the input dataset? How can we help programmers in detecting, understanding, and exploiting the role of hyperparameters to improve the fairness? We design three search-based software testing algorithms to un-cover the precision-fairness frontier of the hyperparameter space. We complement these algorithms with statistical debugging to explain the role of these parameters in improving fairness. We implement the proposed approaches in the tool Parfait-ML (PARameter FAIrness Testing for ML Libraries) and show its effectiveness and utility over five mature ML algorithms as used in six social-critical applications. In these applications, our approach successfully iden-tified hyperparameters that significantly improve (vis-a-vis the state-of-the-art techniques) the fairness without sacrificing precision. Surprisingly, for some algorithms (e.g., random forest), our approach showed that certain configuration of hyperparameters (e.g., restricting the search space of attributes) can amplify biases across applications. Upon further investigation, we found intuitive explanations of these phenomena, and the results corroborate simi-lar observations from the literature.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3510202",
      "Funding Information": "NSF; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794108",
      "IEEE_Terms": "Software testing;Machine learning algorithms;Software algorithms;Computer bugs;Libraries;Software;Space exploration",
      "Article Citation Count": "4",
      "Reference Count": "41",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Automatic Characterization of Exploitable Faults: A Machine Learning Approach",
      "Authors": "S. Saha; D. Jap; S. Patranabis; D. Mukhopadhyay; S. Bhasin; P. Dasgupta",
      "Author Affiliations": "Department of Computer Science and Engineering, IIT Kharagpur, Kharagpur, India; Physical Analysis & Cryptographic Engineering Labs, Nanyang Technical University, Singapore; Department of Computer Science and Engineering, IIT Kharagpur, Kharagpur, India; Department of Computer Science and Engineering, IIT Kharagpur, Kharagpur, India; Physical Analysis & Cryptographic Engineering Labs, Nanyang Technical University, Singapore; Department of Computer Science and Engineering, IIT Kharagpur, Kharagpur, India",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "31-Oct-18",
      "Publication Year": "2019",
      "Volume": "14",
      "Issue": "4",
      "Start Page": "954",
      "End Page": "968",
      "Abstract": "Characterizing the fault space of a cipher to filter out a set of faults potentially exploitable for fault attacks (FA), is a problem with immense practical value. A quantitative knowledge of the exploitable fault space is desirable in several applications, such as security evaluation, cipher construction and implementation, design, testing of countermeasures, and so on. In this paper, we investigate this problem in the context of block ciphers. The formidable size of the fault space of a block cipher mandates the use of an automation strategy to solve this problem, which should be able to characterize each individual fault instance quickly. On the other hand, the automation strategy is expected to be applicable to most of the block cipher constructions. Existing techniques for automated fault attacks do not satisfy both of these goals simultaneously, and hence are not directly applicable in the context of exploitable fault characterization. In this paper, we present a supervised machine learning assisted automated framework, which successfully addresses both of the criteria mentioned. The key idea is to extrapolate the knowledge of some existing FAs on a cipher to rapidly figure out new attack instances. Experimental validation of this idea on two state-of-the-art block ciphers - PRESENT and LED - establishes that our approach is able to provide fairly good accuracy in identifying exploitable fault instances at a reasonable cost. Utilizing this observation, we propose a statistical framework for exploitable fault space characterization, which can provide an estimate of the success rate of an attacker corresponding to the given fault model and fault location. The framework also returns test vectors leading toward successful attacks. As a potential application, the effect of different S-Boxes on the fault space of a cipher is evaluated utilizing the framework.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2018.2868245",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8452997",
      "Author_Keywords": "Security;block cipher;fault attack;machine learning",
      "IEEE_Terms": "Ciphers;Tools;Mathematical model;Machine learning;Testing",
      "Article Citation Count": "19",
      "Reference Count": "45",
      "License": "IEEE",
      "Online Date": "31-Aug-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "A Search-Based Testing Approach for Deep Reinforcement Learning Agents",
      "Authors": "A. Zolfagharian; M. Abdellatif; L. C. Briand; M. Bagherzadeh; R. S",
      "Author Affiliations": "School of Electrical Engineering and Computer Science (EECS), University of Ottawa, Ottawa, ON, Canada; Software and Information Technology Engineering Department, √âcole de Technologie Sup√©rieure, Montreal, QC, Canada; School of Electrical Engineering and Computer Science (EECS), University of Ottawa, Ottawa, ON, Canada; Cisco, Ottawa, ON, Canada; Department of Research and Development, General Motors, Warren, MI, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "17-Jul-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "7",
      "Start Page": "3715",
      "End Page": "3735",
      "Abstract": "Deep Reinforcement Learning (DRL) algorithms have been increasingly employed during the last decade to solve various decision-making problems such as autonomous driving, trading decisions, and robotics. However, these algorithms have faced great challenges when deployed in safety-critical environments since they often exhibit erroneous behaviors that can lead to potentially critical errors. One of the ways to assess the safety of DRL agents is to test them to detect possible faults leading to critical failures during their execution. This raises the question of how we can efficiently test DRL policies to ensure their correctness and adherence to safety requirements. Most existing works on testing DRL agents use adversarial attacks that perturb states or actions of the agent. However, such attacks often lead to unrealistic states of the environment. Furthermore, their main goal is to test the robustness of DRL agents rather than testing the compliance of the agents‚Äô policies with respect to requirements. Due to the huge state space of DRL environments, the high cost of test execution, and the black-box nature of DRL algorithms, exhaustive testing of DRL agents is impossible. In this paper, we propose a Search-based Testing Approach of Reinforcement Learning Agents (STARLA) to test the policy of a DRL agent by effectively searching for failing executions of the agent within a limited testing budget. We rely on machine learning models and a dedicated genetic algorithm to narrow the search toward faulty episodes (i.e., sequences of states and actions produced by the DRL agent). We apply STARLA on Deep-Q-Learning agents trained on two different RL problems widely used as benchmarks and show that STARLA significantly outperforms Random Testing by detecting more faults related to the agent's policy. We also investigate how to extract rules that characterize faulty episodes of the DRL agent using our search results. Such rules can be used to understand the conditions under which the agent fails and thus assess the risks of deploying it.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2023.3269804",
      "Funding Information": "Natural Sciences and Engineering Research Council of Canada; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10107813",
      "Author_Keywords": "Genetic algorithm;machine learning;reinforcement learning;state abstraction;testing",
      "IEEE_Terms": "Testing;Reinforcement learning;Safety;Deep learning;Closed box;Training;Genetic algorithms",
      "Article Citation Count": "5",
      "Reference Count": "85",
      "License": "CCBY",
      "Online Date": "25-Apr-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Reinforcement Learning Guided Symbolic Execution",
      "Authors": "J. Wu; C. Zhang; G. Pu",
      "Author Affiliations": "East China Normal University, Shanghai, China; East China Normal University, Shanghai, China; East China Normal University, Shanghai, China",
      "Publication Title": "2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "2-Apr-20",
      "Publication Year": "2020",
      "Start Page": "662",
      "End Page": "663",
      "Abstract": "Symbolic execution is an indispensable technique for software testing and program analysis. Path-explosion is one of the key challenges in symbolic execution. To relieve the challenge, this paper leverages the Q-learning algorithm to guide symbolic execution. Our guided symbolic execution technique focuses on generating a test input for triggering a particular statement in the program. In our approach, we first obtain the dominators with respect to a particular statement with static analysis. Such dominators are the statements that have to be visited before reaching the particular statement. Then we start the symbolic execution with the branch choice controlled by the policy in Q-learning. Only when symbolic execution encounters a dominator, it returns a positive reward to Q-learning. Otherwise, it will return a negative reward. And we update the Q-table in Q-learning accordingly. Our initial evaluation results indicate that in average more than 90% of exploration paths and instructions are reduced for reaching the target statement compared with the default search strategy in KLEE, which shows the promise of this work.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-7281-5143-4",
      "DOI": "10.1109/SANER48275.2020.9054815",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054815",
      "Author_Keywords": "symbolic execution;reinforcement learning;debugging",
      "IEEE_Terms": "Software testing;Machine learning algorithms;Q-learning;Conferences;Software algorithms;Static analysis;Search problems",
      "Article Citation Count": "7",
      "Reference Count": "8",
      "License": "IEEE",
      "Online Date": "2-Apr-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Identifying Self-Admitted Technical Debts With Jitterbug: A Two-Step Approach",
      "Authors": "Z. Yu; F. M. Fahid; H. Tu; T. Menzies",
      "Author Affiliations": "Department of Software Engineering, Rochester Institute of Technology, Rochester, NY, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "16-May-22",
      "Publication Year": "2022",
      "Volume": "48",
      "Issue": "5",
      "Start Page": "1676",
      "End Page": "1691",
      "Abstract": "Keeping track of and managing Self-Admitted Technical Debts (SATDs) are important to maintaining a healthy software project. This requires much time and effort from human experts to identify the SATDs manually. The current automated solutions do not have satisfactory precision and recall in identifying SATDs to fully automate the process. To solve the above problems, we propose a two-step framework called Jitterbug for identifying SATDs. Jitterbug first identifies the ‚Äúeasy to find‚Äù SATDs automatically with close to 100 percent precision using a novel pattern recognition technique. Subsequently, machine learning techniques are applied to assist human experts in manually identifying the remaining ‚Äúhard to find‚Äù SATDs with reduced human effort. Our simulation studies on ten software projects show that Jitterbug can identify SATDs more efficiently (with less human effort) than the prior state-of-the-art methods.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2020.3031401",
      "Funding Information": "National Science Foundation(grant numbers:#1703487); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9226105",
      "Author_Keywords": "Technical debt;software engineering;machine learning;pattern recognition",
      "IEEE_Terms": "Software;Machine learning;Pattern recognition;Training;Computer hacking;Machine learning algorithms;Estimation",
      "Article Citation Count": "18",
      "Reference Count": "52",
      "License": "IEEE",
      "Online Date": "15-Oct-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "A Comprehensive Investigation of the Role of Imbalanced Learning for Software Defect Prediction",
      "Authors": "Q. Song; Y. Guo; M. Shepperd",
      "Author Affiliations": "Department of Computer Science & Technology, Xi'an Jiaotong University, Xi'an, China; Department of Computer Science & Technology, Xi'an Jiaotong University, Xi'an, China; Department of Computer Science, Brunel University, Uxbridge, United Kingdom",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "10-Dec-19",
      "Publication Year": "2019",
      "Volume": "45",
      "Issue": "12",
      "Start Page": "1253",
      "End Page": "1269",
      "Abstract": "Context: Software defect prediction (SDP) is an important challenge in the field of software engineering, hence much research work has been conducted, most notably through the use of machine learning algorithms. However, class-imbalance typified by few defective components and many non-defective ones is a common occurrence causing difficulties for these methods. Imbalanced learning aims to deal with this problem and has recently been deployed by some researchers, unfortunately with inconsistent results. Objective: We conduct a comprehensive experiment to explore (a) the basic characteristics of this problem; (b) the effect of imbalanced learning and its interactions with (i) data imbalance, (ii) type of classifier, (iii) input metrics and (iv) imbalanced learning method. Method: We systematically evaluate 27 data sets, 7 classifiers, 7 types of input metrics and 17 imbalanced learning methods (including doing nothing) using an experimental design that enables exploration of interactions between these factors and individual imbalanced learning algorithms. This yields 27 √ó 7 √ó 7 √ó 17 = 22491 results. The Matthews correlation coefficient (MCC) is used as an unbiased performance measure (unlike the more widely used F1 and AUC measures). Results: (a) we found a large majority (87 percent) of 106 public domain data sets exhibit moderate or low level of imbalance (imbalance ratio <; 10; median = 3.94); (b) anything other than low levels of imbalance clearly harm the performance of traditional learning for SDP; (c) imbalanced learning is more effective on the data sets with moderate or higher imbalance, however negative results are always possible; (d) type of classifier has most impact on the improvement in classification performance followed by the imbalanced learning method itself. Type of input metrics is not influential. (e) only 52% of the combinations of Imbalanced Learner and Classifier have a significant positive effect. Conclusion: This paper offers two practical guidelines. First, imbalanced learning should only be considered for moderate or highly imbalanced SDP data sets. Second, the appropriate combination of imbalanced method and classifier needs to be carefully chosen to ameliorate the imbalanced learning problem for SDP. In contrast, the indiscriminate application of imbalanced learning can be harmful.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2018.2836442",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:61373046,61210004); Brunel University London; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8359087",
      "Author_Keywords": "Software defect prediction;bug prediction;imbalanced learning;imbalance ratio;effect size",
      "IEEE_Terms": "Software measurement;Boosting;Machine learning algorithms;Bagging;Computer bugs",
      "Article Citation Count": "161",
      "Reference Count": "92",
      "License": "IEEE",
      "Online Date": "15-May-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Defuse: A Data Annotator and Model Builder for Software Defect Prediction",
      "Authors": "S. D. Palma; D. Di Nucci; D. Tamburri",
      "Author Affiliations": "Tilburg University/JADS; University of Salerno; Eindhoven University/JADS",
      "Publication Title": "2022 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "19-Dec-22",
      "Publication Year": "2022",
      "Start Page": "479",
      "End Page": "483",
      "Abstract": "We propose a language-agnostic tool for software defect prediction, called DEFUSE. The tool automatically collects and classifies failure data, enables the correction of those classifications, and builds machine learning models to detect defects based on those data. We instantiated the tool in the scope of Infrastructure-as-Code, the DevOps practice enabling management and provisioning of infrastructure through the definition of machine-readable files. We present its architecture and provide examples of its application.Demo video: https://youtu.be/37mmLdCX3jU.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-6654-7956-1",
      "DOI": "10.1109/ICSME55016.2022.00063",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9978237",
      "Author_Keywords": "defect prediction;machine learning;mining software repositories",
      "IEEE_Terms": "Software maintenance;Costs;Instruments;Machine learning;Computer architecture;Predictive models;Maintenance engineering",
      "Article Citation Count": "1",
      "Reference Count": "19",
      "License": "IEEE",
      "Online Date": "19-Dec-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Software Visualization and Deep Transfer Learning for Effective Software Defect Prediction",
      "Authors": "J. Chen; K. Hu; Y. Yu; Z. Chen; Q. Xuan; Y. Liu; V. Filkov",
      "Author Affiliations": "College of Information Engineering, Zhejiang University of Technology, Hangzhou, China; College of Information Engineering, Zhejiang University of Technology, Hangzhou, China; College of Computer, National University of Defense Technology, Hefei, China; College of Information Engineering, Zhejiang University of Technology, Hangzhou, China; Institute of Cyberspace Security, Zhejiang University of Technology, Hangzhou, China; Institute of Process Equipment and Control Engineering, Zhejiang University of Technology, Hangzhou, China; Department of Computer Science, University of California, Davis, CA, USA",
      "Publication Title": "2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "21-Dec-20",
      "Publication Year": "2020",
      "Start Page": "578",
      "End Page": "589",
      "Abstract": "Software defect prediction aims to automatically locate defective code modules to better focus testing resources and human effort. Typically, software defect prediction pipelines are comprised of two parts: the first extracts program features, like abstract syntax trees, by using external tools, and the second applies machine learning-based classification models to those features in order to predict defective modules. Since such approaches depend on specific feature extraction tools, machine learning classifiers have to be custom-tailored to effectively build most accurate models. To bridge the gap between deep learning and defect prediction, we propose an end-to-end framework which can directly get prediction results for programs without utilizing feature-extraction tools. To that end, we first visualize programs as images, apply the self-attention mechanism to extract image features, use transfer learning to reduce the difference in sample distributions between projects, and finally feed the image files into a pre-trained, deep learning model for defect prediction. Experiments with 10 open source projects from the PROMISE dataset show that our method can improve cross-project and within-project defect prediction. Our code and data pointers are available at https://zenodo.org/record/3373409#.XV0Oy5Mza35.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-7121-6",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:61502423,61572439,61702534); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284026",
      "Author_Keywords": "Cross-project defect prediction;within-project defect prediction;deep transfer learning;self-attention;software visualization",
      "IEEE_Terms": "Deep learning;Data visualization;Tools;Predictive models;Feature extraction;Software;Testing",
      "Article Citation Count": "2",
      "Reference Count": "76",
      "Online Date": "21-Dec-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Ensemble Random Forests Classifier for Detecting Coincidentally Correct Test Cases",
      "Authors": "S. Dass; X. Xue; A. Siami Namin",
      "Author Affiliations": "Texas Tech University; Adobe Inc.; Texas Tech University",
      "Publication Title": "2020 IEEE 44th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "22-Sep-20",
      "Publication Year": "2020",
      "Start Page": "1326",
      "End Page": "1331",
      "Abstract": "The performance of coverage-based fault localization greatly depends on the quality of test cases being executed. These test cases execute some lines of the given program and determine whether the underlying tests are passed or failed. In particular, some test cases may be well-behaved (i.e., passed) while executing faulty statements. These test cases, also known as coincidentally correct test cases, may negatively influence the performance of the spectra-based fault localization and thus be less helpful as a tool for the purpose of automated debugging. In other words, the involvement of these coincidentally correct test cases may introduce noises to the fault localization computation and thus cause in divergence of effectively localizing the location of possible bugs in the given code. In this paper, we propose a hybrid approach of ensemble learning combined with a supervised learning algorithm namely, Random Forests (RF) for the purpose of correctly identifying test cases that are mislabeled to be the passing test cases. A cost-effective analysis of flipping the test status or trimming (i.e., eliminating from the computation) the coincidental correct test cases is also reported.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-7281-7303-0",
      "DOI": "10.1109/COMPSAC48688.2020.00-72",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9202681",
      "Author_Keywords": "Fault localization, coincidentally correct, random forests, ensemble learning",
      "IEEE_Terms": "Forestry;Radio frequency;Machine learning;Testing;Training;Support vector machines;Principal component analysis",
      "Article Citation Count": "4",
      "Reference Count": "10",
      "License": "IEEE",
      "Online Date": "22-Sep-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Cross-Lingual Transfer Learning Framework for Program Analysis",
      "Authors": "Z. Li",
      "Author Affiliations": "School of Computer Science and Engineering, Nanyang Technological University, Singapore",
      "Publication Title": "2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "20-Jan-22",
      "Publication Year": "2021",
      "Start Page": "1074",
      "End Page": "1078",
      "Abstract": "Deep learning-based techniques have been widely applied to program analysis tasks, in fields such as type inference, fault localization, and code summarization. Hitherto deep learning-based software engineering systems rely thoroughly on supervised learning approaches, which require laborious manual effort to collect and label a prohibitively large amount of data. However, most Turing-complete imperative languages share similar control- and data-flow structures, which make it possible to transfer knowledge learned from one language to another. In this paper, we propose a general cross-lingual transfer learning framework PLATO for program analysis by using a series of techniques that are general to different downstream tasks. PLATO allows Bert-based models to leverage prior knowledge learned from the labeled dataset of one language and transfer it to the others. We evaluate our approaches on several downstream tasks such as type inference and code summarization to demonstrate its feasibility.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-6654-0337-5",
      "DOI": "10.1109/ASE51524.2021.9678848",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9678848",
      "Author_Keywords": "program analysis;transfer learning;domain adaptation;deep learning;graph kernel",
      "IEEE_Terms": "Location awareness;Codes;Transfer learning;Supervised learning;Manuals;Task analysis;Kernel",
      "Reference Count": "29",
      "License": "IEEE",
      "Online Date": "20-Jan-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Poligraph: Intrusion-Tolerant and Distributed Fake News Detection System",
      "Authors": "G. Shan; B. Zhao; J. R. Clavin; H. Zhang; S. Duan",
      "Author Affiliations": "Department of Management Information System, Temple University, Philadelphia, PA, USA; Institute for Advanced Study, Tsinghua University, Beijing, China; University of Maryland, Baltimore County, Baltimore, MD, USA; Department of Information Systems, Shandong Institute of Blockchain, Jinan, China; Institute for Advanced Study and the Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "15-Dec-21",
      "Publication Year": "2022",
      "Volume": "17",
      "Start Page": "28",
      "End Page": "41",
      "Abstract": "We present Poligraph, an intrusion-tolerant and decentralized fake news detection system. Poligraph aims to address architectural, system, technical, and social challenges of building a practical, long-term fake news detection platform. We first conduct a case study for fake news detection at authors‚Äô institute, showing that machine learning-based reviews are less accurate but timely, while human reviews, in particular, experts reviews, are more accurate but time-consuming. This justifies the need for combining both approaches. At the core of Poligraph is two-layer consensus allowing seamlessly combining machine learning techniques and human expert determination. We construct the two-layer consensus using Byzantine fault-tolerant (BFT) and asynchronous threshold common coin protocols. We prove the correctness of our system in terms of conventional definitions of security in distributed systems (agreement, total order, and liveness) as well as new review validity (capturing the accuracy of news reviews). We also provide theoretical foundations on parameter selection for our system. We implement Poligraph and evaluate its performance on Amazon EC2 using a variety of news from online publications and social media. We demonstrate Poligraph achieves throughput of more than 5,000 transactions per second and latency as low as 0.05 second. The throughput of Poligraph is only marginally ( ${4\\%}$ ‚Äì ${7\\%}$ ) slower than that of an unreplicated, single-server implementation. In addition, we conduct a real-world case study for the review of fake and real news among both experts and non-experts, which validates the practicality of our approach.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2021.3131026",
      "Funding Information": "Shandong Key Research and Development Program(grant numbers:2020ZLYS09); National Key Research and Development Program of China(grant numbers:2018YFA0704701); Shandong Key Research and Development Program(grant numbers:2020ZLYS09); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9627681",
      "Author_Keywords": "Reliability;fault tolerance;machine learning (ML)",
      "IEEE_Terms": "Feature extraction;Social networking (online);Throughput;Machine learning;Data models;Visualization;Buildings",
      "Article Citation Count": "9",
      "Reference Count": "86",
      "License": "IEEE",
      "Online Date": "25-Nov-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Program Repair With Repeated Learning",
      "Authors": "L. Chen; Y. Pei; M. Pan; T. Zhang; Q. Wang; C. A. Furia",
      "Author Affiliations": "Department of Computing, The Hong Kong Polytechnic University, Hong Kong; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China; State Key Laboratory for Novel Software Technology, Software Institute of Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China; Software Institute of USI, Universit√† della Svizzera italiana, Lugano, Switzerland",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "14-Feb-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "2",
      "Start Page": "831",
      "End Page": "848",
      "Abstract": "A key challenge in generate-and-validate automated program repair is directing the search for fixes so that it can efficiently find those that are more likely to be correct. To this end, several techniques use machine learning to capture the features of programmer-written fixes. In existing approaches, fitting the model typically takes place before fix generation and is independent of it: the fix generation process uses the learned model as one of its inputs. However, the intermediate outcomes of an ongoing fix generation process often provide valuable information about which candidate fixes were ‚Äúbetter‚Äù; this information could profitably be used to retrain the model, so that each new iteration of the fixing process would also learn from the outcome of previous ones. In this paper, we propose the Liana technique for automated program repair, which is based on this idea of repeatedly learning the features of generated fixes. To this end, Liana uses a fine-grained model that combines information about fix characteristics, their relations to the fixing context, and the results of test execution. The model is initially trained offline, and then repeatedly updated online as the fix generation process unravels; at any step, the most up-to-date model is used to guide the search for fixes‚Äîprioritizing those that are more likely to include the right ingredients. In an experimental evaluation on 732 real-world Java bugs from 3 popular benchmarks, Liana built correct fixes for 134 faults (83 ranked as first in its output)‚Äî improving over several other generate-and-validate program repair tools according to various measures.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2022.3164662",
      "Funding Information": "Hong Kong Research Grants Council(grant numbers:PolyU 152002/18E); National Natural Science Foundation of China(grant numbers:61972193); Hong Kong RGC Theme-Based Research Scheme(grant numbers:T22-505/19-N (P0031331, RBCR, P0031259, RBCP)); RGC GRF(grant numbers:PolyU 152002/18E (P0005550, Q67V),PolyU 152164/14E (P0004750, Q44B)); RGC Germany/HK(grant numbers:G-PolyU503/16); Hong Kong Polytechnic University Fund(grant numbers:P0033695 (ZVRD),P0013879 (BBWH),P0031950 (ZE1N),P0036469 (CDA8),8B2V); Schweizerischer Nationalfonds zur F√∂rderung der Wissenschaftlichen Forschung(grant numbers:Hi-Fi 200021-182060); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9749899",
      "Author_Keywords": "Automated program repair (APR);generate-and-validate APR;learning-to-rank;repeated learning",
      "IEEE_Terms": "Java;Fitting;Computer bugs;Machine learning;Maintenance engineering;Benchmark testing;Context modeling",
      "Article Citation Count": "2",
      "Reference Count": "84",
      "License": "IEEE",
      "Online Date": "5-Apr-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "A Machine Learning Approach for Vulnerability Curation",
      "Authors": "Y. Chen; A. E. Santosa; A. M. Yi; A. Sharma; A. Sharma; D. Lo",
      "Author Affiliations": "Veracode; Veracode; Veracode; Veracode; Veracode; Singapore Management University",
      "Publication Title": "2020 IEEE/ACM 17th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "20-Jun-23",
      "Publication Year": "2020",
      "Start Page": "32",
      "End Page": "42",
      "Abstract": "Software composition analysis depends on database of open-source library vulerabilities, curated by security researchers using various sources, such as bug tracking systems, commits, and mailing lists. We report the design and implementation of a machine learning system to help the curation by by automatically predicting the vulnerability-relatedness of each data item. It supports a complete pipeline from data collection, model training and prediction, to the validation of new models before deployment. It is executed iteratively to generate better models as new input data become available. We use self-training to significantly and automatically increase the size of the training dataset, opportunistically maximizing the improvement in the models' quality at each iteration. We devised new deployment stability metric to evaluate the quality of the new models before deployment into production, which helped to discover an error. We experimentally evaluate the improvement in the performance of the models in one iteration, with 27.59% maximum PR AUC improvements. Ours is the first of such study across a variety of data sources. We discover that the addition of the features of the corresponding commits to the features of issues/pull requests improve the precision for the recall values that matter. We demonstrate the effectiveness of self-training alone, with 10.50% PR AUC improvement, and we discover that there is no uniform ordering of word2vec parameters sensitivity across data sources.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-4503-7517-7",
      "DOI": "10.1145/3379597.3387461",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10148736",
      "Author_Keywords": "application security;open-source software;machine learning;classifiers ensemble;self-training",
      "IEEE_Terms": "Training;Sensitivity;Soft sensors;Pipelines;Machine learning;Predictive models;Data models",
      "Article Citation Count": "11",
      "Reference Count": "50",
      "Online Date": "20-Jun-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "The Diversity Crisis of Software Engineering for Artificial Intelligence",
      "Authors": "B. Adams; F. Khomh",
      "Author Affiliations": "Computer science engineering, Ghent University, Belgium; Computer science, University of Montreal, Quebec",
      "Publication Title": "IEEE Software",
      "Date Added To Xplore": "21-Aug-20",
      "Publication Year": "2020",
      "Volume": "37",
      "Issue": "5",
      "Start Page": "104",
      "End Page": "108",
      "Abstract": "Artificial Intelligence (AI) is experiencing a \"diversity crisis.\"1 Several reports1-3 have shown how the breakthrough of modern AI has not yet been able to improve on existing diversity challenges regarding gender, race, geography, and other factors, neither for the end users of those products nor the companies and organizations building them. Plenty of examples have surfaced in which biased data engineering practices or existing data sets led to incorrect, painful, or sometimes even harmful consequences for unassuming end users.4 The problem is that ruling out such biases is not straightforward due to the sheer number of different bias types.5 To have a chance to eliminate as many biases as possible, most of the experts agree that the teams and organizations building AI products should be made more diverse.1-3 This harkens back to Linus' law6 for open source development (\"given enough eyeballs, all bugs are shallow\") but applied to the development process of AI products.",
      "ISSN": "1937-4194",
      "DOI": "10.1109/MS.2020.2975075",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9173624",
      "IEEE_Terms": "Companies;Software engineering;Machine learning;Artificial intelligence;Google;Industries",
      "Article Citation Count": "6",
      "Reference Count": "16",
      "License": "IEEE",
      "Online Date": "21-Aug-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Magazines"
    },
    {
      "Document Title": "Repairing Intricate Faults in Code Using Machine Learning and Path Exploration",
      "Authors": "D. Gopinath; K. Wang; J. Hua; S. Khurshid",
      "Author Affiliations": "The University of Texas, Austin; The University of Texas, Austin; The University of Texas, Austin; The University of Texas, Austin",
      "Publication Title": "2016 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "16-Jan-17",
      "Publication Year": "2016",
      "Start Page": "453",
      "End Page": "457",
      "Abstract": "Debugging remains costly and tedious, especially for code that performs intricate operations that are conceptually complex to reason about. We present MLR, a novel approach for repairing faults in such operations, specifically in the context of complex data structures. Our focus is on faults in conditional statements. Our insight is that an integrated approach based on machine learning and systematic path exploration can provide effective repairs. MLR mines the data-spectra of the passing and failing executions of conditional branches to prune the search space for repair and generate patches that are likely valid beyond the existing test-suite. We apply MLR to repair faults in small but complex data structure subjects to demonstrate its efficacy. Experimental results show that MLR has the potential to repair this fault class more effectively than state-of-the-art repair tools.",
      "ISBNs": "978-1-5090-3806-0",
      "DOI": "10.1109/ICSME.2016.75",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7816493",
      "Author_Keywords": "program repair;semi-supervised learning;decisiontree learning;JPF;data-structures;condition faults",
      "IEEE_Terms": "Maintenance engineering;Support vector machines;Data structures;Systematics;Semisupervised learning;Debugging;Space exploration",
      "Article Citation Count": "2",
      "Reference Count": "21",
      "License": "IEEE",
      "Online Date": "16-Jan-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Automatic Identification of Vulnerable Code: Investigations with an AST-Based Neural Network",
      "Authors": "G. Partenza; T. Amburgey; L. Deng; J. Dehlinger; S. Chakraborty",
      "Author Affiliations": "Department of Computer and Information Sciences, Towson University, Towson, MD, USA; Department of Computer and Information Sciences, Towson University, Towson, MD, USA; Department of Computer and Information Sciences, Towson University, Towson, MD, USA; Department of Computer and Information Sciences, Towson University, Towson, MD, USA; Department of Computer and Information Sciences, Towson University, Towson, MD, USA",
      "Publication Title": "2021 IEEE 45th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "9-Sep-21",
      "Publication Year": "2021",
      "Start Page": "1475",
      "End Page": "1482",
      "Abstract": "The increasing complexity of software applications and the necessity for minimizing software vulnerabilities has given rise to the use of machine learning techniques that can identify software vulnerabilities in source code. However, many of these techniques lack the accuracy needed for industrial practice. The contribution of this work is the novel use of an Abstract Syntax Tree Neural Network (ASTNN) to identify and classify software vulnerabilities in the Common Weakness Enumeration (CWE) types. We make two fundamental claims in this work. First, the use of an ASTNN performs better than prior machine learning neural network architectures. Second, the benchmark data set commonly used for machine learning vulnerability classification is flawed for this use. To illustrate these claims, we describe our ASTNN architecture and evaluate it with more than 44,000 test cases across 29 CWEs in the NIST Juliet Test Suite data set. Results show a minimum of 88% accuracy across all CWEs.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-6654-2463-9",
      "DOI": "10.1109/COMPSAC51774.2021.00219",
      "Funding Information": "Towson University; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9529451",
      "Author_Keywords": "Software Security;Security Vulnerability Analysis;Artificial Intelligence;Machine Learning;Neural Networks",
      "IEEE_Terms": "Codes;Conferences;Neural networks;Machine learning;Computer architecture;Syntactics;NIST",
      "Article Citation Count": "6",
      "Reference Count": "39",
      "License": "IEEE",
      "Online Date": "9-Sep-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Cost Reduction on Testing Evolving Cancer Registry System",
      "Authors": "E. Isaku; H. Sartaj; C. Laaber; T. Yue; S. Ali; T. Schwitalla; J. F. Nyg√•rd",
      "Author Affiliations": "Simula Research Laboratory, Oslo, Norway; Simula Research Laboratory, Oslo, Norway; Simula Research Laboratory, Oslo, Norway; Simula Research Laboratory, Oslo, Norway; Simula Research Laboratory, Oslo, Norway; Cancer Registry of Norway, Oslo, Norway; Cancer Registry of Norway, Oslo, Norway",
      "Publication Title": "2023 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "11-Dec-23",
      "Publication Year": "2023",
      "Start Page": "508",
      "End Page": "518",
      "Abstract": "The Cancer Registration Support System (CaReSS), built by the Cancer Registry of Norway (CRN), is a complex real-world socio-technical software system that undergoes continuous evolution in its implementation. Consequently, continuous testing of CaReSS with automated testing tools is needed such that its dependability is always ensured. Towards automated testing of a key software subsystem of CaReSS, i.e., GURI, we present a real-world application of an extension to the open-source tool EvoMaster, which automatically generates test cases with evolutionary algorithms. We named the extension EvoClass, which enhances EvoMaster with a machine learning classifier to reduce the overall testing cost. This is imperative since testing with EvoMaster involves sending many requests to GURI deployed in different environments, including the production environment, whose performance and functionality could potentially be affected by many requests. The machine learning classifier of EvoClass can predict whether a request generated by EvoMaster will be executed successfully or not; if not, the classifier filters out such requests, consequently reducing the number of requests to be executed on GURI. We evaluated EvoClass on ten GURI versions over four years in three environments: development, testing, and production. Results showed that EvoClass can significantly reduce the testing cost of evolving GURI without reducing testing effectiveness (measured as rule coverage) across all three environments, as compared to the default EvoMaster. Overall, EvoClass achieved ‚âà31% of overall cost reduction. Finally, we report our experiences and lessons learned that are equally valuable for researchers and practitioners.",
      "ISSN": "2576-3148",
      "ISBNs": "979-8-3503-2783-0",
      "DOI": "10.1109/ICSME58846.2023.00065",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10336343",
      "Author_Keywords": "Software Evolution;Testing;Machine Learning",
      "IEEE_Terms": "Software maintenance;Costs;Machine learning;Production;Evolutionary computation;Software systems;Test pattern generators",
      "Reference Count": "35",
      "License": "IEEE",
      "Online Date": "11-Dec-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "SAIL: Analyzing Structural Artifacts of Logic Locking Using Machine Learning",
      "Authors": "P. Chakraborty; J. Cruz; A. Alaql; S. Bhunia",
      "Author Affiliations": "Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; King Abdulaziz City for Science and Technology (KACST), Communication and Information Technology Research Institute, Riyadh, Saudi Arabia; Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "13-Aug-21",
      "Publication Year": "2021",
      "Volume": "16",
      "Start Page": "3828",
      "End Page": "3842",
      "Abstract": "Obfuscation or Logic locking (LL) is a technique for protecting hardware intellectual property (IP) blocks against diverse threats, including IP theft, reverse engineering, and malicious modifications. State-of-the-art locking techniques primarily focus on securing a design from unauthorized usage by disabling correct functionality ‚Äì they often do not directly address hiding design intent through structural transformations. They rely on the synthesis tool to introduce structural changes. We observe that this process is insufficient as the resulting changes in circuit topology are: (1) local and (2) predictable. In this paper, we analyze the structural transformations introduced by LL and introduce a potential attack, called SAIL, that can exploit structural artifacts introduced by LL. SAIL uses machine learning (ML) guided structural recovery that exposes a critical vulnerability in these techniques. Through this attack, we demonstrate that the gate-level structure of a locked design can be retrieved in most parts through a systematic set of steps. The proposed attack is applicable to most forms of logic locking, and significantly more powerful than existing attacks, e.g., SAT-based attacks, since it does not require the availability of golden functional responses (e.g., an unlocked IC). Evaluation on benchmark circuits shows that we can recover an average of about 92%, up to 97%, transformations (Top-10 R-Metric) introduced by logic locking. We show that this attack is scalable, flexible, and versatile. Additionally, to evaluate the SAIL attack resilience of a locked design, we present the SIVA-Metric that is fast in terms of computation speed and does not require any training. We also propose possible mitigation steps for incorporating SAIL resilience into a locked design.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2021.3096028",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9478898",
      "Author_Keywords": "Hardware obfuscation;logic locking;hardware security;cybersecurity;machine learning",
      "IEEE_Terms": "Logic gates;Resilience;Machine learning;Hardware;Interference;Benchmark testing;Training",
      "Article Citation Count": "12",
      "Reference Count": "44",
      "License": "IEEE",
      "Online Date": "9-Jul-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Boa Meets Python: A Boa Dataset of Data Science Software in Python Language",
      "Authors": "S. Biswas; M. J. Islam; Y. Huang; H. Rajan",
      "Author Affiliations": "Department of Computer Science, Iowa State University, Ames, IA, USA; Department of Computer Science, Iowa State University, Ames, IA, USA; Department of Computer Science, Iowa State University, Ames, IA, USA; Department of Computer Science, Iowa State University, Ames, IA, USA",
      "Publication Title": "2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "29-Aug-19",
      "Publication Year": "2019",
      "Start Page": "577",
      "End Page": "581",
      "Abstract": "The popularity of Python programming language has surged in recent years due to its increasing usage in Data Science. The availability of Python repositories in Github presents an opportunity for mining software repository research, e.g., suggesting the best practices in developing Data Science applications, identifying bug-patterns, recommending code enhancements, etc. To enable this research, we have created a new dataset that includes 1,558 mature Github projects that develop Python software for Data Science tasks. By analyzing the metadata and code, we have included the projects in our dataset which use a diverse set of machine learning libraries and managed by a variety of users and organizations. The dataset is made publicly available through Boa infrastructure both as a collection of raw projects as well as in a processed form that could be used for performing large scale analysis using Boa language. We also present two initial applications to demonstrate the potential of the dataset that could be leveraged by the community.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-7281-3412-3",
      "DOI": "10.1109/MSR.2019.00086",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8816757",
      "Author_Keywords": "MSR;Boa;AST;machine learning;data science;open source repositories;program analysis",
      "IEEE_Terms": "Python;Data science;Libraries;Metadata;Machine learning;Data mining",
      "Article Citation Count": "15",
      "Reference Count": "18",
      "License": "IEEE",
      "Online Date": "29-Aug-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Identifying Coincidental Correct Test Cases with Multiple Features Extraction for Fault Localization",
      "Authors": "Y. Wu; S. Tian; Z. Yang; Z. Li; Y. Liu; X. Chen",
      "Author Affiliations": "College of Information Science and Technology, Beijing University of Chemical Technology, China; College of Information Science and Technology, Beijing University of Chemical Technology, China; College of Information Science and Technology, Beijing University of Chemical Technology, China; College of Information Science and Technology, Beijing University of Chemical Technology, China; College of Information Science and Technology, Beijing University of Chemical Technology, China; School of Information Science and Technology, Nantong University, China",
      "Publication Title": "2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "2-Aug-23",
      "Publication Year": "2023",
      "Start Page": "800",
      "End Page": "809",
      "Abstract": "Spectrum-Based Fault Localization (SBFL) technique is widely applied for fault localization, identifying faulty statements potentially resulting in unexpected faulty programs‚Äô behavior. However, researchers have approved that Coincidental Correct (CC) test cases contained in test suites can negatively affect the accuracy of SBFL. Previous researchers sought to identify CC test cases through machine learning algorithms, but the feature representation is insufficient, leading to limited accuracy. To address this challenge, we propose the Machine Learning-based CC test cases Identification approach (MLCCI), which leverages multiple features extracted from the program under test to identify CC test cases and map the CC identification task to a learning problem. To evaluate the performance of MLCCI, we conduct experiments in the well-known dataset Defects4J. The experimental results compared with state-of-the-art baselines indicate that: (1) MLCCI achieves higher CC identifying accuracy, with the average Recall, P recision, and F -measure values of MLCCI are 65.93%, 71.69%, and 53.74%, respectively; (2) The fault localization accuracy of MLCCI with the Jaccard formula outperforms baselines, where the values of Accuracy@ 1, 3, and 5 are 347, 369, and 393, achieving the maximum 137.67%, 67.73%, and 47.74% improvement against baselines, respectively. Besides, we perform ablation analysis to reveal the effectiveness of features utilized in this study.",
      "ISSN": "0730-3157",
      "ISBNs": "979-8-3503-2697-0",
      "DOI": "10.1109/COMPSAC57700.2023.00109",
      "Funding Information": "National Natural Science Foundation of China; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10196979",
      "Author_Keywords": "software debugging;spectrum-based fault localization;coincidental correct test case;features extraction;machine learning",
      "IEEE_Terms": "Location awareness;Fault diagnosis;Deep learning;Machine learning algorithms;Software algorithms;Feature extraction;Software",
      "Reference Count": "35",
      "License": "IEEE",
      "Online Date": "2-Aug-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Fingerprinting the Fingerprinters: Learning to Detect Browser Fingerprinting Behaviors",
      "Authors": "U. Iqbal; S. Englehardt; Z. Shafiq",
      "Author Affiliations": "The University of Iowa; Mozilla Corporation; University of California, Davis",
      "Publication Title": "2021 IEEE Symposium on Security and Privacy (SP)",
      "Date Added To Xplore": "26-Aug-21",
      "Publication Year": "2021",
      "Start Page": "1143",
      "End Page": "1161",
      "Abstract": "Browser fingerprinting is an invasive and opaque stateless tracking technique. Browser vendors, academics, and standards bodies have long struggled to provide meaningful protections against browser fingerprinting that are both accurate and do not degrade user experience. We propose FP-Inspector, a machine learning based syntactic-semantic approach to accurately detect browser fingerprinting. We show that FP-Inspector performs well, allowing us to detect 26% more fingerprinting scripts than the state-of-the-art. We show that an API-level fingerprinting countermeasure, built upon FP-Inspector, helps reduce website breakage by a factor of 2. We use FP-Inspector to perform a measurement study of browser fingerprinting on top-100K websites. We find that browser fingerprinting is now present on more than 10% of the top-100K websites and over a quarter of the top-10K websites. We also discover previously unreported uses of JavaScript APIs by fingerprinting scripts suggesting that they are looking to exploit APIs in new and unexpected ways.",
      "ISSN": "2375-1207",
      "ISBNs": "978-1-7281-8934-5",
      "DOI": "10.1109/SP40001.2021.00017",
      "Funding Information": "National Science Foundation; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9519502",
      "Author_Keywords": "fingerprinting;tracking;machine-learning",
      "IEEE_Terms": "Privacy;Virtual assistants;Standards organizations;Computer bugs;Prototypes;Machine learning;Fingerprint recognition",
      "Article Citation Count": "28",
      "Reference Count": "96",
      "License": "IEEE",
      "Online Date": "26-Aug-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "METHODS2TEST: A dataset of focal methods mapped to test cases",
      "Authors": "M. Tufano; S. K. Deng; N. Sundaresan; A. Svyatkovskiy",
      "Author Affiliations": "Microsoft, Redmond, WA, USA; Microsoft, Redmond, WA, USA; Microsoft, Redmond, WA, USA; Microsoft, Redmond, WA, USA",
      "Publication Title": "2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "21-Jun-22",
      "Publication Year": "2022",
      "Start Page": "299",
      "End Page": "303",
      "Abstract": "Unit testing is an essential part of the software development process, which helps to identify issues with source code in early stages of development and prevent regressions. Machine learning has emerged as viable approach to help software developers generate automated unit tests. However, generating reliable unit test cases that are semantically correct and capable of catching software bugs or unintended behavior via machine learning requires large, metadata-rich, datasets. In this paper we present Methods2Test: a large, supervised dataset of test cases mapped to corresponding methods under test (i.e., focal methods). This dataset contains 780,944 pairs of JUnit tests and focal methods, extracted from a total of 91,385 Java open source projects hosted on GitHub with licenses permitting re-distribution. The main challenge behind the creation of the Methods2Test was to establish a reliable mapping between a test case and the relevant focal method. To this aim, we designed a set of heuristics, based on developers' best practices in software testing, which identify the likely focal method for a given test case. To facilitate further analysis, we store a rich set of metadata for each method-test pair in JSON-formatted files. Additionally, we extract textual corpus from the dataset at different context levels, which we provide both in raw and tokenized forms, in order to enable researchers to train and evaluate machine learning models for Automated Test Generation. Methods2Test is publicly available at: https://github.com/microsoft/methods2test",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-4503-9303-4",
      "DOI": "10.1145/3524842.3528009",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796371",
      "Author_Keywords": "datasets;software testing",
      "IEEE_Terms": "Software testing;Java;Machine learning;Metadata;Software reliability",
      "Reference Count": "28",
      "Online Date": "21-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Towards Accurate Duplicate Bug Retrieval Using Deep Learning Techniques",
      "Authors": "J. Deshmukh; K. M. Annervaz; S. Podder; S. Sengupta; N. Dubash",
      "Author Affiliations": "Accenture Technology Labs; Accenture Technology Labs; Accenture Technology Labs; Accenture Technology Labs; Accenture Technology Labs",
      "Publication Title": "2017 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "7-Nov-17",
      "Publication Year": "2017",
      "Start Page": "115",
      "End Page": "124",
      "Abstract": "Duplicate Bug Detection is the problem of identifying whether a newly reported bug is a duplicate of an existing bug in the system and retrieving the original or similar bugs from the past. This is required to avoid costly rediscovery and redundant work. In typical software projects, the number of duplicate bugs reported may run into the order of thousands, making it expensive in terms of cost and time for manual intervention. This makes the problem of duplicate or similar bug detection an important one in Software Engineering domain. However, an automated solution for the same is not quite accurate yet in practice, in spite of many reported approaches using various machine learning techniques. In this work, we propose a retrieval and classification model using Siamese Convolutional Neural Networks (CNN) and Long Short Term Memory (LSTM) for accurate detection and retrieval of duplicate and similar bugs. We report an accuracy close to 90% and recall rate close to 80%, which makes possible the practical use of such a system. We describe our model in detail along with related discussions from the Deep Learning domain. By presenting the detailed experimental results, we illustrate the effectiveness of the model in practical systems, including for repositories for which supervised training data is not available.",
      "ISBNs": "978-1-5386-0992-7",
      "DOI": "10.1109/ICSME.2017.69",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094414",
      "Author_Keywords": "Information Retrieval;Duplicate Bug Detection;Deep Learning;Natural Language Processing;Word Embeddings;Siamese Networks;Convolutional Neural Networks;Long Short Term Memory",
      "IEEE_Terms": "Computer bugs;Machine learning;Neural networks;Training;Computational modeling;Sun",
      "Article Citation Count": "54",
      "Reference Count": "40",
      "License": "IEEE",
      "Online Date": "7-Nov-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "DeepOrder: Deep Learning for Test Case Prioritization in Continuous Integration Testing",
      "Authors": "A. Sharif; D. Marijan; M. Liaaen",
      "Author Affiliations": "Simula Research Laboratory, Norway; Simula Research Laboratory, Norway; Cisco Systems Norway",
      "Publication Title": "2021 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "24-Nov-21",
      "Publication Year": "2021",
      "Start Page": "525",
      "End Page": "534",
      "Abstract": "Continuous integration testing is an important step in the modern software engineering life cycle. Test prioritization is a method that can improve the efficiency of continuous integration testing by selecting test cases that can detect faults in the early stage of each cycle. As continuous integration testing produces voluminous test execution data, test history is a commonly used artifact in test prioritization. However, existing test prioritization techniques for continuous integration either cannot handle large test history or are optimized for using a limited number of historical test cycles. We show that such a limitation can decrease fault detection effectiveness of prioritized test suites. This work introduces DeepOrder, a deep learning-based model that works on the basis of regression machine learning. DeepOrder ranks test cases based on the historical record of test executions from any number of previous test cycles. DeepOrder learns failed test cases based on multiple factors including the duration and execution status of test cases. We experimentally show that deep neural networks, as a simple regression model, can be efficiently used for test case prioritization in continuous integration testing. DeepOrder is evaluated with respect to time-effectiveness and fault detection effectiveness in comparison with an industry practice and the state of the art approaches. The results show that DeepOrder outperforms the industry practice and state-of-the-art test prioritization approaches in terms of these two metrics.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-6654-2882-8",
      "DOI": "10.1109/ICSME52107.2021.00053",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9609187",
      "Author_Keywords": "Regression testing;Test case prioritization;Test case selection;Deep Learning;Machine Learning;Continuous Integration",
      "IEEE_Terms": "Industries;Deep learning;Measurement;Software maintenance;Fault detection;Conferences;History",
      "Article Citation Count": "12",
      "Reference Count": "38",
      "License": "IEEE",
      "Online Date": "24-Nov-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Comparative Study Using Discriminant Analysis on a Questionnaire Survey Regarding Project Managers‚Äô Cognition and Team Characteristics",
      "Authors": "A. Masuda; T. Matsuodani; K. Tsuda",
      "Author Affiliations": "Dept. Project Promotion Sec., FeliCa Networks Inc. Corporate Strategy, Tokyo, Japan; Debug Engineering Research Laboratory, Tokyo, Japan; University of Tsukuba, Graduate School of Business Sciences, Tokyo, Japan",
      "Publication Title": "2017 IEEE 41st Annual Computer Software and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "11-Sep-17",
      "Publication Year": "2017",
      "Volume": "2",
      "Start Page": "643",
      "End Page": "648",
      "Abstract": "The purpose of this study is to create a model of a relationship in which the dependent variable is the result of a project and the independent variables are the characteristics of human resources. We attempted a comparative evaluation of discriminant analyses with a statistical model and a machine learning model using assessments of the results of projects and team characteristics derived from questionnaire survey data. The results of the evaluation demonstrate that the machine learning model shows a higher discrimination rate within the range of the data used in the analysis, but it became clear that the discrimination rate worsens in comparison with the statistical model when extrapolated.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-5386-0367-3",
      "DOI": "10.1109/COMPSAC.2017.11",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8030005",
      "Author_Keywords": "software development;project;team condition;machine learning;discriminant analysis;questionnaire survey",
      "IEEE_Terms": "Data models;Analytical models;Software;Timing;Mathematical model;Productivity",
      "Reference Count": "5",
      "License": "IEEE",
      "Online Date": "11-Sep-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "ClusterCommit: A Just-in-Time Defect Prediction Approach Using Clusters of Projects",
      "Authors": "M. A. Shehab; A. Hamou-Lhadj; L. Alawneh",
      "Author Affiliations": "ECE, Concordia University, Montreal, QC, Canada; ECE, Concordia University, Montreal, QC, Canada; Jordan University of Science and Technology, Irbid, Jordan",
      "Publication Title": "2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "21-Jul-22",
      "Publication Year": "2022",
      "Start Page": "333",
      "End Page": "337",
      "Abstract": "Existing Just-in-Time (JIT) bug prediction techniques are designed to work on single projects. In this paper, we present ClusterCommit, a JIT bug prediction approach geared towards clusters of projects that share common libraries and functionalities. Unlike existing techniques, ClusterCommit trains a machine learning model by combining commits from a set of projects that are part of a larger cluster. Once this model is built, ClusterCommit can be used to detect buggy commits in each of these projects. When applying ClusterCommits to 16 projects that revolve around the Hadoop ecosystem and 10 projects of the Hive ecosystem, the results show that ClusterCommit achieves an F1-score of 73% and MCC of 0.44 for both clusters. These preliminary results are very promising and may lead to new JIT bug prediction techniques geared towards projects that are part of a large cluster.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-6654-3786-8",
      "DOI": "10.1109/SANER53432.2022.00049",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9825789",
      "Author_Keywords": "Bug Prediction;Commit Analysis;Machine Learning;Just-In-Time Software Maintenance;Software Reliability",
      "IEEE_Terms": "Training;Conferences;Computer bugs;Ecosystems;Transfer learning;Predictive models;Software",
      "Article Citation Count": "2",
      "Reference Count": "22",
      "License": "IEEE",
      "Online Date": "21-Jul-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Learn&Fuzz: Machine learning for input fuzzing",
      "Authors": "P. Godefroid; H. Peleg; R. Singh",
      "Author Affiliations": "Microsoft Research, USA; Technion, Israel; Microsoft Research, USA",
      "Publication Title": "2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "23-Nov-17",
      "Publication Year": "2017",
      "Start Page": "50",
      "End Page": "59",
      "Abstract": "Fuzzing consists of repeatedly testing an application with modified, or fuzzed, inputs with the goal of finding security vulnerabilities in input-parsing code. In this paper, we show how to automate the generation of an input grammar suitable for input fuzzing using sample inputs and neural-network-based statistical machine-learning techniques. We present a detailed case study with a complex input format, namely PDF, and a large complex security-critical parser for this format, namely, the PDF parser embedded in Microsoft's new Edge browser. We discuss and measure the tension between conflicting learning and fuzzing goals: learning wants to capture the structure of well-formed inputs, while fuzzing wants to break that structure in order to cover unexpected code paths and find bugs. We also present a new algorithm for this learn&fuzz challenge which uses a learnt input probability distribution to intelligently guide where to fuzz inputs.",
      "ISBNs": "978-1-5386-2684-9",
      "DOI": "10.1109/ASE.2017.8115618",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115618",
      "Author_Keywords": "Fuzzing;Deep Learning;Grammar-based Fuzzing;Grammar Learning",
      "IEEE_Terms": "Portable document format;Grammar;Training;Probability distribution;Recurrent neural networks",
      "Article Citation Count": "164",
      "Patent Citation Count": "2",
      "Reference Count": "31",
      "License": "IEEE",
      "Online Date": "23-Nov-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Neural Transfer Learning for Repairing Security Vulnerabilities in C Code",
      "Authors": "Z. Chen; S. Kommrusch; M. Monperrus",
      "Author Affiliations": "KTH Royal Institute of Technology, Stockholm, Sweden; Colorado State University, Fort Collins, CO, USA; KTH Royal Institute of Technology, Stockholm, Sweden",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "6-Jan-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "1",
      "Start Page": "147",
      "End Page": "165",
      "Abstract": "In this paper, we address the problem of automatic repair of software vulnerabilities with deep learning. The major problem with data-driven vulnerability repair is that the few existing datasets of known confirmed vulnerabilities consist of only a few thousand examples. However, training a deep learning model often requires hundreds of thousands of examples. In this work, we leverage the intuition that the bug fixing task and the vulnerability fixing task are related and that the knowledge learned from bug fixes can be transferred to fixing vulnerabilities. In the machine learning community, this technique is called transfer learning. In this paper, we propose an approach for repairing security vulnerabilities named VRepair which is based on transfer learning. VRepair is first trained on a large bug fix corpus and is then tuned on a vulnerability fix dataset, which is an order of magnitude smaller. In our experiments, we show that a model trained only on a bug fix corpus can already fix some vulnerabilities. Then, we demonstrate that transfer learning improves the ability to repair vulnerable C functions. We also show that the transfer learning model performs better than a model trained with a denoising task and fine-tuned on the vulnerability fixing task. To sum up, this paper shows that transfer learning works well for repairing security vulnerabilities in C compared to learning on a small dataset.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2022.3147265",
      "Funding Information": "Wallenberg Artificial Intelligence, Autonomous Systems and Software Program; Knut och Alice Wallenbergs Stiftelse; Swedish Foundation for Strategic Research; National Science Foundation(grant numbers:CCF-1750399); Vetenskapsr√•det(grant numbers:2018-05973); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9699412",
      "Author_Keywords": "Vulnerability fixing;transfer learning;seq2seq learning",
      "IEEE_Terms": "Transfer learning;Task analysis;Computer bugs;Transformers;Codes;Training;Software",
      "Article Citation Count": "20",
      "Reference Count": "81",
      "License": "CCBY",
      "Online Date": "1-Feb-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Cost-effective Simulation-based Test Selection in Self-driving Cars Software with SDC-Scissor",
      "Authors": "C. Birchler; N. Ganz; S. Khatiri; A. Gambi; S. Panichella",
      "Author Affiliations": "Zurich University of Applied Sciences, Switzerland; Zurich University of Applied Sciences, Switzerland; Software Institute - USI Lugano and Zurich University of Applied Sciences, Switzerland; University of Passau, Germany; Zurich University of Applied Sciences, Switzerland",
      "Publication Title": "2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "21-Jul-22",
      "Publication Year": "2022",
      "Start Page": "164",
      "End Page": "168",
      "Abstract": "Simulation platforms facilitate the continuous development of complex systems such as self-driving cars (SDCs). However, previous results on testing SDCs using simulations have shown that most of the automatically generated tests do not strongly contribute to establishing confidence in the quality and reliability of the SDC. Therefore, those tests can be characterized as ‚Äúuninformative‚Äù, and running them generally means wasting precious computational resources. We address this issue with SDC-Scissor, a framework that leverages Machine Learning to identify simulation-based tests that are unlikely to detect faults in the SDC software under test and skip them before their execution. Consequently, by filtering out those tests, SDC-Scissor reduces the number of long-running simulations to execute and drastically increases the cost-effectiveness of simulation-based testing of SDCs software. Our evaluation concerning two large datasets and around 12'000 tests showed that SDC-Scissor achieved a higher classification F1-score (between 47% and 90%) than a randomized baseline in identifying tests that lead to a fault and reduced the time spent running uninformative tests (speedup between 107% and 170%). Webpage & Video: https://github.com/ChristianBirchler/sdc-scissor",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-6654-3786-8",
      "DOI": "10.1109/SANER53432.2022.00030",
      "Funding Information": "DFG(grant numbers:FR 2955/4-1); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9825849",
      "Author_Keywords": "Self-driving cars;Software Simulation;Regression Testing;Test Case Selection;Continuous Integration",
      "IEEE_Terms": "Fault diagnosis;Filtering;Computational modeling;Transportation;Machine learning;Feature extraction;Software",
      "Article Citation Count": "17",
      "Reference Count": "28",
      "License": "IEEE",
      "Online Date": "21-Jul-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Self-Adaptive Bell‚ÄìLaPadula Model Based on Model Training With Historical Access Logs",
      "Authors": "Z. Tang; X. Ding; Y. Zhong; L. Yang; K. Li",
      "Author Affiliations": "National Supercomputing Center in Changsha, Hunan University, Changsha, China; National Supercomputing Center in Changsha, Hunan University, Changsha, China; National Supercomputing Center in Changsha, Hunan University, Changsha, China; College of Computer and Communication Engineering, Changsha University of Science and Technology, Hunan, China; National Supercomputing Center in Changsha, Hunan University, Changsha, China",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "16-Apr-18",
      "Publication Year": "2018",
      "Volume": "13",
      "Issue": "8",
      "Start Page": "2047",
      "End Page": "2061",
      "Abstract": "In currently popular access control models, the security policies and regulations never change in the running system process once they are identified, which makes it possible for attackers to find the vulnerabilities in a system, resulting in the lack of ability to perceive the system security status and risks in a dynamic manner and exposing the system to such risks. By introducing the maximum entropy (MaxENT) models into the rule optimization for the Bell-LaPadula (BLP) model, this paper proposes an improved BLP model with the self-learning function: MaxENT-BLP. This model first formalizes the security properties, system states, transformational rules, and a constraint model based on the states transition of the MaxENT. After handling the historical system access logs as the original data sets, this model extracts the user requests, current states, and decisions to act as the feature vectors. Second, we use k -fold cross validation to divide all vectors into a training set and a testing set. In this paper, the model training process is based on the Broyden-Fletcher-Goldfarb-Shanno algorithm. And this model contains a strategy update algorithm to adjust the access control rules dynamically according to the access and decision records in a system. Third, we prove that MaxENT-BLP is secure through theoretical analysis. By estimating the precision, recall, and F1-score, the experiments show the availability and accuracy of this model. Finally, this paper provides the process of model training based on deep learning and discussions regarding adversarial samples from the malware classifiers. We demonstrate that MaxENT-BLP is an appropriate choice and has the ability to help running information systems to avoid more risks and losses.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2018.2807793",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:61572176,L1624040); National Key Research and Development Program of China(grant numbers:2017YFB0202201); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8295130",
      "Author_Keywords": "Adversarial sample;BLP;machine learning;mandatory access control;maximum entropy model;rule optimization",
      "IEEE_Terms": "Hidden Markov models;Training;Access control;Data models;Feature extraction;Machine learning",
      "Article Citation Count": "17",
      "Reference Count": "37",
      "License": "IEEE",
      "Online Date": "19-Feb-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "An Empirical Study on Program Failures of Deep Learning Jobs",
      "Authors": "R. Zhang; W. Xiao; H. Zhang; Y. Liu; H. Lin; M. Yang",
      "Author Affiliations": "Microsoft Research; Alibaba Group; The University of Newcastle; Microsoft Research; Microsoft Research; Microsoft Research",
      "Publication Title": "2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "21-Dec-20",
      "Publication Year": "2020",
      "Start Page": "1159",
      "End Page": "1170",
      "Abstract": "Deep learning has made significant achievements in many application areas. To train and test models more efficiently, enterprise developers submit and run their deep learning programs on a shared, multi-tenant platform. However, some of the programs fail after a long execution time due to code/script defects, which reduces the development productivity and wastes expensive resources such as GPU, storage, and network I/O. This paper presents the first comprehensive empirical study on program failures of deep learning jobs. 4960 real failures are collected from a deep learning platform in Microsoft. We manually examine their failure messages and classify them into 20 categories. In addition, we identify the common root causes and bug-fix solutions on a sample of 400 failures. To better understand the current testing and debugging practices for deep learning, we also conduct developer interviews. Our major findings include: (1) 48.0% of the failures occur in the interaction with the platform rather than in the execution of code logic, mostly due to the discrepancies between local and platform execution environments; (2) Deep learning specific failures (13.5%) are mainly caused by inappropriate model parameters/structures and framework API misunderstanding; (3) Current debugging practices are not efficient for fault localization in many cases, and developers need more deep learning specific tools. Based on our findings, we further suggest possible research topics and tooling support that could facilitate future deep learning development.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-7121-6",
      "DOI": "10.1145/3377811.3380362",
      "Funding Information": "ARC(grant numbers:DP200102940); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284109",
      "Author_Keywords": "Deep learning jobs;Program failures;Empirical study",
      "IEEE_Terms": "Deep learning;Training;Debugging;Tools;Interviews;Testing;Software engineering",
      "Article Citation Count": "24",
      "Reference Count": "50",
      "Online Date": "21-Dec-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Comprehensive Feature Extraction for Cross-Project Software Defect Prediction",
      "Authors": "J. M. Reddy; M. K; H. Shahriar; V. Clincy; N. Sakib",
      "Author Affiliations": "Dept. of CSE, University at Buffalo, Buffalo, NY, USA; School of CSE, Vellore Institute of Technology, Chennai, India; Department of Information Technology, Kennesaw State University, Georgia, United States; Department of Computer Science, Kennesaw State University, Georgia, United States; Department of Information Technology, Kennesaw State University, Georgia, United States",
      "Publication Title": "2022 IEEE 46th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "10-Aug-22",
      "Publication Year": "2022",
      "Start Page": "450",
      "End Page": "451",
      "Abstract": "Quality of software is determined by analyzing the source code metrics and defects. Prediction of pre-and post-release defects and fixing them when they are raised will improve overall quality of software systems. The main aim of this work is to reduce the cost incurred in identifying defects which is a challenging task. Over a decade, the academia and industry addressed the problem of software defect prediction using machine learning. This work emphasizes on the selection of static code metrics and process metrics for defect prediction. Metrics are mined from different open source projects hosted on GitHub. For our experiments, we have chosen projects with at least 10k commits. This paper is establishing a hypothesis that, as the number of commits increase, the bugs are also likely to increase, as our experiments indicate. The software metrics are carefully chosen to identify defects across software projects to help the development and testing teams.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-6654-8810-5",
      "DOI": "10.1109/COMPSAC54236.2022.00085",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9842463",
      "Author_Keywords": "Defects;Classification;Machine Learning;Software Metrics;Feature Selection;Predictions",
      "IEEE_Terms": "Measurement;Industries;Codes;Software metrics;Machine learning;Software systems;Feature extraction",
      "Reference Count": "9",
      "License": "IEEE",
      "Online Date": "10-Aug-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Learning Off-By-One Mistakes: An Empirical Study",
      "Authors": "H. Sellik; O. van Paridon; G. Gousios; M. Aniche",
      "Author Affiliations": "Delft University of Technology, Delft, The Netherlands; Adyen N.V., Amsterdam, The Netherlands; Delft University of Technology, Delft, The Netherlands; Delft University of Technology, Delft, The Netherlands",
      "Publication Title": "2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "28-Jun-21",
      "Publication Year": "2021",
      "Start Page": "58",
      "End Page": "67",
      "Abstract": "Mistakes in binary conditions are a source of error in many software systems. They happen when developers use, e.g., `<;' or `>' instead of `<;=' or `>='. These boundary mistakes are hard to find and impose manual, labor-intensive work for software developers. While previous research has been proposing solutions to identify errors in boundary conditions, the problem remains open. In this paper, we explore the effectiveness of deep learning models in learning and predicting mistakes in boundary conditions. We train different models on approximately 1.6M examples with faults in different boundary conditions. We achieve a precision of 85% and a recall of 84% on a balanced dataset, but lower numbers in an imbalanced dataset. We also perform tests on 41 real-world boundary condition bugs found from GitHub, where the model shows only a modest performance. Finally, we test the model on a large-scale Java code base from Adyen, our industrial partner. The model reported 36 buggy methods, but none of them were confirmed by developers.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-7281-8710-5",
      "DOI": "10.1109/MSR52588.2021.00019",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9463090",
      "Author_Keywords": "machine learning for software engineering;deep learning for software engineering;software testing;boundary testing",
      "IEEE_Terms": "Deep learning;Java;Analytical models;Adaptation models;Computer bugs;Static analysis;Tools",
      "Article Citation Count": "2",
      "Reference Count": "36",
      "License": "IEEE",
      "Online Date": "28-Jun-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Learning from Mutants: Using Code Mutation to Learn and Monitor Invariants of a Cyber-Physical System",
      "Authors": "Y. Chen; C. M. Poskitt; J. Sun",
      "Author Affiliations": "Singapore University of Technology and Design, Singapore, Singapore; Singapore University of Technology and Design, Singapore, Singapore; Singapore University of Technology and Design, Singapore, Singapore",
      "Publication Title": "2018 IEEE Symposium on Security and Privacy (SP)",
      "Date Added To Xplore": "26-Jul-18",
      "Publication Year": "2018",
      "Start Page": "648",
      "End Page": "660",
      "Abstract": "Cyber-physical systems (CPS) consist of sensors, actuators, and controllers all communicating over a network; if any subset becomes compromised, an attacker could cause significant damage. With access to data logs and a model of the CPS, the physical effects of an attack could potentially be detected before any damage is done. Manually building a model that is accurate enough in practice, however, is extremely difficult. In this paper, we propose a novel approach for constructing models of CPS automatically, by applying supervised machine learning to data traces obtained after systematically seeding their software components with faults (\"mutants\"). We demonstrate the efficacy of this approach on the simulator of a real-world water purification plant, presenting a framework that automatically generates mutants, collects data traces, and learns an SVM-based model. Using cross-validation and statistical model checking, we show that the learnt model characterises an invariant physical property of the system. Furthermore, we demonstrate the usefulness of the invariant by subjecting the system to 55 network and code-modification attacks, and showing that it can detect 85% of them from the data logs generated at runtime.",
      "ISSN": "2375-1207",
      "ISBNs": "978-1-5386-4353-2",
      "DOI": "10.1109/SP.2018.00016",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8418629",
      "Author_Keywords": "cyber physical systems;water treatment systems;invariants;anomaly detection;attestation;system modelling;machine learning;mutation testing;attacks",
      "IEEE_Terms": "Sensors;Software;Actuators;Data models;Feature extraction;Monitoring;Model checking",
      "Article Citation Count": "85",
      "Reference Count": "48",
      "License": "IEEE",
      "Online Date": "26-Jul-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "FRUGAL: Unlocking Semi-Supervised Learning for Software Analytics",
      "Authors": "H. Tu; T. Menzies",
      "Author Affiliations": "Department of Computer Science, North Carolina State University, Raleigh, USA; Department of Computer Science, North Carolina State University, Raleigh, USA",
      "Publication Title": "2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "20-Jan-22",
      "Publication Year": "2021",
      "Start Page": "394",
      "End Page": "406",
      "Abstract": "Standard software analytics often involves having a large amount of data with labels in order to commission models with acceptable performance. However, prior work has shown that such requirements can be expensive, taking several weeks to label thousands of commits, and not always available when traversing new research problems and domains. Unsupervised Learning is a promising direction to learn hidden patterns within unlabelled data, which has only been extensively studied in defect prediction. Nevertheless, unsupervised learning can be ineffective by itself and has not been explored in other domains (e.g., static analysis and issue close time).Motivated by this literature gap and technical limitations, we present FRUGAL, a tuned semi-supervised method that builds on a simple optimization scheme that does not require sophisticated (e.g., deep learners) and expensive (e.g., 100% manually labelled data) methods. FRUGAL optimizes the unsupervised learner‚Äôs configurations (via a simple grid search) while validating our design decision of labelling just 2.5% of the data before prediction.As shown by the experiments of this paper FRUGAL outperforms the state-of-the-art adoptable static code warning recognizer and issue closed time predictor, while reducing the cost of labelling by a factor of 40 (from 100% to 2.5%). Hence we assert that FRUGAL can save considerable effort in data labelling especially in validating prior work or researching new problems.Based on this work, we suggest that proponents of complex and expensive methods should always baseline such methods against simpler and cheaper alternatives. For instance, a semi-supervised learner like FRUGAL can serve as a baseline to the state-of-theart software analytics.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-6654-0337-5",
      "DOI": "10.1109/ASE51524.2021.9678617",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9678617",
      "Author_Keywords": "Software Analytics;Data Labelling Efforts;Semi-Supervised Learning",
      "IEEE_Terms": "Costs;Static analysis;Semisupervised learning;Software;Data models;Labeling;Unsupervised learning",
      "Article Citation Count": "1",
      "Reference Count": "86",
      "License": "IEEE",
      "Online Date": "20-Jan-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Ticket Tagger: Machine Learning Driven Issue Classification",
      "Authors": "R. Kallis; A. Di Sorbo; G. Canfora; S. Panichella",
      "Author Affiliations": "Department of Informatics, University of Zurich, Zurich, Switzerland; Department of Engineering, University of Sannio, Benevento, Italy; Department of Engineering, University of Sannio, Benevento, Italy; School of Engineering, Zurich University of Applied Sciences, Zurich, Switzerland",
      "Publication Title": "2019 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "5-Dec-19",
      "Publication Year": "2019",
      "Start Page": "406",
      "End Page": "409",
      "Abstract": "Software maintenance is crucial for software projects evolution and success: code should be kept up-to-date and error-free, this with little effort and continuous updates for the end-users. In this context, issue trackers are essential tools for creating, managing and addressing the several (often hundreds of) issues that occur in software systems. A critical aspect for handling and prioritizing issues involves the assignment of labels to them (e.g., for projects hosted on GitHub), in order to determine the type (e.g., bug report, feature request and so on) of each specific issue. Although this labeling process has a positive impact on the effectiveness of issue processing, the current labeling mechanism is scarcely used on GitHub. In this demo, we introduce a tool, called Ticket Tagger, which leverages machine learning strategies on issue titles and descriptions for automatically labeling GitHub issues. Ticket Tagger automatically predicts the labels to assign to issues, with the aim of stimulating the use of labeling mechanisms in software projects, this to facilitate the issue management and prioritization processes. Along with the presentation of the tool's architecture and usage, we also evaluate its effectiveness in performing the issue labeling/classification process, which is critical to help maintainers to keep control of their workloads by focusing on the most critical issue tickets.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-7281-3094-1",
      "DOI": "10.1109/ICSME.2019.00070",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918993",
      "Author_Keywords": "Software maintenance and evolution;Issue Processing;Unstructured Data Labeling",
      "IEEE_Terms": "Computer bugs;Labeling;Software maintenance;Pattern classification;Software systems",
      "Article Citation Count": "51",
      "Reference Count": "14",
      "License": "IEEE",
      "Online Date": "5-Dec-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "DLFix: Context-based Code Transformation Learning for Automated Program Repair",
      "Authors": "Y. Li; S. Wang; T. N. Nguyen",
      "Author Affiliations": "New Jersey Inst. of Technology, USA; New Jersey Inst. of Technology, USA; University of Texas at Dallas, USA",
      "Publication Title": "2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "21-Dec-20",
      "Publication Year": "2020",
      "Start Page": "602",
      "End Page": "614",
      "Abstract": "Automated Program Repair (APR) is very useful in helping developers in the process of software development and maintenance. Despite recent advances in deep learning (DL), the DL-based APR approaches still have limitations in learning bug-fixing code changes and the context of the surrounding source code of the bug-fixing code changes. These limitations lead to incorrect fixing locations or fixes. In this paper, we introduce DLFix, a two-tier DL model that treats APR as code transformation learning from the prior bug fixes and the surrounding code contexts of the fixes. The first layer is a tree-based RNN model that learns the contexts of bug fixes and its result is used as an additional weighting input for the second layer designed to learn the bug-fixing code transformations. We conducted several experiments to evaluate DLFix in two benchmarks: Defect4J and Bugs.jar, and a newly built bug datasets with a total of +20K real-world bugs in eight projects. We compared DLFix against a total of 13 state-of-the-art pattern-based APR tools. Our results show that DLFix can auto-fix more bugs than 11 of them, and is comparable and complementary to the top two pattern-based APR tools in which there are 7 and 11 unique bugs that they cannot detect, respectively, but we can. Importantly, DLFix is fully automated and data-driven, and does not require hard-coding of bug-fixing patterns as in those tools. We compared DLFix against 4 state-of-the-art deep learning based APR models. DLFix is able to fix 2.5 times more bugs than the best performing baseline.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-7121-6",
      "Funding Information": "US National Science Foundation (NSF)(grant numbers:CCF-1723215,CCF-1723432,TWC-1723198,CCF-1518897,CNS-1513263); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284100",
      "Author_Keywords": "Deep Learning;Automated Program Repair;Context-based Code Transformation Learning",
      "IEEE_Terms": "Deep learning;Computer bugs;Tools;Maintenance engineering;Benchmark testing;Context modeling;Software engineering",
      "Article Citation Count": "12",
      "Reference Count": "46",
      "Online Date": "21-Dec-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Improving Bug Triaging with High Confidence Predictions at Ericsson",
      "Authors": "A. Sarkar; P. C. Rigby; B. Bartalos",
      "Author Affiliations": "Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada; Ericsson, Budapest, Hungary",
      "Publication Title": "2019 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "5-Dec-19",
      "Publication Year": "2019",
      "Start Page": "81",
      "End Page": "91",
      "Abstract": "Correctly assigning bugs to the right developer or team, i.e. bug triaging, is a costly activity. A concerted effort at Ericsson has been done to adopt automated bug triaging to reduce development costs. In this work, we replicate the research approaches that have been widely used in the literature. We apply them on over 10k bug reports for 9 large products at Ericsson. We find that a logistic regression classifier including the simple textual and categorical attributes of the bug reports has the highest precision and recall of 78.09% and 79.00%, respectively. Ericsson's bug reports often contain logs that have crash dumps and alarms. We add this information to the bug triage models. We find that this information does not improve the precision and recall of bug triaging in Ericsson's context. Although our models perform as well as the best ones reported in the literature, a criticism of bug triaging at Ericsson is that the accuracy is not sufficient for regular use. We develop a novel approach where we only triage bugs when the model has high confidence in the triage prediction. We find that we improve the accuracy to 90%, but we can make predictions for 62% of the bug reports.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-7281-3094-1",
      "DOI": "10.1109/ICSME.2019.00018",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8919115",
      "Author_Keywords": "Bug Triaging;Machine Learning;Log Analysis;Incremental Learning",
      "IEEE_Terms": "Computer bugs;Support vector machines;Machine learning;Software;Manuals;Social network services",
      "Article Citation Count": "18",
      "Reference Count": "31",
      "License": "IEEE",
      "Online Date": "5-Dec-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "On the Relationship between User Churn and Software Issues",
      "Authors": "O. E. Zarif; D. A. Da Costa; S. Hassan; Y. Zou",
      "Author Affiliations": "Queen's University, School Of Computing Kingston, Ontario, Canada; Department of Information Science, University of Otago, Dunedin, Otago, New Zealand; Queen's University, School Of Computing Kingston, Ontario, Canada; Department of Electrical and Computer Engineering, Queen's University, Kingston, Ontario, Canada",
      "Publication Title": "2020 IEEE/ACM 17th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "20-Jun-23",
      "Publication Year": "2020",
      "Start Page": "339",
      "End Page": "349",
      "Abstract": "The satisfaction of users is only part of the success of a software product, since a strong competition can easily detract users from a software product/service. User churn is the jargon used to denote when a user changes from a product / service to the one offered by the competition. In this study, we empirically investigate the relationship between the issues that are present in a software product and user churn. For this purpose, we investigate a new dataset provided by the alternativeto.net platform. Alternativeto.net has a unique feature that allows users to recommend alternatives for a specific software product, which signals the intention to switch from one software product to another. Through our empirical study, we observe that (i) the intention to change software is tightly associated to the issues that are present in these software; (ii) we can predict the rate of potential churn using machine learning models; (iii) the longer the issue takes to be fixed, the higher the chances of user churn; and (iv) issues within more general software modules are more likely to be associated with user churn. Our study can provide more insights on the prioritization of issues that need to be fixed to proactively minimize the chances of user churn.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-4503-7517-7",
      "DOI": "10.1145/3379597.3387456",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10148789",
      "Author_Keywords": "software issues;users churn;software alternatives;deep learning",
      "IEEE_Terms": "Computer bugs;Machine learning;Switches;Documentation;Predictive models;Software;Web servers",
      "Article Citation Count": "1",
      "Reference Count": "0",
      "Online Date": "20-Jun-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "RMove: Recommending Move Method Refactoring Opportunities using Structural and Semantic Representations of Code",
      "Authors": "D. Cui; S. Wang; Y. Luo; X. Li; J. Dai; L. Wang; Q. Li",
      "Author Affiliations": "School of Computer Science and Technology, Xidian University, Xi‚Äôan, China; School of Computer Science and Technology, Xidian University, Xi‚Äôan, China; School of Computer Science and Technology, Xidian University, Xi‚Äôan, China; School of Computer Science and Technology, Xidian University, Xi‚Äôan, China; School of Computer Science and Technology, Xidian University, Xi‚Äôan, China; School of Computer Science and Technology, Xidian University, Xi‚Äôan, China; School of Computer Science and Technology, Xidian University, Xi‚Äôan, China",
      "Publication Title": "2022 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "19-Dec-22",
      "Publication Year": "2022",
      "Start Page": "281",
      "End Page": "292",
      "Abstract": "Incorrect placement of methods within classes is a typical code smell called Feature Envy, which causes additional maintenance and cost during evolution. To remove this design flaw, several Move Method refactoring tools have been proposed. To the best of our knowledge, state-of-the-art related techniques can be broadly divided into two categories: the first line is non-machine-learning-based approaches built on software measurement, while the selection and thresholds of software metrics heavily rely on expert knowledge. The second line is machine learning-based approaches, which suggest Move Method refactoring by learning to extract features from code information. However, most approaches in this line treat different forms of code information identically, disregarding their significant variation on data analysis. In this paper, we propose an approach to recommend Move Method refactoring named RMove by automatically learning structural and semantic representation from code fragment respectively. We concatenate these representations together and further train the machine learning classifiers to guide the movement of method to suitable classes. We evaluate our approach on two publicly available datasets. The results show that our approach outperforms three state-of-the-art refactoring tools including PathMove, JDeodorant, and JMove in effectiveness and usefulness. The results also unveil useful findings and provide new insights that benefit other types of feature envy refactoring techniques.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-6654-7956-1",
      "DOI": "10.1109/ICSME55016.2022.00033",
      "Funding Information": "Research and Development; Fundamental Research Funds for the Central Universities; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9978256",
      "IEEE_Terms": "Software maintenance;Codes;Data analysis;Costs;Software metrics;Semantics;Machine learning",
      "Reference Count": "65",
      "License": "IEEE",
      "Online Date": "19-Dec-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Byzantines Can Also Learn From History: Fall of Centered Clipping in Federated Learning",
      "Authors": "K. √ñzfatura; E. √ñzfatura; A. K√ºp√ß√º; D. Gunduz",
      "Author Affiliations": "KUIS AI Center, Ko√ß University, ƒ∞Istanbul, Turkey; IPC Laboratory, Imperial College London, London, U.K; Department of Computer Engineering, Ko√ß University, ƒ∞Istanbul, Turkey; IPC Laboratory, Imperial College London, London, U.K",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "3-Jan-24",
      "Publication Year": "2024",
      "Volume": "19",
      "Start Page": "2010",
      "End Page": "2022",
      "Abstract": "The increasing popularity of the federated learning (FL) framework due to its success in a wide range of collaborative learning tasks also induces certain security concerns. Among many vulnerabilities, the risk of Byzantine attacks is of particular concern, which refers to the possibility of malicious clients participating in the learning process. Hence, a crucial objective in FL is to neutralize the potential impact of Byzantine attacks and to ensure that the final model is trustable. It has been observed that the higher the variance among the clients‚Äô models/updates, the more space there is for Byzantine attacks to be hidden. As a consequence, by utilizing momentum, and thus, reducing the variance, it is possible to weaken the strength of known Byzantine attacks. The centered clipping (CC) framework has further shown that the momentum term from the previous iteration, besides reducing the variance, can be used as a reference point to neutralize Byzantine attacks better. In this work, we first expose vulnerabilities of the CC framework, and introduce a novel attack strategy that can circumvent the defences of CC and other robust aggregators and reduce their test accuracy up to %33 on best-case scenarios in image classification tasks. Then, we propose a new robust and fast defence mechanism that is effective against the proposed and other existing Byzantine attacks.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2023.3345171",
      "Funding Information": "T√úBƒ∞ITAK; Scientific and Technological Research Council of Turkey(grant numbers:119E088); UK Research and Innovation (UKRI) for the Project ‚ÄúAIR‚Äù (European Research Council (ERC)-Consolidator Grant)(grant numbers:EP/X030806/1); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10366296",
      "Author_Keywords": "Federated learning;adversarial machine learning;deep learning",
      "IEEE_Terms": "Task analysis;Robustness;Federated learning;Security;Training;Aggregates;Taxonomy",
      "Reference Count": "58",
      "License": "IEEE",
      "Online Date": "19-Dec-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Fault Localization for Buggy Deep Learning Framework Conversions in Image Recognition",
      "Authors": "N. Louloudakis; P. Gibson; J. Cano; A. Rajan",
      "Author Affiliations": "University of Edinburgh; University of Glasgow; University of Glasgow; University of Edinburgh",
      "Publication Title": "2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "8-Nov-23",
      "Publication Year": "2023",
      "Start Page": "1795",
      "End Page": "1799",
      "Abstract": "When deploying Deep Neural Networks (DNNs), developers often convert models from one deep learning framework to another (e.g., TensorFlow to PyTorch). However, this process is error-prone and can impact target model accuracy. To identify the extent of such impact, we perform and briefly present a differential analysis against three DNNs widely used for image recognition (MobileNetV2, ResNet101, and InceptionV3)converted across four well-known deep learning frameworks (PyTorch, Keras, TensorFlow (TF), and TFLite), which revealed numerous model crashes and output label discrepancies of up to 72%. To mitigate such errors, we present a novel approach towards fault localization and repair of buggy deep learning framework conversions, focusing on pre-trained image recognition models. Our technique consists of four stages of analysis: 1) conversion tools, 2) model parameters, 3) model hyperparameters, and 4) graph representation. In addition, we propose various strategies towards fault repair of the faults detected. We implement our technique on top of the Apache TVM deep learning compiler, and we test it by conducting a preliminary fault localization analysis for the conversion of InceptionV3 from TF to TFLite. Our approach detected a fault in a common DNN converter tool, which introduced precision errors in weights, reducing model accuracy. After our fault localization, we repaired the issue, reducing our conversion error to zero.",
      "ISSN": "2643-1572",
      "ISBNs": "979-8-3503-2996-4",
      "DOI": "10.1109/ASE56229.2023.00147",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298525",
      "Author_Keywords": "software engineering;software testing;fault localization;deep learning;image recognition;deep neural networks;deep learning framework conversions",
      "IEEE_Terms": "Deep learning;Location awareness;Analytical models;Image recognition;Fault detection;Focusing;Artificial neural networks",
      "Article Citation Count": "1",
      "Reference Count": "35",
      "License": "IEEE",
      "Online Date": "8-Nov-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Why Is Static Application Security Testing Hard to Learn?",
      "Authors": "P. Krishnan; C. Cifuentes; L. Li; T. F. Bissyand√©; J. Klein",
      "Author Affiliations": "Oracle Labs, Brisbane, QLD, Australia; Oracle Labs, Brisbane, QLD, Australia; Software Assurance, Oracle Labs, Brisbane, QLD, Australia; School of Software, Beihang University, Beijing, China; School of Software, Beihang University, Beijing, China",
      "Publication Title": "IEEE Security & Privacy",
      "Date Added To Xplore": "6-Sep-23",
      "Publication Year": "2023",
      "Volume": "21",
      "Issue": "5",
      "Start Page": "68",
      "End Page": "72",
      "Abstract": "In this article, we summarize our experience in combining program analysis with machine learning (ML) to develop a technique that can improve the development of specific program analyses. Our experience is negative. We describe the areas that need to be addressed if ML techniques are to be useful in the program analysis context. Most of the issues that we report are different from the ones that discuss the state of the art in the use of ML techniques to detect security vulnerabilities",
      "ISSN": "1558-4046",
      "DOI": "10.1109/MSEC.2023.3287206",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10242233",
      "IEEE_Terms": "Privacy;Machine learning;Application security;Security;Software testing;Performance analysis",
      "Article Citation Count": "1",
      "Reference Count": "15",
      "License": "IEEE",
      "Online Date": "6-Sep-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Magazines"
    },
    {
      "Document Title": "Reducing Features to Improve Code Change-Based Bug Prediction",
      "Authors": "S. Shivaji; E. James Whitehead; R. Akella; S. Kim",
      "Author Affiliations": "Department of Computer Science, Baskin School of Engineering, University of California, Santa Cruz, Santa Cruz, CA, USA; Department of Computer Science, Baskin School of Engineering, University of California, Santa Cruz, Santa Cruz, CA, USA; Technology and Information Management Program Baskin School of Engineering, University of California, Santa Cruz, Santa Cruz, CA, USA; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "26-Mar-13",
      "Publication Year": "2013",
      "Volume": "39",
      "Issue": "4",
      "Start Page": "552",
      "End Page": "569",
      "Abstract": "Machine learning classifiers have recently emerged as a way to predict the introduction of bugs in changes made to source code files. The classifier is first trained on software history, and then used to predict if an impending change causes a bug. Drawbacks of existing classifier-based bug prediction techniques are insufficient performance for practical use and slow prediction times due to a large number of machine learned features. This paper investigates multiple feature selection techniques that are generally applicable to classification-based bug prediction methods. The techniques discard less important features until optimal classification performance is reached. The total number of features used for training is substantially reduced, often to less than 10 percent of the original. The performance of Naive Bayes and Support Vector Machine (SVM) classifiers when using this technique is characterized on 11 software projects. Naive Bayes using feature selection provides significant improvement in buggy F-measure (21 percent improvement) over prior change classification bug prediction results (by the second and fourth authors [28]). The SVM's improvement in buggy F-measure is 9 percent. Interestingly, an analysis of performance for varying numbers of features shows that strong performance is achieved at even 1 percent of the original number of features.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2012.43",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6226427",
      "Author_Keywords": "Reliability;bug prediction;machine learning;feature selection",
      "IEEE_Terms": "Software;Support vector machines;History;Machine learning;Feature extraction;Measurement;Computer bugs",
      "Article Citation Count": "169",
      "Reference Count": "53",
      "License": "IEEE",
      "Online Date": "26-Jun-12",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Trimming Test Suites with Coincidentally Correct Test Cases for Enhancing Fault Localizations",
      "Authors": "X. Xue; Y. Pang; A. S. Namin",
      "Author Affiliations": "Department of Computer Science, Texas Tech University, Lubbock, Texas, USA; Department of Mathematics and Statistics, Texas Tech University, Lubbock, Texas, USA; Department of Computer Science, Texas Tech University, Lubbock, Texas, USA",
      "Publication Title": "2014 IEEE 38th Annual Computer Software and Applications Conference",
      "Date Added To Xplore": "22-Sep-14",
      "Publication Year": "2014",
      "Start Page": "239",
      "End Page": "244",
      "Abstract": "Although empirical studies have demonstrated the usefulness of statistical fault localizations based on code coverage, the effectiveness of these techniques may be deteriorated due to the presence of some undesired circumstances such as the existence of coincidental correctness where one or more passing test cases exercise a faulty statement and thus causing some confusion to decide whether the underlying exercised statement is faulty or not. Fault localizations based on coverage can be improved if all possible instances of coincidental correctness are identified and proper strategies are employed to deal with these troublesome test cases. We introduce a technique to effectively identify coincidentally correct test cases. The proposed technique combines support vector machines and ensemble learning to detect mislabeled test cases, i.e. Coincidentally correct test cases. The ensemble-based support vector machine then can be used to trim a test suite or flip the test status of the coincidental correctness test cases and thus improving the effectiveness of fault localizations.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-4799-3575-8",
      "DOI": "10.1109/COMPSAC.2014.32",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6899222",
      "Author_Keywords": "coverage-based faults localization;coincidentally correct;support vector machine;ensemble learning",
      "IEEE_Terms": "Vectors;Support vector machines;Labeling;Measurement;Training data;Data models;Training",
      "Article Citation Count": "17",
      "Reference Count": "11",
      "License": "IEEE",
      "Online Date": "22-Sep-14",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "White-Box Analysis over Machine Learning: Modeling Performance of Configurable Systems",
      "Authors": "M. Velez; P. Jamshidi; N. Siegmund; S. Apel; C. K√§stner",
      "Author Affiliations": "Carnegie Mellon University; University of South Carolina; Leipzig University; Saarland Informatics Campus, Saarland University; Carnegie Mellon University, Pittsburgh, PA, USA",
      "Publication Title": "2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "7-May-21",
      "Publication Year": "2021",
      "Start Page": "1072",
      "End Page": "1084",
      "Abstract": "Performance-influence models can help stakeholders understand how and where configuration options and their interactions influence the performance of a system. With this understanding, stakeholders can debug performance behavior and make deliberate configuration decisions. Current black-box techniques to build such models combine various sampling and learning strategies, resulting in tradeoffs between measurement effort, accuracy, and interpretability. We present Comprex, a white-box approach to build performance-influence models for configurable systems, combining insights of local measurements, dynamic taint analysis to track options in the implementation, compositionality, and compression of the configuration space, without relying on machine learning to extrapolate incomplete samples. Our evaluation on 4 widely-used, open-source projects demonstrates that Comprex builds similarly accurate performance-influence models to the most accurate and expensive black-box approach, but at a reduced cost and with additional benefits from interpretable and local models.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-0296-5",
      "DOI": "10.1109/ICSE43902.2021.00100",
      "Funding Information": "Ministry of Education; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9401991",
      "Author_Keywords": "Performance influence modeling;Software configuration;Dynamic analysis",
      "IEEE_Terms": "Analytical models;Current measurement;Buildings;Machine learning;Stakeholders;Open source software;Software engineering",
      "Article Citation Count": "15",
      "Reference Count": "82",
      "License": "IEEE",
      "Online Date": "7-May-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Optimal Adversarial Policies in the Multiplicative Learning System With a Malicious Expert",
      "Authors": "S. R. Etesami; N. Kiyavash; V. Leon; H. V. Poor",
      "Author Affiliations": "Department of Industrial and Enterprise Systems Engineering, University of Illinois at Urbana‚ÄìChampaign, Urbana, IL, USA; College of Management of Technology, EPFL, Lausanne, Switzerland; Department of Industrial and Enterprise Systems Engineering, University of Illinois at Urbana‚ÄìChampaign, Urbana, IL, USA; Department of Electrical Engineering, Princeton University, Princeton, NJ, USA",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "10-Feb-21",
      "Publication Year": "2021",
      "Volume": "16",
      "Start Page": "2276",
      "End Page": "2287",
      "Abstract": "We consider a learning system based on the conventional multiplicative weight (MW) rule that combines experts' advice to predict a sequence of true outcomes. It is assumed that one of the experts is malicious and aims to impose the maximum loss on the system. The system's loss is naturally defined to be the aggregate absolute difference between the sequence of predicted outcomes and the true outcomes. We consider this problem under both offline and online settings. In the offline setting where the malicious expert must choose its entire sequence of decisions a priori, we show somewhat surprisingly that a simple greedy policy of always reporting false prediction is asymptotically optimal with an approximation ratio of 1+O‚àö(ln N)/N, where N is the total number of prediction stages. In particular, we describe a policy that closely resembles the structure of the optimal offline policy. For the online setting where the malicious expert can adaptively make its decisions, we show that the optimal online policy can be efficiently computed by solving a dynamic program in O(N3). We also discuss a generalization of our model to multi-expert settings. Our results provide a new direction for vulnerability assessment of commonly-used learning algorithms to internal adversarial attacks.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2021.3052360",
      "Funding Information": "U.S. National Science Foundation(grant numbers:EPCN-1944403,CCF-1908308); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9328196",
      "Author_Keywords": "Adversarial learning;expert advice;Markov decision process;dynamic programming;approximation ratio",
      "IEEE_Terms": "Learning systems;Prediction algorithms;Machine learning algorithms;Motion pictures;Approximation algorithms;Analytical models;Training",
      "Article Citation Count": "1",
      "Reference Count": "23",
      "License": "IEEE",
      "Online Date": "18-Jan-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Bridging the Gap Between Academia and Industry in Machine Learning Software Defect Prediction: Thirteen Considerations",
      "Authors": "S. Stradowski; L. Madeyski",
      "Author Affiliations": "Mobile Networks, Radio Frequency Nokia, Wroc≈Çaw, Poland; Department of Applied Informatics, Wroc≈Çaw University of Science and Technology, Wroc≈Çaw, Poland",
      "Publication Title": "2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "8-Nov-23",
      "Publication Year": "2023",
      "Start Page": "1098",
      "End Page": "1110",
      "Abstract": "This experience paper describes thirteen considerations for implementing machine learning software defect prediction (ML SDP) in vivo. Specifically, we provide the following report on the ground of the most important observations and lessons learned gathered during a large-scale research effort and introduction of ML SDP to the system-level testing quality assurance process of one of the leading telecommunication vendors in the world ‚Äî Nokia. We adhere to a holistic and logical progression based on the principles of the business analysis body of knowledge: from identifying the need and setting requirements, through designing and implementing the solution, to profitability analysis, stakeholder management, and handover. Conversely, for many years, industry adoption has not kept up the pace of academic achievements in the field, despite promising potential to improve quality and decrease the cost of software products for many companies worldwide. Therefore, discussed considerations hopefully help researchers and practitioners bridge the gaps between academia and industry.",
      "ISSN": "2643-1572",
      "ISBNs": "979-8-3503-2996-4",
      "DOI": "10.1109/ASE56229.2023.00026",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298304",
      "Author_Keywords": "machine learning;software defect prediction;Nokia 5G;industry introduction;experience paper",
      "IEEE_Terms": "Industries;Costs;Profitability;Buildings;Machine learning;Companies;Standards",
      "Reference Count": "59",
      "License": "IEEE",
      "Online Date": "8-Nov-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "ConEx: Efficient Exploration of Big-Data System Configurations for Better Performance",
      "Authors": "R. Krishna; C. Tang; K. Sullivan; B. Ray",
      "Author Affiliations": "Department of Computer Science, Columbia University, New York, NY, USA; Walmart Labs, Mountain View, CA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, Columbia University, New York, NY, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "15-Mar-22",
      "Publication Year": "2022",
      "Volume": "48",
      "Issue": "3",
      "Start Page": "893",
      "End Page": "909",
      "Abstract": "Configuration space complexity makes the big-data software systems hard to configure well. Consider Hadoop, with over nine hundred parameters, developers often just use the default configurations provided with Hadoop distributions. The opportunity costs in lost performance are significant. Popular learning-based approaches to auto-tune software does not scale well for big-data systems because of the high cost of collecting training data. We present a new method based on a combination of Evolutionary Markov Chain Monte Carlo (EMCMC) sampling and cost reduction techniques to find better-performing configurations for big data systems. For cost reduction, we developed and experimentally tested and validated two approaches: using scaled-up big data jobs as proxies for the objective function for larger jobs and using a dynamic job similarity measure to infer that results obtained for one kind of big data problem will work well for similar problems. Our experimental results suggest that our approach promises to improve the performance of big data systems significantly and that it outperforms competing approaches based on random sampling, basic genetic algorithms (GA), and predictive model learning. Our experimental results support the conclusion that our approach strongly demonstrates the potential to improve the performance of big data systems significantly and frugally.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2020.3007560",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9134972",
      "Author_Keywords": "Performance optimization;MCMC;SBSE;machine learning",
      "IEEE_Terms": "Big Data;Software systems;Machine learning;Markov processes;Monte Carlo methods;Predictive models",
      "Article Citation Count": "9",
      "Reference Count": "66",
      "License": "IEEE",
      "Online Date": "7-Jul-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Systematic Analysis of Deep Learning Model for Vulnerable Code Detection",
      "Authors": "M. T. Bin Nazim; M. J. H. Faruk; H. Shahriar; M. A. Khan; M. Masum; N. Sakib; F. Wu",
      "Author Affiliations": "Department Computer Science, Kennesaw State University, USA; Department of Software Engineering and Game Development, Kennesaw State University, USA; Department of Information Technology, Kennesaw State University, USA; Department Computer Science, Kennesaw State University, USA; School of Data Science, Kennesaw State University, USA; Department of Information Technology, Kennesaw State University, USA; Department of Computer Science, Tuskegee University, USA",
      "Publication Title": "2022 IEEE 46th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "10-Aug-22",
      "Publication Year": "2022",
      "Start Page": "1768",
      "End Page": "1773",
      "Abstract": "Software vulnerabilities have become a serious problem with the emergence of new applications that contain potentially vulnerable or malicious code that can compromise the system. The growing volume and complexity of software source codes have opened a need for vulnerability detection methods to successfully predict malicious codes before being the prey of cyberattacks. As leveraging humans to check sources codes requires extensive time and resources and preexisting static code analyzers are unable to properly detect vulnerable codes. Thus, artificial intelligence techniques, mainly deep learning models, have gained traction to detect source code vulnerability. A systematic review is carried out to explore and understand the various deep learning methods employed for the task and their efficacy as a prediction model. Additionally, a summary of each process and its characteristics are examined and its implementation on specific data sets and their evaluation will be discussed.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-6654-8810-5",
      "DOI": "10.1109/COMPSAC54236.2022.00281",
      "Funding Information": "National Science Foundation(grant numbers:2100134,2100115,1723578,1723586); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9842566",
      "Author_Keywords": "Deep Learning;Software Security;Source code Vulnerability",
      "IEEE_Terms": "Deep learning;Training;Analytical models;Codes;Systematics;Computational modeling;Predictive models",
      "Article Citation Count": "2",
      "Reference Count": "52",
      "License": "IEEE",
      "Online Date": "10-Aug-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Analyzing Android Encrypted Network Traffic to Identify User Actions",
      "Authors": "M. Conti; L. V. Mancini; R. Spolaor; N. V. Verde",
      "Author Affiliations": "Dipartimento di Matematica, Universit√† di Padova, Padua, Italy; Dipartimento di Informatica, Sapienza Universit√† di Roma, Rome, Italy; Dipartimento di Matematica, Universit√† di Padova, Padua, Italy; Dipartimento di Informatica, Sapienza Universit√† di Roma, Rome, Italy",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "19-May-17",
      "Publication Year": "2016",
      "Volume": "11",
      "Issue": "1",
      "Start Page": "114",
      "End Page": "125",
      "Abstract": "Mobile devices can be maliciously exploited to violate the privacy of people. In most attack scenarios, the adversary takes the local or remote control of the mobile device, by leveraging a vulnerability of the system, hence sending back the collected information to some remote web service. In this paper, we consider a different adversary, who does not interact actively with the mobile device, but he is able to eavesdrop the network traffic of the device from the network side (e.g., controlling a Wi-Fi access point). The fact that the network traffic is often encrypted makes the attack even more challenging. In this paper, we investigate to what extent such an external attacker can identify the specific actions that a user is performing on her mobile apps. We design a system that achieves this goal using advanced machine learning techniques. We built a complete implementation of this system, and we also run a thorough set of experiments, which show that our attack can achieve accuracy and precision higher than 95%, for most of the considered actions. We compared our solution with the three state-of-the-art algorithms, and confirming that our system outperforms all these direct competitors.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2015.2478741",
      "Funding Information": "TENACE PRIN Project through the Italian Ministry of Education, University and Research(grant numbers:20103P34XC); European Commission Directorate General Home Affairs through the GAINS Project(grant numbers:HOME/2013/CIPS/AG/4000005057); European Commission through the H2020 SUNFISH Project(grant numbers:644666); EU-India REACH Project(grant numbers:ICI+/2014/342-896); Project entitled Tackling Mobile Malware with Innovative Machine Learning Techniques through the University of Padua; Marie Curie Fellowship through the European Commission(grant numbers:PCIG11-GA-2012-321980); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7265055",
      "Author_Keywords": "Cellular phones;information security;privacy",
      "IEEE_Terms": "Time series analysis;Cryptography;Privacy;IP networks;Mobile handsets;Machine learning algorithms;Mobile communication",
      "Article Citation Count": "189",
      "Reference Count": "43",
      "License": "IEEE",
      "Online Date": "14-Sep-15",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Towards Privacy Preserving Cross Project Defect Prediction with Federated Learning",
      "Authors": "H. Yamamoto; D. Wang; G. K. Rajbahadur; M. Kondo; Y. Kamei; N. Ubayashi",
      "Author Affiliations": "Kyushu University, Fukuoka, Japan; Kyushu University, Fukuoka, Japan; Huawei Technologies Canada Co., Ltd., Canada; Kyushu University, Fukuoka, Japan; Kyushu University, Fukuoka, Japan; Kyushu University, Fukuoka, Japan",
      "Publication Title": "2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "15-May-23",
      "Publication Year": "2023",
      "Start Page": "485",
      "End Page": "496",
      "Abstract": "Defect prediction models can predict defects in software projects, and many researchers study defect prediction models to assist debugging efforts in software development. In recent years, there has been growing interest in Cross Project Defect Prediction (CPDP), which predicts defects in a project using a defect prediction model learned from other projects‚Äô data when there is insufficient data to construct a defect prediction model. Since CPDP uses other projects‚Äô data, data privacy preservation is one of the most significant issues. However, prior CPDP studies still require data sharing among projects to train models, and do not fully consider protecting project confidentiality. To address this, we propose a CPDP model FLR employing federated learning, a distributed machine learning approach that does not require data sharing. We evaluate FLR, using 25 projects, to investigate its effectiveness and feature interpretation. Our key results show that first, FLR outperforms the existing privacy-preserving methods (i.e., LACE2). Meanwhile, the performance is relatively comparable to the conventional methods (e.g., supervised and unsupervised learning). Second, the results of the interpretation analysis show that scale-related features have a common effect on the prediction performance of the FLR. In addition, further insights demonstrate that parameters of federated learning (e.g., learning rates and the number of clients) also play a role in the performance. This study is served as a first step to confirm the feasibility of the employment of federated learning in CPDP to ensure privacy preservation and lays the groundwork for future research on applying other machine learning models to federated learning.",
      "ISSN": "2640-7574",
      "ISBNs": "978-1-6654-5278-6",
      "DOI": "10.1109/SANER56733.2023.00052",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10123655",
      "Author_Keywords": "Defect Prediction;Cross Project;Privacy Preservation;Federated Learning",
      "IEEE_Terms": "Privacy;Data privacy;Federated learning;Employment;Distributed databases;Debugging;Predictive models",
      "Article Citation Count": "1",
      "Reference Count": "48",
      "License": "IEEE",
      "Online Date": "15-May-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Neural SZZ Algorithm",
      "Authors": "L. Tang; L. Bao; X. Xia; Z. Huang",
      "Author Affiliations": "College of Computer Science and Technology, Zhejiang University, China; College of Computer Science and Technology, Zhejiang University, China; College of Computer Science and Technology, Zhejiang University, China; College of Computer Science and Technology, Zhejiang University, China",
      "Publication Title": "2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "8-Nov-23",
      "Publication Year": "2023",
      "Start Page": "1024",
      "End Page": "1035",
      "Abstract": "The SZZ algorithm has been widely used for identifying bug-inducing commits. However, it suffers from low precision, as not all deletion lines in the bug-fixing commit are related to the bug fix. Previous studies have attempted to address this issue by using static methods to filter out noise, e.g., comments and refactoring operations in the bug-fixing commit. However, these methods have two limitations. First, it is challenging to include all refactoring and non-essential change patterns in a tool, leading to the potential exclusion of relevant lines and the inclusion of irrelevant lines. Second, applying these tools might not always improve performance. In this paper, to address the aforementioned challenges, we propose NEURALSZZ, a deep learning approach for detecting the root cause deletion lines in a bug-fixing commit and using them as input for the SZZ algorithm. NEURALSZZ first constructs a heterogeneous graph attention network model that captures the semantic relationships between each deletion line and the other deletion and addition lines. To pinpoint the root cause of a bug, Neuralszz uses a learning-to-rank technique to rank all deletion lines in the commit. To evaluate the effectiveness of NEURALSZZ, we utilize three datasets containing high-quality bug-fixing and bug-inducing commits. The experiment results show that NEURALSZZ outperforms various baseline methods, e.g., traditional machine learning-based approaches and BI-LSTM in identifying the root cause of bugs. Moreover, by utilizing the top-ranked deletion lines and applying the SZZ algorithm, Neuralszz demonstrates better precision and F1-score compared to previous SZZ algorithms.",
      "ISSN": "2643-1572",
      "ISBNs": "979-8-3503-2996-4",
      "DOI": "10.1109/ASE56229.2023.00037",
      "Funding Information": "National Key Research and Development Program of China(grant numbers:2021YFB2701102); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298347",
      "Author_Keywords": "SZZ Algorithm;Deep Learning;Heterogeneous Graph Attention Network;Learning to Rank",
      "IEEE_Terms": "Deep learning;Machine learning algorithms;Software algorithms;Computer bugs;Semantics;Filtering algorithms;Software engineering",
      "Article Citation Count": "1",
      "Reference Count": "68",
      "License": "IEEE",
      "Online Date": "8-Nov-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Using machine learning for estimating the defect content after an inspection",
      "Authors": "F. Padberg; T. Ragg; R. Schoknecht",
      "Author Affiliations": "Fakult√§t fur Informatik, Universit√§t Karlsruhe, Karlsruhe, Germany; Quantiom bioinformatics GmbH, Weingarten, Germany; Fakult√§t fur Informatik, Universit√§t Karlsruhe, Karlsruhe, Germany",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "19-Feb-04",
      "Publication Year": "2004",
      "Volume": "30",
      "Issue": "1",
      "Start Page": "17",
      "End Page": "28",
      "Abstract": "We view the problem of estimating the defect content of a document after an inspection as a machine learning problem: The goal is to learn from empirical data the relationship between certain observable features of an inspection (such as the total number of different defects detected) and the number of defects actually contained in the document. We show that some features can carry significant nonlinear information about the defect content. Therefore, we use a nonlinear regression technique, neural networks, to solve the learning problem. To select the best among all neural networks trained on a given data set, one usually reserves part of the data set for later cross-validation; in contrast, we use a technique which leaves the full data set for training. This is an advantage when the data set is small. We validate our approach on a known empirical inspection data set. For that benchmark, our novel approach clearly outperforms both linear regression and the current standard methods in software engineering for estimating the defect content, such as capture-recapture. The validation also shows that our machine learning approach can be successful even when the empirical inspection data set is small.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2004.1265733",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1265733",
      "IEEE_Terms": "Machine learning;Inspection;Neural networks;Software engineering;Curve fitting;Linear regression;Software standards;Software testing;Quality assurance;Estimation error",
      "Article Citation Count": "16",
      "Reference Count": "25",
      "License": "IEEE",
      "Online Date": "19-Feb-04",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "EtherGIS: A Vulnerability Detection Framework for Ethereum Smart Contracts Based on Graph Learning Features",
      "Authors": "Q. Zeng; J. He; G. Zhao; S. Li; J. Yang; H. Tang; H. Luo",
      "Author Affiliations": "School of Computer Science, South China Normal University, Guangzhou, China; WeBank Co., Ltd, Shenzhen, China; School of Computer Science, South China Normal University, Guangzhou, China; School of Computer Science, South China Normal University, Guangzhou, China; School of Computer Science, South China Normal University, Guangzhou, China; School of Computer Science, South China Normal University, Guangzhou, China; School of Computer Science, South China Normal University, Guangzhou, China",
      "Publication Title": "2022 IEEE 46th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "10-Aug-22",
      "Publication Year": "2022",
      "Start Page": "1742",
      "End Page": "1749",
      "Abstract": "The financial property of Ethereum makes smart contract attacks frequently bring about tremendous economic loss. Method for effective detection of vulnerabilities in contracts imperative. Existing efforts for contract security analysis heavily rely on rigid rules defined by experts, which are labor-intensive and non-scalable. There is still a lack of effort that considers combining expert-defined security patterns with deep learning. This paper proposes EtherGIS, a vulnerability detection framework that utilizes graph neural networks (GNN) and expert knowledge to extract the graph feature from smart contract control flow graphs (CFG). To gain multi-dimensional contract information and reinforce the attention of vulnerability-related graph features, sensitive EVM instruction corpora are constructed by analyzing EVM underlying logic and diverse vulnerability triggering mechanisms. The characteristic of nodes and edges in a CFG is initially confirmed according to the corpora, generating the corresponding attribute graph. GNN is adopted to aggregate the whole graph's attribute and structure information, bridging the semantic gap between low-level graph features and high-level contract features. The feature representation of the graph is finally input into the graph classification model for vulnerability detection. Furthermore, automated machine learning (AutoML) is adopted to automate the entire deep learning process. Data for this research was collected from Ethereum to build up a dataset of six vulnerabilities for evaluation. Experimental results demonstrate that EtherGIS can productively detect vulnerabilities in Ethereum smart contracts in terms of accuracy, precision, recall, and F1-score. All aspects outperform the existing work.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-6654-8810-5",
      "DOI": "10.1109/COMPSAC54236.2022.00277",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9842713",
      "Author_Keywords": "Ethereum smart contract;vulnerability detection;EVM instruction;deep learning",
      "IEEE_Terms": "Deep learning;Knowledge engineering;Smart contracts;Semantics;Feature extraction;Software;Graph neural networks",
      "Article Citation Count": "7",
      "Reference Count": "28",
      "License": "IEEE",
      "Online Date": "10-Aug-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Learning CI Configuration Correctness for Early Build Feedback",
      "Authors": "M. Santolucito; J. Zhang; E. Zhai; J. Cito; R. Piskac",
      "Author Affiliations": "Barnard College, Columbia University, NYC, USA; Yale University, New Haven, USA; Alibaba Group, Seattle, USA; TU Wien, Vienna, Austria; Yale University, New Haven, USA",
      "Publication Title": "2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "21-Jul-22",
      "Publication Year": "2022",
      "Start Page": "1006",
      "End Page": "1017",
      "Abstract": "Continuous Integration (CI) allows developers to check whether their code can build successfully and pass tests across various system environments with every commit. To use a CI platform, a developer must provide configuration files within a code repository to specify build conditions. Incorrect configuration settings lead to CI build failures, which can take hours to run, wasting valuable developer time and delaying product release dates. Debugging CI configurations is a slow and error-prone process. The only way to check the correctness of CI configurations is to push a commit and wait for the build result. We present VeriCI, the first system for localizing CI configuration errors at the code level. VeriCI runs as a static analysis tool, before the developer sends the build request to the CI server. Our key insight is that the commit history and the corresponding build histories available in CI environments can be used both for build error prediction and build error localization. We leverage the build history as a labeled dataset to automatically derive customized rules describing correct CI configurations, using supervised machine learning techniques. To more accurately identify root causes, we train a neural network that filters out constraints that are less likely to be connected to the root cause of build failure. We evaluate VeriCI on real world data from GitHub and achieve 91% accuracy of predicting a build failure and correctly identify the root cause in 75% of cases. We also conducted a between-subjects user study with 20 software developers, showing that VeriCI significantly helps users in identifying and fixing errors in CI.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-6654-3786-8",
      "DOI": "10.1109/SANER53432.2022.00118",
      "Funding Information": "National Science Foundation(grant numbers:CCF-1715387,CCF-2105208,CCF-1553168,CNS-1565208); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9825801",
      "Author_Keywords": "configuration files;program analysis;continuous integration",
      "IEEE_Terms": "Productivity;Location awareness;Codes;Neural networks;Static analysis;Machine learning;Software",
      "Reference Count": "61",
      "License": "IEEE",
      "Online Date": "21-Jul-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Representation vs. Model: What Matters Most for Source Code Vulnerability Detection",
      "Authors": "W. Zheng; A. O. Abdallah Semasaba; X. Wu; S. A. Agyemang; T. Liu; Y. Ge",
      "Author Affiliations": "School of Software, Northwestern Polytechnical University, Xi‚ÄôAn, China; School of Computer Science, Northwestern Polytechnical University, Xi‚ÄôAn, China; School of Cyberspace Security, Northwestern Polytechnical University, Xi‚ÄôAn, China; School of Software, Northwestern Polytechnical University, Xi‚ÄôAn, China; School of Computer and Information, Anhui Polytechnic University, Wuhu, Anhui; School of Electrical Engineering, Anhui Polytechnic University, Wuhu, Anhui",
      "Publication Title": "2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "11-May-21",
      "Publication Year": "2021",
      "Start Page": "647",
      "End Page": "653",
      "Abstract": "Vulnerabilities in the source code of software are critical issues in the realm of software engineering. Coping with vulnerabilities in software source code is becoming more challenging due to several aspects of complexity and volume. Deep learning has gained popularity throughout the years as a means of addressing such issues. In this paper, we propose an evaluation of vulnerability detection performance on source code representations and evaluate how Machine Learning (ML) strategies can improve them. The structure of our experiment consists of 3 Deep Neural Networks (DNNs) in conjunction with five different source code representations; Abstract Syntax Trees (ASTs), Code Gadgets (CGs), Semantics-based Vulnerability Candidates (SeVCs), Lexed Code Representations (LCRs), and Composite Code Representations (CCRs). Experimental results show that employing different ML strategies in conjunction with the base model structure influences the performance results to a varying degree. However, ML-based techniques suffer from poor performance on class imbalance handling when used in conjunction with source code representations for software vulnerability detection.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-7281-9630-5",
      "DOI": "10.1109/SANER50967.2021.00082",
      "Funding Information": "Ministry of Education; Northwestern Polytechnical University; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9426055",
      "Author_Keywords": "security;software vulnerability detection;deep learning",
      "IEEE_Terms": "Deep learning;Measurement;Analytical models;Conferences;Transfer learning;Neural networks;Syntactics",
      "Article Citation Count": "3",
      "Reference Count": "24",
      "License": "IEEE",
      "Online Date": "11-May-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "EnHMM: On the Use of Ensemble HMMs and Stack Traces to Predict the Reassignment of Bug Report Fields",
      "Authors": "M. S. Islam; A. Hamou-Lhadj; K. K. Sabor; M. Hamdaqa; H. Cai",
      "Author Affiliations": "Dept. Electrical and Computer Engineering, Concordia University, Montreal, QC, Canada; Dept. Electrical and Computer Engineering, Concordia University, Montreal, QC, Canada; Dept. Electrical and Computer Engineering, Concordia University, Montreal, QC, Canada; Department of Computer and Software Engineering, Polytechnique Montreal, Montreal, QC, Canada; School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA, USA",
      "Publication Title": "2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "11-May-21",
      "Publication Year": "2021",
      "Start Page": "411",
      "End Page": "421",
      "Abstract": "Bug reports (BR) contain vital information that can help triaging teams prioritize and assign bugs to developers who will provide the fixes. However, studies have shown that BR fields often contain incorrect information that need to be reassigned, which delays the bug fixing process. There exist approaches for predicting whether a BR field should be reassigned or not. These studies use mainly BR descriptions and traditional machine learning algorithms (SVM, KNN, etc.). As such, they do not fully benefit from the sequential order of information in BR data, such as function call sequences in BR stack traces, which may be valuable for improving the prediction accuracy. In this paper, we propose a novel approach, called EnHMM, for predicting the reassignment of BR fields using ensemble Hidden Markov Models (HMMs), trained on stack traces. EnHMM leverages the natural ability of HMMs to represent sequential data to model the temporal order of function calls in BR stack traces. When applied to Eclipse and Gnome BR repositories, EnHMM achieves an average precision, recall, and F-measure of 54%, 76%, and 60% on Eclipse dataset and 41%, 69%, and 51% on Gnome dataset. We also found that EnHMM improves over the best single HMM by 36% for Eclipse and 76% for Gnome. Finally, when comparing EnHMM to Im.ML.KNN, a recent approach in the field, we found that the average F-measure score of EnHMM improves the average F-measure of Im.ML.KNN by 6.80% and improves the average recall of Im.ML.KNN by 36.09%. However, the average precision of EnHMM is lower than that of Im.ML.KNN (53.93% as opposed to 56.71%).",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-7281-9630-5",
      "DOI": "10.1109/SANER50967.2021.00045",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9425928",
      "Author_Keywords": "Bug Report Field Reassignment;Stack Traces;Ensemble HMMs;Machine Learning;Mining Bug Repositories",
      "IEEE_Terms": "Support vector machines;Training;Software maintenance;Machine learning algorithms;Computer bugs;Software algorithms;Hidden Markov models",
      "Article Citation Count": "4",
      "Reference Count": "40",
      "License": "IEEE",
      "Online Date": "11-May-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Predicting Merge Conflicts in Collaborative Software Development",
      "Authors": "M. Owhadi-Kareshk; S. Nadi; J. Rubin",
      "Author Affiliations": "Dept. of Computing Science, University of Alberta, Edmonton, Canada; Dept. of Computing Science, University of Alberta, AB, Canada, Edmonton, Canada; Dept. of Electrical and Computer Engineering, University of British Columbia, BC, Canada, Vancouver, Canada",
      "Publication Title": "2019 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)",
      "Date Added To Xplore": "17-Oct-19",
      "Publication Year": "2019",
      "Start Page": "1",
      "End Page": "11",
      "Abstract": "Background. During collaborative software development, developers often use branches to add features or fix bugs. When merging changes from two branches, conflicts may occur if the changes are inconsistent. Developers need to resolve these conflicts before completing the merge, which is an error-prone and time-consuming process. Early detection of merge conflicts, which warns developers about resolving conflicts before they become large and complicated, is among the ways of dealing with this problem. Existing techniques do this by continuously pulling and merging all combinations of branches in the background to notify developers as soon as a conflict occurs, which is a computationally expensive process. One potential way for reducing this cost is to use a machine-learning based conflict predictor that filters out the merge scenarios that are not likely to have conflicts, i.e.safe merge scenarios.Aims. In this paper, we assess if conflict prediction is feasible.Method. We design a classifier for predicting merge conflicts, based on 9 light-weight Git feature sets. To evaluate our predictor, we perform a large-scale study on 267,657 merge scenarios from 744 GitHub repositories in seven programming languages.Results. Our results show that we achieve high f1-scores, varying from 0.95 to 0.97 for different programming languages, when predicting safe merge scenarios. The f1-score is between 0.57 and 0.68 for the conflicting merge scenarios.Conclusions. Predicting merge conflicts is feasible in practice, especially in the context of predicting safe merge scenarios as a pre-filtering step for speculative merging.",
      "ISSN": "1949-3789",
      "ISBNs": "978-1-7281-2968-6",
      "DOI": "10.1109/ESEM.2019.8870173",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8870173",
      "Author_Keywords": "Conflict Prediction;Git;Software Merging",
      "IEEE_Terms": "Merging;Computer languages;Feature extraction;Software;Tools;Machine learning;Correlation",
      "Article Citation Count": "22",
      "Reference Count": "42",
      "License": "IEEE",
      "Online Date": "17-Oct-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Patching as Translation: the Data and the Metaphor",
      "Authors": "Y. Ding; B. Ray; P. Devanbu; V. J. Hellendoorn",
      "Author Affiliations": "Columbia University; Columbia University; Columbia University; Columbia University",
      "Publication Title": "2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "24-Dec-20",
      "Publication Year": "2020",
      "Start Page": "275",
      "End Page": "286",
      "Abstract": "Machine Learning models from other fields, like Computational Linguistics, have been transplanted to Software Engineering tasks, often quite successfully. Yet a transplanted model's initial success at a given task does not necessarily mean it is well-suited for the task. In this work, we examine a common example of this phenomenon: the conceit that software patching is like language translation. We demonstrate empirically that there are subtle, but critical distinctions between sequence-to-sequence models and translation model: while program repair benefits greatly from the former, general modeling architecture, it actually suffers from design decisions built into the latter, both in terms of translation accuracy and diversity. Given these findings, we demonstrate how a more principled approach to model design, based on our empirical findings and general knowledge of software development, can lead to better solutions. Our findings also lend strong support to the recent trend towards synthesizing edits of code conditional on the buggy context, to repair bugs. We implement such models ourselves as ‚Äúproof-of-concept‚Äù tools and empirically confirm that they behave in a fundamentally different, more effective way than the studied translation-based architectures. Overall, our results demonstrate the merit of studying the intricacies of machine learned models in software engineering: not only can this help elucidate potential issues that may be overshadowed by increases in accuracy; it can also help innovate on these models to raise the state-of-the-art further. We will publicly release our replication data and materials at https://github.com/ARiSE-Lab/Patch-as-translation.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-4503-6768-4",
      "Funding Information": "NSF(grant numbers:CCF-1414172,CCF-1845893,CNS-1842456,CCF-182296); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9286060",
      "Author_Keywords": "neural machine translation;big code;sequence-to-sequence model;automated program repair",
      "IEEE_Terms": "Adaptation models;Machine learning;Computer architecture;Maintenance engineering;Software;Task analysis;Software engineering",
      "Article Citation Count": "12",
      "Reference Count": "34",
      "Online Date": "24-Dec-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "RoFL: Robustness of Secure Federated Learning",
      "Authors": "H. Lycklama; L. Burkhalter; A. Viand; N. K√ºchler; A. Hithnawi",
      "Author Affiliations": "ETH Zurich; ETH Zurich; ETH Zurich; ETH Zurich; ETH Zurich",
      "Publication Title": "2023 IEEE Symposium on Security and Privacy (SP)",
      "Date Added To Xplore": "21-Jul-23",
      "Publication Year": "2023",
      "Start Page": "453",
      "End Page": "476",
      "Abstract": "Even though recent years have seen many attacks exposing severe vulnerabilities in Federated Learning (FL), a holistic understanding of what enables these attacks and how they can be mitigated effectively is still lacking. In this work, we demystify the inner workings of existing (targeted) attacks. We provide new insights into why these attacks are possible and why a definitive solution to FL robustness is challenging. We show that the need for ML algorithms to memorize tail data has significant implications for FL integrity. This phenomenon has largely been studied in the context of privacy; our analysis sheds light on its implications for ML integrity. We show that certain classes of severe attacks can be mitigated effectively by enforcing constraints such as norm bounds on clients‚Äô updates. We investigate how to efficiently incorporate these constraints into secure FL protocols in the single-server setting. Based on this, we propose RoFL, a new secure FL system that extends secure aggregation with privacy-preserving input validation. Specifically, RoFL can enforce constraints such as L2 and L‚àû bounds on high-dimensional encrypted model updates.",
      "ISSN": "2375-1207",
      "ISBNs": "978-1-6654-9336-9",
      "DOI": "10.1109/SP46215.2023.10179400",
      "Funding Information": "Semiconductor Research Corporation; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10179400",
      "Author_Keywords": "federated-learning;secure-aggregation;privacy-preserving-machine-learning",
      "IEEE_Terms": "Privacy;Protocols;Federated learning;Scalability;Aggregates;Bandwidth;Tail",
      "Article Citation Count": "4",
      "Reference Count": "99",
      "License": "IEEE",
      "Online Date": "21-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Identifying Redundancies in Fork-based Development",
      "Authors": "L. Ren; S. Zhou; C. K√§stner; A. WƒÖsowski",
      "Author Affiliations": "Peking University, China; Carnegie Mellon University, USA; Carnegie Mellon University, USA; IT University of Copenhagen, Denmark",
      "Publication Title": "2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "18-Mar-19",
      "Publication Year": "2019",
      "Start Page": "230",
      "End Page": "241",
      "Abstract": "Fork-based development is popular and easy to use, but makes it difficult to maintain an overview of the whole community when the number of forks increases. This may lead to redundant development where multiple developers are solving the same problem in parallel without being aware of each other. Redundant development wastes effort for both maintainers and developers. In this paper, we designed an approach to identify redundant code changes in forks as early as possible by extracting clues indicating similarities between code changes, and building a machine learning model to predict redundancies. We evaluated the effectiveness from both the maintainer's and the developer's perspectives. The result shows that we achieve 57-83% precision for detecting duplicate code changes from maintainer's perspective, and we could save developers' effort of 1.9-3.0 commits on average. Also, we show that our approach significantly outperforms existing state-of-art.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-7281-0591-8",
      "DOI": "10.1109/SANER.2019.8668023",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8668023",
      "Author_Keywords": "Forking;Redundant Development;Natural Language Processing;Machine Learning",
      "IEEE_Terms": "Computer bugs;Machine learning;Cloning;Redundancy;Buildings;Predictive models;Maintenance engineering",
      "Article Citation Count": "14",
      "Reference Count": "47",
      "License": "IEEE",
      "Online Date": "18-Mar-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Automated Image Reduction for Explaining Black-box Classifiers",
      "Authors": "M. Jiang; C. Tang; X. -Y. Zhang; Y. Zhao; Z. Ding",
      "Author Affiliations": "Zhejiang Sci-Tech University, Hangzhou, China; Zhejiang Sci-Tech University, Hangzhou, China; University of Science and Technology Beijing, Beijing, China; Zhejiang Sci-Tech University, Hangzhou, China; Zhejiang Sci-Tech University, Hangzhou, China",
      "Publication Title": "2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "15-May-23",
      "Publication Year": "2023",
      "Start Page": "367",
      "End Page": "378",
      "Abstract": "Due to the prevalent application of machine learning (ML) techniques and the intrinsic black-box nature of ML models, the need for good explanations that are sufficient and necessary towards a model‚Äôs prediction has been well recognized and emphasized. Existing explanation approaches, however, favor either the sufficiency or necessity. To fill this gap, we present DDImage, a technique and tool that automatically produces explanations preserving dual properties for ML-based image classifiers. The core idea behind DDImage is to discover an appropriate explanation by debugging the given input image via a series of image reductions, with respect to the sufficiency and necessity properties. We conduct comprehensive experiments to compare our approach against two state-of-the-art approaches, BayLIME and SEDC, on widely-used models and datasets. The results show that our approach outperforms the other methods in producing minimal explanations preserving both sufficiency and necessity, and it matches or exceeds the other methods in terms of stability.",
      "ISSN": "2640-7574",
      "ISBNs": "978-1-6654-5278-6",
      "DOI": "10.1109/SANER56733.2023.00042",
      "Funding Information": "Nature; Research and Development; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10123601",
      "Author_Keywords": "Machine learning;Explainability;Software debugging",
      "IEEE_Terms": "Closed box;Debugging;Machine learning;Predictive models;Stability analysis",
      "Reference Count": "44",
      "License": "IEEE",
      "Online Date": "15-May-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "An Empirical Study on Performance Bugs in Deep Learning Frameworks",
      "Authors": "T. Makkouk; D. J. Kim; T. -H. P. Chen",
      "Author Affiliations": "Software PEformance, Analysis and Reliability (SPEAR) Lab, Concordia University, Montreal, Canada; Software PEformance, Analysis and Reliability (SPEAR) Lab, Concordia University, Montreal, Canada; Software PEformance, Analysis and Reliability (SPEAR) Lab, Concordia University, Montreal, Canada",
      "Publication Title": "2022 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "19-Dec-22",
      "Publication Year": "2022",
      "Start Page": "35",
      "End Page": "46",
      "Abstract": "Machine Learning (ML) and Deep Learning (DL) applications are becoming more popular due to the availability of DL frameworks such as TensorFlow and PyTorch. Therefore, the quality of DL frameworks is essential to ensure DL/ML application quality. Given the computationally expensive nature of DL tasks (e.g., training), performance is a critical aspect of DL frameworks. However, optimizing DL frameworks may have its own unique challenges due to the peculiarities of DL (e.g., hardware integration and the nature of the computation). In this paper, we conduct an empirical study on the performance bugs in DL frameworks. We conduct our study on TensorFlow and PyTorch by identifying the performance and non-performance bugs by mining the GitHub repositories. We find that 1) the proportion of newly reported performance bugs increases faster than fixed performance bugs, and the ratio of performance bugs among all bugs increases over time; 2) performance bugs take more time to fix, have larger fix sizes, and more community engagement (e.g., discussion) compared to non-performance bugs; and 3) we manually derived a taxonomy of 12 categories and 19 sub-categories of the root causes of performance bugs by studying all performance bug fixes. Finally, we present some actionable implications for researchers and developers.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-6654-7956-1",
      "DOI": "10.1109/ICSME55016.2022.00012",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9978257",
      "Author_Keywords": "empirical;software engineering;machine learning;deep learning;performance bugs",
      "IEEE_Terms": "Deep learning;Training;Software maintenance;Computer bugs;Taxonomy;Hardware;Data mining",
      "Article Citation Count": "2",
      "Reference Count": "81",
      "License": "IEEE",
      "Online Date": "19-Dec-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "When Less is Enough: Positive and Unlabeled Learning Model for Vulnerability Detection",
      "Authors": "X. -C. Wen; X. Wang; C. Gao; S. Wang; Y. Liu; Z. Gu",
      "Author Affiliations": "School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; Central University of Finance and Economics, China; School of Computer Science and Engineering, Nanyang Technological University, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China",
      "Publication Title": "2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "8-Nov-23",
      "Publication Year": "2023",
      "Start Page": "345",
      "End Page": "357",
      "Abstract": "Automated code vulnerability detection has gained increasing attention in recent years. The deep learning (DL)-based methods, which implicitly learn vulnerable code patterns, have proven effective in vulnerability detection. The performance of DL-based methods usually relies on the quantity and quality of labeled data. However, the current labeled data are generally automatically collected, such as crawled from human-generated commits, making it hard to ensure the quality of the labels. Prior studies have demonstrated that the non-vulnerable code (i.e., negative labels) tends to be unreliable in commonly-used datasets, while vulnerable code (i.e., positive labels) is more determined. Considering the large numbers of unlabeled data in practice, it is necessary and worth exploring to leverage the positive data and large numbers of unlabeled data for more accurate vulnerability detection. In this paper, we focus on the Positive and Unlabeled (PU) learning problem for vulnerability detection and propose a novel model named PILOT, i.e., Positive and unlabeled Learning mOdel for vulnerability deTection. PILOT only learns from positive and unlabeled data for vulnerability detection. It mainly contains two modules: (1) A distance-aware label selection module, aiming at generating pseudo-labels for selected unlabeled data, which involves the inter-class distance prototype and progressive fine-tuning; (2) A mixed-supervision representation learning module to further alleviate the influence of noise and enhance the discrimination of representations. Extensive experiments in vulnerability detection are conducted to evaluate the effectiveness of PILOT based on real-world vulnerability datasets. The experimental results show that PILOT outperforms the popular weakly supervised methods by 2.78%-18.93% in the PU learning setting. Compared with the state-of-the-art methods, PILOT also improves the performance of 1.34%-12.46 % in F1 score metrics in the supervised setting. In addition, PILOT can identify 23 mislabeled from the FFMPeg+Qemu dataset in the PU learning setting based on manual checking.",
      "ISSN": "2643-1572",
      "ISBNs": "979-8-3503-2996-4",
      "DOI": "10.1109/ASE56229.2023.00144",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298363",
      "Author_Keywords": "Software vulnerability detection;positive and unlabeled learning;source code representation",
      "IEEE_Terms": "Representation learning;Measurement;Deep learning;Codes;Source coding;Prototypes;Benchmark testing",
      "Reference Count": "84",
      "License": "IEEE",
      "Online Date": "8-Nov-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Study of Gender Discussions in Mobile Apps",
      "Authors": "M. Shahin; M. Zahedi; H. Khalajzadeh; A. Rezaei Nasab",
      "Author Affiliations": "School of Computing Technologies, RMIT University, Melbourne, Australia; School of Computing and Information Systems, University of Melbourne, Melbourne, Australia; School of Information Technology, Deakin University, Melbourne, Australia; School of Electrical and Computer Engineering, Shiraz University, Shiraz, Iran",
      "Publication Title": "2023 IEEE/ACM 20th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "12-Jul-23",
      "Publication Year": "2023",
      "Start Page": "598",
      "End Page": "610",
      "Abstract": "Mobile software apps (\"apps\") are one of the prevailing digital technologies that our modern life heavily depends on. A key issue in the development of apps is how to design gender-inclusive apps. Apps that do not consider gender inclusion, diversity, and equality in their design can create barriers (e.g., excluding some of the users because of their gender) for their diverse users. While there have been some efforts to develop gender-inclusive apps, a lack of deep understanding regarding user perspectives on gender may prevent app developers and owners from identifying issues related to gender and proposing solutions for improvement. Users express many different opinions about apps in their reviews, from sharing their experiences, and reporting bugs, to requesting new features. In this study, we aim at unpacking gender discussions about apps from the user perspective by analysing app reviews. We first develop and evaluate several Machine Learning (ML) and Deep Learning (DL) classifiers that automatically detect gender reviews (i.e., reviews that contain discussions about gender). We apply our ML and DL classifiers on a manually constructed dataset of 1,440 app reviews from the Google App Store, composing 620 gender reviews and 820 non-gender reviews. Our best classifier achieves an F1-score of 90.77%. Second, our qualitative analysis of a randomly selected 388 out of 620 gender reviews shows that gender discussions in app reviews revolve around six topics: App Features, Appearance, Content, Company Policy and Censorship, Advertisement, and Community. Finally, we provide some practical implications and recommendations for developing gender-inclusive apps.",
      "ISSN": "2574-3864",
      "ISBNs": "979-8-3503-1184-6",
      "DOI": "10.1109/MSR59073.2023.00086",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10174058",
      "Author_Keywords": "Gender;Mobile App;App Review;Machine Learning;Deep Learning",
      "IEEE_Terms": "Deep learning;Computer bugs;Companies;Software;Censorship;Mobile applications;Internet",
      "Reference Count": "87",
      "License": "IEEE",
      "Online Date": "12-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Detecting Malicious Attacks Exploiting Hardware Vulnerabilities Using Performance Counters",
      "Authors": "C. Li; J. -L. Gaudiot",
      "Author Affiliations": "Electrical Engineering and Computer Science, University of California, Irvine, Irvine, USA; Electrical Engineering and Computer Science, University of California, Irvine, Irvine, USA",
      "Publication Title": "2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "9-Jul-19",
      "Publication Year": "2019",
      "Volume": "1",
      "Start Page": "588",
      "End Page": "597",
      "Abstract": "Over the past decades, the major objectives of computer design have been to improve performance and to reduce cost, energy consumption, and size, while security has remained a secondary concern. Meanwhile, malicious attacks have rapidly grown as the number of Internet-connected devices, ranging from personal smart embedded systems to large cloud servers, have been increasing. Traditional antivirus software cannot keep up with the increasing incidence of these attacks, especially for exploits targeting hardware design vulnerabilities. For example, as DRAM process technology scales down, it becomes easier for DRAM cells to electrically interact with each other. For instance, in Rowhammer attacks, it is possible to corrupt data in nearby rows by reading the same row in DRAM. As Rowhammer exploits a computer hardware weakness, no software patch can completely fix the problem. Similarly, there is no efficient software mitigation to the recently reported attack Spectre. The attack exploits microarchitectural design vulnerabilities to leak protected data through side channels. In general, completely fixing hardware-level vulnerabilities would require a redesign of the hardware which cannot be backported. In this paper, we demonstrate that by monitoring deviations in microarchitectural events such as cache misses, branch mispredictions from existing CPU performance counters, hardware-level attacks such as Rowhammer and Spectre can be efficiently detected during runtime with promising accuracy and reasonable performance overhead using various machine learning classifiers.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-7281-2607-4",
      "DOI": "10.1109/COMPSAC.2019.00090",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8754201",
      "Author_Keywords": "security, machine learning, malware detection, microarchitectural features",
      "IEEE_Terms": "Hardware;Microarchitecture;Software;Arrays;Random access memory;Feature extraction;Monitoring",
      "Article Citation Count": "20",
      "Reference Count": "49",
      "License": "IEEE",
      "Online Date": "9-Jul-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Automatically generating commit messages from diffs using neural machine translation",
      "Authors": "S. Jiang; A. Armaly; C. McMillan",
      "Author Affiliations": "Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA",
      "Publication Title": "2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "23-Nov-17",
      "Publication Year": "2017",
      "Start Page": "135",
      "End Page": "146",
      "Abstract": "Commit messages are a valuable resource in comprehension of software evolution, since they provide a record of changes such as feature additions and bug repairs. Unfortunately, programmers often neglect to write good commit messages. Different techniques have been proposed to help programmers by automatically writing these messages. These techniques are effective at describing what changed, but are often verbose and lack context for understanding the rationale behind a change. In contrast, humans write messages that are short and summarize the high level rationale. In this paper, we adapt Neural Machine Translation (NMT) to automatically \"translate\" diffs into commit messages. We trained an NMT algorithm using a corpus of diffs and human-written commit messages from the top 1k Github projects. We designed a filter to help ensure that we only trained the algorithm on higher-quality commit messages. Our evaluation uncovered a pattern in which the messages we generate tend to be either very high or very low quality. Therefore, we created a quality-assurance filter to detect cases in which we are unable to produce good messages, and return a warning instead.",
      "ISBNs": "978-1-5386-2684-9",
      "DOI": "10.1109/ASE.2017.8115626",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115626",
      "IEEE_Terms": "Algorithm design and analysis;Software;Natural languages;Software algorithms;Machine learning;Computer bugs;Prediction algorithms",
      "Article Citation Count": "130",
      "Patent Citation Count": "1",
      "Reference Count": "59",
      "License": "IEEE",
      "Online Date": "23-Nov-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Test input prioritization for Machine Learning Classifiers",
      "Authors": "X. Dang; Y. Li; M. Papadakis; J. Klein; T. F. Bissyand√©; Y. L. Traon",
      "Author Affiliations": "University of Luxembourg; University of Luxembourg; University of Luxembourg; University of Luxembourg; University of Luxembourg; University of Luxembourg",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Publication Year": "2024",
      "Volume": "PP",
      "Issue": "99",
      "Start Page": "1",
      "End Page": "29",
      "Abstract": "Machine learning has achieved remarkable success across diverse domains. Nevertheless, concerns about interpretability in black-box models, especially within Deep Neural Networks (DNNs), have become pronounced in safety-critical fields like healthcare and finance. Classical machine learning (ML) classifiers, known for their higher interpretability, are preferred in these domains. Similar to DNNs, classical ML classifiers can exhibit bugs that could lead to severe consequences in practice. Test input prioritization has emerged as a promising approach to ensure the quality of an ML system, which prioritizes potentially misclassified tests so that such tests can be identified earlier with limited manual labeling costs. However, when applying to classical ML classifiers, existing DNN test prioritization methods are constrained from three perspectives: 1) Coverage-based methods are inefficient and time-consuming; 2) Mutation-based methods cannot be adapted to classical ML models due to mismatched model mutation rules; 3) Confidence-based methods are restricted to a single dimension when applying to binary ML classifiers, solely depending on the model‚Äôs prediction probability for one class. To overcome the challenges, we propose MLPrior, a test prioritization approach specifically tailored for classical ML models. MLPrior leverages the characteristics of classical ML classifiers (i.e., interpretable models and carefully engineered attribute features) to prioritize test inputs. The foundational principles are: 1) tests more sensitive to mutations are more likely to be misclassified, and 2) tests closer to the model‚Äôs decision boundary are more likely to be misclassified. Building on the first concept, we design mutation rules to generate two types of mutation features (i.e., model mutation features and input mutation features) for each test. Drawing from the second notion, MLPrior generates attribute features of each test based on its attribute values, which can indirectly reveal the proximity between the test and the decision boundary. For each test, MLPrior combines all three types of features of it into a final vector. Subsequently, MLPrior employs a pre-trained ranking model to predict the misclassification probability of each test based on its final vector and ranks tests accordingly. We conducted an extensive study to evaluate MLPrior based on 185 subjects, encompassing natural datasets, mixed noisy datasets, and fairness datasets. The results demonstrate that MLPrior outperforms all the compared test prioritization approaches, with an average improvement of 14.74%‚àº66.93% on natural datasets, 18.55%‚àº67.73% on mixed noisy datasets, and 15.34%‚àº62.72% on fairness datasets.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2024.3350019",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10382258",
      "Author_Keywords": "Test Input Prioritization;Machine Learning;Mutation analysis;Learning to Rank;Labelling",
      "IEEE_Terms": "Predictive models;Adaptation models;Labeling;Machine learning;Testing;Noise measurement;Manuals",
      "License": "CCBY",
      "Online Date": "5-Jan-24",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Early Access Articles"
    },
    {
      "Document Title": "A Semi-supervised Approach to Software Defect Prediction",
      "Authors": "H. Lu; B. Cukic; M. Culp",
      "Author Affiliations": "Lane Department of Computer Science and Electrical Engineering, West Virginia University Morgantown, WV, USA; Lane Department of Computer Science and Electrical Engineering, West Virginia University Morgantown, WV, USA; Department of Statistics, West Virginia University Morgantown, WV, USA",
      "Publication Title": "2014 IEEE 38th Annual Computer Software and Applications Conference",
      "Date Added To Xplore": "22-Sep-14",
      "Publication Year": "2014",
      "Start Page": "416",
      "End Page": "425",
      "Abstract": "Accurate detection of software components that need to be exposed to additional verification and validation offers the path to high quality products while minimizing non essential software assurance expenditures. In this type of quality modeling we assume that software modules with known fault content developed in similar environment are available. Supervised learning algorithms are the traditional methods of choice for training on existing modules. The models are then used to predict fault content for newly developed software components prior to product release. However, one needs to realize that establishing whether a module contains a fault or not, only to be used for model training, can be expensive. The basic idea behind semi-supervised learning is to learn from a small number of software modules with known fault content and supplement model training with modules for which the fault information is not available, thus reducing the overall cost of quality assurance. In this study, we investigate the performance of semi-supervised learning for software fault prediction. A preprocessing strategy, multidimensional scaling, is embedded in the approach to reduce the dimensional complexity of software metrics used for prediction. Our results show that the dimension-reduction with semi-supervised learning algorithm preforms significantly better than one of the best performing supervised learning algorithm - random forest - in situations when few modules with known fault content are available. We compare our results with the published benchmarks and clearly demonstrate performance benefits.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-4799-3575-8",
      "DOI": "10.1109/COMPSAC.2014.65",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6899244",
      "Author_Keywords": "software fault prediction;semi-supervised learning;dimension reduction;software metrics",
      "IEEE_Terms": "Software;Prediction algorithms;Predictive models;Measurement;Semisupervised learning;Training;Software algorithms",
      "Article Citation Count": "11",
      "Reference Count": "32",
      "License": "IEEE",
      "Online Date": "22-Sep-14",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Detecting False Alarms from Automatic Static Analysis Tools: How Far are We?",
      "Authors": "H. J. Kang; K. L. Aw; D. Lo",
      "Author Affiliations": "Singapore Management University Singapore, Singapore; Singapore Management University Singapore, Singapore; Singapore Management University Singapore, Singapore",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "698",
      "End Page": "709",
      "Abstract": "Automatic static analysis tools (ASATs), such as Findbugs, have a high false alarm rate. The large number of false alarms produced poses a barrier to adoption. Researchers have proposed the use of machine learning to prune false alarms and present only actionable warnings to developers. The state-of-the-art study has identified a set of ‚ÄúGolden Features‚Äù based on metrics computed over the characteristics and history of the file, code, and warning. Recent studies show that machine learning using these features is extremely effective and that they achieve almost perfect performance. We perform a detailed analysis to better understand the strong performance of the ‚ÄúGolden Features‚Äù. We found that several studies used an experimental procedure that results in data leakage and data duplication, which are subtle issues with significant implications. Firstly, the ground-truth labels have leaked into features that measure the proportion of actionable warnings in a given context. Secondly, many warnings in the testing dataset appear in the training dataset. Next, we demonstrate limitations in the warning oracle that determines the ground-truth labels, a heuristic comparing warnings in a given revision to a reference revision in the future. We show the choice of reference revision influences the warning distribution. Moreover, the heuristic produces labels that do not agree with human oracles. Hence, the strong performance of these techniques previously seen is overoptimistic of their true performance if adopted in practice. Our results convey several lessons and provide guidelines for evaluating false alarm detectors.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3510214",
      "Funding Information": "National Research Foundation, Singapore; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793908",
      "Author_Keywords": "static analysis;false alarms;data leakage;data duplication",
      "IEEE_Terms": "Training;Measurement;Codes;Static analysis;Machine learning;Detectors;History",
      "Article Citation Count": "8",
      "Reference Count": "64",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "VulHunter: Hunting Vulnerable Smart Contracts at EVM Bytecode-Level via Multiple Instance Learning",
      "Authors": "Z. Li; S. Lu; R. Zhang; Z. Zhao; R. Liang; R. Xue; W. Li; F. Zhang; S. Gao",
      "Author Affiliations": "State Key Laboratory of Information Security, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Information Engineering University, Zhengzhou, China; State Key Laboratory of Information Security, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Information Engineering University, Zhengzhou, China; State Key Laboratory of Information Security, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Information Security, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; School of Information, Central University of Finance and Economics, Beijing, China",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "16-Nov-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "11",
      "Start Page": "4886",
      "End Page": "4916",
      "Abstract": "With the economic development of Ethereum, the frequent security incidents involving smart contracts running on this platform have caused billions of dollars in losses. Consequently, there is a pressing need to identify the vulnerabilities in contracts, while the state-of-the-art (SOTA) detection methods have been limited in this regard as they cannot overcome three challenges at the same time. (i) Meet the requirements of detecting the source code, bytecode, and opcode of contracts simultaneously; (ii) reduce the reliance on manual pre-defined rules/patterns and expert involvement; (iii) assist contract developers in completing the contract lifecycle more safely, e.g., vulnerability repair and abnormal monitoring. With the development of machine learning (ML), using it to detect the contract runtime execution sequences (called instances) has made it possible to address these challenges. However, the lack of datasets with fine-grained sequence labels poses a significant obstacle, given the unreadability of bytecode/opcode. To this end, we propose a method named VulHunter that extracts the instances by traversing the Control Flow Graph built from contract opcodes. Based on the hybrid attention and multi-instance learning mechanisms, VulHunter reasons the instance labels and designs an optional classifier to automatically capture the subtle features of both normal and defective contracts, thereby identifying the vulnerable instances. Then, it combines the symbolic execution to construct and solve symbolic constraints to validate their feasibility. Finally, we implement a prototype of VulHunter with 15K lines of code and compare it with 9 SOTA methods on five open source datasets including 52,042 source codes and 184,289 bytecodes. The results indicate that VulHunter can detect contract vulnerabilities more accurately (90.04% accuracy and 85.60% F1 score), efficiently (only 4.4 seconds per contract), and robustly (0% analysis failure rate) than SOTA methods. Also, it can focus on specific metrics such as precision and recall by employing different baseline models and hyperparameters to meet the various user requirements, e.g., vulnerability discovery and misreport mitigation. More importantly, compared with the previous ML-based arts, it can not only provide classification results, defective contract source code statements, key opcode fragments, and vulnerable execution paths, but also eliminate misreports and facilitate more operations such as vulnerability repair and attack simulation during the contract lifecycle.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2023.3317209",
      "Funding Information": "National Key R&D Program of China(grant numbers:2021YFB2700603); National Natural Science Foundation of China(grant numbers:62172405,62072487,62227805,62072398); Major Public Welfare Projects Foundation of Henan(grant numbers:201300210200); Beijing Natural Science Foundation(grant numbers:M21036); Zhejiang Key R&D Plan(grant numbers:2021C01116); Leading Innovative and Entrepreneur Team Introduction Program of Zhejiang(grant numbers:2018R01005); Zhejiang Provincial Natural Science Foundation of China(grant numbers:LD22F020002); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10261219",
      "Author_Keywords": "Blockchain;smart contract;security analysis;multiple instance learning;symbolic execution",
      "IEEE_Terms": "Source coding;Smart contracts;Codes;Pattern matching;Testing;Monitoring;Maintenance engineering",
      "Reference Count": "76",
      "License": "CCBY",
      "Online Date": "22-Sep-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Losing Confidence in Quality: Unspoken Evolution of Computer Vision Services",
      "Authors": "A. Cummaudo; R. Vasa; J. Grundy; M. Abdelrazek; A. Cain",
      "Author Affiliations": "Applied Artificial Intelligence Institute, Deakin University, Geelong, Australia; Applied Artificial Intelligence Institute, Deakin University, Geelong, Australia; Faculty of Information Technology, Monash University, Clayton, Australia; School of Information Technology, Deakin University, Geelong, Australia; School of Information Technology, Deakin University, Geelong, Australia",
      "Publication Title": "2019 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "5-Dec-19",
      "Publication Year": "2019",
      "Start Page": "333",
      "End Page": "342",
      "Abstract": "The following topics are dealt with: software maintenance; public domain software; program testing; source code (software); program debugging; software quality; program diagnostics; learning (artificial intelligence); mobile computing; data mining.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-7281-3094-1",
      "DOI": "10.1109/ICSME.2019.00051",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8919078",
      "Author_Keywords": "machine learning;intelligent service;computer vision;quality assurance;evolution risk;documentation",
      "IEEE_Terms": "Computer vision;Dogs;Testing;Cloud computing;Documentation;Software quality",
      "Article Citation Count": "14",
      "Reference Count": "63",
      "License": "Crown",
      "Online Date": "5-Dec-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Why Don‚Äôt XAI Techniques Agree? Characterizing the Disagreements Between Post-hoc Explanations of Defect Predictions",
      "Authors": "S. Roy; G. Laberge; B. Roy; F. Khomh; A. Nikanjam; S. Mondal",
      "Author Affiliations": "University of Saskatchewan, Canada; Polytechnique Montr√©al, Canada; University of Saskatchewan, Canada; University of Saskatchewan, Canada; University of Saskatchewan, Canada; University of Saskatchewan, Canada",
      "Publication Title": "2022 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "19-Dec-22",
      "Publication Year": "2022",
      "Start Page": "444",
      "End Page": "448",
      "Abstract": "Machine Learning (ML) based defect prediction models can be used to improve the reliability and overall quality of software systems. However, such defect predictors might not be deployed in real applications due to the lack of transparency. Thus, recently, application of several post-hoc explanation methods (e.g., LIME and SHAP) have gained popularity. These explanation methods can offer insight by ranking features based on their importance in black box decisions. The explainability of ML techniques is reasonably novel in the Software Engineering community. However, it is still unclear whether such explainability methods genuinely help practitioners make better decisions regarding software maintenance. Recent user studies show that data scientists usually utilize multiple post-hoc explainers to understand a single model decision because of the lack of ground truth. Such a scenario causes disagreement between explainability methods and impedes drawing a conclusion. Therefore, our study first investigates three disagreement metrics between LIME and SHAP explanations of 10 defect-predictors, and exposes that disagreements regarding the rankings of feature importance are most frequent. Our findings lead us to propose a method of aggregating LIME and SHAP explanations that puts less emphasis on these disagreements while highlighting the aspect on which explanations agree.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-6654-7956-1",
      "DOI": "10.1109/ICSME55016.2022.00056",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9978217",
      "Author_Keywords": "Empirical;Defect Prediction;eXplainable AI;LIME;SHAP;Software Maintenance",
      "IEEE_Terms": "Measurement;Software maintenance;Closed box;Machine learning;Predictive models;Maintenance engineering;Software systems",
      "Article Citation Count": "3",
      "Reference Count": "23",
      "License": "IEEE",
      "Online Date": "19-Dec-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Training Data Debugging for the Fairness of Machine Learning Software",
      "Authors": "Y. Li; L. Meng; L. Chen; L. Yu; D. Wu; Y. Zhou; B. Xu",
      "Author Affiliations": "State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; Momenta, Suzhou, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "2215",
      "End Page": "2227",
      "Abstract": "With the widespread application of machine learning (ML) software, especially in high-risk tasks, the concern about their unfairness has been raised towards both developers and users of ML software. The unfairness of ML software indicates the software behavior affected by the sensitive features (e.g., sex), which leads to biased and illegal decisions and has become a worthy problem for the whole software engineering community. According to the ‚Äúdata-driven‚Äù programming paradigm of ML software, we consider the root cause of the unfairness as biased features in training data. Inspired by software debugging, we propose a novel method, Linear-regression based Training Data Debugging (LTDD), to debug feature values in training data, i.e., (a) identify which features and which parts of them are biased, and (b) exclude the biased parts of such features to recover as much valuable and unbiased information as possible to build fair ML software. We conduct an extensive study on nine data sets and three classifiers to evaluate the effect of our method LTDD compared with four baseline methods. Experimental results show that (a) LTDD can better improve the fairness of ML software with less or comparable damage to the performance, and (b) LTDD is more actionable for fairness improvement in realistic scenarios.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3510091",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:62172202,61872177,61772259,62172205,61832009,61772263); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794106",
      "Author_Keywords": "Debugging;Fairness;ML Software;Training Data",
      "IEEE_Terms": "Training;Linear regression;Training data;Machine learning;Debugging;Programming;Software",
      "Article Citation Count": "3",
      "Reference Count": "50",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Comments on ‚ÄúResearcher Bias: The Use of Machine Learning in Software Defect Prediction‚Äù",
      "Authors": "C. Tantithamthavorn; S. McIntosh; A. E. Hassan; K. Matsumoto",
      "Author Affiliations": "Graduate School of Information Science, Nara Institute of Science and Technology, Nara, Japan; Department of Electrical and Computer Engineering, McGill University, Montreal, QC, Canada; School of Computing, Queen's University, Kingston, ON, Canada; Graduate School of Information Science, Nara Institute of Science and Technology, Nara, Japan",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "10-Nov-16",
      "Publication Year": "2016",
      "Volume": "42",
      "Issue": "11",
      "Start Page": "1092",
      "End Page": "1094",
      "Abstract": "Shepperd et al. find that the reported performance of a defect prediction model shares a strong relationship with the group of researchers who construct the models. In this paper, we perform an alternative investigation of Shepperd et al.'s data. We observe that (a) research group shares a strong association with other explanatory variables (i.e., the dataset and metric families that are used to build a model); (b) the strong association among these explanatory variables makes it difficult to discern the impact of the research group on model performance; and (c) after mitigating the impact of this strong association, we find that the research group has a smaller impact than the metric family. These observations lead us to conclude that the relationship between the research group and the performance of a defect prediction model are more likely due to the tendency of researchers to reuse experimental components (e.g., datasets and metrics). We recommend that researchers experiment with a broader selection of datasets and metrics to combat any potential bias in their results.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2016.2553030",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7450669",
      "Author_Keywords": "Software quality assurance;defect prediction;researcher bias",
      "IEEE_Terms": "Measurement;Interference;Analysis of variance;Predictive models;Analytical models;NASA;Data models",
      "Article Citation Count": "60",
      "Reference Count": "18",
      "License": "IEEE",
      "Online Date": "11-Apr-16",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Authors‚Äô Reply to ‚ÄúComments on ‚ÄòResearcher Bias: The Use of Machine Learning in Software Defect Prediction‚Äô‚Äù",
      "Authors": "M. Shepperd; T. Hall; D. Bowes",
      "Author Affiliations": "Department of Computer Science, Brunel University London, Uxbridge, United Kingdom; Department of Computer Science, Brunel University London, Uxbridge, United Kingdom; University of Hertfordshire, Hatfield, United Kingdom",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "11-Nov-18",
      "Publication Year": "2018",
      "Volume": "44",
      "Issue": "11",
      "Start Page": "1129",
      "End Page": "1131",
      "Abstract": "In 2014 we published a meta-analysis of software defect prediction studies [1] . This suggested that the most important factor in determining results was Research Group, i.e., who conducts the experiment is more important than the classifier algorithms being investigated. A recent re-analysis [2] sought to argue that the effect is less strong than originally claimed since there is a relationship between Research Group and Dataset. In this response we show (i) the re-analysis is based on a small (21 percent) subset of our original data, (ii) using the same re-analysis approach with a larger subset shows that Research Group is more important than type of Classifier and (iii) however the data are analysed there is compelling evidence that who conducts the research has an effect on the results. This means that the problem of researcher bias remains. Addressing it should be seen as a matter of priority amongst those of us who conduct and publish experiments comparing the performance of competing software defect prediction systems.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2017.2731308",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7990255",
      "Author_Keywords": "Software quality assurance;defect prediction;researcher bias",
      "IEEE_Terms": "Software;NASA;Measurement;Analysis of variance;Data models;Predictive models;Analytical models",
      "Article Citation Count": "8",
      "Reference Count": "5",
      "License": "IEEE",
      "Online Date": "24-Jul-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Identifying Vulnerable IoT Applications using Deep Learning",
      "Authors": "H. Naeem; M. H. Alalfi",
      "Author Affiliations": "Department of Computer Science, Ryerson University, Toronto, ON, Canada; Department of Computer Science, Ryerson University, Toronto, ON, Canada",
      "Publication Title": "2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "2-Apr-20",
      "Publication Year": "2020",
      "Start Page": "582",
      "End Page": "586",
      "Abstract": "This paper presents an approach for the identification of vulnerable IoT applications using deep learning algorithms. The approach focuses on a category of vulnerabilities that leads to sensitive information leakage which can be identified using taint flow analysis. First, we analyze the source code of IoT apps in order to recover tokens along their frequencies and tainted flows. Second, we develop, Token2Vec, which transforms the source code tokens into vectors. We have also developed Flow2Vec, which transforms the identified tainted flows into vectors. Third, we use the recovered vectors to train a deep learning algorithm to build a model for the identification of tainted apps. We have evaluated the approach on two datasets and the experiments show that the proposed approach of combining tainted flows features with the base benchmark that uses token frequencies only, has improved the accuracy of the prediction models from 77.78% to 92.59% for Corpus1 and 61.11% to 87.03% for Corpus2.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-7281-5143-4",
      "DOI": "10.1109/SANER48275.2020.9054817",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054817",
      "IEEE_Terms": "Deep learning;Training;Codes;Software algorithms;Transforms;Tools;Predictive models",
      "Article Citation Count": "5",
      "Reference Count": "10",
      "License": "IEEE",
      "Online Date": "2-Apr-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Adaptive Immunity for Software: Towards Autonomous Self-healing Systems",
      "Authors": "M. Ali Naqvi; M. Astekin; S. Malik; L. Moonen",
      "Author Affiliations": "Simula Research Laboratory, Oslo, Norway; Simula Research Laboratory, Oslo, Norway; Simula Research Laboratory, Oslo, Norway; Simula Research Laboratory, Oslo, Norway",
      "Publication Title": "2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "11-May-21",
      "Publication Year": "2021",
      "Start Page": "521",
      "End Page": "525",
      "Abstract": "Testing and code reviews are known techniques to improve the quality and robustness of software. Unfortunately, the complexity of modern software systems makes it impossible to anticipate all possible problems that can occur at runtime, which limits what issues can be found using testing and reviews. Thus, it is of interest to consider autonomous self-healing software systems, which can automatically detect, diagnose, and contain unanticipated problems at runtime. Most research in this area has adopted a model-driven approach, where actual behavior is checked against a model specifying the intended behavior, and a controller takes action when the system behaves outside of the specification. However, it is not easy to develop these specifications, nor to keep them up-to-date as the system evolves. We pose that, with the recent advances in machine learning, such models may be learned by observing the system. Moreover, we argue that artificial immune systems (AISs) are particularly well-suited for building self-healing systems, because of their anomaly detection and diagnosis capabilities. We present the state-of-the-art in self-healing systems and in AISs, surveying some of the research directions that have been considered up to now. To help advance the state-of-the-art, we develop a research agenda for building self-healing software systems using AISs, identifying required foundations, and promising research directions.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-7281-9630-5",
      "DOI": "10.1109/SANER50967.2021.00058",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9425979",
      "Author_Keywords": "self-healing;artificial immune systems;anomaly detection;runtime diagnosis;fault containment;dependability",
      "IEEE_Terms": "Runtime;Conferences;Buildings;Machine learning;Software systems;Robustness;Complexity theory",
      "Reference Count": "50",
      "License": "IEEE",
      "Online Date": "11-May-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "DeepAnalyze: Learning to Localize Crashes at Scale",
      "Authors": "M. Shetty; C. Bansal; S. Nath; S. Bowles; H. Wang; O. Arman; S. Ahari",
      "Author Affiliations": "Microsoft Research, Bangalore, India; Microsoft Research, Bangalore, India; Microsoft Research, Bangalore, India; Microsoft, Redmond, USA; Microsoft, Redmond, USA; Microsoft, Redmond, USA; Microsoft, Redmond, USA",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "549",
      "End Page": "560",
      "Abstract": "Crash localization, an important step in debugging crashes, is challenging when dealing with an extremely large number of diverse applications and platforms and underlying root causes. Large-scale error reporting systems, e.g., Windows Error Reporting (WER), commonly rely on manually developed rules and heuristics to localize blamed frames causing the crashes. As new applications and features are routinely introduced and existing applications are run under new environments, developing new rules and maintaining existing ones become extremely challenging. We propose a data-driven solution to address the problem. We start with the first large-scale empirical study of 362K crashes and their blamed methods reported to WER by tens of thousands of applications running in the field. The analysis provides valuable insights on where and how the crashes happen and what methods to blame for the crashes. These insights enable us to develop Deep-Analyze, a novel multi-task sequence labeling approach for identifying blamed frames in stack traces. We evaluate our model with over a million real-world crashes from four popular Microsoft applications and show that DeepAnalyze, trained with crashes from one set of applications, not only accurately localizes crashes of the same applications, but also bootstrap crash localization for other applications with zero to very little additional training data.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3512759",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794075",
      "Author_Keywords": "Software Engineering;Machine Learning;Crash Localization",
      "IEEE_Terms": "Location awareness;Operating systems;Training data;Debugging;Multitasking;Computer crashes;Data models",
      "Reference Count": "62",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Local-based active classification of test report to assist crowdsourced testing",
      "Authors": "J. Wang; S. Wang; Q. Cui; Q. Wang",
      "Author Affiliations": "University of Chinese Academy of Sciences, Beijing, China; Laboratory for Internet Software Technolocies; Laboratory for Internet Software Technolocies; Laboratory for Internet Software Technolocies",
      "Publication Title": "2016 31st IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "6-Oct-16",
      "Publication Year": "2016",
      "Start Page": "190",
      "End Page": "201",
      "Abstract": "In crowdsourced testing, an important task is to identify the test reports that actually reveal fault - true fault, from the large number of test reports submitted by crowd workers. Most existing approaches towards this problem utilized supervised machine learning techniques, which often require users to manually label a large amount of training data. Such process is time-consuming and labor-intensive. Thus, reducing the onerous burden of manual labeling while still being able to achieve good performance is crucial. Active learning is one potential technique to address this challenge, which aims at training a good classifier with as few labeled data as possible. Nevertheless, our observation on real industrial data reveals that existing active learning approaches generate poor and unstable performances on crowdsourced testing data. We analyze the deep reason and find that the dataset has significant local biases. To address the above problems, we propose LOcal-based Active ClassiFication (LOAF) to classify true fault from crowdsourced test reports. LOAF recommends a small portion of instances which are most informative within local neighborhood, and asks user their labels, then learns classifiers based on local neighborhood. Our evaluation on 14,609 test reports of 34 commercial projects from one of the Chinese largest crowdsourced testing platforms shows that our proposed LOAF can generate promising results. In addition, its performance is even better than existing supervised learning approaches which built on large amounts of labelled historical data. Moreover, we also implement our approach and evaluate its usefulness using real-world case studies. The feedbacks from testers demonstrate its practical value.",
      "ISBNs": "978-1-4503-3845-5",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582757",
      "Author_Keywords": "Crowdsourced Testing;Test Report Classification;Active Learning",
      "IEEE_Terms": "Testing;Software;Feature extraction;Labeling;Training data;Speech recognition;Manuals",
      "Article Citation Count": "4",
      "Reference Count": "44",
      "Online Date": "6-Oct-16",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Natural Language Processing Approach for Instruction Set Architecture Identification",
      "Authors": "D. Sahabandu; J. S. Mertoguno; R. Poovendran",
      "Author Affiliations": "Department of Electrical and Computer Engineering, Network Security Laboratory, University of Washington, Seattle, WA, USA; Institute for Information Security and Privacy, Georgia Institute of Technology, Atlanta, GA, USA; Department of Electrical and Computer Engineering, Network Security Laboratory, University of Washington, Seattle, WA, USA",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "20-Jul-23",
      "Publication Year": "2023",
      "Volume": "18",
      "Start Page": "4086",
      "End Page": "4099",
      "Abstract": "Binary analysis of software is a critical step in cyber forensics applications such as program vulnerability assessment and malware detection. This involves interpreting instructions executed by software and often necessitates converting the software‚Äôs binary file data to assembly language. The conversion process requires information about the binary file‚Äôs target instruction set architecture (ISA). However, ISA information might not be included in binary files due to compilation errors, partial downloads, or adversarial corruption of file metadata. Machine learning (ML) is a promising methodology that can be used to identify the target ISA using binary data in the object code section of binary files. In this paper we propose a binary code feature extraction model to improve the accuracy and scalability of ML-based ISA identification methods. Our feature extraction model can be used in the absence of domain knowledge about the ISAs. Specifically, we adapt models from natural language processing (NLP) to i) identify successive byte patterns commonly observed in binary codes, ii) estimate the significance of each byte pattern to a binary file, and iii) estimate the relevance of each byte pattern in distinguishing between ISAs. We introduce character-level features of encoded binaries to identify fine-grained bit patterns inherent to each ISA. We evaluate our approach using two different datasets: binaries from 12 ISAs and 23 ISAs. Empirical evaluations show that using our byte-level features in ML-based ISA identification results in ~98% accuracy compared to the ~91% accuracy of state-of-the-art features based on byte-histograms and byte pattern signatures. We observe that character-level features allow reducing the size of the feature set by up to 16x while maintaining accuracy of ISA identification above 97%.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2023.3288456",
      "Funding Information": "ONR(grant numbers:N00014-20-1-2636,N00014-23-1-2386); DARPA SSITH(grant numbers:D22AC00123-00); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10159173",
      "Author_Keywords": "Computer architecture;natural language processing(NLP);machine learning (ML)",
      "IEEE_Terms": "Feature extraction;Codes;Natural language processing;Computer architecture;Source coding;Registers;Reduced instruction set computing",
      "Article Citation Count": "1",
      "Reference Count": "61",
      "License": "IEEE",
      "Online Date": "21-Jun-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Bugsplainer: Leveraging Code Structures to Explain Software Bugs with Neural Machine Translation",
      "Authors": "P. Mahbub; M. M. Rahman; O. Shuvo; A. Gopal",
      "Author Affiliations": "Dalhousie University, Canada; Dalhousie University, Canada; Dalhousie University, Canada; Metabob Inc., USA",
      "Publication Title": "2023 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "11-Dec-23",
      "Publication Year": "2023",
      "Start Page": "530",
      "End Page": "535",
      "Abstract": "Software bugs cost the global economy billions of dollars each year and take up ‚âà50% of the development time. Once a bug is reported, the assigned developer attempts to identify and understand the source code responsible for the bug and then corrects the code. Over the last five decades, there has been significant research on automatically finding or correcting software bugs. However, there has been little research on automatically explaining the bugs to the developers, which is essential but a highly challenging task. In this paper, we propose Bugsplainer, a novel web-based debugging solution that generates natural language explanations for software bugs by learning from a large corpus of bug-fix commits. Bugsplainer leverages code structures to reason about a bug and employs the fine-tuned version of a text generation model ‚Äì CodeT5 ‚Äì to generate the explanations.Tool video: https://youtu.be/xga-ScvULpk",
      "ISSN": "2576-3148",
      "ISBNs": "979-8-3503-2783-0",
      "DOI": "10.1109/ICSME58846.2023.00067",
      "Funding Information": "Dalhousie University; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10336326",
      "Author_Keywords": "software bug;bug explanation;software maintenance;software engineering;natural language processing;deep learning;neural text generation",
      "IEEE_Terms": "Software maintenance;Java;Codes;Source coding;Computer bugs;Natural languages;Debugging",
      "Reference Count": "33",
      "License": "IEEE",
      "Online Date": "11-Dec-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "LogOptPlus: Learning to Optimize Logging in Catch and If Programming Constructs",
      "Authors": "S. Lal; N. Sardana; A. Sureka",
      "Author Affiliations": "JIIT, Noida, Uttar Pradesh, India; JIIT, Noida, Uttar Pradesh, India; JIIT, Noida, Uttar Pradesh, India",
      "Publication Title": "2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "25-Aug-16",
      "Publication Year": "2016",
      "Volume": "1",
      "Start Page": "215",
      "End Page": "220",
      "Abstract": "Software logging is a common software development practice which is used to log program execution points. This execution information is later used by software developers for debugging purpose. Software logging is useful but it has cost and benefit tradeoff. Hence it is important to optimize the number of log statements in the code. However, previous studies on logging show that optimal logging is challenging for software developers. Hence tools and techniques which can help developers in making optimized logging decision can be beneficial. We propose LogOptPlus, a machine learning based tool to help software developers to optimize the number of log statements in the source code, for two focused code construct types. LogOptPlus is a significant extension of our previously published work 'LogOpt'. LogOpt is designed to predict logging for catch-blocks. We extend the functionality of LogOpt to predict logging for both if-blocks and catch-blocks. We identify distinguishing static features from the source code for logging prediction. We present intuition and results of quantitative analysis of all the features. We present results of comprehensive evaluation of LogOptPlus with five different machine learning algorithms on two two large Open Source projects (i.e., Apache Tomcat and CloudStack). Encouraging experimental results on two Open Source projects show that LogOptPlus is effective in logging prediction for two focused code construct types.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-4673-8845-0",
      "DOI": "10.1109/COMPSAC.2016.149",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552011",
      "Author_Keywords": "Logging;Machine Learning;Source Code Analysis;Software Debugging and Maintenance;Tracing",
      "IEEE_Terms": "Feature extraction;Software;Containers;Debugging;Java;Complexity theory;Statistical analysis",
      "Article Citation Count": "10",
      "Reference Count": "8",
      "License": "IEEE",
      "Online Date": "25-Aug-16",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Scalable and Accurate Test Case Prioritization in Continuous Integration Contexts",
      "Authors": "A. S. Yaraghi; M. Bagherzadeh; N. Kahani; L. C. Briand",
      "Author Affiliations": "School of EECS, University of Ottawa, Ottawa, ON, Canada; School of EECS, University of Ottawa, Ottawa, ON, Canada; Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada; School of EECS, University of Ottawa, Ottawa, ON, Canada",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "18-Apr-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "4",
      "Start Page": "1615",
      "End Page": "1639",
      "Abstract": "Continuous Integration (CI) requires efficient regression testing to ensure software quality without significantly delaying its CI builds. This warrants the need for techniques to reduce regression testing time, such as Test Case Prioritization (TCP) techniques that prioritize the execution of test cases to detect faults as early as possible. Many recent TCP studies employ various Machine Learning (ML) techniques to deal with the dynamic and complex nature of CI. However, most of them use a limited number of features for training ML models and evaluate the models on subjects for which the application of TCP makes little practical sense, due to their small regression testing time and low number of failed builds. In this work, we first define, at a conceptual level, a data model that captures data sources and their relations in a typical CI environment. Second, based on this data model, we define a comprehensive set of features that covers all features previously used by related studies. Third, we develop methods and tools to collect the defined features for 25 open-source software systems with enough failed builds and whose regression testing takes at least five minutes. Fourth, relying on the collected dataset containing a comprehensive feature set, we answer four research questions concerning data collection time, the effectiveness of ML-based TCP, the impact of the features on effectiveness, the decay of ML-based TCP models over time, and the trade-off between data collection time and the effectiveness of ML-based TCP techniques.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2022.3184842",
      "Funding Information": "Huawei Technologies Canada; Mitacs; Natural Sciences and Engineering Research Council of Canada; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9801672",
      "Author_Keywords": "Machine learning;software testing;test case prioritization;test case selection;continuous integration",
      "IEEE_Terms": "Feature extraction;Codes;Testing;History;Training;Data collection;Computational modeling",
      "Article Citation Count": "8",
      "Reference Count": "71",
      "License": "IEEE",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Identifying Compiler and Optimization Options from Binary Code using Deep Learning Approaches",
      "Authors": "D. Pizzolotto; K. Inoue",
      "Author Affiliations": "Osaka University, Osaka, Japan; Osaka University, Osaka, Japan",
      "Publication Title": "2020 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "2-Nov-20",
      "Publication Year": "2020",
      "Start Page": "232",
      "End Page": "242",
      "Abstract": "When compiling a source file, several flags can be passed to the compiler. These flags, however, can vary between debug and release compilation. In the release compilation, in fact, smaller or faster executables are usually preferred, whereas for a debug one, ease-of-debug is preferred over speed and no optimization is involved. After the compilation, however, most of the flags used cannot be inferred from the compiled file. These flags could be useful in case we want to classify if an older build was made for release or debug purposes, or to check if the file was compiled with flags that could expose vulnerabilities. In this paper we present a deep learning network capable of automatically detecting, with function granularity, the compiler used and the presence of optimization with 99% accuracy. We also analyze the change in accuracy when submitting increasingly shorter amounts of data, from 2048 up to a single byte, obtaining competitive results with less than 100 bytes. We also present our process in the huge dataset creation and manipulation, along with a comparison with other less successful networks using functions of varying size.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-7281-5619-4",
      "DOI": "10.1109/ICSME46990.2020.00031",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240714",
      "Author_Keywords": "Static Analysis;Binary Analysis;Deep Learning;Compilers",
      "IEEE_Terms": "Deep learning;Software maintenance;Conferences;Binary codes;Convolutional neural networks;Optimization",
      "Article Citation Count": "8",
      "Reference Count": "28",
      "License": "IEEE",
      "Online Date": "2-Nov-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "SWAN_ASSIST: Semi-Automated Detection of Code-Specific, Security-Relevant Methods",
      "Authors": "G. Piskachev; L. Nguyen Quang Do; O. Johnson; E. Bodden",
      "Author Affiliations": "Fraunhofer IEM; Paderborn University; Fraunhofer IEM; Paderborn University",
      "Publication Title": "2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "9-Jan-20",
      "Publication Year": "2019",
      "Start Page": "1094",
      "End Page": "1097",
      "Abstract": "To detect specific types of bugs and vulnerabilities, static analysis tools must be correctly configured with security-relevant methods (SRM), e.g., sources, sinks, sanitizers and authentication methods-usually a very labour-intensive and error-prone process. This work presents the semi-automated tool SWAN_ASSIST, which aids the configuration with an IntelliJ plugin based on active machine learning. It integrates our novel automated machine-learning approach SWAN, which identifies and classifies Java SRM. SWAN_ASSIST further integrates user feedback through iterative learning. SWAN_ASSIST aids developers by asking them to classify at each point in time exactly those methods whose classification best impact the classification result. Our experiments show that SWAN_ASSIST classifies SRM with a high precision, and requires a relatively low effort from the user. A video demo of SWAN_ASSIST can be found at https://youtu.be/fSyD3V6EQOY. The source code is available at https://github.com/secure-software-engineering/swan.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-7281-2508-4",
      "DOI": "10.1109/ASE.2019.00110",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952264",
      "Author_Keywords": "Program Analysis;Security;Machine-Learning",
      "IEEE_Terms": "Training;Java;Machine learning;Authentication;Libraries;Graphical user interfaces",
      "Article Citation Count": "1",
      "Reference Count": "9",
      "License": "IEEE",
      "Online Date": "9-Jan-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Understanding the Automated Parameter Optimization on Transfer Learning for Cross-Project Defect Prediction: An Empirical Study",
      "Authors": "K. Li; Z. Xiang; T. Chen; S. Wang; K. C. Tan",
      "Author Affiliations": "Department of Computer Science, University of Exeter, Exeter, UK; College of Computer Science and Engineering, UESTC, Chengdu, China; Department of Computer Science, Loughborough University, Loughborough, UK; School of Computer Science, University of Birmingham, Birmingham, UK; Department of Computer Science, City University of Hong Kong, Hong Kong SAR",
      "Publication Title": "2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "21-Dec-20",
      "Publication Year": "2020",
      "Start Page": "566",
      "End Page": "577",
      "Abstract": "Data-driven defect prediction has become increasingly important in software engineering process. Since it is not uncommon that data from a software project is insufficient for training a reliable defect prediction model, transfer learning that borrows data/konwledge from other projects to facilitate the model building at the current project, namely cross-project defect prediction (CPDP), is naturally plausible. Most CPDP techniques involve two major steps, i.e., transfer learning and classification, each of which has at least one parameter to be tuned to achieve their optimal performance. This practice fits well with the purpose of automated parameter optimization. However, there is a lack of thorough understanding about what are the impacts of automated parameter optimization on various CPDP techniques. In this paper, we present the first empirical study that looks into such impacts on 62 CPDP techniques, 13 of which are chosen from the existing CPDP literature while the other 49 ones have not been explored before. We build defect prediction models over 20 real-world software projects that are of different scales and characteristics. Our findings demonstrate that: (1) Automated parameter optimization substantially improves the defect prediction performance of 77% CPDP techniques with a manageable computational cost. Thus more efforts on this aspect are required in future CPDP studies. (2) Transfer learning is of ultimate importance in CPDP. Given a tight computational budget, it is more cost-effective to focus on optimizing the parameter configuration of transfer learning algorithms (3) The research on CPDP is far from mature where it is ‚Äònot difficult‚Äô to find a better alternative by making a combination of existing transfer learning and classification techniques. This finding provides important insights about the future design of CPDP techniques.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-7121-6",
      "DOI": "10.1145/3377811.3380360",
      "Funding Information": "Royal Society(grant numbers:IEC/NSFC/170243); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284059",
      "Author_Keywords": "Cross-project defect prediction;transfer learning;classification techniques;automated parameter optimization",
      "IEEE_Terms": "Training;Predictive models;Software;Data models;Optimization;Tuning;Software engineering",
      "Article Citation Count": "12",
      "Reference Count": "70",
      "Online Date": "21-Dec-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Predictive Mutation Testing",
      "Authors": "J. Zhang; L. Zhang; M. Harman; D. Hao; Y. Jia; L. Zhang",
      "Author Affiliations": "Institute of Software, EECS, Peking University, Beijing, China; Department of Computer Science, University of Texas at Dallas, Richardson, TX; Facebook, London, United Kingdom; Institute of Software, EECS, Peking University, Beijing, China; Facebook, London, United Kingdom; Institute of Software, EECS, Peking University, Beijing, China",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "17-Sep-19",
      "Publication Year": "2019",
      "Volume": "45",
      "Issue": "9",
      "Start Page": "898",
      "End Page": "918",
      "Abstract": "Test suites play a key role in ensuring software quality. A good test suite may detect more faults than a poor-quality one. Mutation testing is a powerful methodology for evaluating the fault-detection ability of test suites. In mutation testing, a large number of mutants may be generated and need to be executed against the test suite under evaluation to check how many mutants the test suite is able to detect, as well as the kind of mutants that the current test suite fails to detect. Consequently, although highly effective, mutation testing is widely recognized to be also computationally expensive, inhibiting wider uptake. To alleviate this efficiency concern, we propose Predictive Mutation Testing (PMT): the first approach to predicting mutation testing results without executing mutants. In particular, PMT constructs a classification model, based on a series of features related to mutants and tests, and uses the model to predict whether a mutant would be killed or remain alive without executing it. PMT has been evaluated on 163 real-world projects under two application scenarios (cross-version and cross-project). The experimental results demonstrate that PMT improves the efficiency of mutation testing by up to 151.4X while incurring only a small accuracy loss. It achieves above 0.80 AUC values for the majority of projects, indicating a good tradeoff between the efficiency and effectiveness of predictive mutation testing. Also, PMT is shown to perform well on different tools and tests, be robust in the presence of imbalanced data, and have high predictability (over 60 percent confidence) when predicting the execution results of the majority of mutants.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2018.2809496",
      "Funding Information": "National Basic Research Program of China (973 Program)(grant numbers:2016YFB1000801); National Natural Science Foundation of China(grant numbers:61522201,61529201); NSF(grant numbers:CCF-1566589); EPSRC grant DAASE Dynamic Adaptive Automated Software Engineering(grant numbers:EP/J017515/); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8304576",
      "Author_Keywords": "PMT;mutation testing;machine learning;binary classification",
      "IEEE_Terms": "Predictive models;Pattern classification;Software testing;Sensitivity analysis;Software quality;Machine learning",
      "Article Citation Count": "78",
      "Reference Count": "105",
      "License": "IEEE",
      "Online Date": "28-Feb-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "PatchNet: Hierarchical Deep Learning-Based Stable Patch Identification for the Linux Kernel",
      "Authors": "T. Hoang; J. Lawall; Y. Tian; R. J. Oentaryo; D. Lo",
      "Author Affiliations": "Singapore Management University, Singapore; Inria, LIP6, Sorbonne University, Paris, France; Queen's University, Kingston, ON, Canada; McLaren Applied Technologies, Singapore; Singapore Management University, Singapore",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "11-Nov-21",
      "Publication Year": "2021",
      "Volume": "47",
      "Issue": "11",
      "Start Page": "2471",
      "End Page": "2486",
      "Abstract": "Linux kernel stable versions serve the needs of users who value stability of the kernel over new features. The quality of such stable versions depends on the initiative of kernel developers and maintainers to propagate bug fixing patches to the stable versions. Thus, it is desirable to consider to what extent this process can be automated. A previous approach relies on words from commit messages and a small set of manually constructed code features. This approach, however, shows only moderate accuracy. In this paper, we investigate whether deep learning can provide a more accurate solution. We propose PatchNet, a hierarchical deep learning-based approach capable of automatically extracting features from commit messages and commit code and using them to identify stable patches. PatchNet contains a deep hierarchical structure that mirrors the hierarchical and sequential structure of commit code, making it distinctive from the existing deep learning models on source code. Experiments on 82,403 recent Linux patches confirm the superiority of PatchNet against various state-of-the-art baselines, including the one recently-adopted by Linux kernel maintainers.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2019.2952614",
      "Funding Information": "National Research Foundation Singapore(grant numbers:NRF2016-NRF-ANR003); ANR ITrans; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8896061",
      "Author_Keywords": "Linux kernel;patch classification;deep learning",
      "IEEE_Terms": "Kernel;Linux;Computer bugs;Feature extraction;Deep learning;Indexes;Manuals",
      "Article Citation Count": "12",
      "Reference Count": "72",
      "License": "IEEE",
      "Online Date": "11-Nov-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Style-Analyzer: Fixing Code Style Inconsistencies with Interpretable Unsupervised Algorithms",
      "Authors": "V. Markovtsev; W. Long; H. Mougard; K. Slavnov; E. Bulychev",
      "Author Affiliations": "source{d}, Madrid, Spain; source{d}, Madrid, Spain; source{d}, Madrid, Spain; source{d}, Madrid, Spain; source{d}, Madrid, Spain",
      "Publication Title": "2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "29-Aug-19",
      "Publication Year": "2019",
      "Start Page": "468",
      "End Page": "478",
      "Abstract": "Source code reviews are manual, time-consuming, and expensive. Human involvement should be focused on analyzing the most relevant aspects of the program, such as logic and maintainability, rather than amending style, syntax, or formatting defects. Some tools with linting capabilities can format code automatically and report various stylistic violations for supported programming languages. They are based on rules written by domain experts, hence, their configuration is often tedious, and it is impractical for the given set of rules to cover all possible corner cases. Some machine learning-based solutions exist, but they remain uninterpretable black boxes. This paper introduces style-analyzer, a new open source tool to automatically fix code formatting violations using the decision tree forest model which adapts to each codebase and is fully unsupervised. style-analyzer is built on top of our novel assisted code review framework, Lookout. It accurately mines the formatting style of each analyzed Git repository and expresses the found format patterns with compact human-readable rules. style-analyzer can then suggest style inconsistency fixes in the form of code review comments. We evaluate the output quality and practical relevance of style-analyzer by demonstrating that it can reproduce the original style with high precision, measured on 19 popular JavaScript projects, and by showing that it yields promising results in fixing real style mistakes. style-analyzer includes a web application to visualize how the rules are triggered. We release style-analyzer as a reusable and extendable open source software package on GitHub for the benefit of the community.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-7281-3412-3",
      "DOI": "10.1109/MSR.2019.00073",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8816753",
      "Author_Keywords": "assisted code review, code style, decision tree forest, interpretable machine learning",
      "IEEE_Terms": "Decision trees;Feature extraction;Tools;Machine learning;Forestry;Syntactics;Training",
      "Article Citation Count": "5",
      "Reference Count": "23",
      "License": "IEEE",
      "Online Date": "29-Aug-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Dynamically Generate Password Policy via Zipf Distribution",
      "Authors": "Y. Xiao; J. Zeng",
      "Author Affiliations": "School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "3-Mar-22",
      "Publication Year": "2022",
      "Volume": "17",
      "Start Page": "835",
      "End Page": "848",
      "Abstract": "Password composition policies are helpful in strengthening password‚Äôs resistance against guessing attacks. Sadly, existing off-the-shelf composition policies often remain static, which creates potential security vulnerability. In this paper, we propose a new adaptive password policy generation framework called HTPG. Based on the Zipf distribution of passwords, HTPG classifies all passwords in data set into two categories, that is, head passwords and tail passwords. We find that head passwords are vulnerable and high-value for attackers because they are most frequently used, while tail passwords have higher strength than head passwords. According to this fact, HTPG dynamically generates policies to enhance head passwords by modifying them so as to be closer to tail passwords on feature space. By introducing the idea of machine learning, we propose a policy sort method based on information gain ratio to help user choose more effective policies in enhancing head passwords. HTPG can effectively improve the security of entire password data set and make the password distribution more uniform. Experiments show that the number of cracked head passwords decreases 69% on average, compared with the original head passwords, by adopting policies generated by HTPG. Surveys on usability show that 80.23% enhanced passwords can be recalled by those who remember the corresponding original passwords.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2022.3152357",
      "Funding Information": "Shanghai Municipal Natural Science Foundation(grant numbers:151403700); Joint Foundation for Industry and Education, Ministry of Education, China(grant numbers:2017A03021); National Key Research and Development Program of China(grant numbers:20170803203); National Key Research and Development Program of China(grant numbers:20160800101); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9715109",
      "Author_Keywords": "Authentication;Zipf distribution;machine learning;password policy",
      "IEEE_Terms": "Passwords;Magnetic heads;Security;Usability;Machine learning;Generators;Blocklists",
      "Article Citation Count": "3",
      "Reference Count": "37",
      "License": "IEEE",
      "Online Date": "16-Feb-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "2PCLA: Provable Secure and Privacy Preserving Enhanced Certificateless Authentication Scheme for Distributed Learning",
      "Authors": "Y. Ma; Q. Cheng; X. Luo",
      "Author Affiliations": "Fourth Department, Information Engineering University, Zhengzhou, China; Fourth Department, Information Engineering University, Zhengzhou, China; Henan Province Key Laboratory of Cyberspace Situation Awareness, Zhengzhou, China",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "9-Oct-23",
      "Publication Year": "2023",
      "Volume": "18",
      "Start Page": "5876",
      "End Page": "5889",
      "Abstract": "Distributed learning (DL) emerges as machine learning and the Internet of Things develop quickly and widely. As edge servers pre-process and pre-learn the statistics, global servers can reduce costs, improve efficiency and output more precise results. However, to acquire high-quality and adequate data, servers should collect information from a number of end devices, which naturally leads to confidentiality and privacy problems during information transmission. If the private information or the data are compromised by malicious attackers, the users‚Äô security and the network operation will all be in danger. To resolve this thorny challenge, numerous schemes have been put forward, adopting different cryptography technologies and aiming at aspects of security. However, many state-of-the-art schemes can hardly satisfy the security demands and are pointed out to be defective. Lately, Jiang et al. made an effort and proposed a certificateless signature scheme, as well as an authentication scheme for the purpose of solving the privacy issues. Unfortunately, in this paper, we point out that their schemes can hardly resist forgery attacks and ephemeral key leakage attacks. Further, we will propose an improved scheme noted as 2PCLA and change the method of generating the session key. Theoretical analysis and formal security analysis utilizing Tamarin analysis tool are provided to prove the security of 2PCLA scheme. Performance evaluation has been done from both theoretical and experimental perspectives. The assessment results illustrate that 2PCLA can balance security properties with execution efficiency relatively well.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2023.3318952",
      "Funding Information": "National Key Research and Development Program of China(grant numbers:2022YFB3102900); National Natural Science Foundation of China(grant numbers:61872449,62172433,62172435); Science Foundation for the Excellent Youth Scholars of Henan Province(grant numbers:222300420099); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10262019",
      "Author_Keywords": "Distributed learning (DL);certificateless-based cryptography;privacy preservation;authentication",
      "IEEE_Terms": "Security;Servers;Authentication;Privacy;Protocols;Machine learning;Immune system",
      "Reference Count": "26",
      "License": "IEEE",
      "Online Date": "25-Sep-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Fault Localization with Code Coverage Representation Learning",
      "Authors": "Y. Li; S. Wang; T. Nguyen",
      "Author Affiliations": "Department of Informatics, New Jersey Institute of Technology, New Jersey, USA; Department of Informatics, New Jersey Institute of Technology, New Jersey, USA; University of Texas at Dallas, Dallas, TX, USA",
      "Publication Title": "2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "7-May-21",
      "Publication Year": "2021",
      "Start Page": "661",
      "End Page": "673",
      "Abstract": "In this paper, we propose DeepRL4FL, a deep learning fault localization (FL) approach that locates the buggy code at the statement and method levels by treating FL as an image pattern recognition problem. DeepRL4FL does so via novel code coverage representation learning (RL) and data dependencies RL for program statements. Those two types of RL on the dynamic information in a code coverage matrix are also combined with the code representation learning on the static information of the usual suspicious source code. This combination is inspired by crime scene investigation in which investigators analyze the crime scene (failed test cases and statements) and related persons (statements with dependencies), and at the same time, examine the usual suspects who have committed a similar crime in the past (similar buggy code in the training data). For the code coverage information, DeepRL4FL first orders the test cases and marks error-exhibiting code statements, expecting that a model can recognize the patterns discriminating between faulty and non-faulty statements/methods. For dependencies among statements, the suspiciousness of a statement is seen taking into account the data dependencies to other statements in execution and data flows, in addition to the statement by itself. Finally, the vector representations for code coverage matrix, data dependencies among statements, and source code are combined and used as the input of a classifier built from a Convolution Neural Network to detect buggy statements/methods. Our empirical evaluation shows that DeepRL4FL improves the top-1 results over the state-of-the-art statement-level FL baselines from 173.1% to 491.7%. It also improves the top-1 results over the existing method-level FL baselines from 15.0% to 206.3%.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-0296-5",
      "DOI": "10.1109/ICSE43902.2021.00067",
      "Funding Information": "National Science Foundation; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9402079",
      "Author_Keywords": "Fault Localization;Code Coverage;Representation Learning;Machine Learning;Deep Learning",
      "IEEE_Terms": "Location awareness;Deep learning;Training;Image recognition;Neural networks;Pattern recognition;Software engineering",
      "Article Citation Count": "39",
      "Reference Count": "60",
      "License": "IEEE",
      "Online Date": "7-May-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Improving Machine Translation Systems via Isotopic Replacement",
      "Authors": "Z. Sun; J. M. Zhang; Y. Xiong; M. Harman; M. Papadakis; L. Zhang",
      "Author Affiliations": "Key Laboratory of High Confidence Software Technologies, MoE, School of Computer Science, Peking University; University College London; Key Laboratory of High Confidence Software Technologies, MoE, School of Computer Science, Peking University; Meta platforms, University College London; University of Luxembourg; Key Laboratory of High Confidence Software Technologies, MoE, School of Computer Science, Peking University",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "1181",
      "End Page": "1192",
      "Abstract": "Machine translation plays an essential role in people's daily international communication. However, machine translation systems are far from perfect. To tackle this problem, researchers have proposed several approaches to testing machine translation. A promising trend among these approaches is to use word replacement, where only one word in the original sentence is replaced with another word to form a sentence pair. However, precise control of the impact of word replacement remains an outstanding issue in these approaches. To address this issue, we propose CAT, a novel word-replacement-based approach, whose basic idea is to identify word replacement with controlled impact (referred to as isotopic replacement). To achieve this purpose, we use a neural-based language model to encode the sentence context, and design a neural-network-based algorithm to evaluate context-aware semantic similarity between two words. Furthermore, similar to TransRepair, a state-of-the-art word-replacement-based approach, CAT also provides automatic fixing of revealed bugs without model retraining. Our evaluation on Google Translate and Transformer indicates that CAT achieves significant improvements over TransRepair. In particular, 1) CAT detects seven more types of bugs than TransRe-pair; 2) CAT detects 129% more translation bugs than TransRepair; 3) CAT repairs twice more bugs than TransRepair, many of which may bring serious consequences if left unfixed; and 4) CAT has better efficiency than TransRepair in input generation (0.01s v.s. 0.41s) and comparable efficiency with TransRepair in bug repair (1.92s v.s. 1.34s).",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3510206",
      "Funding Information": "National Key Research and Development Program of China(grant numbers:2019YFE0198100); Innovation and Technology Commission of HKSAR(grant numbers:MHP/055/19); National Natural Science Foundation of China(grant numbers:61922003); ERC(grant numbers:741278); Luxembourg National Research Fund (FNR)(grant numbers:C17/IS/11686509/CODEMATES); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793859",
      "Author_Keywords": "machine translation;testing and repair;machine learning testing;neural networks",
      "IEEE_Terms": "Computer bugs;Semantics;Maintenance engineering;Transformers;Market research;Internet;Machine translation",
      "Article Citation Count": "7",
      "Reference Count": "40",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "SequenceR: Sequence-to-Sequence Learning for End-to-End Program Repair",
      "Authors": "Z. Chen; S. Kommrusch; M. Tufano; L. -N. Pouchet; D. Poshyvanyk; M. Monperrus",
      "Author Affiliations": "KTH Royal Institute of Technology, Stockholm, Sweden; Colorado State University, Fort Collins, CO, USA; The College of William and Mary, Williamsburg, VA, USA; Colorado State University, Fort Collins, CO, USA; The College of William and Mary, Williamsburg, VA, USA; KTH Royal Institute of Technology, Stockholm, Sweden",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "16-Sep-21",
      "Publication Year": "2021",
      "Volume": "47",
      "Issue": "9",
      "Start Page": "1943",
      "End Page": "1959",
      "Abstract": "This paper presents a novel end-to-end approach to program repair based on sequence-to-sequence learning. We devise, implement, and evaluate a technique, called SequenceR, for fixing bugs based on sequence-to-sequence learning on source code. This approach uses the copy mechanism to overcome the unlimited vocabulary problem that occurs with big code. Our system is data-driven; we train it on 35,578 samples, carefully curated from commits to open-source repositories. We evaluate SequenceR on 4,711 independent real bug fixes, as well on the Defects4J benchmark used in program repair research. SequenceR is able to perfectly predict the fixed line for 950/4,711 testing samples, and find correct patches for 14 bugs in Defects4J benchmark. SequenceR captures a wide range of repair operators without any domain-specific top-down design.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2019.2940179",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827954",
      "Author_Keywords": "Program repair;machine learning",
      "IEEE_Terms": "Maintenance engineering;Computer bugs;Vocabulary;Training;Natural languages;Benchmark testing",
      "Article Citation Count": "105",
      "Reference Count": "51",
      "License": "IEEE",
      "Online Date": "10-Sep-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Explainable AI for Software Engineering",
      "Authors": "C. K. Tantithamthavorn; J. Jiarpakdee",
      "Author Affiliations": "Monash University, Melbourne, Australia; Monash University, Melbourne, Australia",
      "Publication Title": "2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "20-Jan-22",
      "Publication Year": "2021",
      "Start Page": "1",
      "End Page": "2",
      "Abstract": "The success of software engineering projects largely depends on complex decision-making. For example, which tasks should a developer do first, who should perform this task, is the software of high quality, is a software system reliable and resilient enough to deploy, etc. However, erroneous decision-making for these complex questions is costly in terms of money and reputation. Thus, Artificial Intelligence/Machine Learning (AI/ML) techniques have been widely used in software engineering for developing software analytics tools and techniques to improve decision-making, developer productivity, and software quality. However, the predictions of such AI/ML models for software engineering are still not practical (i.e., coarse-grained), not explainable, and not actionable. These concerns often hinder the adoption of AI/ML models in software engineering practices. In addition, many recent studies still focus on improving the accuracy, while a few of them focus on improving explainability. Are we moving in the right direction? How can we better improve the SE community (both research and education)?In this tutorial, we first provide a concise yet essential introduction to the most important aspects of Explainable AI and a hands-on tutorial of Explainable AI tools and techniques. Then, we introduce the fundamental knowledge of defect prediction (an example application of AI for Software Engineering). Finally, we demonstrate three successful case studies on how Explainable AI techniques can be used to address the aforementioned challenges by making the predictions of software defect prediction models more practical, explainable, and actionable. The materials are available at https://xai4se.github.io.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-6654-0337-5",
      "DOI": "10.1109/ASE51524.2021.9678580",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9678580",
      "Author_Keywords": "Explainable AI;Software Engineering",
      "IEEE_Terms": "Productivity;Decision making;Tutorials;Software quality;Learning (artificial intelligence);Predictive models;Software systems",
      "Article Citation Count": "27",
      "Reference Count": "17",
      "License": "IEEE",
      "Online Date": "20-Jan-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Evaluating Adversarial Evasion Attacks in the Context of Wireless Communications",
      "Authors": "B. Flowers; R. M. Buehrer; W. C. Headley",
      "Author Affiliations": "Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, USA; Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, USA; Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, USA",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "5-Dec-19",
      "Publication Year": "2020",
      "Volume": "15",
      "Start Page": "1102",
      "End Page": "1113",
      "Abstract": "Recent advancements in radio frequency machine learning (RFML) have demonstrated the use of raw in-phase and quadrature (IQ) samples for multiple spectrum sensing tasks. Yet, deep learning techniques have been shown, in other applications, to be vulnerable to adversarial machine learning (ML) techniques, which seek to craft small perturbations that are added to the input to cause a misclassification. The current work differentiates the threats that adversarial ML poses to RFML systems based on where the attack is executed from: direct access to classifier input, synchronously transmitted over the air (OTA), or asynchronously transmitted from a separate device. Additionally, the current work develops a methodology for evaluating adversarial success in the context of wireless communications, where the primary metric of interest is bit error rate and not human perception, as is the case in image recognition. The methodology is demonstrated using the well known Fast Gradient Sign Method to evaluate the vulnerabilities of raw IQ based Automatic Modulation Classification and concludes RFML is vulnerable to adversarial examples, even in OTA attacks. However, RFML domain specific receiver effects, which would be encountered in an OTA attack, can present significant impairments to adversarial evasion.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2019.2934069",
      "Funding Information": "Bradley Masters Fellowship through the Bradley Department of Electrical and Computer Engineering at Virginia Tech; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8792120",
      "Author_Keywords": "Cognitive radio security;machine learning;modulation classification",
      "IEEE_Terms": "Perturbation methods;Receivers;Transmitters;Wireless communication;Modulation",
      "Article Citation Count": "77",
      "Reference Count": "34",
      "License": "IEEE",
      "Online Date": "8-Aug-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "High Intrinsic Dimensionality Facilitates Adversarial Attack: Theoretical Evidence",
      "Authors": "L. Amsaleg; J. Bailey; A. Barbe; S. M. Erfani; T. Furon; M. E. Houle; M. Radovanoviƒá; X. V. Nguyen",
      "Author Affiliations": "Inria, CNRS, IRISA, Campus de Beaulieu, Univ Rennes, Rennes, France; School of Computing and Information Systems, The University of Melbourne, Parkville, VIC, Australia; Laboratoire de Physique, √âcole Normale Sup√©rieure de Lyon, Lyon, France; School of Computing and Information Systems, The University of Melbourne, Parkville, VIC, Australia; Inria, CNRS, IRISA, Campus de Beaulieu, Univ Rennes, Rennes, France; National Institute of Informatics, Tokyo, Japan; Faculty of Sciences, University of Novi Sad, Novi Sad, Serbia; NVIDIA Corporation, Santa Clara, CA, USA",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "7-Oct-20",
      "Publication Year": "2021",
      "Volume": "16",
      "Start Page": "854",
      "End Page": "865",
      "Abstract": "Machine learning systems are vulnerable to adversarial attack. By applying to the input object a small, carefully-designed perturbation, a classifier can be tricked into making an incorrect prediction. This phenomenon has drawn wide interest, with many attempts made to explain it. However, a complete understanding is yet to emerge. In this paper we adopt a slightly different perspective, still relevant to classification. We consider retrieval, where the output is a set of objects most similar to a user-supplied query object, corresponding to the set of k-nearest neighbors. We investigate the effect of adversarial perturbation on the ranking of objects with respect to a query. Through theoretical analysis, supported by experiments, we demonstrate that as the intrinsic dimensionality of the data domain rises, the amount of perturbation required to subvert neighborhood rankings diminishes, and the vulnerability to adversarial attack rises. We examine two modes of perturbation of the query: either `closer' to the target point, or `farther' from it. We also consider two perspectives: `query-centric', examining the effect of perturbation on the query's own neighborhood ranking, and `target-centric', considering the ranking of the query point in the target's neighborhood set. All four cases correspond to practical scenarios involving classification and retrieval.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2020.3023274",
      "Funding Information": "European(grant numbers:CHIST-ERA ID_IOT); Australian Research Council(grant numbers:DP140101969); ANR-AID Chaire SAIDA; JSPS Kakenhi Kiban (B) Research(grant numbers:18H03296); Serbian National Project(grant numbers:OI174023); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9194069",
      "Author_Keywords": "Adversarial attack;intrinsic dimensionality;nearest neighbor",
      "IEEE_Terms": "Perturbation methods;Feature extraction;Machine learning;Neural networks;Databases;Content-based retrieval;Learning systems",
      "Article Citation Count": "15",
      "Reference Count": "51",
      "License": "IEEE",
      "Online Date": "10-Sep-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "DeepFD: Automated Fault Diagnosis and Localization for Deep Learning Programs",
      "Authors": "J. Cao; M. Li; X. Chen; M. Wen; Y. Tian; B. Wu; S. -C. Cheung",
      "Author Affiliations": "The Hong Kong University of Science and Technology, and Guangzhou HKUST Fok Ying Tung Research Institute, China; The Hong Kong University of Science and Technology, China; The Hong Kong University of Science and Technology, China; The Hong Kong University of Science and Technology, China; University of Waterloo, Canada, and The Hong Kong University of Science and Technology, China; MIT-IBM Watson AI Lab, U.S.; The Hong Kong University of Science and Technology, and Guangzhou HKUST Fok Ying Tung Research Institute, China",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "573",
      "End Page": "585",
      "Abstract": "As Deep Learning (DL) systems are widely deployed for mission-critical applications, debugging such systems becomes essential. Most existing works identify and repair suspicious neurons on the trained Deep Neural Network (DNN), which, unfortunately, might be a detour. Specifically, several existing studies have reported that many unsatisfactory behaviors are actually originated from the faults residing in DL programs. Besides, locating faulty neurons is not actionable for developers, while locating the faulty statements in DL programs can provide developers with more useful information for debugging. Though a few recent studies were proposed to pinpoint the faulty statements in DL programs or the training settings (e.g. too large learning rate), they were mainly designed based on predefined rules, leading to many false alarms or false negatives, especially when the faults are beyond their capabilities. In view of these limitations, in this paper, we proposed DeepFD, a learning-based fault diagnosis and localization framework which maps the fault localization task to a learning problem. In particu-lar, it infers the suspicious fault types via monitoring the runtime features extracted during DNN model training, and then locates the diagnosed faults in DL programs. It overcomes the limitations by identifying the root causes of faults in DL programs instead of neurons, and diagnosing the faults by a learning approach instead of a set of hard-coded rules. The evaluation exhibits the potential of DeepFD. It correctly diagnoses 52% faulty DL programs, compared with around half (27%) achieved by the best state-of-the-art works. Besides, for fault localization, DeepFD also outperforms the existing works, correctly locating 42% faulty programs, which almost doubles the best result (23%) achieved by the existing works.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3510099",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:61932021,62002125); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793970",
      "Author_Keywords": "Neural Networks;Fault Diagnosis;Fault Localization;Debugging",
      "IEEE_Terms": "Location awareness;Fault diagnosis;Deep learning;Training;Runtime;Neurons;Debugging",
      "Article Citation Count": "5",
      "Reference Count": "73",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Prevent: An Unsupervised Approach to Predict Software Failures in Production",
      "Authors": "G. Denaro; R. Heydarov; A. Mohebbi; M. Pezz√®",
      "Author Affiliations": "Department of Informatics, Systems and Communication, University of Milano-Bicocca, Milano, Italy; Faculty of Informatics, USI Universit√† della Svizzera Italiana (USI), Lugano, Switzerland; Faculty of Informatics, USI Universit√† della Svizzera Italiana (USI), Lugano, Switzerland; Faculty of Informatics, USI Universit√† della Svizzera Italiana, Lugano, Switzerland",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "12-Dec-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "12",
      "Start Page": "5139",
      "End Page": "5153",
      "Abstract": "This paper presents Prevent, a fully unsupervised approach to predict and localize failures in distributed enterprise applications. Software failures in production are unavoidable. Predicting failures and locating failing components online are the first steps to proactively manage faults in production. Many techniques predict failures from anomalous combinations of system metrics with supervised, weakly supervised, and semi-supervised learning models. Supervised approaches require large sets of labelled data not commonly available in large enterprise applications, and address failure types that can be either captured with predefined rules or observed while training supervised models. Prevent integrates the core ingredients of unsupervised approaches into a novel fully unsupervised approach to predict failures and localize failing resources. The results of experimenting with Prevent on a commercially-compliant distributed cloud system indicate that Prevent provides more stable, reliable and timely predictions than supervised learning approaches, without requiring the often impractical training with labeled data.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2023.3327583",
      "Funding Information": "Swiss SNF project ASTERIx: Automatic System TEsting of InteRactive software applications(grant numbers:SNF 200021_178742); Italian PRIN project SISMA(grant numbers:PRIN 201752ENYB); Italian PRIN project BigSistah(grant numbers:PRIN 2022EYX28N); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10305549",
      "Author_Keywords": "Failure prediction;distributed applications;machine learning",
      "IEEE_Terms": "Training;Production;Predictive models;Monitoring;Key performance indicator;Training data;Time measurement",
      "Reference Count": "67",
      "License": "CCBY",
      "Online Date": "2-Nov-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Sine-Cosine Algorithm for Software Fault Prediction",
      "Authors": "T. Sharma; O. P. Sangwan",
      "Author Affiliations": "Deptt. of Computer Science and Engineering, G J University of Science and Technology, Hisar, India; Deptt. of Computer Science and Engineering, G J University of Science and Technology, Hisar, India",
      "Publication Title": "2021 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "24-Nov-21",
      "Publication Year": "2021",
      "Start Page": "701",
      "End Page": "706",
      "Abstract": "For developing an efficient and quality Software Fault Prediction (SFP) model, redundant and irrelevant features need to be removed. This task can be achieved, to a significant extent, with Feature Selection (FS) methods. Many empirical studies have been proposed on FS methods (Filter and Wrapper-based) and have shown effective results in reducing the problem of high dimensionality in metrics-based SFP models. This study evaluates the performance of novel wrapper-based Sine Cosine Algorithm (SCA) on five datasets of the AEEEM repository and compares the results with two metaheuristic techniques Genetic Algorithm (GA) and Cuckoo Search algorithm (CSA) on four different Machine Learning (ML) classifiers - Random Forest (RF), Support Vector Machine (SVM), Na√Øve Bayes (NB), and K-Nearest Neighbor (KNN). We found that the application of FS methods (SCA, GA & CSA) has improved the classifier performance. SCA has proved to be more efficient than GA and CSA in terms of lesser convergence time with the smallest subset of selected features and equivalent performance.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-6654-2882-8",
      "DOI": "10.1109/ICSME52107.2021.00084",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9609148",
      "Author_Keywords": "software fault prediction;feature selection;sine cosine algorithm;metaheuristic techniques",
      "IEEE_Terms": "Support vector machines;Software maintenance;Machine learning algorithms;Software algorithms;Stochastic processes;Predictive models;Prediction algorithms",
      "Reference Count": "32",
      "License": "IEEE",
      "Online Date": "24-Nov-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Deep Learning-Based Model for Automated Quality Control in the Pharmaceutical Industry",
      "Authors": "D. Raab; E. Fezer; J. Breitenbach; H. Baumgartl; D. Sauter; R. Buettner",
      "Author Affiliations": "Aalen University, Aalen, Germany; Aalen University, Aalen, Germany; University of Bayreuth, Bayreuth, Germany; Aalen University, Aalen, Germany; Aalen University, Aalen, Germany; University of Bayreuth Fraunhofer FIT, Bayreuth, Germany",
      "Publication Title": "2022 IEEE 46th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "10-Aug-22",
      "Publication Year": "2022",
      "Start Page": "266",
      "End Page": "271",
      "Abstract": "For highly sensitive products such as pharmaceuticals, quality is a decisive factor in ensuring the therapeutic benefit that consumers expect and not jeopardizing consumers' health. So far, the quality control of pharmaceuticals is largely performed manually by qualified individuals. However, this is a time-consuming, repetitive, and error-prone process subject to natural performance fluctuations. To contribute to addressing this issue, we present an automated quality control approach for pharmaceutical capsules using a transfer learning-based convolutional neural network with a balanced accuracy of 97.27%, outperforming all current benchmarks. To increase trust in the model predictions, we incorporated two explainable artificial intelligence (XAI) methods into our approach.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-6654-8810-5",
      "DOI": "10.1109/COMPSAC54236.2022.00045",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9842705",
      "Author_Keywords": "Quality control;defect detection;pharmaceutical industry;pharmaceutical capsules;deep learning;XAI",
      "IEEE_Terms": "Industries;Root cause analysis;Transfer learning;Quality control;Computer architecture;Predictive models;Benchmark testing",
      "Article Citation Count": "1",
      "Reference Count": "55",
      "License": "IEEE",
      "Online Date": "10-Aug-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Software Defect Prediction Using Semi-Supervised Learning with Change Burst Information",
      "Authors": "Q. He; B. Shen; Y. Chen",
      "Author Affiliations": "School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China",
      "Publication Title": "2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "25-Aug-16",
      "Publication Year": "2016",
      "Volume": "1",
      "Start Page": "113",
      "End Page": "122",
      "Abstract": "Software defect prediction is an important software quality assurance technique. It utilizes historical project data and previously discovered defects to predict potential defects. However, most of existing methods assume that large amounts of labeled historical data are available for prediction, while in the early stage of the life cycle, projects may lack the data needed for building such predictors. In addition, most of existing techniques use static code metrics as predictors, while they omit change information that may introduce risks into software development. In this paper, we take these two issues into consideration, and propose a semi-supervised based defect prediction approach - extRF. extRF extends the classical supervised Random Forest algorithm by self-training paradigm. It also employs change burst information for improving accuracy of software defect prediction. We also conduct an experiment to evaluate extRF against three other supervised machine learners (i.e. Logistic Regression, Naive Bayes, Random Forest) and compare the effectiveness of code metrics, change burst metrics, and a combination of them. Experimental results show that extRF trained with a small size of labeled dataset achieves comparable performance to some supervised learning approaches trained with a larger size of labeled dataset. When only 2% of Eclipse 2.0 data are used for training, extRF can achieve F-measure about 0.562, approximate to that of LR (a supervised learning approach) at labeled sampling rate of 50%. Besides, change burst metrics outperform code metrics in that F-measure rises to a peak value of 0.75 for Eclipse 3.0 and JDT.Core.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-4673-8845-0",
      "DOI": "10.1109/COMPSAC.2016.193",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7551999",
      "Author_Keywords": "Defect Prediction;Software Quality Assurance;Semi-supervised Learning;Change Metrics",
      "IEEE_Terms": "Measurement;Software;Predictive models;Vegetation;Data models;Supervised learning;Training",
      "Article Citation Count": "12",
      "Reference Count": "30",
      "License": "IEEE",
      "Online Date": "25-Aug-16",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Learning the Relation Between Code Features and Code Transforms With Structured Prediction",
      "Authors": "Z. Yu; M. Martinez; Z. Chen; T. F. Bissyand√©; M. Monperrus",
      "Author Affiliations": "Shandong University, Jinan, China; Universitat Polit√®cnica de Catalunya, Barcelona, Spain; KTH Royal Institute of Technology, Stockholm, Sweden; University of Luxembourg, Esch-sur-Alzette, Luxembourg; KTH Royal Institute of Technology, Stockholm, Sweden",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "17-Jul-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "7",
      "Start Page": "3872",
      "End Page": "3900",
      "Abstract": "To effectively guide the exploration of the code transform space for automated code evolution techniques, we present in this article the first approach for structurally predicting code transforms at the level of AST nodes using conditional random fields (CRFs). Our approach first learns offline a probabilistic model that captures how certain code transforms are applied to certain AST nodes, and then uses the learned model to predict transforms for arbitrary new, unseen code snippets. Our approach involves a novel representation of both programs and code transforms. Specifically, we introduce the formal framework for defining the so-called AST-level code transforms and we demonstrate how the CRF model can be accordingly designed, learned, and used for prediction. We instantiate our approach in the context of repair transform prediction for Java programs. Our instantiation contains a set of carefully designed code features, deals with the training data imbalance issue, and comprises transform constraints that are specific to code. We conduct a large-scale experimental evaluation based on a dataset of bug fixing commits from real-world Java projects. The results show that when the popular evaluation metric top-3 is used, our approach predicts the code transforms with an accuracy varying from 41% to 53% depending on the transforms. Our model outperforms two baselines based on history probability and neural machine translation (NMT), suggesting the importance of considering code structure in achieving good prediction accuracy. In addition, a proof-of-concept synthesizer is implemented to concretize some repair transforms to get the final patches. The evaluation of the synthesizer on the Defects4j benchmark confirms the usefulness of the predicted AST-level repair transforms in producing high-quality patches.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2023.3275380",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:62102233); Shandong Province Overseas Outstanding Youth Fund(grant numbers:2022HWYQ-043); Qilu Young Scholar Program of Shandong University; Wallenberg Artificial Intelligence; Wallenberg Autonomous Systems and Software Program; Knut och Alice Wallenbergs Stiftelse; Swedish National Infrastructure for Computing; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10130317",
      "Author_Keywords": "Code transform;big code;machine learning;program repair",
      "IEEE_Terms": "Transforms;Codes;Maintenance engineering;Predictive models;Synthesizers;Computer bugs;Feature extraction",
      "Article Citation Count": "1",
      "Reference Count": "113",
      "License": "IEEE",
      "Online Date": "22-May-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Improving Vulnerability Inspection Efficiency Using Active Learning",
      "Authors": "Z. Yu; C. Theisen; L. Williams; T. Menzies",
      "Author Affiliations": "Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Microsoft, Seattle, WA, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "11-Nov-21",
      "Publication Year": "2021",
      "Volume": "47",
      "Issue": "11",
      "Start Page": "2401",
      "End Page": "2420",
      "Abstract": "Software engineers can find vulnerabilities with less effort if they are directed towards code that might contain more vulnerabilities. HARMLESS is an incremental support vector machine tool that builds a vulnerability prediction model from the source code inspected to date, then suggests what source code files should be inspected next. In this way, HARMLESS can reduce the time and effort required to achieve some desired level of recall for finding vulnerabilities. The tool also provides feedback on when to stop (at that desired level of recall) while at the same time, correcting human errors by double-checking suspicious files. This paper evaluates HARMLESS on Mozilla Firefox vulnerability data. HARMLESS found 80, 90, 95, 99 percent of the vulnerabilities by inspecting 10, 16, 20, 34 percent of the source code files. When targeting 90, 95, 99 percent recall, HARMLESS could stop after inspecting 23, 30, 47 percent of the source code files. Even when human reviewers fail to identify half of the vulnerabilities (50 percent false negative rate), HARMLESS could detect 96 percent of the missing vulnerabilities by double-checking half of the inspected files. Our results serve to highlight the very steep cost of protecting software from vulnerabilities (in our case study that cost is, for example, the human effort of inspecting 28,750 √ó 20% = 5,750 source code files to identify 95 percent of the vulnerabilities). While this result could benefit the mission-critical projects where human resources are available for inspecting thousands of source code files, the research challenge for future work is how to further reduce that cost. The conclusion of this paper discusses various ways that goal might be achieved.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2019.2949275",
      "Funding Information": "National Science Foundation(grant numbers:#1506586,#1909516); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8883076",
      "Author_Keywords": "Active learning;security;vulnerabilities;software engineering;error correction",
      "IEEE_Terms": "Inspection;Software;Tools;Security;Predictive models;Error correction;NIST",
      "Article Citation Count": "13",
      "Reference Count": "50",
      "License": "IEEE",
      "Online Date": "25-Oct-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "A Simple NLP-Based Approach to Support Onboarding and Retention in Open Source Communities",
      "Authors": "C. Stanik; L. Montgomery; D. Martens; D. Fucci; W. Maalej",
      "Author Affiliations": "University of Hamburg, Germany; University of Hamburg, Germany; University of Hamburg, Germany; University of Hamburg, Germany; University of Hamburg, Germany",
      "Publication Title": "2018 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "11-Nov-18",
      "Publication Year": "2018",
      "Start Page": "172",
      "End Page": "182",
      "Abstract": "Successful open source communities are constantly looking for new members and helping them become active developers. A common approach for developer onboarding in open source projects is to let newcomers focus on relevant yet easy-to-solve issues to familiarize themselves with the code and the community. The goal of this research is twofold. First, we aim at automatically identifying issues that newcomers can resolve by analyzing the history of resolved issues by simply using the title and description of issues. Second, we aim at automatically identifying issues, that can be resolved by newcomers who later become active developers. We mined the issue trackers of three large open source projects and extracted natural language features from the title and description of resolved issues. In a series of experiments, we optimized and compared the accuracy of four supervised classifiers to address our research goals. Random Forest, achieved up to 91% precision (F1-score 72%) towards the first goal while for the second goal, Decision Tree achieved a precision of 92% (F1-score 91%). A qualitative evaluation gave insights on what information in the issue description is helpful for newcomers. Our approach can be used to automatically identify, label, and recommend issues for newcomers in open source software projects based only on the text of the issues.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-5386-7870-1",
      "DOI": "10.1109/ICSME.2018.00027",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8530027",
      "Author_Keywords": "open source software;onboarding;task selection;newcomers;machine learning;natural language processing",
      "IEEE_Terms": "Feature extraction;Machine learning;Computer bugs;Open source software;Natural language processing;History;Forestry",
      "Article Citation Count": "17",
      "Reference Count": "41",
      "License": "IEEE",
      "Online Date": "11-Nov-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "DIComP: Lightweight Data-Driven Inference of Binary Compiler Provenance with High Accuracy",
      "Authors": "L. Chen; Z. He; H. Wu; F. Xu; Y. Qian; B. Mao",
      "Author Affiliations": "State Key Laboratory for Novel Software Technology, Nanjing University; State Key Laboratory for Novel Software Technology, Nanjing University; State Key Laboratory for Novel Software Technology, Nanjing University; State Key Laboratory for Novel Software Technology, Nanjing University; State Key Laboratory for Novel Software Technology, Nanjing University; State Key Laboratory for Novel Software Technology, Nanjing University",
      "Publication Title": "2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "21-Jul-22",
      "Publication Year": "2022",
      "Start Page": "112",
      "End Page": "122",
      "Abstract": "Binary analysis is pervasively utilized to assess software security and test vulnerabilities without accessing source codes. The analysis validity is heavily influenced by the inferring ability of information related to the code compilation. Among the compilation information, compiler type and optimization level, as the key factors determining how binaries look like, are still difficult to be inferred efficiently with existing tools. In this paper, we conduct a thorough empirical study on the binary's appearance under various compilation settings and propose a lightweight binary analysis tool based on the simplest machine learning method, called DIComP to infer the compiler and optimization level via most relevant features according to the observation. Our comprehensive evaluations demonstrate that DIComP can fully recognize the compiler provenance, and it is effective in inferring the optimization levels with up to 90% accuracy. Also, it is efficient to infer thousands of binaries at a millisecond level with our lightweight machine learning model (1MB).",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-6654-3786-8",
      "DOI": "10.1109/SANER53432.2022.00025",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9825843",
      "Author_Keywords": "Binary Analysis;Compilation Options",
      "IEEE_Terms": "Codes;Conferences;Neural networks;Machine learning;Software;Security;Optimization",
      "Article Citation Count": "3",
      "Reference Count": "28",
      "License": "IEEE",
      "Online Date": "21-Jul-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Predicting Likelihood of Requirement Implementation within the Planned Iteration: An Empirical Study at IBM",
      "Authors": "A. Dehghan; A. Neal; K. Blincoe; J. Linaker; D. Damian",
      "Author Affiliations": "Computer Science Department, University of Victoria, BC, Canada; Persistent Systems, Kanata, ON, Canada; Department of Electrical and Computer Engineering, University of Auckland, New Zealand; Computer Science Department, Lund University, Sweden; Computer Science Department, University of Victoria, BC, Canada",
      "Publication Title": "2017 IEEE/ACM 14th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "3-Jul-17",
      "Publication Year": "2017",
      "Start Page": "124",
      "End Page": "134",
      "Abstract": "There has been a significant interest in the estimation of time and effort in fixing defects among both software practitioners and researchers over the past two decades. However, most of the focus has been on prediction of time and effort in resolving bugs, without much regard to predicting time needed to complete high-level requirements, a critical step in release planning. In this paper, we describe a mixed-method empirical study on three large IBM projects in which we developed and evaluated a process of training a predictive model constituting a set of 29 features in nine categories in order to predict if a requirement will be completed within its planned iteration. We conducted feature engineering through iterative interviews with IBM practitioners as well as analysis of large development repositories of these three projects. Using machine learning techniques, we were able to make predictions on completion time of requirements at four different stages of their lifetime. Using our industrial partner's interest in high precision over recall, we then adopted a cost sensitive learning method and maximized precision of predictions (ranging from 0.8 to 0.97) while maintaining an acceptable recall. We also ranked the features based on their relative importance to the optimized predictive model. We show that although satisfying predictions can be made at early stages, performance of predictions improves over time by taking advantage of requirements' progress data. Furthermore, feature importance ranking results show that although importance of features are highly dependent on project and prediction stage, there are certain features (e.g. requirement creator, time remained to the end of iteration, time since last requirement summary change and number of times requirement has been replanned for a new iteration) that emerge as important across most projects and stages, implying future worthwhile research directions for both researchers and practitioners.",
      "ISBNs": "978-1-5386-1544-7",
      "DOI": "10.1109/MSR.2017.53",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7962362",
      "Author_Keywords": "mining software repositories;machine learning;completion time prediction;release planning",
      "IEEE_Terms": "Software;Predictive models;Computer bugs;Interviews;Planning;History;Computer science",
      "Article Citation Count": "7",
      "Reference Count": "43",
      "License": "IEEE",
      "Online Date": "3-Jul-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Data Transfer and Relevant Metrics Matching Based Approach for Heterogeneous Defect Prediction",
      "Authors": "P. R. Bal; S. Kumar",
      "Author Affiliations": "Department of Computer Science and Engineering, Indian Institute of Technology Roorkee, Roorkee, Uttarakhand, India; Department of Computer Science and Engineering, Indian Institute of Technology Roorkee, Roorkee, Uttarakhand, India",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "14-Mar-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "3",
      "Start Page": "1232",
      "End Page": "1245",
      "Abstract": "Heterogeneous defect prediction (HDP) is a promising research area in the software defect prediction domain to handle the unavailability of the past homogeneous data. In HDP, the prediction is performed using source dataset in which the independent features (metrics) are entirely different than the independent features of target dataset. One important assumption in machine learning is that independent features of the source and target datasets should be relevant to each other for better prediction accuracy. However, these assumptions do not generally hold in HDP. Further in HDP, the selected source dataset for a given target dataset may be of small size causing insufficient training. To resolve these issues, we have proposed a novel heterogeneous data preprocessing method, namely, Transfer of Data from Target dataset to Source dataset selected using Relevance score (TDTSR), for heterogeneous defect prediction. In the proposed approach, we have used chi-square test to select the relevant metrics between source and target datasets and have performed experiments using proposed approach with various machine learning algorithms. Our proposed method shows an improvement of at least 14% in terms of AUC score in the HDP scenario compared to the existing state of the art models.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2022.3173678",
      "Funding Information": "Ministry of Human Resource Development; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9772411",
      "Author_Keywords": "Heterogeneous defect prediction;heterogeneous metrics;chi square test;random forest;relevant metrics",
      "IEEE_Terms": "Measurement;Software;Data models;Predictive models;Kernel;Correlation;Transfer learning",
      "Article Citation Count": "1",
      "Reference Count": "36",
      "License": "IEEE",
      "Online Date": "10-May-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "FedDebug: Systematic Debugging for Federated Learning Applications",
      "Authors": "W. Gill; A. Anwar; M. A. Gulzar",
      "Author Affiliations": "Computer Science Department, Virginia Tech, Blacksburg, USA; Computer Science and Engineering Department, University of Minnesota Twin Cities, Minneapolis, USA; Computer Science Department, Virginia Tech, Blacksburg, USA",
      "Publication Title": "2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "14-Jul-23",
      "Publication Year": "2023",
      "Start Page": "512",
      "End Page": "523",
      "Abstract": "In Federated Learning (FL), clients independently train local models and share them with a central aggregator to build a global model. Impermissibility to access clients' data and collaborative training make FL appealing for applications with data-privacy concerns, such as medical imaging. However, these FL characteristics pose unprecedented challenges for debugging. When a global model's performance deteriorates, identifying the responsible rounds and clients is a major pain point. Developers resort to trial-and-error debugging with subsets of clients, hoping to increase the global model's accuracy or let future FL rounds retune the model, which are time-consuming and costly. We design a systematic fault localization framework, Fedde-bug,that advances the FL debugging on two novel fronts. First, Feddebug enables interactive debugging of realtime collaborative training in FL by leveraging record and replay techniques to construct a simulation that mirrors live FL. Feddebug'sbreakpoint can help inspect an FL state (round, client, and global model) and move between rounds and clients' models seam-lessly, enabling a fine-grained step-by-step inspection. Second, Feddebug automatically identifies the client(s) responsible for lowering the global model's performance without any testing data and labels-both are essential for existing debugging techniques. Feddebug's strengths come from adapting differential testing in conjunction with neuron activations to determine the client(s) deviating from normal behavior. Feddebug achieves 100% accuracy in finding a single faulty client and 90.3% accuracy in finding multiple faulty clients. Feddebug's interactive de-bugging incurs 1.2% overhead during training, while it localizes a faulty client in only 2.1% of a round's training time. With FedDebug,we bring effective debugging practices to federated learning, improving the quality and productivity of FL application developers.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-5701-9",
      "DOI": "10.1109/ICSE48619.2023.00053",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172839",
      "Author_Keywords": "software debugging;federated learning;testing;client;fault localization;neural networks;CNN",
      "IEEE_Terms": "Training;Location awareness;Fault diagnosis;Adaptation models;Systematics;Federated learning;Collaboration",
      "Article Citation Count": "1",
      "Reference Count": "59",
      "License": "IEEE",
      "Online Date": "14-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Dazzle: Using Optimized Generative Adversarial Networks to Address Security Data Class Imbalance Issue",
      "Authors": "R. Shu; T. Xia; L. Williams; T. Menzies",
      "Author Affiliations": "North Carolina State University, USA; North Carolina State University, USA; North Carolina State University, USA; North Carolina State University, USA",
      "Publication Title": "2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "21-Jun-22",
      "Publication Year": "2022",
      "Start Page": "144",
      "End Page": "155",
      "Abstract": "Background: Machine learning techniques have been widely used and demonstrate promising performance in many software security tasks such as software vulnerability prediction. However, the class ratio within software vulnerability datasets is often highly imbalanced (since the percentage of observed vulnerability is usually very low). Goal: To help security practitioners address software security data class imbalanced issues and further help build better prediction models with resampled datasets. Method: We introduce an approach called Dazzle which is an optimized version of conditional Wasserstein Generative Adversarial Networks with gradient penalty (cWGAN-GP). Dazzle explores the architecture hyperparameters of cWGAN-GP with a novel optimizer called Bayesian Optimization. We use Dazzle to generate minority class samples to resample the original imbalanced training dataset. Results: We evaluate Dazzle with three software security datasets, i.e., Moodle vulnerable files, Ambari bug reports, and JavaScript function code. We show that Dazzle is practical to use and demonstrates promising improvement over existing state-of-the-art oversampling techniques such as SMOTE (e.g., with an average of about 60% improvement rate over SMOTE in recall among all datasets). Conclusion: Based on this study, we would suggest the use of optimized GANs as an alternative method for security vulnerability data class imbalanced issues.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-4503-9303-4",
      "DOI": "10.1145/3524842.3528437",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796337",
      "Author_Keywords": "Security Vulnerability Prediction;Class Imbalance;Hyperparameter Optimization;Generative Adversarial Networks",
      "IEEE_Terms": "Training;Computer architecture;Predictive models;Generative adversarial networks;Software;Data models;Security",
      "Article Citation Count": "3",
      "Reference Count": "69",
      "Online Date": "21-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "On the Security of Python Virtual Machines: An Empirical Study",
      "Authors": "X. Lin; B. Hua; Q. Fan",
      "Author Affiliations": "School of Software Engineering, University of Science and Technology of China, China; School of Software Engineering, University of Science and Technology of China, China; School of Software Engineering, University of Science and Technology of China, China",
      "Publication Title": "2022 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "19-Dec-22",
      "Publication Year": "2022",
      "Start Page": "223",
      "End Page": "234",
      "Abstract": "Python continues to be one of the most popular programming languages and has been used in many safety-critical fields such as medical treatment, autonomous driving systems, and data science. These fields put forward higher security requirements to Python ecosystems. However, existing studies on machine learning systems in Python concentrate on data security, model security and model privacy, and just assume the underlying Python virtual machines (PVMs) are secure and trustworthy. Unfortunately, whether such an assumption really holds is still unknown.This paper presents, to the best of our knowledge, the first and most comprehensive empirical study on the security of CPython, the official and most deployed Python virtual machine. To this end, we first designed and implemented a software prototype dubbed PVMSCAN, then use it to scan the source code of the latest CPython (version 3.10) and other 10 versions (3.0 to 3.9), which consists of 3,838,606 lines of source code. Empirical results give relevant findings and insights towards the security of Python virtual machines, such as: 1) CPython virtual machines are still vulnerable, for example, PVMSCAN detected 239 vulnerabilities in version 3.10, including 55 null dereferences, 86 uninitialized variables and 98 dead stores; Python/C API-related vulnerabilities are very common and have become one of the most severe threats to the security of PVMs: for example, 70 Python/C API-related vulnerabilities are identified in CPython 3.10; 3) the overall quality of the code remained stable during the evolution of Python VMs with vulnerabilities per thousand line (VPTL) to be 0.50; and 4) automatic vulnerability rectification is effective: 166 out of 239 (69.46%) vulnerabilities can be rectified by a simple yet effective syntax-directed heuristics.We have reported our empirical results to the developers of CPython, and they have acknowledged us and already confirmed and fixed 2 bugs (as of this writing) while others are still being analyzed. This study not only demonstrates the effectiveness of our approach, but also highlights the need to improve the reliability of infrastructures like Python virtual machines by leveraging state-of-the-art security techniques and tools.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-6654-7956-1",
      "DOI": "10.1109/ICSME55016.2022.00028",
      "Funding Information": "University of Science and Technology of China; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9978245",
      "Author_Keywords": "Empirical;Python virtual machines;Security",
      "IEEE_Terms": "Software maintenance;Source coding;Prototypes;Data science;Writing;Virtual machining;Data models",
      "Reference Count": "110",
      "License": "IEEE",
      "Online Date": "19-Dec-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Machine-Learning Attacks on PolyPUFs, OB-PUFs, RPUFs, LHS-PUFs, and PUF‚ÄìFSMs",
      "Authors": "J. Delvaux",
      "Author Affiliations": "imec-COSIC, KU Leuven, Leuven, Belgium",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "8-May-19",
      "Publication Year": "2019",
      "Volume": "14",
      "Issue": "8",
      "Start Page": "2043",
      "End Page": "2058",
      "Abstract": "A physically unclonable function (PUF) is a circuit of which the input-output behavior is designed to be sensitive to the random variations of its manufacturing process. This building block hence facilitates the authentication of any given device in a population of identically laid-out silicon chips, similar to the biometric authentication of a human. The focus and novelty of this paper is the development of efficient impersonation attacks on the following five Arbiter PUF-based authentication protocols: 1) the so-called Poly PUF protocol of Konigsmark et al. as published in the IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems in 2016; 2) the so-called OB-PUF protocol of Gao et al. as presented at the IEEE Conference PerCom 2016; 3) the so-called RPUF protocol of Ye et al. as presented at the IEEE Conference AsianHOST 2016; 4) the so-called LHS-PUF protocol of Idriss and Bayoumi as presented at the IEEE Conference RFID-TA 2017; and 5) the so-called PUF-FSM protocol of Gao et al. as published in the IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems in 2018. The common flaw of all five designs is that the use of lightweight obfuscation logic provides insufficient protection against machine-learning attacks.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2019.2891223",
      "Funding Information": "KU Leuven(grant numbers:C16/15/058); European Research Council (ERC)(grant numbers:695305); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8603753",
      "Author_Keywords": "Physically unclonable function;machine learning;entity authentication",
      "IEEE_Terms": "Protocols;Machine learning;Authentication;Delays;Tin;Sociology;Statistics",
      "Article Citation Count": "113",
      "Reference Count": "38",
      "License": "IEEE",
      "Online Date": "6-Jan-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Keeping Pace with Ever-Increasing Data: Towards Continual Learning of Code Intelligence Models",
      "Authors": "S. Gao; H. Zhang; C. Gao; C. Wang",
      "Author Affiliations": "School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; School of Big Data and Software Engineering, Chongqing University, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China",
      "Publication Title": "2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "14-Jul-23",
      "Publication Year": "2023",
      "Start Page": "30",
      "End Page": "42",
      "Abstract": "Previous research on code intelligence usually trains a deep learning model on a fixed dataset in an offline manner. However, in real-world scenarios, new code repositories emerge incessantly, and the carried new knowledge is beneficial for providing up-to-date code intelligence services to developers. In this paper, we aim at the following problem: How to enable code intelligence models to continually learn from ever-increasing data? One major challenge here is catastrophic forgetting, meaning that the model can easily forget knowledge learned from previous datasets when learning from the new dataset. To tackle this challenge, we propose REPEAT, a novel method for continual learning of code intelligence models. Specifically, REPEAT addresses the catastrophic forgetting problem with representative exemplars replay and adaptive parameter regularization. The representative exemplars replay component selects informative and diverse exemplars in each dataset and uses them to re-train model periodically. The adaptive parameter regularization component recognizes important parameters in the model and adaptively penalizes their changes to preserve the knowledge learned before. We evaluate the proposed approach on three code intelligence tasks including code summarization, software vulnerability detection, and code clone detection. Extensive experiments demonstrate that REPEAT consistently outperforms baseline methods on all tasks. For example, REPEAT improves the conventional fine-tuning method by 1.22, 5.61, and 1.72 on code summarization, vulnerability detection and clone detection, respectively.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-5701-9",
      "DOI": "10.1109/ICSE48619.2023.00015",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172346",
      "IEEE_Terms": "Deep learning;Adaptation models;Codes;Cloning;Data models;Software;Task analysis",
      "Article Citation Count": "2",
      "Reference Count": "63",
      "License": "IEEE",
      "Online Date": "14-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Federated Learning for Software Engineering: A Case Study of Code Clone Detection and Defect Prediction",
      "Authors": "Y. Yang; X. Hu; Z. Gao; J. Chen; C. Ni; X. Xia; D. Lo",
      "Author Affiliations": "Department of Computer Science and Technology, Zhejiang University, Ningbo, China; School of Software Technology, Zhejiang University, Ningbo, China; Shanghai Institute for Advanced Study, Zhejiang University, Hangzhou, China; School of Computer Science, Wuhan University, Wuhan, China; School of Software Technology, Zhejiang University, Ningbo, China; Software Engineering Application Technology Lab, Huawei, Hangzhou, China; School of Computing and Information Systems, Singapore Management University, Singapore",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "13-Feb-24",
      "Publication Year": "2024",
      "Volume": "50",
      "Issue": "2",
      "Start Page": "296",
      "End Page": "321",
      "Abstract": "In various research domains, artificial intelligence (AI) has gained significant prominence, leading to the development of numerous learning-based models in research laboratories, which are evaluated using benchmark datasets. While the models proposed in previous studies may demonstrate satisfactory performance on benchmark datasets, translating academic findings into practical applications for industry practitioners presents challenges. This can entail either the direct adoption of trained academic models into industrial applications, leading to a performance decrease, or retraining models with industrial data, a task often hindered by insufficient data instances or skewed data distributions. Real-world industrial data is typically significantly more intricate than benchmark datasets, frequently exhibiting data-skewing issues, such as label distribution skews and quantity skews. Furthermore, accessing industrial data, particularly source code, can prove challenging for Software Engineering (SE) researchers due to privacy policies. This limitation hinders SE researchers‚Äô ability to gain insights into industry developers‚Äô concerns and subsequently enhance their proposed models. To bridge the divide between academic models and industrial applications, we introduce a federated learning (FL)-based framework called Almity. Our aim is to simplify the process of implementing research findings into practical use for both SE researchers and industry developers. Almity enhances model performance on sensitive skewed data distributions while ensuring data privacy and security. It introduces an innovative aggregation strategy that takes into account three key attributes: data scale, data balance, and minority class learnability. This strategy is employed to refine model parameters, thereby enhancing model performance on sensitive skewed datasets. In our evaluation, we employ two well-established SE tasks, i.e., code clone detection and defect prediction, as evaluation tasks. We compare the performance of Almity on both machine learning (ML) and deep learning (DL) models against two mainstream training methods, specifically the Centralized Training Method (CTM) and Vanilla Federated Learning (VFL), to validate the effectiveness and generalizability of Almity. Our experimental results demonstrate that our framework is not only feasible but also practical in real-world scenarios. Almity consistently enhances the performance of learning-based models, outperforming baseline training methods across all types of data distributions.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2023.3347898",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:62141222); National Research Foundation(grant numbers:NRF-NRFI08-2022-0002); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10379838",
      "Author_Keywords": "Federated learning;parameter aggregation strategy;skewed data distribution;code clone detection;defect prediction",
      "IEEE_Terms": "Data models;Training;Codes;Cloning;Task analysis;Benchmark testing;Industries",
      "Reference Count": "85",
      "License": "IEEE",
      "Online Date": "3-Jan-24",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Empirical Validation of Automated Vulnerability Curation and Characterization",
      "Authors": "A. Okutan; P. Mell; M. Mirakhorli; I. Khokhlov; J. C. S. Santos; D. Gonzalez; S. Simmons",
      "Author Affiliations": "Leidos, Reston, VA, USA; National Institute of Standards and Technology, Gaithersburg, MD, USA; Department of Software Engineering, Rochester Institute of Technology, Rochester, NY, USA; Sacred Heart University, Fairfield, CT, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Software Engineering, Rochester Institute of Technology, Rochester, NY, USA; Department of Software Engineering, Rochester Institute of Technology, Rochester, NY, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "15-May-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "5",
      "Start Page": "3241",
      "End Page": "3260",
      "Abstract": "Prior research has shown that public vulnerability systems such as US National Vulnerability Database (NVD) rely on a manual, time-consuming, and error-prone process which has led to inconsistencies and delays in releasing final vulnerability results. This work provides an approach to curate vulnerability reports in real-time and map textual vulnerability reports to machine readable structured vulnerability attribute data. Designed to support the time consuming human analysis done by vulnerability databases, the system leverages the Common Vulnerabilities and Exposures (CVE) list of vulnerabilities and the vulnerability attributes described by the National Institute of Standards and Technology (NIST) Vulnerability Description Ontology (VDO) framework. Our work uses Natural Language Processing (NLP), Machine Learning (ML) and novel Information Theoretical (IT) methods to provide automated techniques for near real-time publishing, and characterization of vulnerabilities using 28 attributes in 5 domains. Experiment results indicate that vulnerabilities can be evaluated up to 95 hours earlier than using manual methods, they can be characterized with F-Measure values over 0.9, and the proposed automated approach could save up to 47% of the time spent for CVE characterization.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2023.3250479",
      "Funding Information": "U.S. Department of Homeland Security(grant numbers:70RSAT19CB0000020); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10056768",
      "Author_Keywords": "CVE;NIST vulnerability description ontology;software vulnerability;vulnerability characterization",
      "IEEE_Terms": "Security;NIST;Databases;Virtual machine monitors;Software;Feature extraction;Codes",
      "Article Citation Count": "1",
      "Reference Count": "71",
      "License": "IEEE",
      "Online Date": "28-Feb-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Regression Testing of Massively Multiplayer Online Role-Playing Games",
      "Authors": "Y. Wu; Y. Chen; X. Xie; B. Yu; C. Fan; L. Ma",
      "Author Affiliations": "Fuxi AI Lab, Netease, Inc.; Fuxi AI Lab, Netease, Inc.; Nanyang Technological University; Kyushu University; Fuxi AI Lab, Netease, Inc.; Kyushu University",
      "Publication Title": "2020 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "2-Nov-20",
      "Publication Year": "2020",
      "Start Page": "692",
      "End Page": "696",
      "Abstract": "Regression testing aims to check the functionality consistency during software evolution. Although general regression testing has been extensively studied, regression testing in the context of video games, especially Massively Multiplayer Online Role-Playing Games (MMORPGs), is largely untouched so far. One big challenge is that game testing requires a certain level of intelligence in generating suitable action sequences among the huge search space, to accomplish complex tasks in the MMORPG. Existing game testing mainly relies on either the manual playing or manual scripting, which are labor-intensive and time-consuming. Even worse, it is often unable to satisfy the frequent industrial game evolution. The recent process in machine learning brings new opportunities for automatic game playing and testing. In this paper, we propose a reinforcement learning-based regression testing technique that explores differential behaviors between multiple versions of an MMORPGs such that the potential regression bugs could be detected. The preliminary evaluation on real industrial MMORPGs demonstrates the promising of our technique.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-7281-5619-4",
      "DOI": "10.1109/ICSME46990.2020.00074",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240641",
      "Author_Keywords": "Game Testing, Reinforcement Learning",
      "IEEE_Terms": "Software maintenance;Computer bugs;Games;Manuals;Machine learning;Task analysis;Testing",
      "Article Citation Count": "4",
      "Reference Count": "29",
      "License": "IEEE",
      "Online Date": "2-Nov-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Phrase2Set: Phrase-to-Set Machine Translation and Its Software Engineering Applications",
      "Authors": "T. V. Nguyen; A. Yadavally; T. N. Nguyen",
      "Author Affiliations": "Amazon, Washington, USA; Computer Science Department, University of Texas at Dallas, USA; Computer Science Department, University of Texas at Dallas, USA",
      "Publication Title": "2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "21-Jul-22",
      "Publication Year": "2022",
      "Start Page": "502",
      "End Page": "513",
      "Abstract": "Machine translation has been applied to software engineering (SE) problems, e.g., software tagging, language mi-gration, bug localization, auto program repair, etc. However, ma-chine translation primarily supports only sequence-to-sequence transformations and falls short during the translation/transfor-mation from a phrase or sequence in the input to a set in the output. An example of such a task is tagging the input text in a software library tutorial or a forum entry text with a set of API elements that are relevant to the input. In this work, we propose Phrase2Set, a context-sensitive statistical machine translation model that learns to transform a phrase of a mixture of code and texts into a set of code or text tokens. We first design a token-to-token algorithm that computes the probabilities of mapping individual tokens from phrases to sets. We propose a Bayesian network-based statistical machine translation model that uses these probabilities to decide a trans-lation process that maximizes the joint translation probability. To achieve that, we consider the context of the tokens in the source side and that in the target side via their relative co-occurrence frequencies. We evaluate Phrase2Set in three SE applications: 1) tagging the fragments of texts in a tutorial with the relevant API elements, 2) tagging the StackOverflow entries with relevant API elements, 3) text-to-API translation. Our empirical results show that Phrase2Set achieves high accuracy and outperforms the state-of-the-art models in all three applications. We also provide the lessons learned and other potential applications.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-6654-3786-8",
      "DOI": "10.1109/SANER53432.2022.00068",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9825887",
      "Author_Keywords": "Machine Translation;Phrase-to-Set Translation;Software Tagging;Text-to-Code;Code-to-Text Translation",
      "IEEE_Terms": "Codes;Computational modeling;Tutorials;Transforms;Tagging;Software;Bayes methods",
      "Reference Count": "59",
      "License": "IEEE",
      "Online Date": "21-Jul-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Untangling fine-grained code changes",
      "Authors": "M. Dias; A. Bacchelli; G. Gousios; D. Cassou; S. Ducasse",
      "Author Affiliations": "RMoD Inria Lille‚ÄìNord Europe, University of Lille ‚Äî CRIStAL, France; SORCERERS @ Software Engineering Research Group, Delft University of Technology, The Netherlands; Digital Security Group, Radboud Universiteit Nijmegen, The Netherlands; RMoD Inria Lille‚ÄìNord Europe, University of Lille ‚Äî CRIStAL, France; RMoD Inria Lille‚ÄìNord Europe, University of Lille ‚Äî CRIStAL, France",
      "Publication Title": "2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER)",
      "Date Added To Xplore": "9-Apr-15",
      "Publication Year": "2015",
      "Start Page": "341",
      "End Page": "350",
      "Abstract": "After working for some time, developers commit their code changes to a version control system. When doing so, they often bundle unrelated changes (e.g., bug fix and refactoring) in a single commit, thus creating a so-called tangled commit. Sharing tangled commits is problematic because it makes review, reversion, and integration of these commits harder and historical analyses of the project less reliable. Researchers have worked at untangling existing commits, i.e., finding which part of a commit relates to which task. In this paper, we contribute to this line of work in two ways: (1) A publicly available dataset of untangled code changes, created with the help of two developers who accurately split their code changes into self contained tasks over a period of four months; (2) a novel approach, EpiceaUntangler, to help developers share untangled commits (aka. atomic commits) by using fine-grained code change information. EpiceaUntangler is based and tested on the publicly available dataset, and further evaluated by deploying it to 7 developers, who used it for 2 weeks. We recorded a median success rate of 91% and average one of 75%, in automatically creating clusters of untangled fine-grained code changes.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-4799-8469-5",
      "DOI": "10.1109/SANER.2015.7081844",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7081844",
      "IEEE_Terms": "Software;Clustering algorithms;Testing;Reliability;Machine learning algorithms;Training;Java",
      "Article Citation Count": "59",
      "Reference Count": "28",
      "License": "IEEE",
      "Online Date": "9-Apr-15",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Challenges in Migrating Imperative Deep Learning Programs to Graph Execution: An Empirical Study",
      "Authors": "T. C. V√©lez; R. Khatchadourian; M. Bagherzadeh; A. Raja",
      "Author Affiliations": "City University of New York (CUNY) Graduate Center, New York, NY, USA; City University of New York (CUNY) Hunter College, New York, NY, USA; Oakland University, Rochester, MI, USA; City University of New York (CUNY) Hunter College, New York, NY, USA",
      "Publication Title": "2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "21-Jun-22",
      "Publication Year": "2022",
      "Start Page": "469",
      "End Page": "481",
      "Abstract": "Efficiency is essential to support responsiveness w.r.t. ever-growing datasets, especially for Deep Learning (DL) systems. DL frameworks have traditionally embraced deferred execution-style DL code that supports symbolic, graph-based Deep Neural Network (DNN) computation. While scalable, such development tends to produce DL code that is error-prone, non-intuitive, and difficult to debug. Consequently, more natural, less error-prone imperative DL frameworks encouraging eager execution have emerged at the expense of run-time performance. While hybrid approaches aim for the ‚Äúbest of both worlds,‚Äù the challenges in applying them in the real world are largely unknown. We conduct a data-driven analysis of challenges-and resultant bugs-involved in writing reliable yet performant imperative DL code by studying 250 open-source projects, consisting of 19.7 MLOC, along with 470 and 446 manually examined code patches and bug reports, respectively. The results indicate that hybridization: (i) is prone to API misuse, (ii) can result in performance degradation-the opposite of its intention, and (iii) has limited application due to execution mode incompatibility. We put forth several recommendations, best practices, and anti-patterns for effectively hybridizing imperative DL code, potentially benefiting DL practitioners, API designers, tool developers, and educators.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-4503-9303-4",
      "DOI": "10.1145/3524842.3528455",
      "Funding Information": "City University of New York; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796227",
      "Author_Keywords": "empirical studies;deep learning;imperative programs;hybrid programming paradigms;graph-based execution;software evolution",
      "IEEE_Terms": "Deep learning;Codes;Neural networks;Computer bugs;Writing;Reliability;Data mining",
      "Article Citation Count": "2",
      "Reference Count": "103",
      "Online Date": "21-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "An Empirical Study on Bugs Inside PyTorch: A Replication Study",
      "Authors": "S. C. Yin Ho; V. Majdinasab; M. Islam; D. E. Costa; E. Shihab; F. Khomh; S. Nadi; M. Raza",
      "Author Affiliations": "Concordia University; Polytechnique Montr√©al; University of Alberta; Universit√© du Qu√©bec √† Montr√©al; Concordia University; Polytechnique Montr√©al; University of Alberta; Queen‚Äôs University",
      "Publication Title": "2023 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "11-Dec-23",
      "Publication Year": "2023",
      "Start Page": "220",
      "End Page": "231",
      "Abstract": "Software systems are increasingly relying on deep learning components, due to their remarkable capability of identifying complex data patterns and powering intelligent behaviour. A core enabler of this change in software development is the availability of easy-to-use deep learning libraries. Libraries like PyTorch and TensorFlow empower a large variety of intelligent systems, offering a multitude of algorithms and configuration options, applicable to numerous domains of systems. However, bugs in those popular deep learning libraries also may have dire consequences for the quality of systems they enable; thus, it is important to understand how bugs are identified and fixed in those libraries.Inspired by a study of Jia et al., which investigates the bug identification and fixing process at TensorFlow, we characterize bugs in the PyTorch library, a very popular deep learning framework. We investigate the causes and symptoms of bugs identified during PyTorch‚Äôs development, and assess their locality within the project, and extract patterns of bug fixes. Our results highlight that PyTorch bugs are more like traditional software projects bugs, than related to deep learning characteristics. Finally, we also compare our results with the study on TensorFlow, highlighting similarities and differences across the bug identification and fixing process.",
      "ISSN": "2576-3148",
      "ISBNs": "979-8-3503-2783-0",
      "DOI": "10.1109/ICSME58846.2023.00031",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10336350",
      "Author_Keywords": "Deep Learning;Bug Analysis;Software Library Defect;PyTorch;Empirical Study",
      "IEEE_Terms": "Deep learning;Software maintenance;Computer bugs;Software algorithms;Software systems;Libraries;Intelligent systems",
      "Reference Count": "57",
      "License": "IEEE",
      "Online Date": "11-Dec-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Comparative Study of Transformer-Based Neural Text Representation Techniques on Bug Triaging",
      "Authors": "A. K. Dipongkor; K. Moran",
      "Author Affiliations": "Dept. of Computer Science, University of Central Florida, Orlando, USA; Dept. of Computer Science, University of Central Florida, Orlando, USA",
      "Publication Title": "2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "8-Nov-23",
      "Publication Year": "2023",
      "Start Page": "1012",
      "End Page": "1023",
      "Abstract": "Bug report management has been shown to be an important and time consuming software maintenance task. Often, the first step in managing bug reports is related to triaging a bug to the appropriate developer who is best suited to understand, localize, and fix the target bug. Additionally, assigning a given bug to a particular part of a software project can help to expedite the fixing process. However, despite the importance of these activities, they are quite challenging, where days can be spent on the manual triaging process. Past studies have attempted to leverage the limited textual data of bug reports to train text classification models that automate this process - to varying degrees of success. However, the textual representations and machine learning models used in prior work are limited by their expressiveness, often failing to capture nuanced textual patterns that might otherwise aid in the triaging process. Recently, large, transformer-based, pre-tained neural text representation techniques (i.e., large language models or LLMs) such as BERT and CodeBERT have achieved greater performance with simplified training procedures in several natural language processing tasks, including text classification. However, the potential for using these techniques to improve upon prior approaches for automated bug triaging is not well studied or understood. Therefore, in this paper we offer one of the first investigations that fine-tunes transformer-based language models for the task of bug triaging on four open source datasets, spanning a collective 53 years of development history with over 400 developers and over 150 software project components. Our study includes both a quantitative and qualitative analysis of effectiveness. Our findings illustrate that DeBERTa is the most effective technique across the triaging tasks of developer and component assignment, and the measured performance delta is statistically significant compared to other techniques. However, through our qualitative analysis, we also observe that each technique possesses unique abilities best suited to certain types of bug reports.",
      "ISSN": "2643-1572",
      "ISBNs": "979-8-3503-2996-4",
      "DOI": "10.1109/ASE56229.2023.00217",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298494",
      "Author_Keywords": "Bug Triaging;Transformer;LLMs;Text-Embedding;DL4SE",
      "IEEE_Terms": "Training;Software maintenance;Computer bugs;Text categorization;Manuals;Machine learning;Transformers",
      "Reference Count": "48",
      "License": "IEEE",
      "Online Date": "8-Nov-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Toward Comprehensible Software Fault Prediction Models Using Bayesian Network Classifiers",
      "Authors": "K. Dejaeger; T. Verbraken; B. Baesens",
      "Author Affiliations": "Department of Decision Sciences and Information Management, Faculty of Business and Economics, Katholieke Universiteit Leuven, Leuven, Belgium; Department of Decision Sciences and Information Management, Faculty of Business and Economics, Katholieke Universiteit Leuven, Leuven, Belgium; School of Management, University of Southampton, Southampton, UK",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "24-Jan-13",
      "Publication Year": "2013",
      "Volume": "39",
      "Issue": "2",
      "Start Page": "237",
      "End Page": "257",
      "Abstract": "Software testing is a crucial activity during software development and fault prediction models assist practitioners herein by providing an upfront identification of faulty software code by drawing upon the machine learning literature. While especially the Naive Bayes classifier is often applied in this regard, citing predictive performance and comprehensibility as its major strengths, a number of alternative Bayesian algorithms that boost the possibility of constructing simpler networks with fewer nodes and arcs remain unexplored. This study contributes to the literature by considering 15 different Bayesian Network (BN) classifiers and comparing them to other popular machine learning techniques. Furthermore, the applicability of the Markov blanket principle for feature selection, which is a natural extension to BN theory, is investigated. The results, both in terms of the AUC and the recently introduced H-measure, are rigorously tested using the statistical framework of Dem≈°ar. It is concluded that simple and comprehensible networks with less nodes can be constructed using BN classifiers other than the Naive Bayes classifier. Furthermore, it is found that the aspects of comprehensibility and predictive performance need to be balanced out, and also the development context is an item which should be taken into account during model selection.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2012.20",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6175912",
      "Author_Keywords": "Software fault prediction;Bayesian networks;classification;comprehensibility",
      "IEEE_Terms": "Software;Predictive models;Bayesian methods;Measurement;Capability maturity model;Probability distribution;Machine learning",
      "Article Citation Count": "137",
      "Patent Citation Count": "1",
      "Reference Count": "109",
      "License": "IEEE",
      "Online Date": "3-Apr-12",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Control Parameters Considered Harmful: Detecting Range Specification Bugs in Drone Configuration Modules via Learning-Guided Search",
      "Authors": "R. Han; C. Yang; S. Ma; J. Ma; C. Sun; J. Li; E. Bertino",
      "Author Affiliations": "Xidian University, Xian, China; Xidian University, Xian, China; The University of New South Wales, Canberra, Sydney, Australia; Xidian University, Xian, China; Xidian University, Xian, China; Shanghai Jiao Tong University, Shanghai, China; Purdue University, West Lafayette, USA",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "462",
      "End Page": "473",
      "Abstract": "In order to support a variety of missions and deal with different flight environments, drone control programs typically provide configurable control parameters. However, such a flexibility introduces vulnerabilities. One such vulnerability, referred to as range specification bugs, has been recently identified. The vulnerability originates from the fact that even though each individual parameter receives a value in the recommended value range, certain combinations of parameter values may affect the drone physical stability. In this paper, we develop a novel learning-guided search system to find such combinations, that we refer to as incorrect configurations. Our system applies metaheuristic search algorithms mutating configurations to detect the configuration parameters that have values driving the drone to unstable physical states. To guide the mutations, our system leverages a machine learning based predictor as the fitness evaluator. Finally, by utilizing multi-objective optimization, our system returns the feasible ranges based on the mutation search results. Because in our system the mutations are guided by a predictor, evaluating the parameter configurations does not require realistic/simulation executions. Therefore, our system supports a comprehensive and yet efficient detection of incorrect configurations. We have carried out an experimental evaluation of our system. The evaluation results show that the system successfully reports potentially incorrect configurations, of which over 85% lead to actual unstable physical states.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3510084",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:62121001); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794050",
      "Author_Keywords": "Drone security;configuration test;range specification bug;deep learning approximation",
      "IEEE_Terms": "Machine learning algorithms;Computer bugs;Metaheuristics;Machine learning;Prediction algorithms;Genetics;Mobile handsets",
      "Article Citation Count": "3",
      "Reference Count": "38",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Impact of Discretization Noise of the Dependent Variable on Machine Learning Classifiers in Software Engineering",
      "Authors": "G. K. Rajbahadur; S. Wang; Y. Kamei; A. E. Hassan",
      "Author Affiliations": "Software Analysis and Intelligence Lab (SAIL), School of Computing, Queen's University, Kingston, ON, Canada; Software Analysis and Intelligence Lab (SAIL), School of Computing, Queen's University, Kingston, ON, Canada; Principles of Software Languages (POSL) Lab, Graduate School and Faulty of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan; Software Analysis and Intelligence Lab (SAIL), School of Computing, Queen's University, Kingston, ON, Canada",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "16-Jul-21",
      "Publication Year": "2021",
      "Volume": "47",
      "Issue": "7",
      "Start Page": "1414",
      "End Page": "1430",
      "Abstract": "Researchers usually discretize a continuous dependent variable into two target classes by introducing an artificial discretization threshold (e.g., median). However, such discretization may introduce noise (i.e., discretization noise) due to ambiguous class loyalty of data points that are close to the artificial threshold. Previous studies do not provide a clear directive on the impact of discretization noise on the classifiers and how to handle such noise. In this paper, we propose a framework to help researchers and practitioners systematically estimate the impact of discretization noise on classifiers in terms of its impact on various performance measures and the interpretation of classifiers. Through a case study of 7 software engineering datasets, we find that: 1) discretization noise affects the different performance measures of a classifier differently for different datasets; 2) Though the interpretation of the classifiers are impacted by the discretization noise on the whole, the top 3 most important features are not affected by the discretization noise. Therefore, we suggest that practitioners and researchers use our framework to understand the impact of discretization noise on the performance of their built classifiers and estimate the exact amount of discretization noise to be discarded from the dataset to avoid the negative impact of such noise.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2019.2924371",
      "Funding Information": "JSPS KAKENHI(grant numbers:JP18H03222); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8744330",
      "Author_Keywords": "Discretization noise;discretization;classifiers;feature importance analysis;performance;random forest;logistic regression;decision trees;KNN",
      "IEEE_Terms": "Software engineering;Computer bugs;Noise measurement;Software;Machine learning;Regression tree analysis;Logistics",
      "Article Citation Count": "15",
      "Reference Count": "76",
      "License": "IEEE",
      "Online Date": "24-Jun-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Combining Deep Learning with Information Retrieval to Localize Buggy Files for Bug Reports (N)",
      "Authors": "A. N. Lam; A. T. Nguyen; H. A. Nguyen; T. N. Nguyen",
      "Author Affiliations": "Iowa State University, USA; Iowa State University, USA; Iowa State University, USA; Iowa State University, USA",
      "Publication Title": "2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "7-Jan-16",
      "Publication Year": "2015",
      "Start Page": "476",
      "End Page": "481",
      "Abstract": "Bug localization refers to the automated process of locating the potential buggy files for a given bug report. To help developers focus their attention to those files is crucial. Several existing automated approaches for bug localization from a bug report face a key challenge, called lexical mismatch, in which the terms used in bug reports to describe a bug are different from the terms and code tokens used in source files. This paper presents a novel approach that uses deep neural network (DNN) in combination with rVSM, an information retrieval (IR) technique. rVSM collects the feature on the textual similarity between bug reports and source files. DNN is used to learn to relate the terms in bug reports to potentially different code tokens and terms in source files and documentation if they appear frequently enough in the pairs of reports and buggy files. Our empirical evaluation on real-world projects shows that DNN and IR complement well to each other to achieve higher bug localization accuracy than individual models. Importantly, our new model, HyLoc, with a combination of the features built from DNN, rVSM, and project's bug-fixing history, achieves higher accuracy than the state-of-the-art IR and machine learning techniques. In half of the cases, it is correct with just a single suggested file. Two out of three cases, a correct buggy file is in the list of three suggested files.",
      "ISBNs": "978-1-5090-0025-8",
      "DOI": "10.1109/ASE.2015.73",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372035",
      "Author_Keywords": "Deep Neural Network;Deep Learning;Bug Localization;Information Retrieval;Bug Reports",
      "IEEE_Terms": "Feature extraction;History;Metadata;Computer bugs;Software;Bridges;Information retrieval",
      "Article Citation Count": "114",
      "Patent Citation Count": "1",
      "Reference Count": "10",
      "License": "IEEE",
      "Online Date": "7-Jan-16",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "On the Use of Fine-grained Vulnerable Code Statements for Software Vulnerability Assessment Models",
      "Authors": "T. H. M. Le; M. A. Babar",
      "Author Affiliations": "CREST - The Centre for Research on Engineering Software Technologies, The University of Adelaide, Adelaide, Australia; CREST - The Centre for Research on Engineering Software Technologies, The University of Adelaide, Adelaide, Australia",
      "Publication Title": "2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "21-Jun-22",
      "Publication Year": "2022",
      "Start Page": "621",
      "End Page": "633",
      "Abstract": "Many studies have developed Machine Learning (ML) approaches to detect Software Vulnerabilities (SVs) in functions and fine-grained code statements that cause such SVs. However, there is little work on leveraging such detection outputs for data-driven SV assessment to give information about exploitability, impact, and severity of SVs. The information is important to understand SVs and prioritize their fixing. Using large-scale data from 1,782 functions of 429 SVs in 200 real-world projects, we investigate ML models for automating function-level SV assessment tasks, i.e., predicting seven Common Vulnerability Scoring System (CVSS) metrics. We particularly study the value and use of vulnerable statements as inputs for developing the assessment models because SVs in functions are originated in these statements. We show that vulnerable statements are 5.8 times smaller in size, yet exhibit 7.5-114.5% stronger assessment performance (Matthews Correlation Coefficient (MCC)) than non-vulnerable statements. Incorporating context of vulnerable statements further increases the performance by up to 8.9% (0.64 MCC and 0.75 F1-Score). Overall, we provide the initial yet promising ML-based baselines for function-level SV assessment, paving the way for further research in this direction.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-4503-9303-4",
      "DOI": "10.1145/3524842.3528433",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796209",
      "Author_Keywords": "Security Vulnerability;Vulnerability Assessment;Machine Learning;Mining Software Repositories",
      "IEEE_Terms": "Measurement;Correlation coefficient;Codes;Machine learning;Predictive models;Software;Data models",
      "Article Citation Count": "5",
      "Reference Count": "93",
      "Online Date": "21-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Enhancing Just-in-Time Defect Prediction Using Change Request-based Metrics",
      "Authors": "H. D. Tessema; S. L. Abebe",
      "Author Affiliations": "Addis Ababa Institute of Technology, Addis Ababa University, Addis Ababa, Ethiopia; Addis Ababa Institute of Technology, Addis Ababa University, Addis Ababa, Ethiopia",
      "Publication Title": "2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "11-May-21",
      "Publication Year": "2021",
      "Start Page": "511",
      "End Page": "515",
      "Abstract": "Identifying defective software components as early as their commit helps to reduce significant software development and maintenance costs. In recent years, several studies propose to use just-in-time (JIT) defect prediction techniques to identify changes that could introduce defects at check-in time. To predict defect introducing changes, JIT defect prediction approaches use change metrics collected from software repositories. These change metrics, however, capture code and code change related information. Information related to the change requests (e.g., clarity of change request and difficulty to implement the change) that could determine the change‚Äôs proneness to introducing new defects are not studied. In this study, we propose to augment the publicly available change metrics dataset with six change request- based metrics collected from issue tracking systems. To build the prediction model, we used five machine learning algorithms: AdaBoost, XGBoost, Deep Neural Network, Random Forest and Logistic Regression. The proposed approach is evaluated using a dataset collected from four open source software systems, i.e., Eclipse platform, Eclipse JDT, Bugzilla and Mozilla. The results show that the augmented dataset improves the performance of JIT defect prediction in 19 out of 20 cases. F1-score of JIT defect prediction in the four systems is improved by an average of 4.8%, 3.4%, 1.7%, 1.1% and 1.1% while using AdaBoost, XGBoost, Deep Neural Network, Random Forest and Logistic Regression, respectively.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-7281-9630-5",
      "DOI": "10.1109/SANER50967.2021.00056",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9426021",
      "Author_Keywords": "Just-in-Time Software Defect Prediction;Software Bugs;Issue Tracking Systems;Software Metrics",
      "IEEE_Terms": "Measurement;Machine learning algorithms;Conferences;Neural networks;Predictive models;Maintenance engineering;Random forests",
      "Article Citation Count": "7",
      "Reference Count": "14",
      "License": "IEEE",
      "Online Date": "11-May-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Metric-Based Fault Prediction for Spreadsheets",
      "Authors": "P. Koch; K. Schekotihin; D. Jannach; B. Hofer; F. Wotawa",
      "Author Affiliations": "AAU Klagenfurt, Klagenfurt, Austria; AAU Klagenfurt, Klagenfurt, Austria; AAU Klagenfurt, Klagenfurt, Austria; TU Graz, Graz, Austria; TU Graz, Graz, Austria",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "14-Oct-21",
      "Publication Year": "2021",
      "Volume": "47",
      "Issue": "10",
      "Start Page": "2195",
      "End Page": "2207",
      "Abstract": "Electronic spreadsheets are widely used in organizations for various data analytics and decision-making tasks. Even though faults within such spreadsheets are common and can have significant negative consequences, today's tools for creating and handling spreadsheets provide limited support for fault detection, localization, and repair. Being able to predict whether a certain part of a spreadsheet is faulty or not is often central for the implementation of such supporting functionality. In this work, we propose a novel approach to fault prediction in spreadsheet formulas, which combines an extensive catalog of spreadsheet metrics with modern machine learning algorithms. An analysis of the individual metrics from our catalog reveals that they are generally suited to discover a wide range of faults. Their predictive power is, however, limited when considered in isolation. Therefore, in our approach we apply supervised learning algorithms to obtain fault predictors that utilize all data provided by multiple spreadsheet metrics from our catalog. Experiments on different datasets containing faulty spreadsheets show that particularly Random Forests classifiers are often effective. As a result, the proposed method is in many cases able to make highly accurate predictions whether a given formula of a spreadsheet is faulty.11.Results of a preliminary study were published in [1] .",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2019.2944604",
      "Funding Information": "Austrian Science Fund(grant numbers:I2144); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8859280",
      "Author_Keywords": "Spreadsheets;fault prediction;machine learning",
      "IEEE_Terms": "Measurement;Software;Prediction algorithms;Predictive models;Tools;Radio frequency;Task analysis",
      "Article Citation Count": "5",
      "Reference Count": "50",
      "License": "CCBY",
      "Online Date": "4-Oct-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "The Limitations of Deep Learning in Adversarial Settings",
      "Authors": "N. Papernot; P. McDaniel; S. Jha; M. Fredrikson; Z. B. Celik; A. Swami",
      "Author Affiliations": "Department of Computer Science and Engineering, Penn State University; Department of Computer Science and Engineering, Penn State University; Department of Computer Science and Engineering, Penn State University; Computer Sciences Department, University of Wisconsin-Madison; Department of Computer Science and Engineering, Penn State University; United States Army Research Laboratory, Adelphi, Maryland",
      "Publication Title": "2016 IEEE European Symposium on Security and Privacy (EuroS&P)",
      "Date Added To Xplore": "12-May-16",
      "Publication Year": "2016",
      "Start Page": "372",
      "End Page": "387",
      "Abstract": "Deep learning takes advantage of large datasets and computationally efficient training algorithms to outperform other approaches at various machine learning tasks. However, imperfections in the training phase of deep neural networks make them vulnerable to adversarial samples: inputs crafted by adversaries with the intent of causing deep neural networks to misclassify. In this work, we formalize the space of adversaries against deep neural networks (DNNs) and introduce a novel class of algorithms to craft adversarial samples based on a precise understanding of the mapping between inputs and outputs of DNNs. In an application to computer vision, we show that our algorithms can reliably produce samples correctly classified by human subjects but misclassified in specific targets by a DNN with a 97% adversarial success rate while only modifying on average 4.02% of the input features per sample. We then evaluate the vulnerability of different sample classes to adversarial perturbations by defining a hardness measure. Finally, we describe preliminary work outlining defenses against adversarial samples by defining a predictive measure of distance between a benign input and a target classification.",
      "ISBNs": "978-1-5090-1752-2",
      "DOI": "10.1109/EuroSP.2016.36",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7467366",
      "IEEE_Terms": "Neurons;Training;Machine learning;Biological neural networks;Distortion;Force",
      "Article Citation Count": "1787",
      "Patent Citation Count": "7",
      "Reference Count": "37",
      "License": "IEEE",
      "Online Date": "12-May-16",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Learning to Boost Disjunctive Static Bug-Finders",
      "Authors": "Y. Ko; H. Oh",
      "Author Affiliations": "Meta; Korea University",
      "Publication Title": "2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "14-Jul-23",
      "Publication Year": "2023",
      "Start Page": "1097",
      "End Page": "1109",
      "Abstract": "We present a new learning-based approach for accel-erating disjunctive static bug-finders. Industrial static bug-finders usually perform disjunctive analysis, differentiating program states along different execution paths of a program. Such path-sensitivity is essential for reducing false positives but it also increases analysis costs exponentially. Therefore, practical bug-finders use a state-selection heuristic to keep track of a small number of beneficial states only. However, designing a good heuristic for real-world programs is challenging; as a result, modern static bug-finders still suffer from low cost/bug-finding efficiency. In this paper, we aim to address this problem by learning effective state-selection heuristics from data. To this end, we present a novel data-driven technique that efficiently collects alarm-triggering traces, learns multiple candidate models, and adaptively chooses the best model tailored for each target program. We evaluate our approach with Infer and show that our technique significantly improves Infer's bug-finding efficiency for a range of open-source C programs.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-5701-9",
      "DOI": "10.1109/ICSE48619.2023.00099",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172638",
      "Author_Keywords": "machine learning;static analysis",
      "IEEE_Terms": "Adaptation models;Costs;Software engineering",
      "Reference Count": "41",
      "License": "IEEE",
      "Online Date": "14-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Vulnerability Detection in Smart Contracts Using Deep Learning",
      "Authors": "S. Gopali; Z. A. Khan; B. Chhetri; B. Karki; A. S. Namin",
      "Author Affiliations": "Department of Computer Science, Texas Tech University; Department of Computer Science, Texas Tech University; Department of Computer Science, Texas Tech University; Department of Computer Science, Texas Tech University; Department of Computer Science, Texas Tech University",
      "Publication Title": "2022 IEEE 46th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "10-Aug-22",
      "Publication Year": "2022",
      "Start Page": "1249",
      "End Page": "1255",
      "Abstract": "Various decentralized applications have deployed millions of smart contracts (SCs) on the Blockchain networks. SCs enable programmable transactions involving the transfer of monetary assets between peers on a Blockchain network without any need to a central authority. However, similar to any software program, SCs may contain security issues. Software se-curity engineers and researchers have already uncovered several Ethereum BlockChain and SC vulnerabilities. Still, researchers continuously discover many more security flaws in deployed SCs. Indeed, the popularity of SCs attracts adversaries to launch new attack vectors. Thus, efficient vulnerability detection is necessary. This paper lists broad known vulnerabilities in SCs and classifies them based on the multi-class categories such as Suicidal, Prodigal, Greedy, and Normal SCs. The paper adopts artificial recurrent neural network architecture such as Long Short-Term Memory (LSTM) and Temporal Convolutional Network (TCN) used in deep learning to identify and then classify vulnerable Scs.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-6654-8810-5",
      "DOI": "10.1109/COMPSAC54236.2022.00197",
      "Funding Information": "National Science Foundation(grant numbers:1723765,1821560); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9842527",
      "Author_Keywords": "Temporal Convolutional Network (TCN);Long Short-Term Memory LSTM;Smart Contracts (SC)",
      "IEEE_Terms": "Deep learning;Recurrent neural networks;Conferences;Smart contracts;Computer architecture;Decentralized applications;Software",
      "Article Citation Count": "2",
      "Reference Count": "54",
      "License": "IEEE",
      "Online Date": "10-Aug-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Software Fault Proneness Prediction with Group Lasso Regression: On Factors that Affect Classification Performance",
      "Authors": "K. Goseva-Popstojanova; M. Ahmad; Y. Alshehri",
      "Author Affiliations": "Lane Dept of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA; Lane Dept of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, USA; Department of Computer Science and Engineering, Yanbu University College, Yanbu Alsinayiah, Saudi Arabia",
      "Publication Title": "2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "9-Jul-19",
      "Publication Year": "2019",
      "Volume": "2",
      "Start Page": "336",
      "End Page": "343",
      "Abstract": "Machine learning algorithms have been used extensively for software fault proneness prediction. This paper presents the first application of Group Lasso Regression (G-Lasso) for software fault proneness classification and compares its performance to six widely used machine learning algorithms. Furthermore, we explore the effects of two factors on the prediction performance: the effect of imbalance treatment using the Synthetic Minority Over-sampling Technique (SMOTE), and the effect of datasets used in building the prediction models. Our experimental results are based on 22 datasets extracted from open source projects. The main findings include: (1) G-Lasso is robust to imbalanced data and significantly outperforms the other machine learning algorithms with respect to the Recall and G-Score, i.e., the harmonic mean of Recall and (1- False Positive Rate). (2) Even though SMOTE improved the performance of all learners, it did not have statistically significant effect on G-Lasso's Recall and G-Score. Random Forest was in the top performing group of learners for all performance metrics, while Naive Bayes performed the worst of all learners. (3) When using the same change metrics as features, the choice of the dataset had no effect on the performance of most learners, including G-Lasso. Naive Bayes was the most affected, especially when balanced datasets were used.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-7281-2607-4",
      "DOI": "10.1109/COMPSAC.2019.10229",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8754136",
      "Author_Keywords": "Software fault proneness prediction;Group Lasso regression;imbalance treatment;SMOTE",
      "IEEE_Terms": "Software;Measurement;Machine learning algorithms;Prediction algorithms;Radio frequency;Software algorithms;Predictive models",
      "Article Citation Count": "4",
      "Reference Count": "42",
      "License": "IEEE",
      "Online Date": "9-Jul-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "DRLgencert: Deep Learning-Based Automated Testing of Certificate Verification in SSL/TLS Implementations",
      "Authors": "C. Chen; W. Diao; Y. Zeng; S. Guo; C. Hu",
      "Author Affiliations": "Shandong University, Jinan, China; Jinan University, Guangzhou, China; China Mobile (Hangzhou) Information Technology Co., Ltd., Hangzhou, China; Shandong University, Jinan, China; Shandong University, Jinan, China",
      "Publication Title": "2018 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "11-Nov-18",
      "Publication Year": "2018",
      "Start Page": "48",
      "End Page": "58",
      "Abstract": "The Secure Sockets Layer (SSL) and Transport Layer Security (TLS) protocols are the foundation of network security. The certificate verification in SSL/TLS implementations is vital and may become the \"weak link\" in the whole network ecosystem. In previous works, some research focused on the automated testing of certificate verification, and the main approaches rely on generating massive certificates through randomly combining parts of seed certificates for fuzzing. Although the generated certificates could meet the semantic constraints, the cost is quite heavy, and the performance is limited due to the randomness. To fill this gap, in this paper, we propose DRLGENCERT, the first framework of applying deep reinforcement learning to the automated testing of certificate verification in SSL/TLS implementations. DRLGENCERT accepts ordinary certificates as input and outputs newly generated certificates which could trigger discrepancies with high efficiency. Benefited by the deep reinforcement learning, when generating certificates, our framework could choose the best next action according to the result of a previous modification, instead of simple random combinations. At the same time, we developed a set of new techniques to support the overall design, like new feature extraction method for X.509 certificates, fine-grained differential testing, and so forth. Also, we implemented a prototype of DRLGENCERT and carried out a series of real-world experiments. The results show DRLGENCERT is quite efficient, and we obtained 84,661 discrepancy-triggering certificates from 181,900 certificate seeds, say around 46.5% effectiveness. Also, we evaluated six popular SSL/TLS implementations, including GnuTLS, MatrixSSL, MbedTLS, NSS, OpenSSL, and wolfSSL. DRLGENCERT successfully discovered 23 serious certificate verification flaws, and most of them were previously unknown.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-5386-7870-1",
      "DOI": "10.1109/ICSME.2018.00014",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8529836",
      "Author_Keywords": "Differential Testing;Deep Reinforcement Learning;SSL/TLS Implementations",
      "IEEE_Terms": "Testing;Feature extraction;Security;Task analysis;Semantics",
      "Article Citation Count": "5",
      "Reference Count": "31",
      "License": "IEEE",
      "Online Date": "11-Nov-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Large-Scale Empirical Study of Important Features Indicative of Discovered Vulnerabilities to Assess Application Security",
      "Authors": "M. Zhang; X. de Carn√© de Carnavalet; L. Wang; A. Ragab",
      "Author Affiliations": "Concordia Institute for Information Systems Engineering, Concordia University, Montreal, QC, Canada; Concordia Institute for Information Systems Engineering, Concordia University, Montreal, QC, Canada; Concordia Institute for Information Systems Engineering, Concordia University, Montreal, QC, Canada; Department of Industrial Electronics and Control Engineering, Menoufia University, Menouf, Egypt",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "24-May-19",
      "Publication Year": "2019",
      "Volume": "14",
      "Issue": "9",
      "Start Page": "2315",
      "End Page": "2330",
      "Abstract": "Existing research on vulnerability discovery models shows that the existence of vulnerabilities inside an application may be linked to certain features, e.g., size or complexity, of that application. However, the applicability of such features to demonstrate the relative security between two applications is not well studied, which may depend on multiple factors in a complex way. In this paper, we perform the first large-scale empirical study of the correlation between various features of applications and the abundance of vulnerabilities. Unlike existing work, which typically focuses on one particular application, resulting in limited successes, we focus on the more realistic issue of assessing the relative security level among different applications. To the best of our knowledge, this is the most comprehensive study of 780 real-world applications involving 6498 vulnerabilities. We apply seven feature selection methods to nine feature subsets selected among 34 collected features, which are then fed into six types of machine learning models, producing 523 estimations. The predictive power of important features is evaluated using four different performance measures. This paper reflects that the complexity of applications is not the only factor in vulnerability discovery and the human-related factors contribute to explaining the number of discovered vulnerabilities in an application.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2019.2895963",
      "Funding Information": "Natural Sciences and Engineering Research Council of Canada(grant numbers:N01035); Vanier Canada Graduate Scholarship; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8629314",
      "Author_Keywords": "Software vulnerability analysis;vulnerability discovery model;software security;machine learning",
      "IEEE_Terms": "Feature extraction;Correlation;Measurement;Complexity theory;Software;Predictive models;Security",
      "Article Citation Count": "21",
      "Reference Count": "49",
      "License": "IEEE",
      "Online Date": "29-Jan-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Varangian: A Git Bot for Augmented Static Analysis",
      "Authors": "S. Pujar; Y. Zheng; L. Buratti; B. Lewis; A. Morari; J. Laredo; K. Postlethwait; C. G√∂rn",
      "Author Affiliations": "IBM Research, United States; IBM Research, United States; IBM Research, United States; IBM Research, United States; IBM Research, United States; IBM Research, United States; Red Hat, United States; Red Hat, United States",
      "Publication Title": "2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "21-Jun-22",
      "Publication Year": "2022",
      "Start Page": "766",
      "End Page": "767",
      "Abstract": "The complexity and scale of modern software programs often lead to overlooked programming errors and security vulnerabilities. Developers often rely on automatic tools, like static analysis tools, to look for bugs and vulnerabilities. Static analysis tools are widely used because they can understand nontrivial program behaviors, scale to millions of lines of code, and detect subtle bugs. However, they are known to generate an excess of false alarms which hinder their utilization as it is counterproductive for developers to go through a long list of reported issues, only to find a few true positives. One of the ways proposed to suppress false positives is to use machine learning to identify them. However, training machine learning models requires good quality labeled datasets. For this purpose, we developed D2A [3], a differential analysis based approach that uses the commit history of a code repository to create a labeled dataset of Infer [2] static analysis output.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-4503-9303-4",
      "DOI": "10.1145/3524842.3528516",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796288",
      "Author_Keywords": "security;static analysis;git;bot;machine learning;bert",
      "IEEE_Terms": "Training;Codes;Computer bugs;Static analysis;Machine learning;Programming;Software",
      "Article Citation Count": "1",
      "Reference Count": "3",
      "Online Date": "21-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "An Empirical Analysis on Effective Fault Prediction Model Developed Using Ensemble Methods",
      "Authors": "L. Kumar; S. Rath; A. Sureka",
      "Author Affiliations": "NIT, Rourkela, India; NIT, Rourkela, India; ABB Corporate, Research, India",
      "Publication Title": "2017 IEEE 41st Annual Computer Software and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "11-Sep-17",
      "Publication Year": "2017",
      "Volume": "1",
      "Start Page": "244",
      "End Page": "249",
      "Abstract": "Software fault prediction models are employed to optimize testing resource allocation by identifying fault-prone classes before testing phases. We apply three different ensemble methods to develop a model for predicting fault proneness. We propose a framework to validate the source code metrics and select the right set of metrics with the objective to improve the performance of the fault prediction model. The fault prediction models are then validated using a cost evaluation framework. We conduct a series of experiments on 45 open source project dataset. Key conclusions from our experiments are: (1) Majority Voting Ensemble (MVE) methods outperformed other methods (2) selected set of source code metrics using the suggested source code metrics using validation framework as the input achieves better results compared to all other metrics (3) fault prediction method is effective for software projects with a percentage of faulty classes lower than the threshold value (low - 54.82%, medium - 41.04%, high - 28.10%).",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-5386-0367-3",
      "DOI": "10.1109/COMPSAC.2017.53",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8029614",
      "Author_Keywords": "Software Fault Prediction;Machine Learning;Predictive Modeling;Source Code Metrics;Ensemble Methods",
      "IEEE_Terms": "Measurement;Predictive models;Object oriented modeling;Testing;Computational modeling;Analytical models;Algorithm design and analysis",
      "Article Citation Count": "3",
      "Reference Count": "11",
      "License": "IEEE",
      "Online Date": "11-Sep-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Exploring Word Embedding Techniques to Improve Sentiment Analysis of Software Engineering Texts",
      "Authors": "E. Biswas; K. Vijay-Shanker; L. Pollock",
      "Author Affiliations": "Computer and Information Sciences, University of Delaware, Newark, United States; Computer and Information Sciences, University of Delaware, Newark, United States; Computer and Information Sciences, University of Delaware, Newark, United States",
      "Publication Title": "2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "29-Aug-19",
      "Publication Year": "2019",
      "Start Page": "68",
      "End Page": "78",
      "Abstract": "Sentiment analysis (SA) of text-based software artifacts is increasingly used to extract information for various tasks including providing code suggestions, improving development team productivity, giving recommendations of software packages and libraries, and recommending comments on defects in source code, code quality, possibilities for improvement of applications. Studies of state-of-the-art sentiment analysis tools applied to software-related texts have shown varying results based on the techniques and training approaches. In this paper, we investigate the impact of two potential opportunities to improve the training for sentiment analysis of SE artifacts in the context of the use of neural networks customized using the Stack Overflow data developed by Lin et al. We customize the process of sentiment analysis to the software domain, using software domain-specific word embeddings learned from Stack Overflow (SO) posts, and study the impact of software domain-specific word embeddings on the performance of the sentiment analysis tool, as compared to generic word embeddings learned from Google News. We find that the word embeddings learned from the Google News data performs mostly similar and in some cases better than the word embeddings learned from SO posts. We also study the impact of two machine learning techniques, oversampling and undersampling of data, on the training of a sentiment classifier for handling small SE datasets with a skewed distribution. We find that oversampling alone, as well as the combination of oversampling and undersampling together, helps in improving the performance of a sentiment classifier.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-7281-3412-3",
      "DOI": "10.1109/MSR.2019.00020",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8816816",
      "Author_Keywords": "Sentiment Analysis;Software Engineering;Word Embeddings",
      "IEEE_Terms": "Sentiment analysis;Tools;Software;Training;Neural networks;Software engineering;Machine learning",
      "Article Citation Count": "14",
      "Reference Count": "37",
      "License": "IEEE",
      "Online Date": "29-Aug-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "HERMES: Using Commit-Issue Linking to Detect Vulnerability-Fixing Commits",
      "Authors": "G. Nguyen-Truong; H. J. Kang; D. Lo; A. Sharma; A. E. Santosa; A. Sharma; M. Y. Ang",
      "Author Affiliations": "Singapore Management University, Singapore; Singapore Management University, Singapore; Singapore Management University, Singapore; Veracode, Singapore; Veracode, Singapore; Veracode, Singapore; Veracode, Singapore",
      "Publication Title": "2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "21-Jul-22",
      "Publication Year": "2022",
      "Start Page": "51",
      "End Page": "62",
      "Abstract": "Software projects today rely on many third-party libraries, and therefore, are exposed to vulnerabilities in these libraries. When a library vulnerability is fixed, users are notified and advised to upgrade to a new version of the library. However, not all vulnerabilities are publicly disclosed, and users may not be aware of vulnerabilities that may affect their applications. Due to the above challenges, there is a need for techniques which can identify and alert users to silent fixes in libraries; commits that fix bugs with security implications that are not officially disclosed. We propose a machine learning approach to automatically identify vulnerability-fixing commits. Existing techniques consider only data within a commit, such as its commit message, which does not always have sufficiently discriminative information. To address this limitation, our approach incorporates the rich source of information from issue trackers. When a commit does not link to an issue, we use a commit-issue link recovery technique to infer the potential missing link. Our experiments are promising; incorporating information from issue trackers boosts the performance of a vulnerability-fixing commit classifier, improving over the strongest baseline by 11.1% on the entire dataset, which includes commits that do not link to an issue. On a subset of the data in which all commits explicitly link to an issue, our approach improves over the baseline by 12.5%.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-6654-3786-8",
      "DOI": "10.1109/SANER53432.2022.00018",
      "Funding Information": "National Research Foundation, Singapore; National University of Singapore; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9825835",
      "Author_Keywords": "vulnerability curation;silent fixes;commit classification;commit-issue link recovery",
      "IEEE_Terms": "Conferences;Computer bugs;Machine learning;Libraries;Software;Security",
      "Article Citation Count": "7",
      "Reference Count": "53",
      "License": "IEEE",
      "Online Date": "21-Jul-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "How Well Do Change Sequences Predict Defects? Sequence Learning from Software Changes",
      "Authors": "M. Wen; R. Wu; S. -C. Cheung",
      "Author Affiliations": "Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Kowloon, Hong Kong, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Kowloon, Hong Kong, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Kowloon, Hong Kong, China",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "11-Nov-20",
      "Publication Year": "2020",
      "Volume": "46",
      "Issue": "11",
      "Start Page": "1155",
      "End Page": "1175",
      "Abstract": "Software defect prediction, which aims to identify defective modules, can assist developers in finding bugs and prioritizing limited quality assurance resources. Various features to build defect prediction models have been proposed and evaluated. Among them, process metrics are one important category. Yet, existing process metrics are mainly encoded manually from change histories and ignore the sequential information arising from the changes during software evolution. Are the change sequences derived from such information useful to characterize buggy program modules? How can we leverage such sequences to build good defect prediction models? Unlike traditional process metrics used for existing defect prediction models, change sequences are mostly vectors of variable length. This makes it difficult to apply such sequences directly in prediction models that are driven by conventional classifiers. To resolve this challenge, we utilize Recurrent Neural Network (RNN), which is a deep learning technique, to encode features from sequence data automatically. In this paper, we propose a novel approach called Fences, which extracts six types of change sequences covering different aspects of software changes via fine-grained change analysis. It approaches defects prediction by mapping it to a sequence labeling problem solvable by RNN. Our evaluations on 10 open source projects show that Fences can predict defects with high performance. In particular, our approach achieves an average F-measure of 0.657, which improves the prediction models built on traditional metrics significantly. The improvements vary from 31.6 to 46.8 percent on average. In terms of AUC, Fences achieves an average value of 0.892, and the improvements over baselines vary from 4.2 to 16.1 percent. Fences also outperforms the state-of-the-art technique which learns semantic features automatically from static code via deep learning.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2018.2876256",
      "Funding Information": "Hong Kong RGC/GRF(grant numbers:16202917); 2018 MSRA collaborative research fund; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8493303",
      "Author_Keywords": "Defect prediction;process metrics;sequence learning",
      "IEEE_Terms": "Measurement;Software;Predictive models;Semantics;History;Machine learning;Feature extraction",
      "Article Citation Count": "21",
      "Reference Count": "74",
      "License": "IEEE",
      "Online Date": "16-Oct-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "On the Costs and Profit of Software Defect Prediction",
      "Authors": "S. Herbold",
      "Author Affiliations": "Institute of Computer Science, University of Goettingen, Goettingen, Germany",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "11-Nov-21",
      "Publication Year": "2021",
      "Volume": "47",
      "Issue": "11",
      "Start Page": "2617",
      "End Page": "2631",
      "Abstract": "Defect prediction can be a powerful tool to guide the use of quality assurance resources. However, while lots of research covered methods for defect prediction as well as methodological aspects of defect prediction research, the actual cost saving potential of defect prediction is still unclear. Within this article, we close this research gap and formulate a cost model for software defect prediction. We derive mathematically provable boundary conditions that must be fulfilled by defect prediction models such that there is a positive profit when the defect prediction model is used. Our cost model includes aspects like the costs for quality assurance, the costs of post-release defects, the possibility that quality assurance fails to reveal predicted defects, and the relationship between software artifacts and defects. We initialize the cost model using different assumptions, perform experiments to show trends of the behavior of costs on real projects. Our results show that the unrealistic assumption that defects only affect a single software artifact, which is a standard practice in the defect prediction literature, leads to inaccurate cost estimations. Moreover, the results indicate that thresholds for machine learning metrics are also not suited to define success criteria for software defect prediction.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2019.2957794",
      "Funding Information": "DFG(grant numbers:402774445); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924628",
      "Author_Keywords": "Defect prediction;costs;return on investment",
      "IEEE_Terms": "Predictive models;Software;Quality assurance;Measurement;Mathematical model;Machine learning;Computational modeling",
      "Article Citation Count": "18",
      "Reference Count": "47",
      "License": "IEEE",
      "Online Date": "5-Dec-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "The Anatomy of Software Changes and Bugs in Autonomous Operating System",
      "Authors": "K. Goseva-Popstojanova; D. Hood; J. Schumann; N. Nkwocha",
      "Author Affiliations": "Lane Dept. Computer Science & Electrical Engineering, West Virginia University, Morgantown, WV, USA; Lane Dept. Computer Science & Electrical Engineering, West Virginia University, Morgantown, WV, USA; KBR/WYLE, NASA Ames Research Center, Moffett Field, CA, USA; Katherine Johnson NASA IV&V Facility, Fairmont, WV, USA",
      "Publication Title": "2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "2-Aug-23",
      "Publication Year": "2023",
      "Start Page": "28",
      "End Page": "38",
      "Abstract": "Cyberphysical systems with autonomous functions are complex pieces of software, consisting of many components, some of which implement autonomous functionality and some may use AI or machine learning algorithms. Software bugs in an autonomous system are of particular concern, as they can have catastrophic consequences. However, detailed studies based on empirical data are rare and therefore these bugs are not well understood. This paper aims to contribute towards filling that gap by investigating the software changes and bugs in Autonomy Operating System (AOS) for Unmanned Aircraft Systems (UAS), which consist of 26 components containing about 103,000 lines of code and having a total of 772 bugfixes. Based on the data extracted from the code repository and semi-structured interviews with the developers of AOS, we explore the differences among autonomous software components, components developed using Model-based Software Engineering, and reuse with respect to change proneness, fault proneness, distribution of bugfixes among AOS components and files of these components, and characteristics of bugs of different AOS components. Our results show that the autonomous components were significantly more change prone (measured in number of commits and code churn) and fault prone (measured in bugfixes per KLoC) than non-autonomous components. The distribution of the locations of bugfixes was skewed, both at component and file level (i.e., a small number of components / files contained the majority of bugs). These evidence-based findings provide important insights to researchers and practitioners alike and can be used to efficiently improve the quality and reliability of autonomous systems.",
      "ISSN": "0730-3157",
      "ISBNs": "979-8-3503-2697-0",
      "DOI": "10.1109/COMPSAC57700.2023.00014",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10196853",
      "Author_Keywords": "autonomous operating system;unmanned aircraft systems;change proneness;fault proneness;empirical analysis;qualitative analysis",
      "IEEE_Terms": "Codes;Machine learning algorithms;Autonomous systems;Operating systems;Computer bugs;Software;Software reliability",
      "Reference Count": "24",
      "License": "IEEE",
      "Online Date": "2-Aug-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Preserving Privacy of Neuromorphic Hardware From PCIe Congestion Side-Channel Attack",
      "Authors": "A. Das",
      "Author Affiliations": "Electrical and Computer Engineering, Drexel University, Philadelphia, USA",
      "Publication Title": "2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "2-Aug-23",
      "Publication Year": "2023",
      "Start Page": "689",
      "End Page": "698",
      "Abstract": "Neuromorphic systems are equipped with software-managed scratchpad to cache intermediate results and synaptic weights of a machine learning model. PCIe (Peripheral Component Interconnect Express) is the de facto protocol to interface between scratchpad and main memory. Congestion happens when PCIe traffic overwhelms the PCIe link capacity. This introduces transmission delay, which not only impacts model performance but also leaks sensitive information about a user (the victim).In this paper, we show that inefficient data placement in scratchpad using state-of-the-art compilers may trigger significant data movement over PCIe. An attacker can measure the PCIe congestion to indirectly infer the victim‚Äôs model. Therefore, the delay from PCIe congestion can be exploited as a side-channel.We propose a compiler extension to intelligently manage scratchpad in order to improve model privacy. First, we formulate a design metric to assess the vulnerability of a model to PCIe congestion side-channel attack. Next, we propose an optimization strategy integrated within the compiler to identify contents that should be retained inside scratchpad to minimize this design metric. Finally, we propose a Hill Climbing heuristic to allocate model operations to neuromorphic tiles and improve privacy by efficiently utilizing their on-chip scratchpad capacity.We evaluate our privacy-preserving model execution (PrivacyX) to mitigate PCIe congestion side-channel attack using one attack scenario and 16 image, object, and language-based machine learning models. We show that PrivacyX significantly reduces the vulnerability of a model to PCIe congestion side-channel attack compared to baseline compilers. We also show that PrivacyX, which is managed entirely in software, is complementary to several hardware-based privacy preserving solutions.",
      "ISSN": "0730-3157",
      "ISBNs": "979-8-3503-2697-0",
      "DOI": "10.1109/COMPSAC57700.2023.00094",
      "Funding Information": "U.S. Department of Energy; National Science Foundation; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10196964",
      "Author_Keywords": "Neuromorphic Computing;Scratchpad;Side-Channel Attack;PCIe;Spiking Neural Network (SNN)",
      "IEEE_Terms": "Measurement;Privacy;Neuromorphics;Computational modeling;Side-channel attacks;Machine learning;Software",
      "Reference Count": "62",
      "License": "IEEE",
      "Online Date": "2-Aug-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "CCLearner: A Deep Learning-Based Clone Detection Approach",
      "Authors": "L. Li; H. Feng; W. Zhuang; N. Meng; B. Ryder",
      "Author Affiliations": "Department of Computer Science, Virginia Tech, Blacksburg, VA, USA; Department of Computer Science, Virginia Tech, Blacksburg, VA, USA; Department of Computer Science, Virginia Tech, Blacksburg, VA, USA; Department of Computer Science, Virginia Tech, Blacksburg, VA, USA; Department of Computer Science, Virginia Tech, Blacksburg, VA, USA",
      "Publication Title": "2017 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "7-Nov-17",
      "Publication Year": "2017",
      "Start Page": "249",
      "End Page": "260",
      "Abstract": "Programmers produce code clones when developing software. By copying and pasting code with or without modification, developers reuse existing code to improve programming productivity. However, code clones present challenges to software maintenance: they may require consistent application of the same or similar bug fixes or program changes to multiple code locations. To simplify the maintenance process, various tools have been proposed to automatically detect clones [1], [2], [3], [4], [5], [6]. Some tools tokenize source code, and then compare the sequence or frequency of tokens to reveal clones [1], [3], [4], [5]. Some other tools detect clones using tree-matching algorithms to compare the Abstract Syntax Trees (ASTs) of source code [2], [6]. In this paper, we present CCLEARNER, the first solely token-based clone detection approach leveraging deep learning. CCLEARNER extracts tokens from known method-level code clones and nonclones to train a classifier, and then uses the classifier to detect clones in a given codebase. To evaluate CCLEARNER, we reused BigCloneBench [7], an existing large benchmark of real clones. We used part of the benchmark for training and the other part for testing, and observed that CCLEARNER effectively detected clones. With the same data set, we conducted the first systematic comparison experiment between CCLEARNER and three popular clone detection tools. Compared with the approaches not using deep learning, CCLEARNER achieved competitive clone detection effectiveness with low time cost.",
      "ISBNs": "978-1-5386-0992-7",
      "DOI": "10.1109/ICSME.2017.46",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094426",
      "Author_Keywords": "deep learning;clone detection;empirical",
      "IEEE_Terms": "Cloning;Feature extraction;Machine learning;Neural networks;Tools;Training;Testing",
      "Article Citation Count": "108",
      "Reference Count": "46",
      "License": "IEEE",
      "Online Date": "7-Nov-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Deep-Intelligence Framework for Online Video Processing",
      "Authors": "W. Zhang; L. Xu; Z. Li; Q. Lu; Y. Liu",
      "Author Affiliations": "China University of Petroleum; China University of Petroleum; China University of Petroleum; China University of Petroleum; Concordia University, Montreal",
      "Publication Title": "IEEE Software",
      "Date Added To Xplore": "26-Feb-16",
      "Publication Year": "2016",
      "Volume": "33",
      "Issue": "2",
      "Start Page": "44",
      "End Page": "51",
      "Abstract": "Video data has become the largest source of big data. Owing to video data's complexities, velocity, and volume, public security and other surveillance applications require efficient, intelligent runtime video processing. To address these challenges, a proposed framework combines two cloud-computing technologies: Storm stream processing and Hadoop batch processing. It uses deep learning to realize deep intelligence that can help reveal knowledge hidden in video data. An implementation of this framework combines five architecture styles: service-oriented architecture, publish-subscribe, the Shared Data pattern, MapReduce, and a layered architecture. Evaluations of performance, scalability, and fault tolerance showed the framework's effectiveness. This article is part of a special issue on Software Engineering for Big Data Systems.",
      "ISSN": "1937-4194",
      "DOI": "10.1109/MS.2016.31",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7412619",
      "Author_Keywords": "big data;cloud computing;deep learning;fault tolerance;video processing;MapReduce;Storm;Hadoop;software engineering;software development",
      "IEEE_Terms": "Streaming media;Computer architecture;Real-time systems;Big data;Machine learning;Scalability;Software engineering;Cloud computing;Fault tolerance;Software development;Deep learning",
      "Article Citation Count": "39",
      "Reference Count": "6",
      "License": "IEEE",
      "Online Date": "18-Feb-16",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Magazines"
    },
    {
      "Document Title": "A Conceptual Antifragile Microservice Framework for Reshaping Critical Infrastructures",
      "Authors": "H. Bangui; B. Rossi; B. Buhnova",
      "Author Affiliations": "Faculty of Informatics, Masaryk University, Brno, Czech Republic; Faculty of Informatics, Masaryk University, Brno, Czech Republic; Faculty of Informatics, Masaryk University, Brno, Czech Republic",
      "Publication Title": "2022 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "19-Dec-22",
      "Publication Year": "2022",
      "Start Page": "364",
      "End Page": "368",
      "Abstract": "Recently, microservices have been examined as a solution for reshaping and improving the flexibility, scalability, and maintainability of critical infrastructure systems. However, microservice systems are also suffering from the presence of a substantial number of potentially vulnerable components that may threaten the protection of critical infrastructures. To address the problem, this paper proposes to leverage the concept of antifragility built in a framework for building self-learning microservice systems that could be strengthened by faults and threats instead of being deteriorated by them. To illustrate the approach, we instantiate the proposed approach of autonomous machine learning through an experimental evaluation on a benchmarking dataset of microservice faults.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-6654-7956-1",
      "DOI": "10.1109/ICSME55016.2022.00040",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9977445",
      "Author_Keywords": "Critical Infrastructures;Microservices;Antifragility;Machine Learning;Generative Adversarial Network",
      "IEEE_Terms": "Software maintenance;Autonomous systems;Scalability;Microservice architectures;Termination of employment;Elasticity;Generative adversarial networks",
      "Reference Count": "17",
      "License": "IEEE",
      "Online Date": "19-Dec-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Noisy Label Learning for Security Defects",
      "Authors": "R. Croft; M. A. Babar; H. Chen",
      "Author Affiliations": "CREST - The Centre for Research on Engineering Software Technologies, The University of Adelaide Cyber Security Cooperative Research Centre, Adelaide, Australia; CREST - The Centre for Research on Engineering Software Technologies, The University of Adelaide Cyber Security Cooperative Research Centre, Adelaide, Australia; CREST - The Centre for Research on Engineering Software Technologies, The University of Adelaide Cyber Security Cooperative Research Centre, Adelaide, Australia",
      "Publication Title": "2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "21-Jun-22",
      "Publication Year": "2022",
      "Start Page": "435",
      "End Page": "447",
      "Abstract": "Data-driven software engineering processes, such as vulnerability prediction heavily rely on the quality of the data used. In this paper, we observe that it is infeasible to obtain a noise-free security defect dataset in practice. Despite the vulnerable class, the non-vulnerable modules are difficult to be verified and determined as truly exploit free given the limited manual efforts available. It results in uncertainty, introduces labeling noise in the datasets and affects conclusion validity. To address this issue, we propose novel learning methods that are robust to label impurities and can leverage the most from limited label data; noisy label learning. We investigate various noisy label learning methods applied to soft-ware vulnerability prediction. Specifically, we propose a two-stage learning method based on noise cleaning to identify and remediate the noisy samples, which improves AUC and recall of baselines by up to 8.9% and 23.4%, respectively. Moreover, we discuss several hurdles in terms of achieving a performance upper bound with semi-omniscient knowledge of the label noise. Overall, the experimental results show that learning from noisy labels can be effective for data-driven software and security analytics.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-4503-9303-4",
      "DOI": "10.1145/3524842.3528446",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796240",
      "Author_Keywords": "machine learning;noisy label learning;software vulnerabilities",
      "IEEE_Terms": "Learning systems;Upper bound;Uncertainty;Manuals;Predictive models;Software;Noise measurement",
      "Article Citation Count": "4",
      "Reference Count": "76",
      "Online Date": "21-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Learning to Combine Multiple Ranking Metrics for Fault Localization",
      "Authors": "J. Xuan; M. Monperrus",
      "Author Affiliations": "INRIA Lille - Nord Europe, Lille, France; University of Lille & INRIA, Lille, France",
      "Publication Title": "2014 IEEE International Conference on Software Maintenance and Evolution",
      "Date Added To Xplore": "6-Dec-14",
      "Publication Year": "2014",
      "Start Page": "191",
      "End Page": "200",
      "Abstract": "Fault localization is an inevitable step in software debugging. Spectrum-based fault localization consists in computing a ranking metric on execution traces to identify faulty source code. Existing empirical studies on fault localization show that there is no optimal ranking metric for all faults in practice. In this paper, we propose Multric, a learning-based approach to combining multiple ranking metrics for effective fault localization. In Multric, a suspiciousness score of a program entity is a combination of existing ranking metrics. Multric consists two major phases: learning and ranking. Based on training faults, Multric builds a ranking model by learning from pairs of faulty and non-faulty source code elements. When a new fault appears, Multric computes the final ranking with the learned model. Experiments are conducted on 5386 seeded faults in ten open-source Java programs. We empirically compare Multric against four widely-studied metrics and three recently-proposed one. Our experimental results show that Multric localizes faults more effectively than state-of-art metrics, such as Tarantula, Ochiai, and Ample.",
      "ISSN": "1063-6773",
      "ISBNs": "978-1-4799-6146-7",
      "DOI": "10.1109/ICSME.2014.41",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6976085",
      "Author_Keywords": "Fault localization;learning to rank;multiple ranking metrics",
      "IEEE_Terms": "Measurement;Training data;Training;Object oriented modeling;Computational modeling;Java;Debugging",
      "Article Citation Count": "128",
      "Patent Citation Count": "1",
      "Reference Count": "35",
      "License": "IEEE",
      "Online Date": "6-Dec-14",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Using Deep Learning to Generate Complete Log Statements",
      "Authors": "A. Mastropaolo; L. Pascarella; G. Bavota",
      "Author Affiliations": "SEART @ Software Institute, Universit√† della Svizzera italiana, Switzerland; SEART @ Software Institute, Universit√† della Svizzera italiana, Switzerland; SEART @ Software Institute, Universit√† della Svizzera italiana, Switzerland",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "2279",
      "End Page": "2290",
      "Abstract": "Logging is a practice widely adopted in several phases of the software lifecycle. For example, during software development log statements allow engineers to verify and debug the system by exposing fine-grained information of the running software. While the benefits of logging are undisputed, taking proper decisions about where to inject log statements, what information to log, and at which log level (e.g., error, warning) is crucial for the logging effectiveness. In this paper, we present LANCE (Log stAtemeNt reCommEnder), the first approach supporting developers in all these decisions. LANCE features a Text-To-Text-Transfer-Transformer (T5) model that has been trained on 6,894,456 Java methods. LANCE takes as input a Java method and injects in it a full log statement, including a human-comprehensible logging message and properly choosing the needed log level and the statement location. Our results show that LANCE is able to (i) properly identify the location in the code where to inject the statement in 65.9% of Java methods requiring it; (ii) selecting the proper log level in 66.2% of cases; and (iii) generate a completely correct log statement including a meaningful logging message in 15.2% of cases.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3511561",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794055",
      "Author_Keywords": "Logging;Empirical Study;Machine Learning on Code",
      "IEEE_Terms": "Deep learning;Java;Codes;Software;Software engineering",
      "Article Citation Count": "10",
      "Reference Count": "53",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "An Empirical Investigation into Learning Bug-Fixing Patches in the Wild via Neural Machine Translation",
      "Authors": "M. Tufano; C. Watson; G. Bavota; M. di Penta; M. White; D. Poshyvanyk",
      "Author Affiliations": "College of William and Mary, Williamsburg, VA, USA; College of William and Mary, Williamsburg, VA, USA; Universit√† della Svizzera italiana (USI), Lugano, Switzerland; University of Sannio, Benevento, Italy; College of William and Mary, Williamsburg, VA, USA; College of William and Mary, Williamsburg, VA, USA",
      "Publication Title": "2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "17-Feb-20",
      "Publication Year": "2018",
      "Start Page": "832",
      "End Page": "837",
      "Abstract": "Millions of open-source projects with numerous bug fixes are available in code repositories. This proliferation of software development histories can be leveraged to learn how to fix common programming bugs. To explore such a potential, we perform an empirical study to assess the feasibility of using Neural Machine Translation techniques for learning bug-fixing patches for real defects. We mine millions of bug-fixes from the change histories of GitHub repositories to extract meaningful examples of such bug-fixes. Then, we abstract the buggy and corresponding fixed code, and use them to train an Encoder-Decoder model able to translate buggy code into its fixed version. Our model is able to fix hundreds of unique buggy methods in the wild. Overall, this model is capable of predicting fixed patches generated by developers in 9% of the cases.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-4503-5937-5",
      "DOI": "10.1145/3238147.3240732",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9000077",
      "Author_Keywords": "neural machine translation;bug-fixes",
      "Article Citation Count": "43",
      "Reference Count": "40",
      "Online Date": "17-Feb-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Assessing, Comparing, and Combining State Machine-Based Testing and Structural Testing: A Series of Experiments",
      "Authors": "S. Mouchawrab; L. C. Briand; Y. Labiche; M. Di Penta",
      "Author Affiliations": "Software Quality Engineering Laboratory, Department of Systems and Computer Engineering, Carleton University, Ottawa, ONT, Canada; Department of Software Engineering, Simula Research Laboratory, Lysaker, Norway; Software Quality Engineering Laboratory, Department of Systems and Computer Engineering, Carleton University, Ottawa, ONT, Canada; Department of Engineering, University of Sannio, Piazza Roma, Benevento, Italy",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "24-Mar-11",
      "Publication Year": "2011",
      "Volume": "37",
      "Issue": "2",
      "Start Page": "161",
      "End Page": "187",
      "Abstract": "A large number of research works have addressed the importance of models in software engineering. However, the adoption of model-based techniques in software organizations is limited since these models are perceived to be expensive and not necessarily cost-effective. Focusing on model-based testing, this paper reports on a series of controlled experiments. It investigates the impact of state machine testing on fault detection in class clusters and its cost when compared with structural testing. Based on previous work showing this is a good compromise in terms of cost and effectiveness, this paper focuses on a specific state-based technique: the round-trip paths coverage criterion. Round-trip paths testing is compared to structural testing, and it is investigated whether they are complementary. Results show that even when a state machine models the behavior of the cluster under test as accurately as possible, no significant difference between the fault detection effectiveness of the two test strategies is observed, while the two test strategies are significantly more effective when combined by augmenting state machine testing with structural testing. A qualitative analysis also investigates the reasons why test techniques do not detect certain faults and how the cost of state machine testing can be brought down.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2010.32",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5416729",
      "Author_Keywords": "State-based software testing;structural testing;controlled experiments;state machines.",
      "IEEE_Terms": "Object oriented modeling;Costs;Fault detection;Unified modeling language;System testing;Software testing;Automatic testing;Software engineering;Software design;Logic testing",
      "Article Citation Count": "55",
      "Reference Count": "20",
      "License": "IEEE",
      "Online Date": "18-Feb-10",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Self-Configurable Cyber-Physical Intrusion Detection for Smart Homes Using Reinforcement Learning",
      "Authors": "R. Heartfield; G. Loukas; A. Bezemskij; E. Panaousis",
      "Author Affiliations": "School of Computing and Mathematical Sciences, University of Greenwich, London, U.K.; School of Computing and Mathematical Sciences, University of Greenwich, London, U.K.; School of Computing and Mathematical Sciences, University of Greenwich, London, U.K.; School of Computing and Mathematical Sciences, University of Greenwich, London, U.K.",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "28-Dec-20",
      "Publication Year": "2021",
      "Volume": "16",
      "Start Page": "1720",
      "End Page": "1735",
      "Abstract": "The modern Internet of Things (IoT)-based smart home is a challenging environment to secure: devices change, new vulnerabilities are discovered and often remain unpatched, and different users interact with their devices differently and have different cyber risk attitudes. A security breach's impact is not limited to cyberspace, as it can also affect or be facilitated in physical space, for example, via voice. In this environment, intrusion detection cannot rely solely on static models that remain the same over time and are the same for all users. We present MAGPIE, the first smart home intrusion detection system that is able to autonomously adjust the decision function of its underlying anomaly classification models to a smart home's changing conditions (e.g., new devices, new automation rules and user interaction with them). The method achieves this goal by applying a novel probabilistic cluster-based reward mechanism to non-stationary multi-armed bandit reinforcement learning. MAGPIE rewards the sets of hyperparameters of its underlying isolation forest unsupervised anomaly classifiers based on the cluster silhouette scores of their output. Experimental evaluation in a real household shows that MAGPIE exhibits high accuracy because of two further innovations: it takes into account both cyber and physical sources of data; and it detects human presence to utilise models that exhibit the highest accuracy in each case. MAGPIE is available in open-source format, together with its evaluation datasets, so it can benefit from future advances in unsupervised and reinforcement learning and be able to be enriched with further sources of data as smart home environments and attacks evolve.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2020.3042049",
      "Funding Information": "European Coordinated Research on Long-term Challenges in Information and Communication Sciences and Technologies ERA-NET (CHIST-ERA), under Project COCOON; EPSRC(grant numbers:EP/P016448/1); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9277640",
      "Author_Keywords": "Intrusion detection system;cyber-physical attacks;smart home;reinforcement learning",
      "IEEE_Terms": "Smart homes;IP networks;Intrusion detection;Hidden Markov models;Reinforcement learning;Wireless fidelity;Monitoring",
      "Article Citation Count": "50",
      "Reference Count": "45",
      "License": "IEEE",
      "Online Date": "2-Dec-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Reducing Bug Triaging Confusion by Learning from Mistakes with a Bug Tossing Knowledge Graph",
      "Authors": "Y. Su; Z. Xing; X. Peng; X. Xia; C. Wang; X. Xu; L. Zhu",
      "Author Affiliations": "Australian National University, Australia; Australian National University, Australia; Fudan University, China; Monash University, Australia; Fudan University, China; Data61, CSIRO, Australia; Data61, CSIRO, Australia",
      "Publication Title": "2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "20-Jan-22",
      "Publication Year": "2021",
      "Start Page": "191",
      "End Page": "202",
      "Abstract": "Assigning bugs to the right components is the prerequisite to get the bugs analyzed and fixed. Classification-based techniques have been used in practice for assisting bug component assignments, for example, the BugBug tool developed by Mozilla. However, our study on 124,477 bugs in Mozilla products reveals that erroneous bug component assignments occur frequently and widely. Most errors are repeated errors and some errors are even misled by the BugBug tool. Our study reveals that complex component designs and misleading component names and bug report keywords confuse bug component assignment not only for bug reporters but also developers and even bug triaging tools. In this work, we propose a learning to rank framework that learns to assign components to bugs from correct, erroneous and irrelevant bug-component assignments in the history. To inform the learning, we construct a bug tossing knowledge graph which incorporates not only goal-oriented component tossing relationships but also rich information about component tossing community, component descriptions, and historical closed and tossed bugs, from which three categories and seven types of features for bug, component and bug-component relation can be derived. We evaluate our approach on a dataset of 98,587 closed bugs (including 29,100 tossed bugs) of 186 components in six Mozilla products. Our results show that our approach significantly improves bug component assignments for both tossed and non-tossed bugs over the BugBug tool and the BugBug tool enhanced with component tossing relationships, with >20% Top-k accuracies and >30% NDCG@k (k=1,3,5,10).",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-6654-0337-5",
      "DOI": "10.1109/ASE51524.2021.9678574",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9678574",
      "Author_Keywords": "Bug Triaging;Learning to Rank;Knowledge Graph",
      "IEEE_Terms": "Knowledge engineering;Computer bugs;History;Software engineering",
      "Article Citation Count": "9",
      "Reference Count": "26",
      "License": "IEEE",
      "Online Date": "20-Jan-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "SAFELearning: Secure Aggregation in Federated Learning With Backdoor Detectability",
      "Authors": "Z. Zhang; J. Li; S. Yu; C. Makaya",
      "Author Affiliations": "Electrical and Computer Engineering Department, Stevens Institute of Technology, Hoboken, NJ, USA; Electrical and Computer Engineering Department, Stevens Institute of Technology, Hoboken, NJ, USA; Electrical and Computer Engineering Department, Stevens Institute of Technology, Hoboken, NJ, USA; HP Inc., Palo Alto, CA, USA",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "8-Jun-23",
      "Publication Year": "2023",
      "Volume": "18",
      "Start Page": "3289",
      "End Page": "3304",
      "Abstract": "For model privacy, local model parameters in federated learning shall be obfuscated before sent to the remote aggregator. This technique is referred to as secure aggregation. However, secure aggregation makes model poisoning attacks such as backdooring more convenient given that existing anomaly detection methods mostly require access to plaintext local models. This paper proposes a new federated learning technique SAFELearning to support backdoor detection for secure aggregation. We achieve this through two new primitives -oblivious random grouping (ORG) and partial parameter disclosure (PPD). ORG partitions participants into one-time random subgroups with group configurations oblivious to participants; PPD allows secure partial disclosure of aggregated subgroup models for anomaly detection without leaking individual model privacy. ORG is based on our construction of several new primitives including tree-based random subgroup generation, oblivious secure aggregation, and randomized Diffie-Hellman key exchange. ORG can thwart colluding attackers from knowing each other‚Äôs group membership assignment with non-negligible advantage than random guess. Backdoor attacks are detected based on statistical distributions of the subgroup aggregated parameters of the learning iterations. SAFELearning can significantly reduce backdoor model accuracy without jeopardizing the main task accuracy under common backdoor strategies. Extensive experiments show SAFELearning is robust against malicious and faulty participants, whilst being more efficient than the state-of-art secure aggregation protocol in terms of both communication and computation costs.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2023.3280032",
      "Funding Information": "NSF(grant numbers:ECCS#1923739); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10136231",
      "Author_Keywords": "Federated learning;secure aggregation;backdoor attack;machine learning",
      "IEEE_Terms": "Federated learning;Data models;Computational modeling;Privacy;Servers;Cryptography;Protocols",
      "Article Citation Count": "1",
      "Reference Count": "51",
      "License": "IEEE",
      "Online Date": "25-May-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "MetPurity: A Learning-Based Tool of Pure Method Identification for Automatic Test Generation",
      "Authors": "R. Yu; Y. Zhang; J. Xuan",
      "Author Affiliations": "School of Computer Science Wuhan University, Wuhan, China; School of Computer Science Wuhan University, Wuhan, China; School of Computer Science Wuhan University, Wuhan, China",
      "Publication Title": "2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "24-Dec-20",
      "Publication Year": "2020",
      "Start Page": "1326",
      "End Page": "1330",
      "Abstract": "In object-oriented programming, a method is pure if calling the method does not change object states that exist in the pre-states of the method call. Pure methods are widely-used in automatic techniques, including test generation, compiler optimization, and program repair. Due to the source code dependency, it is infeasible to completely and accurately identify all pure methods. Instead, existing techniques such as ReImInfer are designed to identify a subset of accurate results of pure method and mark the other methods as unknown ones. In this paper, we designed and implemented MetPurity, a learning-based tool of pure method identification. Given all methods in a project, MetPurity labels a training set via automatic program analysis and builds a binary classifier (implemented with the random forest classifier) based on the training set. This classifier is used to predict the purity of all the other methods (i.e., unknown ones) in the same project. Preliminary evaluation on four open-source Java projects shows that Metpurity can provide a list of identified pure methods with a low error rate. Applying Met-purity to EvoSuite can increase the number of generated assertions for regression testing in test generation by EvoSuite.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-4503-6768-4",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9286131",
      "Author_Keywords": "Method purity;static analysis;debugging;machine learning;test generation;regression testing",
      "IEEE_Terms": "Training;Error analysis;Training data;Tools;Test pattern generators;Random forests;Software engineering",
      "Article Citation Count": "1",
      "Reference Count": "18",
      "Online Date": "24-Dec-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Automated Characterization of Software Vulnerabilities",
      "Authors": "D. Gonzalez; H. Hastings; M. Mirakhorli",
      "Author Affiliations": "Rochester Institute of Technology, Rochester, NY, USA; Rochester Institute of Technology, Rochester, NY, USA; Rochester Institute of Technology, Rochester, NY, USA",
      "Publication Title": "2019 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "5-Dec-19",
      "Publication Year": "2019",
      "Start Page": "135",
      "End Page": "139",
      "Abstract": "Preventing vulnerability exploits is a critical software maintenance task, and software engineers often rely on Common Vulnerability and Exposure (CVEs) reports for information about vulnerable systems and libraries. These reports include descriptions, disclosure sources, and manually-populated vulnerability characteristics such as root cause from the NIST Vulnerability Description Ontology (VDO). This information needs to be complete and accurate so stakeholders of affected products can prevent and react to exploits of the reported vulnerabilities. In this study, we demonstrate that VDO characteristics can be automatically detected from the textual descriptions included in CVE reports. We evaluated the performance of 6 classification algorithms with a dataset of 365 vulnerability descriptions, each mapped to 1 of 19 characteristics from the VDO. This work demonstrates that it is feasible to train classification techniques to accurately characterize vulnerabilities from their descriptions. All 6 classifiers evaluated produced accurate results, and the Support Vector Machine classifier was the best-performing individual classifier. Automating the vulnerability characterization process is a step towards ensuring stakeholders have the necessary data to effectively maintain their systems.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-7281-3094-1",
      "DOI": "10.1109/ICSME.2019.00023",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918946",
      "Author_Keywords": "software maintainence;vulnerability characterization;text classification;CVE;VDO",
      "IEEE_Terms": "Support vector machines;Software;Task analysis;Measurement;NIST;Ontologies;Stakeholders",
      "Article Citation Count": "6",
      "Reference Count": "17",
      "License": "IEEE",
      "Online Date": "5-Dec-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Practical Approach to the Automatic Classification of Security-Relevant Commits",
      "Authors": "A. Sabetta; M. Bezzi",
      "Author Affiliations": "SAP Security Research; SAP Security Research",
      "Publication Title": "2018 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "11-Nov-18",
      "Publication Year": "2018",
      "Start Page": "579",
      "End Page": "582",
      "Abstract": "The lack of reliable sources of detailed information on the vulnerabilities of open-source software (OSS) components is a major obstacle to maintaining a secure software supply chain and an effective vulnerability management process. Standard sources of advisories and vulnerability data, such as the National Vulnerability Database (NVD), are known to suffer from poor coverage and inconsistent quality. To reduce our dependency on these sources, we propose an approach that uses machine-learning to analyze source code repositories and to automatically identify commits that are security-relevant (i.e., that are likely to fix a vulnerability). We treat the source code changes introduced by commits as documents written in natural language, classifying them using standard document classification methods. Combining independent classifiers that use information from different facets of commits, our method can yield high precision (80%) while ensuring acceptable recall (43%). In particular, the use of information extracted from the source code changes yields a substantial improvement over the best known approach in state of the art, while requiring a significantly smaller amount of training data and employing a simpler architecture.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-5386-7870-1",
      "DOI": "10.1109/ICSME.2018.00058",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8530068",
      "Author_Keywords": "machine learning;open source software;vulnerabilities;NVD;CVE;commit classification;source code repositories;code change classification",
      "IEEE_Terms": "Security;Standards;Open source software;Databases;Predictive models;Machine learning",
      "Article Citation Count": "35",
      "Reference Count": "8",
      "License": "IEEE",
      "Online Date": "11-Nov-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Using Transfer Learning for Code-Related Tasks",
      "Authors": "A. Mastropaolo; N. Cooper; D. N. Palacio; S. Scalabrino; D. Poshyvanyk; R. Oliveto; G. Bavota",
      "Author Affiliations": "SEART Software Institute, Universit√† della Svizzera italiana, Lugano, Switzerland; SEMERU William & Mary, Williamsburg, VA, USA; SEMERU William & Mary, Williamsburg, VA, USA; University of Molise, Campobasso, CB, Italy; SEMERU William & Mary, Williamsburg, VA, USA; University of Molise, Campobasso, CB, Italy; SEART Software Institute, Universit√† della Svizzera italiana, Lugano, Switzerland",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "18-Apr-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "4",
      "Start Page": "1580",
      "End Page": "1598",
      "Abstract": "Deep learning (DL) techniques have been used to support several code-related tasks such as code summarization and bug-fixing. In particular, pre-trained transformer models are on the rise, also thanks to the excellent results they achieved in Natural Language Processing (NLP) tasks. The basic idea behind these models is to first pre-train them on a generic dataset using a self-supervised task (e.g., filling masked words in sentences). Then, these models are fine-tuned to support specific tasks of interest (e.g., language translation). A single model can be fine-tuned to support multiple tasks, possibly exploiting the benefits of transfer learning. This means that knowledge acquired to solve a specific task (e.g., language translation) can be useful to boost performance on another task (e.g., sentiment classification). While the benefits of transfer learning have been widely studied in NLP, limited empirical evidence is available when it comes to code-related tasks. In this paper, we assess the performance of the Text-To-Text Transfer Transformer (T5) model in supporting four different code-related tasks: (i) automatic bug-fixing, (ii) injection of code mutants, (iii) generation of assert statements, and (iv) code summarization. We pay particular attention in studying the role played by pre-training and multi-task fine-tuning on the model's performance. We show that (i) the T5 can achieve better performance as compared to state-of-the-art baselines; and (ii) while pre-training helps the model, not all tasks benefit from a multi-task fine-tuning.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2022.3183297",
      "Funding Information": "European Research Council(grant numbers:851720); National Science Foundation(grant numbers:CCF-1955853,CCF-1815186,CCF-2007246); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9797060",
      "Author_Keywords": "Deep learning;empirical software engineering",
      "IEEE_Terms": "Task analysis;Codes;Multitasking;Electronic mail;Computer bugs;Natural language processing;Java",
      "Article Citation Count": "13",
      "Reference Count": "87",
      "License": "IEEE",
      "Online Date": "15-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Evaluating Explanation Methods for Deep Learning in Security",
      "Authors": "A. Warnecke; D. Arp; C. Wressnegger; K. Rieck",
      "Author Affiliations": "Technische Universit√§t Braunschweig, Germany; Technische Universit√§t Braunschweig, Germany; Karlsruhe Institute of Technology, Germany; Technische Universit√§t Braunschweig, Germany",
      "Publication Title": "2020 IEEE European Symposium on Security and Privacy (EuroS&P)",
      "Date Added To Xplore": "2-Nov-20",
      "Publication Year": "2020",
      "Start Page": "158",
      "End Page": "174",
      "Abstract": "Deep learning is increasingly used as a building block of security systems. Unfortunately, neural networks are hard to interpret and typically opaque to the practitioner. The machine learning community has started to address this problem by developing methods for explaining the predictions of neural networks. While several of these approaches have been successfully applied in the area of computer vision, their application in security has received little attention so far. It is an open question which explanation methods are appropriate for computer security and what requirements they need to satisfy. In this paper, we introduce criteria for comparing and evaluating explanation methods in the context of computer security. These cover general properties, such as the accuracy of explanations, as well as security-focused aspects, such as the completeness, efficiency, and robustness. Based on our criteria, we investigate six popular explanation methods and assess their utility in security systems for malware detection and vulnerability discovery. We observe significant differences between the methods and build on these to derive general recommendations for selecting and applying explanation methods in computer security.",
      "ISBNs": "978-1-7281-5087-1",
      "DOI": "10.1109/EuroSP48549.2020.00018",
      "Funding Information": "German Federal Ministry of Education and Research (BMBF)(grant numbers:FKZ 16KIS0534); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9230374",
      "Author_Keywords": "AI based security or privacy enhancing tools;Security of AI",
      "IEEE_Terms": "Deep learning;Computer vision;Neural networks;Training data;Robustness;Malware;Computer security",
      "Article Citation Count": "40",
      "Reference Count": "57",
      "License": "IEEE",
      "Online Date": "2-Nov-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "DEEPSEC: A Uniform Platform for Security Analysis of Deep Learning Model",
      "Authors": "X. Ling; S. Ji; J. Zou; J. Wang; C. Wu; B. Li; T. Wang",
      "Author Affiliations": "Zhejiang University; Alibaba-Zhejiang University Joint Research Institute of Frontier Technologies; Zhejiang University; Zhejiang University; Zhejiang University; UIUC; Lehigh University",
      "Publication Title": "2019 IEEE Symposium on Security and Privacy (SP)",
      "Date Added To Xplore": "16-Sep-19",
      "Publication Year": "2019",
      "Start Page": "673",
      "End Page": "690",
      "Abstract": "Deep learning (DL) models are inherently vulnerable to adversarial examples ‚Äì maliciously crafted inputs to trigger target DL models to misbehave ‚Äì which significantly hinders the application of DL in security-sensitive domains. Intensive research on adversarial learning has led to an arms race between adversaries and defenders. Such plethora of emerging attacks and defenses raise many questions: Which attacks are more evasive, preprocessing-proof, or transferable? Which defenses are more effective, utility-preserving, or general? Are ensembles of multiple defenses more robust than individuals? Yet, due to the lack of platforms for comprehensive evaluation on adversarial attacks and defenses, these critical questions remain largely unsolved. In this paper, we present the design, implementation, and evaluation of DEEPSEC, a uniform platform that aims to bridge this gap. In its current implementation, DEEPSEC incorporates 16 state-of-the-art attacks with 10 attack utility metrics, and 13 state-of-the-art defenses with 5 defensive utility metrics. To our best knowledge, DEEPSEC is the first platform that enables researchers and practitioners to (i) measure the vulnerability of DL models, (ii) evaluate the effectiveness of various attacks/defenses, and (iii) conduct comparative studies on attacks/defenses in a comprehensive and informative manner. Leveraging DEEPSEC, we systematically evaluate the existing adversarial attack and defense methods, and draw a set of key findings, which demonstrate DEEPSEC‚Äôs rich functionality, such as (1) the trade-off between misclassification and imperceptibility is empirically confirmed; (2) most defenses that claim to be universally applicable can only defend against limited types of attacks under restricted settings; (3) it is not necessary that adversarial examples with higher perturbation magnitude are easier to be detected; (4) the ensemble of multiple defenses cannot improve the overall defense capability, but can improve the lower bound of the defense effectiveness of individuals. Extensive analysis on DEEPSEC demonstrates its capabilities and advantages as a benchmark platform which can benefit future adversarial learning research.",
      "ISSN": "2375-1207",
      "ISBNs": "978-1-5386-6660-9",
      "DOI": "10.1109/SP.2019.00023",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8835375",
      "Author_Keywords": "Deep-Learning;Adversarial-machine-learning;benchmark-platform",
      "IEEE_Terms": "Measurement;Perturbation methods;Security;Robustness;Terminology;Jacobian matrices;Training",
      "Article Citation Count": "63",
      "Reference Count": "67",
      "License": "IEEE",
      "Online Date": "16-Sep-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Does data sampling improve deep learning-based vulnerability detection? Yeas! and Nays!",
      "Authors": "X. Yang; S. Wang; Y. Li; S. Wang",
      "Author Affiliations": "University of Manitoba, Canada; University of Manitoba, Canada; New Jersey Institute of Technology, USA; New Jersey Institute of Technology, USA",
      "Publication Title": "2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "14-Jul-23",
      "Publication Year": "2023",
      "Start Page": "2287",
      "End Page": "2298",
      "Abstract": "Recent progress in Deep Learning (DL) has sparked interest in using DL to detect software vulnerabilities automatically and it has been demonstrated promising results at detecting vulnerabilities. However, one prominent and practical issue for vulnerability detection is data imbalance. Prior study observed that the performance of state-of-the-art (SOTA) DL-based vulnerability detection (DLVD) approaches drops precipitously in real world imbalanced data and a 73% drop of F1-score on average across studied approaches. Such a significant performance drop can disable the practical usage of any DLVD approaches. Data sampling is effective in alleviating data imbalance for machine learning models and has been demonstrated in various software engineering tasks. Therefore, in this study, we conducted a systematical and extensive study to assess the impact of data sampling for data imbalance problem in DLVD from two aspects: i) the effectiveness of DLVD, and ii) the ability of DLVD to reason correctly (making a decision based on real vulnerable statements). We found that in general, oversampling outperforms undersampling, and sampling on raw data outperforms sampling on latent space, typically random oversampling on raw data performs the best among all studied ones (including advanced one SMOTE and OSS). Surprisingly, OSS does not help alleviate the data imbalance issue in DLVD. If the recall is pursued, random undersampling is the best choice. Random oversampling on raw data also improves the ability of DLVD approaches for learning real vulnerable patterns. However, for a significant portion of cases (at least 33% in our datasets), DVLD approach cannot reason their prediction based on real vulnerable statements. We provide actionable suggestions and a roadmap to practitioners and researchers.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-5701-9",
      "DOI": "10.1109/ICSE48619.2023.00192",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172668",
      "Author_Keywords": "Vulnerability detection;deep learning;data sampling;interpretable AI",
      "IEEE_Terms": "Deep learning;Systematics;Software;Data models;Task analysis;Software engineering",
      "Reference Count": "57",
      "License": "IEEE",
      "Online Date": "14-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Lightweight Assessment of Test-Case Effectiveness Using Source-Code-Quality Indicators",
      "Authors": "G. Grano; F. Palomba; H. C. Gall",
      "Author Affiliations": "University of Zurich, Zurich, Switzerland; University of Zurich, Zurich, Switzerland; University of Zurich, Zurich, Switzerland",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "16-Apr-21",
      "Publication Year": "2021",
      "Volume": "47",
      "Issue": "4",
      "Start Page": "758",
      "End Page": "774",
      "Abstract": "Test cases are crucial to help developers preventing the introduction of software faults. Unfortunately, not all the tests are properly designed or can effectively capture faults in production code. Some measures have been defined to assess test-case effectiveness: the most relevant one is the mutation score, which highlights the quality of a test by generating the so-called mutants, i.e., variations of the production code that make it faulty and that the test is supposed to identify. However, previous studies revealed that mutation analysis is extremely costly and hard to use in practice. The approaches proposed by researchers so far have not been able to provide practical gains in terms of mutation testing efficiency. This leaves the problem of efficiently assessing test-case effectiveness as still open. In this paper, we investigate a novel, orthogonal, and lightweight methodology to assess test-case effectiveness: in particular, we study the feasibility to exploit production and test-code-quality indicators to estimate the mutation score of a test case. We first select a set of 67 factors and study their relation with test-case effectiveness. Then, we devise a mutation score estimation model exploiting such factors and investigate its performance as well as its most relevant features. The key results of the study reveal that our estimation model only based on static features has 86 percent of both F-Measure and AUC-ROC. This means that we can estimate the test-case effectiveness, using source-code-quality indicators, with high accuracy and without executing the tests. As a consequence, we can provide a practical approach that is beyond the typical limitations of current mutation testing techniques.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2019.2903057",
      "Funding Information": "Swiss National Science Foundation (SNSF)(grant numbers:200021_166275,PP00P2_170529); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8658120",
      "Author_Keywords": "Automated software testing;mutation testing;software quality",
      "IEEE_Terms": "Testing;Production;Estimation;Measurement;Predictive models;Machine learning;Computational modeling",
      "Article Citation Count": "24",
      "Reference Count": "108",
      "License": "IEEE",
      "Online Date": "4-Mar-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "An Improved SDA Based Defect Prediction Framework for Both Within-Project and Cross-Project Class-Imbalance Problems",
      "Authors": "X. -Y. Jing; F. Wu; X. Dong; B. Xu",
      "Author Affiliations": "State Key Laboratory of Software Engineering, Wuhan University, Wuhan, China; State Key Laboratory of Software Engineering, Wuhan University, Wuhan, China; State Key Laboratory of Software Engineering, Wuhan University, Wuhan, China; State Key Laboratory of Software Engineering, Wuhan University, Wuhan, China",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "14-Apr-17",
      "Publication Year": "2017",
      "Volume": "43",
      "Issue": "4",
      "Start Page": "321",
      "End Page": "339",
      "Abstract": "Background. Solving the class-imbalance problem of within-project software defect prediction (SDP) is an important research topic. Although some class-imbalance learning methods have been presented, there exists room for improvement. For cross-project SDP, we found that the class-imbalanced source usually leads to misclassification of defective instances. However, only one work has paid attention to this cross-project class-imbalance problem. Objective. We aim to provide effective solutions for both within-project and cross-project class-imbalance problems. Method. Subclass discriminant analysis (SDA), an effective feature learning method, is introduced to solve the problems. It can learn features with more powerful classification ability from original metrics. For within-project prediction, we improve SDA for achieving balanced subclasses and propose the improved SDA (ISDA) approach. For cross-project prediction, we employ the semi-supervised transfer component analysis (SSTCA) method to make the distributions of source and target data consistent, and propose the SSTCA+ISDA prediction approach. Results. Extensive experiments on four widely used datasets indicate that: 1) ISDA-based solution performs better than other state-of-the-art methods for within-project class-imbalance problem; 2) SSTCA+ISDA proposed for cross-project class-imbalance problem significantly outperforms related methods.  Conclusion. Within-project and cross-project class-imbalance problems greatly affect prediction performance, and we provide a unified and effective prediction framework for both problems.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2016.2597849",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:61272273,61572375,61233011,91418202,61472178); The Chinese 973 Program(grant numbers:2014CB340702); Research Project of NJUPT(grant numbers:XJKY14016); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7530877",
      "Author_Keywords": "Software defect prediction (SDP);within-project class-imbalance;cross-project class-imbalance;improved subclass discriminant analysis (ISDA);ISDA based defect prediction framework",
      "IEEE_Terms": "Support vector machines;Learning systems;Predictive models;Software;Software engineering;Measurement",
      "Article Citation Count": "143",
      "Reference Count": "78",
      "License": "IEEE",
      "Online Date": "3-Aug-16",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Improving Fitness Function for Language Fuzzing with PCFG Model",
      "Authors": "X. Sun; Y. Fu; Y. Dong; Z. Liu; Y. Zhang",
      "Author Affiliations": "Trusted Computing and Information Assurance Laboratory, Chinese Academy of Sciences, Beijing, China; Trusted Computing and Information Assurance Laboratory, Chinese Academy of Sciences, Beijing, China; Beijing Capitek Co., Ltd., Beijing, China; Trusted Computing and Information Assurance Laboratory, Chinese Academy of Sciences, Beijing, China; Trusted Computing and Information Assurance Laboratory, Chinese Academy of Sciences, Beijing, China",
      "Publication Title": "2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "22-Jun-18",
      "Publication Year": "2018",
      "Volume": "01",
      "Start Page": "655",
      "End Page": "660",
      "Abstract": "In this paper, we propose to use machine learning techniques to model the vagueness of bugs for language interpreters and develop a fitness function for the language fuzzing based on genetic programming. The basic idea is that bug-triggering scripts usually contain uncommon usages which are not likely used by programmers in daily developments. We capture the uncommonness by using the probabilistic context-free grammar model and the Markov model to compute the probabilities of scripts such that bug-triggering scripts will get lower probabilities and higher fitness values. We choose the ROC (Receiver Operating Characteristic) curves to evaluate the performance of fitness functions in identifying bug-triggering scripts from normal scripts. We use a large corpus of JavaScript scripts from Github and POC test cases of bug-reports from SpiderMonkey's bugzilla for evaluations. The ROC curves from the experiments show that our method can provide better ability to rank the bug triggering scripts in the top-K elements.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-5386-2667-2",
      "DOI": "10.1109/COMPSAC.2018.00098",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8377723",
      "Author_Keywords": "language fuzzing, probabilistic context free grammar, evolutionary algorithm, script ranking, Markov chain",
      "IEEE_Terms": "Fuzzing;Computational modeling;Computer bugs;Machine learning;Markov processes;Reactive power;Mathematical model",
      "Article Citation Count": "1",
      "Reference Count": "28",
      "License": "IEEE",
      "Online Date": "22-Jun-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "DeepJIT: An End-to-End Deep Learning Framework for Just-in-Time Defect Prediction",
      "Authors": "T. Hoang; H. Khanh Dam; Y. Kamei; D. Lo; N. Ubayashi",
      "Author Affiliations": "Singapore Management University, Singapore; University of Wollongong, Australia; Kyushu University, Japan; Singapore Management University, Singapore; Kyushu University, Japan",
      "Publication Title": "2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "29-Aug-19",
      "Publication Year": "2019",
      "Start Page": "34",
      "End Page": "45",
      "Abstract": "Software quality assurance efforts often focus on identifying defective code. To find likely defective code early, change-level defect prediction - aka. Just-In-Time (JIT) defect prediction - has been proposed. JIT defect prediction models identify likely defective changes and they are trained using machine learning techniques with the assumption that historical changes are similar to future ones. Most existing JIT defect prediction approaches make use of manually engineered features. Unlike those approaches, in this paper, we propose an end-to-end deep learning framework, named DeepJIT, that automatically extracts features from commit messages and code changes and use them to identify defects. Experiments on two popular software projects (i.e., QT and OPENSTACK) on three evaluation settings (i.e., cross-validation, short-period, and long-period) show that the best variant of DeepJIT (DeepJIT-Combined), compared with the best performing state-of-the-art approach, achieves improvements of 10.36-11.02% for the project QT and 9.51-13.69% for the project OPENSTACK in terms of the Area Under the Curve (AUC).",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-7281-3412-3",
      "DOI": "10.1109/MSR.2019.00016",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8816772",
      "Author_Keywords": "deep learning;just-in-time defect prediction;convolutional neural network",
      "IEEE_Terms": "Feature extraction;Software;Predictive models;Convolutional codes;Deep learning;Natural language processing;Testing",
      "Article Citation Count": "113",
      "Reference Count": "78",
      "License": "IEEE",
      "Online Date": "29-Aug-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Rete: Learning Namespace Representation for Program Repair",
      "Authors": "N. Parasaram; E. T. Barr; S. Mechtaev",
      "Author Affiliations": "University College London, London, United Kingdom; University College London, London, United Kingdom; University College London, London, United Kingdom",
      "Publication Title": "2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "14-Jul-23",
      "Publication Year": "2023",
      "Start Page": "1264",
      "End Page": "1276",
      "Abstract": "A key challenge of automated program repair is finding correct patches in the vast search space of candidate patches. Real-world programs define large namespaces of variables that considerably contributes to the search space explosion. Existing program repair approaches neglect information about the program namespace, which makes them inefficient and increases the chance of test-overfitting. We propose Rete, a new program repair technique, that learns project-independent information about program namespace and uses it to navigate the search space of patches. Rete uses a neural network to extract project-independent information about variable CDU chains, def-use chains augmented with control flow. Then, it ranks patches by jointly ranking variables and the patch templates into which the variables are inserted. We evaluated Rete on 142 bugs extracted from two datasets, ManyBugs and BugsInPy. Our experiments demonstrate that ReTe generates six new correct patches that fix bugs that previous tools did not repair, an improvement of 31% and 59% over the existing state of the art.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-5701-9",
      "DOI": "10.1109/ICSE48619.2023.00112",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172760",
      "Author_Keywords": "Program Repair;Deep Learning;Patch Prioritisation;Variable Representation",
      "IEEE_Terms": "Navigation;Computer bugs;Neural networks;Maintenance engineering;Aerospace electronics;Explosions;Data mining",
      "Article Citation Count": "2",
      "Reference Count": "73",
      "License": "IEEE",
      "Online Date": "14-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "On Improving Deep Learning Trace Analysis with System Call Arguments",
      "Authors": "Q. Fournier; D. Aloise; S. V. Azhari; F. Tetreault",
      "Author Affiliations": "Polytechnique Montr√©al, Quebec; Polytechnique Montr√©al, Quebec; Ciena, Ottawa; Ciena, Ottawa",
      "Publication Title": "2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "28-Jun-21",
      "Publication Year": "2021",
      "Start Page": "120",
      "End Page": "130",
      "Abstract": "Kernel traces are sequences of low-level events comprising a name and multiple arguments, including a timestamp, a process id, and a return value, depending on the event. Their analysis helps uncover intrusions, identify bugs, and find latency causes. However, their effectiveness is hindered by omitting the event arguments. To remedy this limitation, we introduce a general approach to learning a representation of the event names along with their arguments using both embedding and encoding. The proposed method is readily applicable to most neural networks and is task-agnostic. The benefit is quantified by conducting an ablation study on three groups of arguments: call-related, process-related, and time-related. Experiments were conducted on a novel web request dataset and validated on a second dataset collected on pre-production servers by Ciena, our partnering company. By leveraging additional information, we were able to increase the performance of two widely-used neural networks, an LSTM and a Transformer, by up to 11.3% on two unsupervised language modelling tasks. Such tasks may be used to detect anomalies, pre-train neural networks to improve their performance, and extract a contextual representation of the events.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-7281-8710-5",
      "DOI": "10.1109/MSR52588.2021.00025",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9463093",
      "Author_Keywords": "Tracing;Machine Learning;Deep Learning",
      "IEEE_Terms": "Deep learning;Neural networks;Computer bugs;Companies;Software;Encoding;Servers",
      "Article Citation Count": "5",
      "Reference Count": "31",
      "License": "IEEE",
      "Online Date": "28-Jun-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Improving Cross-Language Code Clone Detection via Code Representation Learning and Graph Neural Networks",
      "Authors": "N. Mehrotra; A. Sharma; A. Jindal; R. Purandare",
      "Author Affiliations": "Department of Computer Science Engineering, IIIT Delhi, Delhi, India; Department of Computer Science Engineering, IIIT Delhi, Delhi, India; Department of Computer Science Engineering, IIIT Delhi, Delhi, India; University of Nebraska‚ÄìLincoln, Lincoln, NE, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "16-Nov-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "11",
      "Start Page": "4846",
      "End Page": "4868",
      "Abstract": "Code clone detection is an important aspect of software development and maintenance. The extensive research in this domain has helped reduce the complexity and increase the robustness of source code, thereby assisting bug detection tools. However, the majority of the clone detection literature is confined to a single language. With the increasing prevalence of cross-platform applications, functionality replication across multiple languages is common, resulting in code fragments having similar functionality but belonging to different languages. Since such clones are syntactically unrelated, single language clone detection tools are not applicable in their case. In this article, we propose a semi-supervised deep learning-based tool Rubhus, capable of detecting clones across different programming languages. Rubhus uses the control and data flow enriched abstract syntax trees (ASTs) of code fragments to leverage their syntactic and structural information and then applies graph neural networks (GNNs) to extract this information for the task of clone detection. We demonstrate the effectiveness of our proposed system through experiments conducted over datasets consisting of Java, C, and Python programs and evaluate its performance in terms of precision, recall, and F1 score. Our results indicate that Rubhus outperforms the state-of-the-art cross-language clone detection tools.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2023.3311796",
      "Funding Information": "Department of Science and Technology (DST) (India); Science and Engineering Research Board (SERB); Confederation of Indian Industry (CII); Infosys Center for Artificial Intelligence at IIIT-Delhi; Nucleus Software Exports Ltd; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10242168",
      "Author_Keywords": "Program representation learning;cross-language code clone detection;graph-based neural networks;abstract syntax trees",
      "IEEE_Terms": "Codes;Cloning;Syntactics;Semantics;Java;Task analysis;Source coding",
      "Reference Count": "76",
      "License": "IEEE",
      "Online Date": "6-Sep-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Unsupervised Labeling and Extraction of Phrase-based Concepts in Vulnerability Descriptions",
      "Authors": "S. Yitagesu; Z. Xing; X. Zhang; Z. Feng; X. Li; L. Han",
      "Author Affiliations": "College of Intelligence and Computing Tianjin University, Tianjin, China; Research School of Computer Science Australian National University, Data61 CSIRO, Australia; College of Intelligence and Computing Tianjin University, Tianjin, China; College of Intelligence and Computing Tianjin University, Tianjin, China; College of Intelligence and Computing Tianjin University, Tianjin, China; College of Intelligence and Computing Tianjin University, Tianjin, China",
      "Publication Title": "2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "20-Jan-22",
      "Publication Year": "2021",
      "Start Page": "943",
      "End Page": "954",
      "Abstract": "People usually describe the key characteristics of software vulnerabilities in natural language mixed with domain-specific names and concepts. This textual nature poses a significant challenge for the automatic analysis of vulnerabilities. Automatic extraction of key vulnerability aspects is highly desirable but demands significant effort to manually label data for model training. In this paper, we propose an unsupervised approach to label and extract important vulnerability concepts in textural vulnerability descriptions (TVDs). We focus on three types of phrase-based vulnerability concepts (root cause, attack vector, and impact) as they are much more difficult to label and extract than name- or number-based entities (i.e., vendor, product, and version). Our approach is based on a key observation that the same-type of phrases, no matter how they differ in sentence structures and phrase expressions, usually share syntactically similar paths in the sentence parsing trees. Therefore, we propose two path representations (absolute paths and relative paths) and use an auto-encoder to encode such syntactic similarities. To address the discrete nature of our paths, we enhance traditional Variational Auto-encoder (VAE) with Gumble-Max trick for categorical data distribution, and thus creates a Categorical VAE (CaVAE). In the latent space of absolute and relative paths, we further use FIt-TSNE and clustering techniques to generate clusters of the same-type of concepts. Our evaluation confirms the effectiveness of our CaVAE for encoding path representations and the accuracy of vulnerability concepts in the resulting clusters. In a concept classification task, our unsupervisedly labeled vulnerability concepts outperform the two manually labeled datasets from previous work.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-6654-0337-5",
      "DOI": "10.1109/ASE51524.2021.9678638",
      "Funding Information": "National Natural Science Foundation of China; Tianjin University; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9678638",
      "Author_Keywords": "Textual Vulnerability Descriptions;Vulnerability Concepts;Unsupervised Representation Learning;Concept Labeling and Extraction",
      "IEEE_Terms": "Training;Natural languages;Training data;Machine learning;Syntactics;Software;Labeling",
      "Article Citation Count": "5",
      "Reference Count": "51",
      "License": "IEEE",
      "Online Date": "20-Jan-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Striking a Balance: Pruning False-Positives from Static Call Graphs",
      "Authors": "A. Utture; S. Liu; C. G. Kalhauge; J. Palsberg",
      "Author Affiliations": "University of California, Los Angeles, U.S.A.; University of California, Los Angeles, U.S.A.; DTU, Denmark; University of California, Los Angeles, U.S.A.",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "2043",
      "End Page": "2055",
      "Abstract": "Researchers have reported that static analysis tools rarely achieve a false-positive rate that would make them attractive to developers. We overcome this problem by a technique that leads to reporting fewer bugs but also much fewer false positives. Our technique prunes the static call graph that sits at the core of many static analyses. Specifically, static call-graph construction proceeds as usual, after which a call-graph pruner removes many false-positive edges but few true edges. The challenge is to strike a balance between being aggressive in removing false-positive edges but not so aggressive that no true edges remain. We achieve this goal by automatically producing a call-graph pruner through an automatic, ahead-of-time learning process. We added such a call-graph pruner to a software tool for null-pointer analysis and found that the false-positive rate decreased from 73% to 23%. This improvement makes the tool more useful to developers.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3510166",
      "Funding Information": "ONR(grant numbers:N00014-18-1-2037); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794059",
      "Author_Keywords": "Static Analysis;Machine learning classification;Call graphs",
      "IEEE_Terms": "Computer bugs;Static analysis;Software tools;Software engineering",
      "Article Citation Count": "4",
      "Reference Count": "50",
      "License": "CCBY",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "RENN: Efficient Reverse Execution with Neural-Network-Assisted Alias Analysis",
      "Authors": "D. Mu; W. Guo; A. Cuevas; Y. Chen; J. Gai; X. Xing; B. Mao; C. Song",
      "Author Affiliations": "National Key Laboratory for Novel Software Technology, Nanjing University, China; College of Information Sciences and Technology, The Pennsylvania State University, USA; College of Information Sciences and Technology, The Pennsylvania State University, USA; College of Information Sciences and Technology, The Pennsylvania State University, USA; College of Information Sciences and Technology, The Pennsylvania State University, USA; College of Information Sciences and Technology, The Pennsylvania State University, USA; National Key Laboratory for Novel Software Technology, Nanjing University, China; University of California, Riverside, USA",
      "Publication Title": "2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "9-Jan-20",
      "Publication Year": "2019",
      "Start Page": "924",
      "End Page": "935",
      "Abstract": "Reverse execution and coredump analysis have long been used to diagnose the root cause of software crashes. Each of these techniques, however, face inherent challenges, such as insufficient capability when handling memory aliases. Recent works have used hypothesis testing to address this drawback, albeit with high computational complexity, making them impractical for real world applications. To address this issue, we propose a new deep neural architecture, which could significantly improve memory alias resolution. At the high level, our approach employs a recurrent neural network (RNN) to learn the binary code pattern pertaining to memory accesses. It then infers the memory region accessed by memory references. Since memory references to different regions naturally indicate a non-alias relationship, our neural architecture can greatly reduce the burden of doing hypothesis testing to track down non-alias relation in binary code. Different from previous researches that have utilized deep learning for other binary analysis tasks, the neural network proposed in this work is fundamentally novel. Instead of simply using off-the-shelf neural networks, we designed a new recurrent neural architecture that could capture the data dependency between machine code segments. To demonstrate the utility of our deep neural architecture, we implement it as RENN, a neural network-assisted reverse execution system. We utilize this tool to analyze software crashes corresponding to 40 memory corruption vulnerabilities from the real world. Our experiments show that RENN can significantly improve the efficiency of locating the root cause for the crashes. Compared to a state-of-the-art technique, RENN has 36.25% faster execution time on average, detects an average of 21.35% more non-alias pairs, and successfully identified the root cause of 12.5% more cases.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-7281-2508-4",
      "DOI": "10.1109/ASE.2019.00090",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952186",
      "Author_Keywords": "Reverse Execution, Deep Learning, Memory Alias",
      "IEEE_Terms": "Computer crashes;Core dumps;Software;Neural networks;Runtime;Testing;Computer architecture",
      "Article Citation Count": "6",
      "Reference Count": "50",
      "License": "IEEE",
      "Online Date": "9-Jan-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Empirical Evaluation of Fault Localisation Using Code and Change Metrics",
      "Authors": "J. Sohn; S. Yoo",
      "Author Affiliations": "School of Computing, Korea Advanced Institute of Science and Technology, Daejon, Republic of Korea; School of Computing, Korea Advanced Institute of Science and Technology, Daejon, Republic of Korea",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "12-Aug-21",
      "Publication Year": "2021",
      "Volume": "47",
      "Issue": "8",
      "Start Page": "1605",
      "End Page": "1625",
      "Abstract": "Fault localisation aims to reduce the debugging efforts of human developers by highlighting the program elements that are suspected to be the root cause of the observed failure. Spectrum Based Fault Localisation (SBFL), a coverage based approach, has been widely studied in many researches as a promising localisation technique. Recently, however, it has been proven that SBFL techniques have reached the limit of further improvement. To overcome the limitation, we extend SBFL with code and change metrics that have been mainly studied in defect prediction, such as size, age, and churn. FLUCCS, our fault learn-to-rank localisation technique, employs both existing SBFL formul√¶ and these metrics as input. We investigate the effect of employing code and change metrics for fault localisation using four different learn-to-rank techniques: Genetic Programming, Gaussian Process Modelling, Support Vector Machine, and Random Forest. We evaluate the performance of FLUCCS with 386 real world faults collected from Defects4J repository. The results show that FLUCCS with code and change metrics places 144 faults at the top and 304 faults within the top ten. This is a significant improvement over the state-of-art SBFL formul√¶, which can locate 65 and 212 faults at the top and within the top ten, respectively. We also investigate the feasibility of cross-project transfer learning of fault localisation. The results show that, while there exist project-specific properties that can be exploited for better localisation per project, ranking models learnt from one project can be applied to others without significant loss of effectiveness.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2019.2930977",
      "Funding Information": "National Research Foundation of Korea(grant numbers:NRF-2016R1C1B1011042); Next-Generation Information Computing Development Program; National Research Foundation of Korea(grant numbers:2017M3C4A7068179); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8772166",
      "Author_Keywords": "Fault localisation;SBSE;genetic programming",
      "IEEE_Terms": "Measurement;Debugging;Genetic programming;Feature extraction;Support vector machines;Training",
      "Article Citation Count": "10",
      "Reference Count": "51",
      "License": "IEEE",
      "Online Date": "25-Jul-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Empirical Evaluation of the Impact of Class Overlap on Software Defect Prediction",
      "Authors": "L. Gong; S. Jiang; R. Wang; L. Jiang",
      "Author Affiliations": "School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, China; School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, China; School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, China; School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, China",
      "Publication Title": "2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "9-Jan-20",
      "Publication Year": "2019",
      "Start Page": "698",
      "End Page": "709",
      "Abstract": "Software defect prediction (SDP) utilizes the learning models to detect the defective modules in project, and their performance depends on the quality of training data. The previous researches mainly focus on the quality problems of class imbalance and feature redundancy. However, training data often contains some instances that belong to different class but have similar values on features, and this leads to class overlap to affect the quality of training data. Our goal is to investigate the impact of class overlap on software defect prediction. At the same time, we propose an improved K-Means clustering cleaning approach (IKMCCA) to solve both the class overlap and class imbalance problems. Specifically, we check whether K-Means clustering cleaning approach (KMCCA) or neighborhood cleaning learning (NCL) or IKMCCA is feasible to improve defect detection performance for two cases (i) within-project defect prediction (WPDP) (ii) cross-project defect prediction (CPDP). To have an objective estimate of class overlap, we carry out our investigations on 28 open source projects, and compare the performance of state-of-the-art learning models for the above-mentioned cases by using IKMCCA or KMCCA or NCL VS. without cleaning data. The experimental results make clear that learning models obtain significantly better performance in terms of balance, Recall and AUC for both WPDP and CPDP when the overlapping instances are removed. Moreover, it is better to consider both class overlap and class imbalance.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-7281-2508-4",
      "DOI": "10.1109/ASE.2019.00071",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952192",
      "Author_Keywords": "Class overlap;Software defect prediction;K Means clustering;Machine learning",
      "IEEE_Terms": "Software;Measurement;Predictive models;Cleaning;NASA;Data models;Training data",
      "Article Citation Count": "19",
      "Reference Count": "41",
      "License": "IEEE",
      "Online Date": "9-Jan-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A General Software Defect-Proneness Prediction Framework",
      "Authors": "Q. Song; Z. Jia; M. Shepperd; S. Ying; J. Liu",
      "Author Affiliations": "Department of Computer Science and Technology, Xi'an Jiaotong University, Xi'an, China; Department of Computer Science and Technology, Xi'an Jiaotong University, Xi'an, China; School of Information Science, Computing, and Mathematics, Brunel University, Uxbridge, UK; State Key Laboratory of Software Engineering, Wuhan University, Wuhan, China; State Key Laboratory of Software Engineering, Wuhan University, Wuhan, China",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "27-May-11",
      "Publication Year": "2011",
      "Volume": "37",
      "Issue": "3",
      "Start Page": "356",
      "End Page": "370",
      "Abstract": "BACKGROUND - Predicting defect-prone software components is an economically important activity and so has received a good deal of attention. However, making sense of the many, and sometimes seemingly inconsistent, results is difficult. OBJECTIVE - We propose and evaluate a general framework for software defect prediction that supports 1) unbiased and 2) comprehensive comparison between competing prediction systems. METHOD - The framework is comprised of 1) scheme evaluation and 2) defect prediction components. The scheme evaluation analyzes the prediction performance of competing learning schemes for given historical data sets. The defect predictor builds models according to the evaluated learning scheme and predicts software defects with new data according to the constructed model. In order to demonstrate the performance of the proposed framework, we use both simulation and publicly available software defect data sets. RESULTS - The results show that we should choose different learning schemes for different data sets (i.e., no scheme dominates), that small details in conducting how evaluations are conducted can completely reverse findings, and last, that our proposed framework is more effective and less prone to bias than previous approaches. CONCLUSIONS - Failure to properly or fully evaluate a learning scheme can be misleading; however, these problems may be overcome by our proposed framework.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2010.90",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5611551",
      "Author_Keywords": "Software defect prediction;software defect-proneness prediction;machine learning;scheme evaluation.",
      "IEEE_Terms": "Software;Training data;Predictive models;Buildings;Data models;Prediction algorithms;Training",
      "Article Citation Count": "240",
      "Patent Citation Count": "1",
      "Reference Count": "44",
      "License": "IEEE",
      "Online Date": "28-Oct-10",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Peeler: Learning to Effectively Predict Flakiness without Running Tests",
      "Authors": "Y. Qin; S. Wang; K. Liu; B. Lin; H. Wu; L. Li; X. Mao; T. F. Bissyand√©",
      "Author Affiliations": "National University of Defense Technology, China; National University of Defense Technology, China; Huawei Software Engineering Application Technology Lab, China; National University of Defense Technology, China; National University of Defense Technology, China; Monash University, Australia; National University of Defense Technology, China; University of Luxembourg, Luxembourg",
      "Publication Title": "2022 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "19-Dec-22",
      "Publication Year": "2022",
      "Start Page": "257",
      "End Page": "268",
      "Abstract": "Regression testing is a widely adopted approach to expose change-induced bugs as well as to verify the correctness/robustness of code in modern software development settings. Unfortunately, the occurrence of flaky tests leads to a significant increase in the cost of regression testing and eventually reduces the productivity of developers (i.e., their ability to find and fix real problems). State-of-the-art approaches leverage dynamic test information obtained through expensive re-execution of test cases to effectively identify flaky tests. Towards accounting for scalability constraints, some recent approaches have built on static test case features, but fall short on effectiveness. In this paper, we introduce Peeler, a new fully static approach for predicting flaky tests through exploring a representation of test cases based on the data dependency relations. The predictor is then trained as a neural network based model, which achieves at the same time scalability (because it does not require any test execution), effectiveness (because it exploits relevant test dependency features), and practicality (because it can be applied in the wild to find new flaky tests). Experimental validation on 17,532 test cases from 21 Java projects shows that Peeler outperforms the state-of-the-art FlakeFlagger by around 20 percentage points: we catch 22% more flaky tests while yielding 51% less false positives. Finally, in a live study with projects in-the-wild, we reported to developers 21 flakiness cases, among which 12 have already been confirmed by developers as being indeed flaky.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-6654-7956-1",
      "DOI": "10.1109/ICSME55016.2022.00031",
      "Funding Information": "National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9978221",
      "Author_Keywords": "Flaky tests;Deep learning;Program dependency",
      "IEEE_Terms": "Productivity;Software maintenance;Java;Costs;Scalability;Neural networks;Computer bugs",
      "Article Citation Count": "3",
      "Reference Count": "44",
      "License": "IEEE",
      "Online Date": "19-Dec-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "BotHunter: An Approach to Detect Software Bots in GitHub",
      "Authors": "A. Abdellatif; M. Wessel; I. Steinmacher; M. A. Gerosa; E. Shihab",
      "Author Affiliations": "Concordia University, Montreal, Canada; Delft University of Technology, Delft, Netherlands; Universidade Tecnol√≥gica Federal do Paran√°, Campo Mour√£o, Brazil; Northern Arizona University, Flagstaff, USA; Concordia University, Montreal, Canada",
      "Publication Title": "2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "21-Jun-22",
      "Publication Year": "2022",
      "Start Page": "6",
      "End Page": "17",
      "Abstract": "Bots have become popular in software projects as they play critical roles, from running tests to fixing bugs/vulnerabilities. However, the large number of software bots adds extra effort to practitioners and researchers to distinguish human accounts from bot accounts to avoid bias in data-driven studies. Researchers developed several approaches to identify bots at specific activity levels (issue/pull request or commit), considering a single repository and disregarding features that showed to be effective in other domains. To address this gap, we propose using a machine learning-based approach to identify the bot accounts regardless of their activity level. We selected and extracted 19 features related to the account's profile information, activities, and comment similarity. Then, we evaluated the performance of five machine learning classifiers using a dataset that has more than 5,000 GitHub accounts. Our results show that the Random Forest classifier performs the best, with an F1-score of 92.4% and AUC of 98.7%. Furthermore, the account profile information (e.g., account login) contains the most relevant features to identify the account type. Finally, we compare the performance of our Random Forest classifier to the state-of-the-art approaches, and our results show that our model outperforms the state-of-the-art techniques in identifying the account type regardless of their activity level.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-4503-9303-4",
      "DOI": "10.1145/3524842.3527959",
      "Funding Information": "National Science Foundation(grant numbers:1815503,1900903); CNPq(grant numbers:313067/2020-1); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796262",
      "Author_Keywords": "Software Bots;Empirical Software Engineering",
      "IEEE_Terms": "Bot (Internet);Feature extraction;Transformers;Software;Encoding;Data mining;Time factors",
      "Article Citation Count": "4",
      "Reference Count": "53",
      "Online Date": "21-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "ProXray: Protocol Model Learning and Guided Firmware Analysis",
      "Authors": "F. Fowze; D. Tian; G. Hernandez; K. Butler; T. Yavuz",
      "Author Affiliations": "Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA; CISE Department, Herbert Wertheim College of Engineering, University of Florida, Gainesville, FL, USA; CISE Department, Herbert Wertheim College of Engineering, University of Florida, Gainesville, FL, USA; Computer and Information Science and Engineering, University of Florida, Gainesville, FL, USA; Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "16-Sep-21",
      "Publication Year": "2021",
      "Volume": "47",
      "Issue": "9",
      "Start Page": "1907",
      "End Page": "1928",
      "Abstract": "The number of Internet of Things (IoT) has reached 7 billion globally in early 2018 and are nearly ubiquitous in daily life. Knowing whether or not these devices are safe and secure to use is becoming critical. IoT devices usually implement communication protocols such as USB and Bluetooth within firmware to allow a wide range of functionality. Thus analyzing firmware using domain knowledge from these protocols is vital to understand device behavior, detect implementation bugs, and identify malicious components. Unfortunately, due to the complexity of these protocols, there is usually no formal specification available that can help automate the firmware analysis; as a result significant manual effort is currently required to study these protocols and to reverse engineer the device firmware. In this paper, we propose a new firmware analysis methodology using symbolic execution called ProXray, which can learn a protocol model from known firmware, and apply the model to recognize the protocol relevant fields and detect functionality within unknown firmware automatically. After the training phase, ProXray can fully automate the firmware analysis process while supporting user's queries in the form of protocol relevant constraints. We have applied ProXray to the USB and the Bluetooth protocols by learning protocol constraint models from firmware that implement these protocols. We are then able to map protocol fields and identify USB functionality automatically within all 6 unknown USB firmware while achieving more than an order of magnitude speedup in reaching protocol relevant targets in unknown Bluetooth firmware. Our model achieved high coverage of the USB and Bluetooth specifications for several important protocol fields. ProXray provides a new method to apply domain knowledge to firmware analysis automatically.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2019.2939526",
      "Funding Information": "National Science Foundation(grant numbers:CNS-1815883); Semiconductor Research Corporation; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8823941",
      "Author_Keywords": "Protocol learning;model extraction;firmware;symbolic execution",
      "IEEE_Terms": "Protocols;Universal Serial Bus;Bluetooth;Hidden Markov models;Analytical models;Microprogramming;Feature extraction",
      "Article Citation Count": "5",
      "Reference Count": "70",
      "License": "IEEE",
      "Online Date": "4-Sep-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Automatic Web Testing Using Curiosity-Driven Reinforcement Learning",
      "Authors": "Y. Zheng; Y. Liu; X. Xie; Y. Liu; L. Ma; J. Hao; Y. Liu",
      "Author Affiliations": "Tianjin University, Tianjin, China; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Dept. of Comp. Sci. and Engr, Southern University of Science and Technology, Shenzhen, China; Kyushu University, Fukuoka, Japan; Tianjin University, Tianjin, China; Nanyang Technological University, Singapore",
      "Publication Title": "2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "7-May-21",
      "Publication Year": "2021",
      "Start Page": "423",
      "End Page": "435",
      "Abstract": "Web testing has long been recognized as a notoriously difficult task. Even nowadays, web testing still mainly relies on manual efforts in many cases while automated web testing is still far from achieving human-level performance. Key challenges include dynamic content update and deep bugs hiding under complicated user interactions and specific input values, which can only be triggered by certain action sequences in the huge space of all possible sequences. In this paper, we propose WebExplor, an automatic end-to-end web testing framework, to achieve an adaptive exploration of web applications. WebExplor adopts a curiosity-driven reinforcement learning to generate high-quality action sequences (test cases) with temporal logical relations. Besides, WebExplor incrementally builds an automaton during the online testing process, which acts as the high-level guidance to further improve the testing efficiency. We have conducted comprehensive evaluations on six real-world projects, a commercial SaaS web application, and performed an in-the-wild study of the top 50 web applications in the world. The results demonstrate that in most cases WebExplor can achieve significantly higher failure detection rate, code coverage and efficiency than existing state-of-the-art web testing techniques. WebExplor also detected 12 previously unknown failures in the commercial web application, which have been confirmed and fixed by the developers. Furthermore, our in-the-wild study further uncovered 3,466 exceptions and errors.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-0296-5",
      "DOI": "10.1109/ICSE43902.2021.00048",
      "Funding Information": "National Natural Science Foundation of China; National Research Foundation; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9402046",
      "Author_Keywords": "Web testing;Reinforcement Learning;Curiosity;Exploration;Software Engineering",
      "IEEE_Terms": "Location awareness;Software as a service;Reinforcement learning;Manuals;Task analysis;Testing;Software engineering",
      "Article Citation Count": "27",
      "Reference Count": "65",
      "License": "IEEE",
      "Online Date": "7-May-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "High-Frequency Keywords to Predict Defects for Android Applications",
      "Authors": "Y. Fan; X. Cao; J. Xu; S. Xu; H. Yang",
      "Author Affiliations": "College of Computer and Control Engineering, Nankai University, Tianjin, China; College of Computer and Control Engineering, Nankai University, Tianjin, China; College of Computer and Control Engineering, Nankai University, Tianjin, China; College of Computer and Control Engineering, Nankai University, Tianjin, China; Centre for Creative Computing, Bath Spa University, Bath, England",
      "Publication Title": "2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "22-Jun-18",
      "Publication Year": "2018",
      "Volume": "02",
      "Start Page": "442",
      "End Page": "447",
      "Abstract": "Android defect prediction has proved to be useful to reduce the manual testing effort for finding bugs. In recent years, researchers design metrics related to defects and analyze historical information to predict whether files contain defects using machine learning. However, those models learn to predict defects based on the characteristics of programs while ignoring the internal information, e.g., the functional and semantic information within the source code. This paper proposes a model, HIRER, to learn the functional and semantic information to predict whether files contain defects automatically for Android applications. Specifically, HIRER learns internal information within the source code based on the high-frequency keywords extracted from programs' Abstract Syntax Trees (ASTs). It gets rule-based programming patterns from high-frequency keywords and uses Deep Belief Network (DBN), a deep neutral network, to learn functional and semantic features from the programming patterns. We implement a defect testing system with five machine learning techniques based on HIRER to predict defective files in source code automatically. Then, we apply it on four open source Android applications. The results show that learned functional and semantic features can predict more defects than traditional metrics. In different versions of MMS, Gallery2, Bluetooth, Calendar open source applications, HIRER improves the AUC of the predicted results respectively in average.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-5386-2667-2",
      "DOI": "10.1109/COMPSAC.2018.10273",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8377901",
      "Author_Keywords": "defect prediction, high-frequency, Android",
      "IEEE_Terms": "Semantics;Feature extraction;Measurement;Predictive models;Androids;Humanoid robots;Programming",
      "Article Citation Count": "3",
      "Reference Count": "14",
      "License": "IEEE",
      "Online Date": "22-Jun-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Predicting Vulnerable Software Components via Text Mining",
      "Authors": "R. Scandariato; J. Walden; A. Hovsepyan; W. Joosen",
      "Author Affiliations": "IBBT-DistriNet, KU Leuven, 3001 Leuven, Belgium; Department of Computer Science, Northern Kentucky University, Highland Heights, KY; IBBT-DistriNet, KU Leuven, 3001 Leuven, Belgium; IBBT-DistriNet, KU Leuven, 3001 Leuven, Belgium",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "9-Oct-14",
      "Publication Year": "2014",
      "Volume": "40",
      "Issue": "10",
      "Start Page": "993",
      "End Page": "1006",
      "Abstract": "This paper presents an approach based on machine learning to predict which components of a software application contain security vulnerabilities. The approach is based on text mining the source code of the components. Namely, each component is characterized as a series of terms contained in its source code, with the associated frequencies. These features are used to forecast whether each component is likely to contain vulnerabilities. In an exploratory validation with 20 Android applications, we discovered that a dependable prediction model can be built. Such model could be useful to prioritize the validation activities, e.g., to identify the components needing special scrutiny.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2014.2340398",
      "Funding Information": "EU FP7(grant numbers:NESSoS); Research Fund KU Leuven; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6860243",
      "Author_Keywords": "Vulnerabilities;prediction model;machine learning",
      "IEEE_Terms": "Software;Predictive models;Measurement;Security;Androids;Humanoid robots;Text mining",
      "Article Citation Count": "218",
      "Reference Count": "40",
      "License": "IEEE",
      "Online Date": "18-Jul-14",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "AUTOTRAINER: An Automatic DNN Training Problem Detection and Repair System",
      "Authors": "X. Zhang; J. Zhai; S. Ma; C. Shen",
      "Author Affiliations": "School of Cyber Science and Engineering, Xi‚Äôan Jiaotong University, Xi‚Äôan, China; Rutgers University, United States; Rutgers University, United States; School of Cyber Science and Engineering, Xi‚Äôan Jiaotong University, Xi‚Äôan, China",
      "Publication Title": "2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "7-May-21",
      "Publication Year": "2021",
      "Start Page": "359",
      "End Page": "371",
      "Abstract": "With machine learning models especially Deep Neural Network (DNN) models becoming an integral part of the new intelligent software, new tools to support their engineering process are in high demand. Existing DNN debugging tools are either post-training which wastes a lot of time training a buggy model and requires expertises, or limited on collecting training logs without analyzing the problem not even fixing them. In this paper, we propose AUTOTRAINER, a DNN training monitoring and automatic repairing tool which supports detecting and auto repairing five commonly seen training problems. During training, it periodically checks the training status and detects potential problems. Once a problem is found, AUTOTRAINER tries to fix it by using built-in state-of-the-art solutions. It supports various model structures and input data types, such as Convolutional Neural Networks (CNNs) for image and Recurrent Neural Networks (RNNs) for texts. Our evaluation on 6 datasets, 495 models show that AUTOTRAINER can effectively detect all potential problems with 100% detection rate and no false positives. Among all models with problems, it can fix 97.33% of them, increasing the accuracy by 47.08% on average.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-0296-5",
      "DOI": "10.1109/ICSE43902.2021.00043",
      "Funding Information": "National Science Foundation; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9402077",
      "Author_Keywords": "software engineering;software tools;deep learning training",
      "IEEE_Terms": "Training;Recurrent neural networks;Tools;Maintenance engineering;Software;Monitoring;Software engineering",
      "Article Citation Count": "15",
      "Reference Count": "123",
      "License": "IEEE",
      "Online Date": "7-May-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Evaluating Bug Prediction under Realistic Settings",
      "Authors": "S. Ogino; Y. Higo; S. Kusumoto",
      "Author Affiliations": "Graduate School of Information Science and Technology, Osaka University, Japan; Graduate School of Information Science and Technology, Osaka University, Japan; Graduate School of Information Science and Technology, Osaka University, Japan",
      "Publication Title": "2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "11-May-21",
      "Publication Year": "2021",
      "Start Page": "491",
      "End Page": "495",
      "Abstract": "Bug prediction is expected to reduce the cost of quality assurance. To build a reliable bug prediction model, we should use realistic settings that satisfy all three of the following conditions. (1) We should build a dataset in a way that allows us to evaluate the prediction performance of the model correctly. (2) We should adopt the optimal granularity of bug prediction to minimize the cost of quality assurance. (3) We should use a dependent variable that correctly represents the presence or absence of bugs in the software modules to be predicted. However, no research has been conducted on bug prediction models built under the above realistic settings. Consequently, we established the following two objectives in this research. (1) We experimentally evaluate the prediction performance of bug prediction models built under realistic settings. (2) We propose techniques to improve the prediction performance of bug prediction models built under realistic settings. The first objective has now been achieved. Our experimental results show that the F-Measure of the bug prediction models built under realistic settings is only 0.19. Thus, there are still some issues to be solved to build a high-performance bug prediction model under realistic settings.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-7281-9630-5",
      "DOI": "10.1109/SANER50967.2021.00052",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9426006",
      "Author_Keywords": "quality assurance;bug prediction;machine learning",
      "IEEE_Terms": "Measurement;Quality assurance;Conferences;Computer bugs;Predictive models;Software;Reliability",
      "Reference Count": "12",
      "License": "IEEE",
      "Online Date": "11-May-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Training Automated Test Oracles to Identify Semantic Bugs",
      "Authors": "C. Geethal",
      "Author Affiliations": "Faculty of Information Technology, Monash University, Melbourne, Australia",
      "Publication Title": "2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "20-Jan-22",
      "Publication Year": "2021",
      "Start Page": "1051",
      "End Page": "1055",
      "Abstract": "Can a machine find and fix a Semantic Bug? A Semantic Bug is a deviation from the expected program behaviour that causes to produce incorrect outputs for certain inputs. To identify this category of bugs, the knowledge on the expected program behaviour is essential. The reason is that a program with a semantic bug does not fail (i.e., crash or hang) in the middle of the execution in most scenarios. Thus, only a human (a user or a developer) knowing the correct program behaviour can detect this kind of bug by observing the output. However, identifying bugs solely through human effort is not practical for all software. A Test Oracle is any procedure used to differentiate the correct and incorrect behaviours of a program. This dissertation mainly focuses on developing learning techniques to produce Automated Test Oracles for programs with semantic bugs. Also, discovering methods to incorporate human knowledge effectively for the learning techniques is another concern. The automated test oracles could make semantic bug detection more efficient. Also, such test oracles could guide Automated Program Repair tools to generate more accurate fixes for semantic bugs.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-6654-0337-5",
      "DOI": "10.1109/ASE51524.2021.9678886",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9678886",
      "Author_Keywords": "Test Oracle Automation;Semantic bugs;Functional bugs;Automated Software Testing",
      "IEEE_Terms": "Training;Computer bugs;Semantics;Maintenance engineering;Software;Software engineering",
      "Article Citation Count": "1",
      "Reference Count": "30",
      "License": "IEEE",
      "Online Date": "20-Jan-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "MANDO-HGT: Heterogeneous Graph Transformers for Smart Contract Vulnerability Detection",
      "Authors": "H. H. Nguyen; N. -M. Nguyen; C. Xie; Z. Ahmadi; D. Kudendo; T. -N. Doan; L. Jiang",
      "Author Affiliations": "L3S Research Center, Leibniz Universit√§t Hannover, Hannover, Germany; Singapore Management University, Singapore; L3S Research Center, Leibniz Universit√§t Hannover, Hannover, Germany; L3S Research Center, Leibniz Universit√§t Hannover, Hannover, Germany; L3S Research Center, Leibniz Universit√§t Hannover, Hannover, Germany; Independent Researcher, Atlanta, Georgia, USA; Singapore Management University, Singapore",
      "Publication Title": "2023 IEEE/ACM 20th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "12-Jul-23",
      "Publication Year": "2023",
      "Start Page": "334",
      "End Page": "346",
      "Abstract": "Smart contracts in blockchains have been increasingly used for high-value business applications. It is essential to check smart contracts' reliability before and after deployment. Although various program analysis and deep learning techniques have been proposed to detect vulnerabilities in either Ethereum smart contract source code or bytecode, their detection accuracy and scalability are still limited. This paper presents a novel framework named MANDO-HGT for detecting smart contract vulnerabilities. Given Ethereum smart contracts, either in source code or bytecode form, and vulnerable or clean, MANDO-HGT custom-builds heterogeneous contract graphs (HCGs) to represent control-flow and/or function-call information of the code. It then adapts heterogeneous graph transformers (HGTs) with customized meta relations for graph nodes and edges to learn their embeddings and train classifiers for detecting various vulnerability types in the nodes and graphs of the contracts more accurately. We have collected more than 55K Ethereum smart contracts from various data sources and verified the labels for 423 buggy and 2,742 clean contracts to evaluate MANDO-HGT. Our empirical results show that MANDO-HGT can significantly improve the detection accuracy of other state-of-the-art vulnerability detection techniques that are based on either machine learning or conventional analysis techniques. The accuracy improvements in terms of F1-score range from 0.7% to more than 76% at either the coarse-grained contract level or the fine-grained line level for various vulnerability types in either source code or bytecode. Our method is general and can be retrained easily for different vulnerability types without the need for manually defined vulnerability patterns.",
      "ISSN": "2574-3864",
      "ISBNs": "979-8-3503-1184-6",
      "DOI": "10.1109/MSR59073.2023.00052",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10174104",
      "Author_Keywords": "vulnerability detection;smart contracts;source code;bytecode;heterogeneous graph learning;graph transformer",
      "IEEE_Terms": "Deep learning;Codes;Source coding;Soft sensors;Scalability;Image edge detection;Smart contracts",
      "Reference Count": "79",
      "License": "IEEE",
      "Online Date": "12-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Centered Hyperspherical and Hyperellipsoidal One-Class Support Vector Machines for Anomaly Detection in Sensor Networks",
      "Authors": "S. Rajasegarar; C. Leckie; J. C. Bezdek; M. Palaniswami",
      "Author Affiliations": "Department of Electrical and Electronics Engineering, University of Melbourne, Melbourne, VIC, Australia; Department of Computer Science and Software Engineering, University of Melbourne, Melbourne, VIC, Australia; Department of Electrical and Electronics Engineering, University of Melbourne, Melbourne, VIC, Australia; Department of Electrical and Electronics Engineering, University of Melbourne, Melbourne, VIC, Australia",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "12-Aug-10",
      "Publication Year": "2010",
      "Volume": "5",
      "Issue": "3",
      "Start Page": "518",
      "End Page": "533",
      "Abstract": "Anomaly detection in wireless sensor networks is an important challenge for tasks such as intrusion detection and monitoring applications. This paper proposes two approaches to detecting anomalies from measurements from sensor networks. The first approach is a linear programming-based hyperellipsoidal formulation, which is called a centered hyperellipsoidal support vector machine (CESVM). While this CESVM approach has advantages in terms of its flexibility in the selection of parameters and the computational complexity, it has limited scope for distributed implementation in sensor networks. In our second approach, we propose a distributed anomaly detection algorithm for sensor networks using a one-class quarter-sphere support vector machine (QSSVM). Here a hypersphere is found that captures normal data vectors in a higher dimensional space for each sensor node. Then summary information about the hyperspheres is communicated among the nodes to arrive at a global hypersphere, which is used by the sensors to identify any anomalies in their measurements. We show that the CESVM and QSSVM formulations can both achieve high detection accuracies on a variety of real and synthetic data sets. Our evaluation of the distributed algorithm using QSSVM reveals that it detects anomalies with comparable accuracy and less communication overhead than a centralized approach.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2010.2051543",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5483231",
      "Author_Keywords": "Anomaly detection;distributed computing;information security;machine learning;outlier detection;security;support vector machines (SVMs);wireless sensor networks",
      "IEEE_Terms": "Support vector machines;Intrusion detection;Wireless sensor networks;Permission;Fault diagnosis;Condition monitoring;Linear programming;Computer networks;Detection algorithms;Computer science",
      "Article Citation Count": "122",
      "Reference Count": "52",
      "License": "IEEE",
      "Online Date": "10-Jun-10",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Revisiting Binary Code Similarity Analysis Using Interpretable Feature Engineering and Lessons Learned",
      "Authors": "D. Kim; E. Kim; S. K. Cha; S. Son; Y. Kim",
      "Author Affiliations": "KAIST, Daejeon, South Korea; KAIST, Daejeon, South Korea; KAIST, Daejeon, South Korea; KAIST, Daejeon, South Korea; KAIST, Daejeon, South Korea",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "18-Apr-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "4",
      "Start Page": "1661",
      "End Page": "1682",
      "Abstract": "Binary code similarity analysis (BCSA) is widely used for diverse security applications, including plagiarism detection, software license violation detection, and vulnerability discovery. Despite the surging research interest in BCSA, it is significantly challenging to perform new research in this field for several reasons. First, most existing approaches focus only on the end results, namely, increasing the success rate of BCSA, by adopting uninterpretable machine learning. Moreover, they utilize their own benchmark, sharing neither the source code nor the entire dataset. Finally, researchers often use different terminologies or even use the same technique without citing the previous literature properly, which makes it difficult to reproduce or extend previous work. To address these problems, we take a step back from the mainstream and contemplate fundamental research questions for BCSA. Why does a certain technique or a certain feature show better results than the others? Specifically, we conduct the first systematic study on the basic features used in BCSA by leveraging interpretable feature engineering on a large-scale benchmark. Our study reveals various useful insights on BCSA. For example, we show that a simple interpretable model with a few basic features can achieve a comparable result to that of recent deep learning-based approaches. Furthermore, we show that the way we compile binaries or the correctness of underlying binary analysis tools can significantly affect the performance of BCSA. Lastly, we make all our source code and benchmark public and suggest future directions in this field to help further research.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2022.3187689",
      "Funding Information": "Institute of Information & Communications Technology Planning & Evaluation(grant numbers:2021-0-01332); Developing Next-Generation Binary Decompiler; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9813408",
      "Author_Keywords": "Binary code similarity analysis;similarity measures;feature evaluation and selection;benchmark",
      "IEEE_Terms": "Benchmark testing;Computer architecture;Binary codes;Syntactics;Semantics;Licenses;Market research",
      "Article Citation Count": "12",
      "Reference Count": "166",
      "License": "CCBY",
      "Online Date": "1-Jul-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Bug or not Bug? Analysing the Reasons Behind Metamorphic Relation Violations",
      "Authors": "A. Duque-Torres; D. Pfahl; C. Klammer; S. Fischer",
      "Author Affiliations": "Institute of Computer Science, University of Tartu, Tartu, Estonia; Institute of Computer Science, University of Tartu, Tartu, Estonia; Software Competence Center Hagenberg (SCCH) GmbH, Hagenberg, Austria; Software Competence Center Hagenberg (SCCH) GmbH, Hagenberg, Austria",
      "Publication Title": "2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "15-May-23",
      "Publication Year": "2023",
      "Start Page": "905",
      "End Page": "912",
      "Abstract": "Metamorphic Testing (MT) is a testing technique that can effectively alleviate the oracle problem. MT uses Metamorphic Relations (MRs) to determine if a test case passes or fails. MRs specify how the outputs should vary in response to specific input changes when executing the System Under Test (SUT). If a particular MR is violated for at least one test input (and its change), there is a high probability that the SUT has a fault. On the other hand, if a particular MR is not violated, it does not guarantee that the SUT is fault free. However, deciding if the MR is being violated due to a bug or because the MR does not hold/fit for particular conditions generated by specific inputs remains a manual task and unexplored. In this paper, we develop a method for refining MRs to offer hints as to whether a violation results from a bug or arises from the MR not being matched to certain test data under specific circumstances. In our initial proof-of-concept, we derive the relevant information from rules using the Association Rule Mining (ARM) technique. In our initial proof-of-concept, we validate our method on a toy example and discuss the lessons learned from our experiments. Our proof-of-concept demonstrates that our method is applicable and that we can provide suggestions that help strengthen the test suite for regression testing purposes.",
      "ISSN": "2640-7574",
      "ISBNs": "978-1-6654-5278-6",
      "DOI": "10.1109/SANER56733.2023.00109",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10123550",
      "Author_Keywords": "Metamorphic testing;metamorphic relation;association rule mining;passive testing",
      "IEEE_Terms": "Computer bugs;Toy manufacturing industry;Refining;Manuals;Software;Data mining;Task analysis",
      "Article Citation Count": "4",
      "Reference Count": "25",
      "License": "IEEE",
      "Online Date": "15-May-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "NeuralCCD: Integrating Multiple Features for Neural Coincidental Correctness Detection",
      "Authors": "Z. Tao; Y. Lei; H. Xie; J. Hu",
      "Author Affiliations": "School of Big Data & Software Engineering, Chongqing University, Chongqing, China; School of Big Data & Software Engineering, Chongqing University, Chongqing, China; School of Big Data & Software Engineering, Chongqing University, Chongqing, China; School of Big Data & Software Engineering, Chongqing University, Chongqing, China",
      "Publication Title": "2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "15-May-23",
      "Publication Year": "2023",
      "Start Page": "85",
      "End Page": "96",
      "Abstract": "Fault localization seeks to locate the suspicious statements possible for causing a program failure. Experimental evidence shows that fault localization effectiveness is affected adversely by the existence of coincidental correctness (CC) test cases, where a CC test case denotes the test case which executes a fault but no failure occurs. Even worse, CC test cases are prevailing in realistic testing and debugging, leading to a severe issue on fault localization effectiveness. Thus, it is indispensable to accurately detect CC test cases and alleviate their harmful effect on fault localization effectiveness.To address this problem, we propose NeuralCCD: a neural coincidental correctness detection approach by integrating multiple features. Specifically, NeuralCCD first leverages suspiciousness score, coverage ratio and similarity to define three CC detection features. Based on these CC detection features and CC labels, NeuralCCD utilizes multi-layer perceptron to learn a different feature-based model for a program, and finally combine the trained models of different programs as an ensemble system to detect CC test cases. To evaluate the effectiveness of NeuralCCD, we conduct large-scale experiments on 247 faulty version of five representative benchmarks and compare NeuralCCD with four state-of-the-art CC detection approaches. The experimental results show that NeuralCCD significantly improves the effectiveness of CC detection, e.g., NeuralCCD yields by at most 109.5%, 93% and 81.3% improvement of Top-1, Top-3 and Top-5 over Tech-I when utilized in Dstar formular.",
      "ISSN": "2640-7574",
      "ISBNs": "978-1-6654-5278-6",
      "DOI": "10.1109/SANER56733.2023.00018",
      "Funding Information": "National Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10123558",
      "Author_Keywords": "fault localization;coincidental correctness;deep learning;multiple features",
      "IEEE_Terms": "Location awareness;Deep learning;Neural networks;Debugging;Benchmark testing;Feature extraction;Software",
      "Article Citation Count": "1",
      "Reference Count": "48",
      "License": "IEEE",
      "Online Date": "15-May-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Defectors: A Large, Diverse Python Dataset for Defect Prediction",
      "Authors": "P. Mahbub; O. Shuvo; M. Masudur Rahman",
      "Author Affiliations": "Dalhousie University; Dalhousie University; Dalhousie University",
      "Publication Title": "2023 IEEE/ACM 20th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "12-Jul-23",
      "Publication Year": "2023",
      "Start Page": "393",
      "End Page": "397",
      "Abstract": "Defect prediction has been a popular research topic where machine learning (ML) and deep learning (DL) have found numerous applications. However, these ML/DL-based defect prediction models are often limited by the quality and size of their datasets. In this paper, we present Defectors, a large dataset for just-in-time and line-level defect prediction. Defectors consists of ‚âà 213K source code files (‚âà 93K defective and ‚âà 120K defect- free) that span across 24 popular Python projects. These projects come from 18 different domains, including machine learning, automation, and internet-of-things. Such a scale and diversity make Defectors a suitable dataset for training ML/DL models, especially transformer models that require large and diverse datasets. We also foresee several application areas of our dataset including defect prediction and defect explanation.",
      "ISSN": "2574-3864",
      "ISBNs": "979-8-3503-1184-6",
      "DOI": "10.1109/MSR59073.2023.00085",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10174122",
      "Author_Keywords": "Defect Prediction;Just-in-Time;Dataset;Software Engineering",
      "IEEE_Terms": "Training;Deep learning;Automation;Source coding;Predictive models;Transformers;Software",
      "Article Citation Count": "1",
      "Reference Count": "33",
      "License": "IEEE",
      "Online Date": "12-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Commit Message Matters: Investigating Impact and Evolution of Commit Message Quality",
      "Authors": "J. Li; I. Ahmed",
      "Author Affiliations": "University of California, Irvine, Irvine, CA, USA; University of California, Irvine, Irvine, CA, USA",
      "Publication Title": "2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "14-Jul-23",
      "Publication Year": "2023",
      "Start Page": "806",
      "End Page": "817",
      "Abstract": "Commit messages play an important role in communication among developers. To measure the quality of commit messages, researchers have defined what semantically constitutes a Good commit message: it should have both the summary of the code change (What) and the motivation/reason behind it (Why). The presence of the issue report/pull request links referenced in a commit message has been treated as a way of providing Why information. In this study, we found several quality issues that could hamper the links' ability to provide Why information. Based on this observation, we developed a machine learning classifier for automatically identifying whether a commit message has What and Why information by considering both the commit messages and the link contents. This classifier outperforms state-of-the-art machine learning classifiers by 12 percentage points improvement in the F1 score. With the improved classifier, we conducted a mixed method empirical analysis and found that: (1) Commit message quality has an impact on software defect proneness, and (2) the overall quality of the commit messages decreases over time, while developers believe they are writing better commit messages. All the research artifacts (i.e., tools, scripts, and data) of this study are available on the accompanying website [2].",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-5701-9",
      "DOI": "10.1109/ICSE48619.2023.00076",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172825",
      "Author_Keywords": "Commit message quality;software defect proneness;empirical analysis",
      "IEEE_Terms": "Codes;Machine learning;Writing;Software;Software engineering",
      "Article Citation Count": "2",
      "Reference Count": "71",
      "License": "IEEE",
      "Online Date": "14-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Debiasing Android Malware Datasets: How Can I Trust Your Results If Your Dataset Is Biased?",
      "Authors": "T. C. Miranda; P. -F. Gimenez; J. -F. Lalande; V. V. T. Tong; P. Wilke",
      "Author Affiliations": "CentraleSup√©lec, Inria, CNRS, University of Rennes 1, IRISA, Rennes, France; CentraleSup√©lec, Inria, CNRS, University of Rennes 1, IRISA, Rennes, France; CentraleSup√©lec, Inria, CNRS, University of Rennes 1, IRISA, Rennes, France; CentraleSup√©lec, Inria, CNRS, University of Rennes 1, IRISA, Rennes, France; CentraleSup√©lec, Inria, CNRS, University of Rennes 1, IRISA, Rennes, France",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "17-Jun-22",
      "Publication Year": "2022",
      "Volume": "17",
      "Start Page": "2182",
      "End Page": "2197",
      "Abstract": "Android security has received a lot of attention over the last decade, especially malware investigation. Researchers attempt to highlight applications‚Äô security-relevant characteristics to better understand malware and effectively distinguish malware from benign applications. The accuracy and the completeness of their proposals are evaluated experimentally on malware and goodware datasets. Thus, the quality of these datasets is of critical importance: if the datasets are outdated or not representative of the studied population, the conclusions may be flawed. We specify different types of experimental scenarios. Some of them require unlabeled but representative datasets of the entire population. Others require datasets labeled with valuable characteristics that may be difficult to compute, such as malware datasets. We discuss the irregularities of datasets used in experiments, questioning the validity of the performances reported in the literature. This article focuses on providing guidelines for designing debiased datasets. First, we propose guidelines for building representative datasets from unlabeled ones. Second, we propose and experiment a debiasing algorithm that, given a biased labeled dataset and a target representative dataset, builds a representative and labeled dataset. Finally, from the previous debiased datasets, we produce datasets for experiments on Android malware detection or classification with machine learning algorithms. Experiments show that debiased datasets perform better when classifying with machine learning algorithms.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2022.3180184",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9787514",
      "Author_Keywords": "Datasets;malware;experiments",
      "IEEE_Terms": "Malware;Statistics;Sociology;Machine learning algorithms;Classification algorithms;Training;Security",
      "Article Citation Count": "4",
      "Reference Count": "81",
      "License": "CCBY",
      "Online Date": "3-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "The Why, When, What, and How About Predictive Continuous Integration: A Simulation-Based Investigation",
      "Authors": "B. Liu; H. Zhang; W. Ma; G. Li; S. Li; H. Shen",
      "Author Affiliations": "State Key Laboratory of Novel Software Technology, Software Institute, Nanjing University, Jiangsu, China; State Key Laboratory of Novel Software Technology, Software Institute, Nanjing University, Jiangsu, China; State Key Laboratory of Novel Software Technology, Software Institute, Nanjing University, Jiangsu, China; State Key Laboratory of Novel Software Technology, Software Institute, Nanjing University, Jiangsu, China; State Key Laboratory of Novel Software Technology, Software Institute, Nanjing University, Jiangsu, China; Peter Faber Business School, Australian Catholic University, Sydney, NSW, Australia",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "12-Dec-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "12",
      "Start Page": "5223",
      "End Page": "5249",
      "Abstract": "Continuous Integration (CI) enables developers to detect defects early and thus reduce lead time. However, the high frequency and long duration of executing CI have a detrimental effect on this practice. Existing studies have focused on using CI outcome predictors to reduce frequency. Since there is no reported project using predictive CI, it is difficult to evaluate its economic impact. This research aims to investigate predictive CI from a process perspective, including why and when to adopt predictors, what predictors to be used, and how to practice predictive CI in real projects. We innovatively employ Software Process Simulation to simulate a predictive CI process with a Discrete-Event Simulation (DES) model and conduct simulation-based experiments. We develop the Rollback-based Identification of Defective Commits (RIDEC) method to account for the negative effects of false predictions in simulations. Experimental results show that: 1) using predictive CI generally improves the effectiveness of CI, reducing time costs by up to 36.8% and the average waiting time before executing CI by 90.5%; 2) the time-saving varies across projects, with higher commit frequency projects benefiting more; and 3) predictor performance does not strongly correlate with time savings, but the precision of both failed and passed predictions should be paid more attention. Simulation-based evaluation helps identify overlooked aspects in existing research. Predictive CI saves time and resources, but improved prediction performance has limited cost-saving benefits. The primary value of predictive CI lies in providing accurate and quick feedback to developers, aligning with the goal of CI.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2023.3330510",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:62072227,62202219,62302210,72372070); Jiangsu Provincial Key Research and Development Program(grant numbers:BE2021002-2); National Key Research and Development Program of China(grant numbers:2019YFE0105500); Innovation Project and Overseas Open Projects of State Key Laboratory for Novel Software Technology (Nanjing University)(grant numbers:ZZKT2022A25,KFKT2022A09,KFKT2023A09); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10315109",
      "Author_Keywords": "Continuous integration;machine learning;software process simulation;discrete-event simulation",
      "IEEE_Terms": "Software;Costs;Servers;Testing;Machine learning;Codes;Surveys",
      "Reference Count": "64",
      "License": "IEEE",
      "Online Date": "10-Nov-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Semantic Learning and Emulation Based Cross-Platform Binary Vulnerability Seeker",
      "Authors": "J. Gao; Y. Jiang; Z. Liu; X. Yang; C. Wang; X. Jiao; Z. Yang; J. Sun",
      "Author Affiliations": "Beijing National Research Center for Information Science and Technology, and Key Laboratory for Information System Security, Ministry of Education, School of Software, Tsinghua University, Beijing, China; Beijing National Research Center for Information Science and Technology, and Key Laboratory for Information System Security, Ministry of Education, School of Software, Tsinghua University, Beijing, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Beijing National Research Center for Information Science and Technology, and Key Laboratory for Information System Security, Ministry of Education, School of Software, Tsinghua University, Beijing, China; Beijing National Research Center for Information Science and Technology, and Key Laboratory for Information System Security, Ministry of Education, School of Software, Tsinghua University, Beijing, China; Department of Electrical and Computer Engineering, Villanova University, Villanova, PA, USA; Department of Computer Science, Western Michigan University, Kalamazoo, MI, USA; Beijing National Research Center for Information Science and Technology, and Key Laboratory for Information System Security, Ministry of Education, School of Software, Tsinghua University, Beijing, China",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "11-Nov-21",
      "Publication Year": "2021",
      "Volume": "47",
      "Issue": "11",
      "Start Page": "2575",
      "End Page": "2589",
      "Abstract": "Clone detection is widely exploited for software vulnerability search. The approaches based on source code analysis cannot be applied to binary clone detection because the same source code can produce significantly different binaries due to different operating systems, microprocessor architectures and compilers. In this paper, we present BinSeeker, a cross-platform binary seeker that integrates semantic learning and emulation. With the help of the labeled semantic flow graph, BinSeeker can quickly identify $M$M candidate functions that are most similar to the vulnerability from the target binary. The value of $M$M is relatively large so this semantic learning procedure essentially eliminates those functions that are very unlikely to have the vulnerability. Then, semantic emulation is conducted on these $M$M candidates to obtain their dynamic signature sequences. By comparing signature sequences, BinSeeker produces top-$N$N functions that exhibit most similar behavior to that of the vulnerability. With fast filtering of semantic learning and accurate comparison of semantic emulation, BinSeeker seeks vulnerability precisely with little overhead. The experiments on six widely used programs with fifteen known CVE vulnerabilities demonstrate that BinSeeker outperforms three state-of-the-art tools Genius, Gemini and CACompare. Regarding search accuracy, BinSeeker achieves an MRR value of 0.65 in the target programs, whereas the MRR values by Genius, Gemini and CACompare are 0.17, 0.07 and 0.42, respectively. If we consider ranking a function with the targeted vulnerability in the top-5 as accurate, BinSeeker achieves the accuracy of 93.33 percent, while the accuracy of the other three tools is merely 33.33, 13.33 and 53.33 percent, respectively. Such accuracy is achieved with 0.27s on average to determine whether the target binary function contains a known vulnerability, and the time for the other three tools are 1.57s, 0.15s and 0.98s, respectively. Compared to the time used to manually identify the true positive vulnerability from the false positive candidates reported by Gemini, the time overhead of BinSeeker is negligible. Evidently, the proposed BinSeeker achieves a better balance between accuracy and efficiency.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2019.2956932",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:61527812); National Science and Technology Major Project of China(grant numbers:2016ZX01038101); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918305",
      "Author_Keywords": "Semantic emulation;semantic learning;cross-platform binary;vulnerability search;neural network",
      "IEEE_Terms": "Drilling machines;Process control;Automation;Rocks;Tools",
      "Article Citation Count": "7",
      "Reference Count": "47",
      "License": "IEEE",
      "Online Date": "2-Dec-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Deep Semantic Feature Learning for Software Defect Prediction",
      "Authors": "S. Wang; T. Liu; J. Nam; L. Tan",
      "Author Affiliations": "Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; School of Computer Science and Electrical Engineering, Handong Global University, Pohang, Korea; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "10-Dec-20",
      "Publication Year": "2020",
      "Volume": "46",
      "Issue": "12",
      "Start Page": "1267",
      "End Page": "1293",
      "Abstract": "Software defect prediction, which predicts defective code regions, can assist developers in finding bugs and prioritizing their testing efforts. Traditional defect prediction features often fail to capture the semantic differences between different programs. This degrades the performance of the prediction models built on these traditional features. Thus, the capability to capture the semantics in programs is required to build accurate prediction models. To bridge the gap between semantics and defect prediction features, we propose leveraging a powerful representation-learning algorithm, deep learning, to learn the semantic representations of programs automatically from source code files and code changes. Specifically, we leverage a deep belief network (DBN) to automatically learn semantic features using token vectors extracted from the programs' abstract syntax trees (AST) (for file-level defect prediction models) and source code changes (for change-level defect prediction models). We examine the effectiveness of our approach on two file-level defect prediction tasks (i.e., file-level within-project defect prediction and file-level cross-project defect prediction) and two change-level defect prediction tasks (i.e., change-level within-project defect prediction and change-level cross-project defect prediction). Our experimental results indicate that the DBN-based semantic features can significantly improve the examined defect prediction tasks. Specifically, the improvements of semantic features against existing traditional features (in F1) range from 2.1 to 41.9 percentage points for file-level within-project defect prediction, from 1.5 to 13.4 percentage points for file-level cross-project defect prediction, from 1.0 to 8.6 percentage points for change-level within-project defect prediction, and from 0.6 to 9.9 percentage points for change-level cross-project defect prediction.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2018.2877612",
      "Funding Information": "Natural Sciences and Engineering Research Council of Canada; National Research Foundation of Korea(grant numbers:2018R1C1B6001919); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502853",
      "Author_Keywords": "Defect prediction;quality assurance;deep learning;semantic features",
      "IEEE_Terms": "Semantics;Predictive models;Feature extraction;Quality assurance;Computer bugs;Data models;Prediction models",
      "Article Citation Count": "151",
      "Reference Count": "111",
      "License": "IEEE",
      "Online Date": "23-Oct-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Automatic Feature Learning for Predicting Vulnerable Software Components",
      "Authors": "H. K. Dam; T. Tran; T. Pham; S. W. Ng; J. Grundy; A. Ghose",
      "Author Affiliations": "Faculty of Engineering and Information Sciences, School of Computing and Information Technology, University of Wollongong, Wollongong, NSW, Australia; School of Information Technology, Deakin University, Waurn Ponds, Victoria, Australia; School of Information Technology, Deakin University, Waurn Ponds, Victoria, Australia; Faculty of Engineering and Information Sciences, School of Computing and Information Technology, University of Wollongong, Wollongong, NSW, Australia; Faculty of Information Technology, Monash University, Clayton, Victoria, Australia; Faculty of Engineering and Information Sciences, School of Computing and Information Technology, University of Wollongong, Wollongong, NSW, Australia",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "8-Jan-21",
      "Publication Year": "2021",
      "Volume": "47",
      "Issue": "1",
      "Start Page": "67",
      "End Page": "85",
      "Abstract": "Code flaws or vulnerabilities are prevalent in software systems and can potentially cause a variety of problems including deadlock, hacking, information loss and system failure. A variety of approaches have been developed to try and detect the most likely locations of such code vulnerabilities in large code bases. Most of them rely on manually designing code features (e.g., complexity metrics or frequencies of code tokens) that represent the characteristics of the potentially problematic code to locate. However, all suffer from challenges in sufficiently capturing both semantic and syntactic representation of source code, an important capability for building accurate prediction models. In this paper, we describe a new approach, built upon the powerful deep learning Long Short Term Memory model, to automatically learn both semantic and syntactic features of code. Our evaluation on 18 Android applications and the Firefox application demonstrates that the prediction power obtained from our learned features is better than what is achieved by state of the art vulnerability prediction models, for both within-project prediction and cross-project prediction.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2018.2881961",
      "Funding Information": "Samsung(grant numbers:2016 Global Research Outreach Program); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8540022",
      "Author_Keywords": "Software vulnerability prediction;mining software engineering repositories;empirical software engineering",
      "IEEE_Terms": "Semantics;Software systems;Predictive models;Security;Feature extraction;System recovery",
      "Article Citation Count": "73",
      "Reference Count": "61",
      "License": "IEEE",
      "Online Date": "18-Nov-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Comments on \"Data Mining Static Code Attributes to Learn Defect Predictors\"",
      "Authors": "H. Zhang; X. Zhang",
      "Author Affiliations": "School of Software, Tsinghua University, Beijing, China; School of Computer Science and Information Technology, RMIT University, Melbourne, Australia",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "13-Aug-07",
      "Publication Year": "2007",
      "Volume": "33",
      "Issue": "9",
      "Start Page": "635",
      "End Page": "637",
      "Abstract": "In this correspondence, we point out a discrepancy in a recent paper, \"data mining static code attributes to learn defect predictors,\" that was published in this journal. Because of the small percentage of defective modules, using probability of detection (pd) and probability of false alarm (pf) as accuracy measures may lead to impractical prediction models.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2007.70706",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4288196",
      "Author_Keywords": "defect prediction;accuracy measures;static code attributes;empirical",
      "IEEE_Terms": "Data mining;Predictive models;Accuracy;Area measurement;Q measurement;Machine learning;Training data;Information retrieval;Resource management",
      "Article Citation Count": "86",
      "Patent Citation Count": "1",
      "Reference Count": "3",
      "License": "IEEE",
      "Online Date": "13-Aug-07",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Machine Learning for Source Code Vulnerability Detection: What Works and What Isn‚Äôt There Yet",
      "Authors": "T. Marjanov; I. Pashchenko; F. Massacci",
      "Author Affiliations": "Vrije Universiteit Amsterdam and University of Cambridge; TomTom; University of Trento and Vrije Universiteit Amsterdam",
      "Publication Title": "IEEE Security & Privacy",
      "Date Added To Xplore": "13-Sep-22",
      "Publication Year": "2022",
      "Volume": "20",
      "Issue": "5",
      "Start Page": "60",
      "End Page": "76",
      "Abstract": "We review machine learning approaches for detecting (and correcting) vulnerabilities in source code, finding that the biggest challenges ahead involve agreeing to a benchmark, increasing language and error type coverage, and using pipelines that do not flatten the code‚Äôs structure.",
      "ISSN": "1558-4046",
      "DOI": "10.1109/MSEC.2022.3176058",
      "Funding Information": "Horizon 2020 research and innovation program(grant numbers:952647); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9859261",
      "IEEE_Terms": "Source coding;Data models;Computer bugs;Syntactics;Training data;Semantics;Machine learning",
      "Article Citation Count": "4",
      "Reference Count": "13",
      "License": "CCBY",
      "Online Date": "17-Aug-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Magazines"
    },
    {
      "Document Title": "Kernel Spectral Embedding Transfer Ensemble for Heterogeneous Defect Prediction",
      "Authors": "H. Tong; B. Liu; S. Wang",
      "Author Affiliations": "Science and Technology on Reliability and Environmental Engineering Laboratory, School of Reliability and Systems Engineering, Beihang University, Beijing, China; Science and Technology on Reliability and Environmental Engineering Laboratory, School of Reliability and Systems Engineering, Beihang University, Beijing, China; Science and Technology on Reliability and Environmental Engineering Laboratory, School of Reliability and Systems Engineering, Beihang University, Beijing, China",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "16-Sep-21",
      "Publication Year": "2021",
      "Volume": "47",
      "Issue": "9",
      "Start Page": "1886",
      "End Page": "1906",
      "Abstract": "Cross-project defect prediction (CPDP) refers to predicting defects in the target project lacking of defect data by using prediction models trained on the historical defect data of other projects (i.e., source data). However, CPDP requires the source and target projects have common metric set (CPDP-CM). Recently, heterogeneous defect prediction (HDP) has drawn the increasing attention, which predicts defects across projects having heterogeneous metric sets. However, building high-performance HDP methods remains a challenge owing to several serious challenges including class imbalance problem, nonlinear, and the distribution differences between source and target datasets. In this paper, we propose a novel kernel spectral embedding transfer ensemble (KSETE) approach for HDP. KSETE first addresses the class-imbalance problem of the source data and then tries to find the latent common feature space for the source and target datasets by combining kernel spectral embedding, transfer learning, and ensemble learning. Experiments are performed on 22 public projects in both HDP and CPDP-CM scenarios in terms of multiple well-known performance measures such as, AUC, G-Measure, and MCC. The experimental results show that (1) KSETE improves the performance over previous HDP methods by at least 22.7, 138.9, and 494.4 percent in terms of AUC, G-Measure, and MCC, respectively. (2) KSETE improves the performance over previous CPDP-CM methods by at least 4.5, 30.2, and 17.9 percent in AUC, G-Measure, and MCC, respectively. It can be concluded that the proposed KSETE is very effective in both the HDP scenario and the CPDP-CM scenario.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2019.2939303",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8823052",
      "Author_Keywords": "Heterogeneous defect prediction;cross-project defect prediction;class imbalance learning;spectral embedding;transfer learning;ensemble learning;multiple kernel learning",
      "IEEE_Terms": "Kernel;Predictive models;Software metrics;Correlation;Buildings;Data models",
      "Article Citation Count": "19",
      "Reference Count": "103",
      "License": "IEEE",
      "Online Date": "3-Sep-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "CLAMI: Defect Prediction on Unlabeled Datasets (T)",
      "Authors": "J. Nam; S. Kim",
      "Author Affiliations": "Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China",
      "Publication Title": "2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "7-Jan-16",
      "Publication Year": "2015",
      "Start Page": "452",
      "End Page": "463",
      "Abstract": "Defect prediction on new projects or projects with limited historical data is an interesting problem in software engineering. This is largely because it is difficult to collect defect information to label a dataset for training a prediction model. Cross-project defect prediction (CPDP) has tried to address this problem by reusing prediction models built by other projects that have enough historical data. However, CPDP does not always build a strong prediction model because of the different distributions among datasets. Approaches for defect prediction on unlabeled datasets have also tried to address the problem by adopting unsupervised learning but it has one major limitation, the necessity for manual effort. In this study, we propose novel approaches, CLA and CLAMI, that show the potential for defect prediction on unlabeled datasets in an automated manner without need for manual effort. The key idea of the CLA and CLAMI approaches is to label an unlabeled dataset by using the magnitude of metric values. In our empirical study on seven open-source projects, the CLAMI approach led to the promising prediction performances, 0.636 and 0.723 in average f-measure and AUC, that are comparable to those of defect prediction based on supervised learning.",
      "ISBNs": "978-1-5090-0025-8",
      "DOI": "10.1109/ASE.2015.56",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7372033",
      "IEEE_Terms": "Predictive models;Measurement;Software;Training;Supervised learning;Data models;Manuals",
      "Article Citation Count": "118",
      "Reference Count": "63",
      "License": "IEEE",
      "Online Date": "7-Jan-16",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "SQLIFIX: Learning Based Approach to Fix SQL Injection Vulnerabilities in Source Code",
      "Authors": "M. L. Siddiq; M. R. R. Jahin; M. R. Ul Islam; R. Shahriyar; A. Iqbal",
      "Author Affiliations": "Bangladesh University of Engineering and Technology; Bangladesh University of Engineering and Technology; Bangladesh University of Engineering and Technology; Bangladesh University of Engineering and Technology; Bangladesh University of Engineering and Technology",
      "Publication Title": "2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "11-May-21",
      "Publication Year": "2021",
      "Start Page": "354",
      "End Page": "364",
      "Abstract": "SQL Injection attack is one of the oldest yet effective attacks for web applications. Even in 2020, applications are vulnerable to SQL Injection attacks. The developers are sup-posed to take precautions such as parameterizing SQL queries, escaping special characters, etc. However, developers, especially inexperienced ones, often fail to comply with such guidelines. There are quite a few SQL Injection detection tools to expose any unattended SQL Injection vulnerability in source code. However, to the best of our knowledge, very few works have been done to suggest a fix of these vulnerabilities in the source code. We have developed a learning-based approach that prepares abstraction of SQL Injection vulnerable codes from training dataset and clusters them using hierarchical clustering. The test samples are matched with a cluster of similar samples and a fix suggestion is generated. We have developed a manually validated training and test dataset from real-world projects of Java and PHP to evaluate our language-agnostic approach. The results establish the superiority of our technique over comparable techniques. The code and dataset are released publicly to encourage reproduction.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-7281-9630-5",
      "DOI": "10.1109/SANER50967.2021.00040",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9425978",
      "Author_Keywords": "SQL Injection;Prepared Statement;Automatic Fix",
      "IEEE_Terms": "Training;Java;Conferences;Training data;Machine learning;SQL injection;Tools",
      "Article Citation Count": "2",
      "Reference Count": "40",
      "License": "IEEE",
      "Online Date": "11-May-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "node2defect: Using Network Embedding to Improve Software Defect Prediction",
      "Authors": "Y. Qu; T. Liu; J. Chi; Y. Jin; D. Cui; A. He; Q. Zheng",
      "Author Affiliations": "Ministry of Education Key Lab For Intelligent Networks and Network Security, Xi'an Jiaotong University, China; School of Electronic and Information Engineering, Xi'an Jiaotong University, China; Xi'an Jiaotong University, China; Xi'an Jiaotong University, China; Xi'an Jiaotong University, China; Xi'an Jiaotong University, China; Xi'an Jiaotong University, China",
      "Publication Title": "2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "17-Feb-20",
      "Publication Year": "2018",
      "Start Page": "844",
      "End Page": "849",
      "Abstract": "Network measures have been proved to be useful in predicting software defects. Leveraging the dependency relationships between software modules, network measures can capture various structural features of software systems. However, existing studies have relied on user-defined network measures (e.g., degree statistics or centrality metrics), which are inflexible and require high computation cost, to describe the structural features. In this paper, we propose a new method called node2defect which uses a newly proposed network embedding technique, node2vec, to automatically learn to encode dependency network structure into low-dimensional vector spaces to improve software defect prediction. Specifically, we firstly construct a program's Class Dependency Network. Then node2vec is used to automatically learn structural features of the network. After that, we combine the learned features with traditional software engineering features, for accurate defect prediction. We evaluate our method on 15 open source programs. The experimental results show that in average, node2defect improves the state-of-the-art approach by 9.15% in terms of F-measure.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-4503-5937-5",
      "DOI": "10.1145/3238147.3240469",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9000072",
      "Author_Keywords": "Software defect;defect prediction;software metrics;network embedding",
      "Article Citation Count": "8",
      "Reference Count": "26",
      "Online Date": "17-Feb-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Using K-core Decomposition on Class Dependency Networks to Improve Bug Prediction Model's Practical Performance",
      "Authors": "Y. Qu; Q. Zheng; J. Chi; Y. Jin; A. He; D. Cui; H. Zhang; T. Liu",
      "Author Affiliations": "Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; School of Computer Science, Xi'an University of Posts and Telecommunications, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "11-Feb-21",
      "Publication Year": "2021",
      "Volume": "47",
      "Issue": "2",
      "Start Page": "348",
      "End Page": "366",
      "Abstract": "In recent years, Complex Network theory and graph algorithms have been proved to be effective in predicting software bugs. On the other hand, as a widely-used algorithm in Complex Network theory, k-core decomposition has been used in software engineering domain to identify key classes. Intuitively, key classes are more likely to be buggy since they participate in more functions or have more interactions and dependencies. However, there is no existing research uses k-core decomposition to analyze software bugs. To fill this gap, we first use k-core decomposition on Class Dependency Networks to analyze software bug distribution from a new perspective. An interesting and widely existed tendency is observed: for classes in k-cores with larger k values, there is a stronger possibility for them to be buggy. Based on this observation, we then propose a simple but effective equation named as top-core which improves the order of classes in the suspicious class list produced by effort-aware bug prediction models. Based on an empirical study on 18 open-source Java systems, we show that the bug prediction models' performances are significantly improved in 85.2 percent experiments in the cross-validation scenario and in 80.95 percent experiments in the forward-release scenario, after using top-core. The models' average performances are improved by 11.5 and 12.6 percent, respectively. It is concluded that the proposed top-core equation can help the testers or code reviewers locate the real bugs more quickly and easily in software bug prediction practices.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2019.2892959",
      "Funding Information": "National Key Research and Development Program of China(grant numbers:2016YFB0800202); National Natural Science Foundation of China(grant numbers:61602369,61632015,61772408,U1766215,61721002,61833015); Ministry of Education Innovation Research Team(grant numbers:IRT_17R86); Shaanxi Province postdoctoral research project funding(grant numbers:2016BSHEDZZ108); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611396",
      "Author_Keywords": "Bug prediction;software defects;complex network;class dependency network;effort-aware bug prediction",
      "IEEE_Terms": "Computer bugs;Software;Mathematical model;Predictive models;Complex networks;Prediction algorithms;Software algorithms",
      "Article Citation Count": "29",
      "Reference Count": "66",
      "License": "IEEE",
      "Online Date": "13-Jan-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Better Pay Attention Whilst Fuzzing",
      "Authors": "S. Zhu; J. Wang; J. Sun; J. Yang; X. Lin; T. Wang; L. Zhang; P. Cheng",
      "Author Affiliations": "College of Control Science and Engineering, Zhejiang University, Zhejiang, China; College of Control Science and Engineering, Zhejiang University, Zhejiang, China; School of Computing and Information Systems, Singapore Management University, Singapore; School of Medicine, Zhejiang University, Zhejiang, China; Ant Group, Hangzhou, China; College of Control Science and Engineering, Zhejiang University, Zhejiang, China; College of Control Science and Engineering, Zhejiang University, Zhejiang, China; College of Control Science and Engineering, Zhejiang University, Zhejiang, China",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "12-Feb-24",
      "Publication Year": "2024",
      "Volume": "50",
      "Issue": "2",
      "Start Page": "190",
      "End Page": "208",
      "Abstract": "Fuzzing is one of the prevailing methods for vulnerability detection. However, even state-of-the-art fuzzing methods become ineffective after some period of time, i.e., the coverage hardly improves as existing methods are ineffective to focus the attention of fuzzing on covering the hard-to-trigger program paths. In other words, they cannot generate inputs that can break the bottleneck due to the fundamental difficulty in capturing the complex relations between the test inputs and program coverage. In particular, existing fuzzers suffer from the following main limitations: 1) lacking an overall analysis of the program to identify the most ‚Äúrewarding‚Äù seeds, and 2) lacking an effective mutation strategy which could continuously select and mutates the more relevant ‚Äúbytes‚Äù of the seeds. In this work, we propose an approach called ATTuzz to address these two issues systematically. First, we propose a lightweight dynamic analysis technique that estimates the ‚Äúreward‚Äù of covering each basic block and selects the most rewarding seeds accordingly. Second, we mutate the selected seeds according to a neural network model which predicts whether a certain ‚Äúrewarding‚Äù block will be covered given certain mutations on certain bytes of a seed. The model is a deep learning model equipped with an attention mechanism which is learned and updated periodically whilst fuzzing. Our evaluation shows that ATTuzz significantly outperforms 5 state-of-the-art grey-box fuzzers on 6 popular real-world programs and MAGMA data sets at achieving higher edge coverage and finding new bugs. In particular, ATTuzz achieved 1.2X edge coverage and 1.8X bugs detected than AFL++ over 24-hour runs. In addition, ATTuzz also finds 4 new bugs in the latest version of some popular software including p7zip and openUSD.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2023.3338129",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:61833015,62293511,62102359); Academic Research Fund Tier 3, Ministry of Education, Singapore(grant numbers:MOET32020-0004); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10339688",
      "Author_Keywords": "Fuzzing;deep learning;program analysis;attention model",
      "IEEE_Terms": "Fuzzing;Deep learning;Computer bugs;Codes;Image edge detection;Electronic mail;Recurrent neural networks",
      "Reference Count": "72",
      "License": "IEEE",
      "Online Date": "4-Dec-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Can We Automatically Fix Bugs by Learning Edit Operations?",
      "Authors": "A. Connor; A. Harris; N. Cooper; D. Poshyvanyk",
      "Author Affiliations": "Computer Science William and Mary, Williamsburg, VA, USA; Computer Science William and Mary, Williamsburg, VA, USA; Computer Science William and Mary, Williamsburg, VA, USA; Computer Science William and Mary, Williamsburg, VA, USA",
      "Publication Title": "2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "21-Jul-22",
      "Publication Year": "2022",
      "Start Page": "782",
      "End Page": "792",
      "Abstract": "There has been much work done in the area of automated program repair, specifically through using machine learning methods to correct buggy code. Whereas some degree of success has been attained by those efforts, there is still considerable room for growth with regard to the accuracy of results produced by such tools. In that vein, we implement Hephaestus, a novel method to improve the accuracy of automated bug repair through learning to apply edit operations. Hephaestus leverages neural machine translation and attempts to produce the edit operations needed to correct a given buggy code segment to a fixed version. We examine the effects of using various forms of edit operations in the completion of this task. Our study found that all models which learned from edit operations were not as effective at repairing bugs as models which learned from fixed code segments directly. This evidences that learning edit operations does not offer an advantage over the standard approach of translating directly from buggy code to fixed code. We conduct an analysis of this lowered efficiency and explore why the complexity of the edit operations-based models may be suboptimal. Interestingly, even though our Hephaestus model exhibited lower translation accuracy than the baseline, Hephaestus was able to perform successful bug repair. This success, albeit small, leaves the door open for other researchers to innovate unique solutions in the realm of automatic bug repair.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-6654-3786-8",
      "DOI": "10.1109/SANER53432.2022.00096",
      "Funding Information": "NSF(grant numbers:CCF-1955853,CCF-2007246); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9825852",
      "Author_Keywords": "automatic program repair;neural networks;neural-machine translation;software defect analysis;negative results",
      "IEEE_Terms": "Training;Codes;Veins;Computer bugs;Maintenance engineering;Software;Machine translation",
      "Article Citation Count": "2",
      "Reference Count": "19",
      "License": "IEEE",
      "Online Date": "21-Jul-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Comprehensive Study on Code Clones in Automated Driving Software",
      "Authors": "R. Mo; Y. Jiang; W. Zhan; D. Wang; Z. Li",
      "Author Affiliations": "Hubei Provincial Key Laboratory of Artificial Intelligence and Smart Learning, School of Computer Science, Central China Normal University, China; Hubei Provincial Key Laboratory of Artificial Intelligence and Smart Learning, School of Computer Science, Central China Normal University, China; Hubei Provincial Key Laboratory of Artificial Intelligence and Smart Learning, School of Computer Science, Central China Normal University, China; Hubei Provincial Key Laboratory of Artificial Intelligence and Smart Learning, School of Computer Science, Central China Normal University, China; Hubei Provincial Key Laboratory of Artificial Intelligence and Smart Learning, School of Computer Science, Central China Normal University, China",
      "Publication Title": "2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "8-Nov-23",
      "Publication Year": "2023",
      "Start Page": "1073",
      "End Page": "1085",
      "Abstract": "With the continuous improvement of artificial intelligence technology, autonomous driving technology has been greatly developed. Hence automated driving software has drawn more and more attention from both researchers and practitioners. Code clone is a commonly used to speed up the development cycle in software development, but many studies have shown that code clones may affect software maintainability. Currently, there is little research investigating code clones in automated driving software. To bridge this gap, we conduct a comprehensive experience study on the code clones in automated driving software. Through the analysis of Apollo and Autoware, we have presented that code clones are prevalent in automated driving software. about 30% of code lines are involved in code clones and more than 50% of files contain code clones. Moreover, a notable portion of these code clones has caused bugs and co-modifications. Due to the high complexity of autonomous driving, the automated driving software is often designed to be modular, with each module responsible for a single task. When considering each module individually, we have found that Perception, Planning, Canbus, and Sensing modules are more likely to encounter code clones, and more likely to have bug-prone and co-modified clones. Finally, we have shown that there exist cross-module clones to propagate bugs and co-modifications in different modules, which undermine the software's modularity.",
      "ISSN": "2643-1572",
      "ISBNs": "979-8-3503-2996-4",
      "DOI": "10.1109/ASE56229.2023.00053",
      "Funding Information": "the National Natural Science Foundation of China(grant numbers:62002129); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298437",
      "Author_Keywords": "Automated Driving Software;Code Clone;Comodification;Bug-proneness;Software Modularity",
      "IEEE_Terms": "Codes;Computer bugs;Cloning;Software systems;Software;Sensors;Planning",
      "Reference Count": "53",
      "License": "IEEE",
      "Online Date": "8-Nov-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Elixir: Effective object-oriented program repair",
      "Authors": "R. K. Saha; Y. Lyu; H. Yoshida; M. R. Prasad",
      "Author Affiliations": "Fujitsu Laboratories of America, Sunnyvale, CA, USA; Fujitsu Laboratories of America, Sunnyvale, CA, USA; Fujitsu Laboratories of America, Sunnyvale, CA, USA; University of Southern California, Los Angeles, CA, USA",
      "Publication Title": "2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "23-Nov-17",
      "Publication Year": "2017",
      "Start Page": "648",
      "End Page": "659",
      "Abstract": "This work is motivated by the pervasive use of method invocations in object-oriented (OO) programs, and indeed their prevalence in patches of OO-program bugs. We propose a generate-and-validate repair technique, called ELIXIR designed to be able to generate such patches. ELIXIR aggressively uses method calls, on par with local variables, fields, or constants, to construct more expressive repair-expressions, that go into synthesizing patches. The ensuing enlargement of the repair space, on account of the wider use of method calls, is effectively tackled by using a machine-learnt model to rank concrete repairs. The machine-learnt model relies on four features derived from the program context, i.e., the code surrounding the potential repair location, and the bug report. We implement ELIXIR and evaluate it on two datasets, the popular Defects4J dataset and a new dataset Bugs.jar created by us, and against 2 baseline versions of our technique, and 5 other techniques representing the state of the art in program repair. Our evaluation shows that ELIXIR is able to increase the number of correctly repaired bugs in Defects4J by 85% (from 14 to 26) and by 57% in Bugs.jar (from 14 to 22), while also significantly out-performing other state-of-the-art repair techniques including ACS, HD-Repair, NOPOL, PAR, and jGenProg.",
      "ISBNs": "978-1-5386-2684-9",
      "DOI": "10.1109/ASE.2017.8115675",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115675",
      "IEEE_Terms": "Maintenance engineering;Computer bugs;Java;Tools;Software;Object oriented modeling;Concrete",
      "Article Citation Count": "102",
      "Patent Citation Count": "1",
      "Reference Count": "45",
      "License": "IEEE",
      "Online Date": "23-Nov-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "RefactorScore: Evaluating Refactor Prone Code",
      "Authors": "K. Jesse; C. Kuhmuench; A. Sawant",
      "Author Affiliations": "Department of Computer Science, University of California Davis, Davis, CA, USA; Siemens Corporation, Princeton, NJ, USA; Endor Labs, Palo Alto, CA, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "16-Nov-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "11",
      "Start Page": "5008",
      "End Page": "5026",
      "Abstract": "We propose RefactorScore, an automatic evaluation metric for code. RefactorScore computes the number of refactor prone locations on each token in a candidate file and maps the occurrences into a quantile to produce a score. RefactorScore is evaluated across 61,735 commits and uses a model called RefactorBERT trained to predict refactors on 1,111,246 commits. Finally, we validate RefactorScore on a set of industry leading projects providing each with a RefactorScore. We calibrate RefactorScore's detection of low quality code with human developers through a human subject study. RefactorBERT, the model driving the scoring mechanism, is capable of predicting defects and refactors predicted by RefDiff 2.0. To our knowledge, our approach, coupled with the use of large scale data for training and validated with human developers, is the first code quality scoring metric of its kind.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2023.3324613",
      "Funding Information": "NSF CCF (SHF)(grant numbers:2107592); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10286315",
      "Author_Keywords": "Refactor;automatic evaluation;machine learning;software repositories",
      "IEEE_Terms": "Codes;Java;Measurement;Unified modeling language;Predictive models;C++ languages;Computational modeling",
      "Reference Count": "76",
      "License": "IEEE",
      "Online Date": "16-Oct-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Vulnerabilities of Data Protection in Vertical Federated Learning Training and Countermeasures",
      "Authors": "D. Zhu; J. Chen; X. Zhou; W. Shang; A. E. Hassan; J. Grossklags",
      "Author Affiliations": "Department of Computer Science, Technical University of Munich, Boltzmannstr. 3, Garching, Germany; School of Computer Science, Wuhan University, Wuhan, China; Huawei Munich Research Center, Riesstra√üe 25, Munich, Germany; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; School of Computing, Queen‚Äôs University, Kingston, Canada; Department of Computer Science, Technical University of Munich, Boltzmannstr. 3, Garching, Germany",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Publication Year": "2024",
      "Volume": "PP",
      "Issue": "99",
      "Start Page": "1",
      "End Page": "1",
      "Abstract": "Vertical federated learning (VFL) is an increasingly popular, yet understudied, collaborative learning technique. In VFL, features and labels are distributed among different participants allowing for various innovative applications in business domains, e.g., online marketing. When deploying VFL, training data (labels and features) from each participant ought to be protected; however, very few studies have investigated the vulnerability of data protection in the VFL training stage. In this paper, we propose a posterior-difference-based data attack, VFLRecon, reconstructing labels and features to examine this problem. Our experiments show that standard VFL is highly vulnerable to serious privacy threats, with reconstruction achieving up to 92% label accuracy and 0.05 feature MSE, compared to our baseline with 55% label accuracy and 0.19 feature MSE. Even worse, this privacy risk remains during standard operations (e.g., encrypted aggregation) that appear to be safe. We also systematically analyze data leakage risks in the VFL training stage across diverse data modalities (i.e., tabular data and images), different training frameworks (i.e., with or without encryption techniques), and a wide range of training hyperparameters. To mitigate this risk, we design a novel defense mechanism, VFLDefender, dedicated to obfuscating the correlation between bottom model changes and labels (features) during training. The experimental results demonstrate that VFLDefender prevents reconstruction attacks during standard encryption operations (around 17% more effective than standard encryption operations).",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2024.3361813",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10430093",
      "Author_Keywords": "Privacy-preserving machine learning;vertical federated learning;privacy leakage;data safety;privacy",
      "IEEE_Terms": "Training;Data models;Federated learning;Computational modeling;Image reconstruction;Encryption;Predictive models",
      "License": "CCBYNCND",
      "Online Date": "8-Feb-24",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Early Access Articles"
    },
    {
      "Document Title": "Semantic-Aware Adversarial Training for Reliable Deep Hashing Retrieval",
      "Authors": "X. Yuan; Z. Zhang; X. Wang; L. Wu",
      "Author Affiliations": "School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; Department of Computer Science, Swansea University, Swansea, U.K.",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "1-Aug-23",
      "Publication Year": "2023",
      "Volume": "18",
      "Start Page": "4681",
      "End Page": "4694",
      "Abstract": "Deep hashing has been intensively studied and successfully applied in large-scale image retrieval systems due to its efficiency and effectiveness. Recent studies have recognized that the existence of adversarial examples poses a security threat to deep hashing models, that is, adversarial vulnerability. Notably, it is challenging to efficiently distill reliable semantic representatives for deep hashing to guide adversarial learning, and thereby it hinders the enhancement of adversarial robustness of deep hashing-based retrieval models. Moreover, current researches on adversarial training for deep hashing are hard to be formalized into a unified minimax structure. In this paper, we explore Semantic-Aware Adversarial Training (SAAT) for improving the adversarial robustness of deep hashing models. Specifically, we conceive a discriminative mainstay features learning (DMFL) scheme to construct semantic representatives for guiding adversarial learning in deep hashing. Particularly, our DMFL with the strict theoretical guarantee is adaptively optimized in a discriminative learning manner, where both discriminative and semantic properties are jointly considered. Moreover, adversarial examples are fabricated by maximizing the Hamming distance between the hash codes of adversarial samples and mainstay features, the efficacy of which is validated in the adversarial attack trials. Further, we, for the first time, formulate the formalized adversarial training of deep hashing into a unified minimax optimization under the guidance of the generated mainstay codes. Extensive experiments on benchmark datasets show superb attack performance against the state-of-the-art algorithms, meanwhile, the proposed adversarial training can effectively eliminate adversarial perturbations for trustworthy deep hashing-based retrieval. Our code is available at https://github.com/xandery-geek/SAAT.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2023.3297791",
      "Funding Information": "Shenzhen Science and Technology Program(grant numbers:RCYX20221008092852077); National Natural Science Foundation of China(grant numbers:62002085); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2023A1515010057); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10189878",
      "Author_Keywords": "Adversarial attack;adversarial training;trustworthy deep hashing;similarity retrieval",
      "IEEE_Terms": "Codes;Training;Semantics;Adversarial machine learning;Task analysis;Robustness;Perturbation methods",
      "Article Citation Count": "1",
      "Reference Count": "50",
      "License": "IEEE",
      "Online Date": "21-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Active Learning of Discriminative Subgraph Patterns for API Misuse Detection",
      "Authors": "H. J. Kang; D. Lo",
      "Author Affiliations": "School of Information Systems, Singapore Management University, Singapore, Singapore; School of Information Systems, Singapore Management University, Singapore, Singapore",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "16-Aug-22",
      "Publication Year": "2022",
      "Volume": "48",
      "Issue": "8",
      "Start Page": "2761",
      "End Page": "2783",
      "Abstract": "A common cause of bugs and vulnerabilities are the violations of usage constraints associated with Application Programming Interfaces (APIs). API misuses are common in software projects, and while there have been techniques proposed to detect such misuses, studies have shown that they fail to reliably detect misuses while reporting many false positives. One limitation of prior work is the inability to reliably identify correct patterns of usage. Many approaches confuse a usage pattern's frequency for correctness. Due to the variety of alternative usage patterns that may be uncommon but correct, anomaly detection-based techniques have limited success in identifying misuses. We address these challenges and propose ALP (Actively Learned Patterns), reformulating API misuse detection as a classification problem. After representing programs as graphs, ALP mines discriminative subgraphs. While still incorporating frequency information, through limited human supervision, we reduce the reliance on the assumption relating frequency and correctness. The principles of active learning are incorporated to shift human attention away from the most frequent patterns. Instead, ALP samples informative and representative examples while minimizing labeling effort. In our empirical evaluation, ALP substantially outperforms prior approaches on both MUBench, an API Misuse benchmark, and a new dataset that we constructed from real-world software projects.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2021.3069978",
      "Funding Information": "National Research Foundation Singapore; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9392340",
      "Author_Keywords": "API-Misuse detection;discriminative subgraph mining;graph classification;active learning",
      "IEEE_Terms": "Detectors;Software development management;Java;Tools;Software;Computer bugs;Ciphers",
      "Article Citation Count": "7",
      "Reference Count": "103",
      "License": "IEEE",
      "Online Date": "31-Mar-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "An Implementation of Just-in-Time Fault-Prone Prediction Technique Using Text Classifier",
      "Authors": "K. Mori; O. Mizuno",
      "Author Affiliations": "Graduate School of Science and Technology, Kyoto Institute of Technology, Japan; Graduate School of Science and Technology, Kyoto Institute of Technology, Japan",
      "Publication Title": "2015 IEEE 39th Annual Computer Software and Applications Conference",
      "Date Added To Xplore": "24-Sep-15",
      "Publication Year": "2015",
      "Volume": "3",
      "Start Page": "609",
      "End Page": "612",
      "Abstract": "Since the fault prediction is an important technique to help allocating software maintenance effort, much research on fault prediction has been proposed so far. The goal of these studies is applying their prediction technique to actual software development. In this paper, we implemented a prototype fault-prone module prediction tool using a text-filtering based technique named \"Fault-Prone Filtering\". Our tool aims to show the result of fault prediction for each change (i.e., Commits) as a probability that a source code file to be faulty. The result is shown on a Web page and easy to track the histories of prediction. A case study performed on three open source projects shows that our tool could detect 90 percent of the actual fault modules (i.e., The recall of 0.9) with the accuracy of 0.67 and the precision of 0.63 on average.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-4673-6564-2",
      "DOI": "10.1109/COMPSAC.2015.143",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273434",
      "Author_Keywords": "software development support tool;fault prediction;software maintenance;mining software repository;machine learning;spam filter",
      "IEEE_Terms": "Predictive models;Filtering;Data mining;Accuracy;Software maintenance;Databases",
      "Article Citation Count": "4",
      "Reference Count": "9",
      "License": "IEEE",
      "Online Date": "24-Sep-15",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Comprehensive Investigation of the Impact of Class Overlap on Software Defect Prediction",
      "Authors": "L. Gong; H. Zhang; J. Zhang; M. Wei; Z. Huang",
      "Author Affiliations": "College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu, China; Software Analysis and Intelligence Lab (SAIL), School of Computing, Queen's University, Kingston, ON, Canada; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu, China",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "18-Apr-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "4",
      "Start Page": "2440",
      "End Page": "2458",
      "Abstract": "Software Defect Prediction (SDP) is one of the most vital and cost-efficient operations to ensure the software quality. However, there exists the phenomenon of class overlap in the SDP datasets (i.e., defective and non-defective modules are similar in terms of values of metrics), which hinders the performance as well as the use of SDP models. Even though efforts have been made to investigate the impact of removing overlapping technique on the performance of SDP, many open issues are still challenging yet unknown. Therefore, we conduct an empirical study to comprehensively investigate the impact of class overlap on SDP. Specifically, we first propose an overlapping instances identification approach by analyzing the class distribution in the local neighborhood of a given instance. We then investigate the impact of class overlap and two common overlapping instance handling techniques on the performance and the interpretation of seven representative SDP models. Through an extensive case study on 230 diversity datasets, we observe that: i) 70.0% of SDP datasets contain overlapping instances; ii) different levels of class overlap have different impacts on the performance of SDP models; iii) class overlap affects the rank of the important feature list of SDP models, particularly the feature lists at the top 2 and top 3 ranks; IV) Class overlap handling techniques could statistically significantly improve the performance of SDP models trained on datasets with over 12.5% overlap ratios. We suggest that future work should apply our KNN method to identify the overlap ratios of datasets before building SDP models.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2022.3220740",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:62202223); Natural Science Foundation of Jiangsu Province(grant numbers:BK20220881); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9944157",
      "Author_Keywords": "Class overlap;data quality;k-nearest neighbourhood;local analysis;software defect prediction;software metrics",
      "IEEE_Terms": "Software;Measurement;Predictive models;Classification tree analysis;Stability analysis;NASA;Machine learning algorithms",
      "Article Citation Count": "5",
      "Reference Count": "84",
      "License": "IEEE",
      "Online Date": "9-Nov-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Buffer Overflow Vulnerability Prediction from x86 Executables Using Static Analysis and Machine Learning",
      "Authors": "B. M. Padmanabhuni; H. B. K. Tan",
      "Author Affiliations": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
      "Publication Title": "2015 IEEE 39th Annual Computer Software and Applications Conference",
      "Date Added To Xplore": "24-Sep-15",
      "Publication Year": "2015",
      "Volume": "2",
      "Start Page": "450",
      "End Page": "459",
      "Abstract": "Mining static code attributes for predicting software vulnerabilities has received some attention recently. There are a number of approaches for detecting vulnerabilities from source code, but commercial off the shelf components are, in general, distributed in binary form. Before using such third-party components it is imperative to check for presence of vulnerabilities. We investigate the use of static analysis and machine learning for predicting buffer overflow vulnerabilities from binaries in this study. To mitigate buffer overflows, developers typically perform size checks and input validation. We propose static code attributes characterizing buffer usage and defense mechanisms implemented in the code for preventing buffer overflows. The proposed approach starts by identifying potential vulnerable statement constructs during binary program analysis and extracts static code attributes for each of them as per proposed characterization scheme to capture buffer usage patterns and defensive mechanisms employed in the code. Data mining methods are then used on these collected code attributes for predicting buffer overflows. Our experimental evaluation on standard buffer overflow benchmark binaries shows that the proposed static code attributes are effective in predicting buffer overflow vulnerabilities.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-4673-6564-2",
      "DOI": "10.1109/COMPSAC.2015.78",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273653",
      "Author_Keywords": "binary static analysis;static code attributes;disassembly;vulnerability prediction;buffer overflow;control and data dependency;buffer usage pattern",
      "IEEE_Terms": "Buffer overflows;Libraries;Filling;Software;Containers;Semantics;Registers",
      "Article Citation Count": "17",
      "Reference Count": "27",
      "License": "IEEE",
      "Online Date": "24-Sep-15",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Poltergeist: Acoustic Adversarial Machine Learning against Cameras and Computer Vision",
      "Authors": "X. Ji; Y. Cheng; Y. Zhang; K. Wang; C. Yan; W. Xu; K. Fu",
      "Author Affiliations": "Ubiquitous System Security Lab (USSLAB), Zhejiang University; Ubiquitous System Security Lab (USSLAB), Zhejiang University; Ubiquitous System Security Lab (USSLAB), Zhejiang University; Ubiquitous System Security Lab (USSLAB), Zhejiang University; Ubiquitous System Security Lab (USSLAB), Zhejiang University; Ubiquitous System Security Lab (USSLAB), Zhejiang University; Security and Privacy Research Group (SPQR), University of Michigan",
      "Publication Title": "2021 IEEE Symposium on Security and Privacy (SP)",
      "Date Added To Xplore": "26-Aug-21",
      "Publication Year": "2021",
      "Start Page": "160",
      "End Page": "175",
      "Abstract": "Autonomous vehicles increasingly exploit computer-vision-based object detection systems to perceive environments and make critical driving decisions. To increase the quality of images, image stabilizers with inertial sensors are added to alleviate image blurring caused by camera jitters. However, such a trend opens a new attack surface. This paper identifies a system-level vulnerability resulting from the combination of the emerging image stabilizer hardware susceptible to acoustic manipulation and the object detection algorithms subject to adversarial examples. By emitting deliberately designed acoustic signals, an adversary can control the output of an inertial sensor, which triggers unnecessary motion compensation and results in a blurred image, even if the camera is stable. The blurred images can then induce object misclassification affecting safety-critical decision making. We model the feasibility of such acoustic manipulation and design an attack framework that can accomplish three types of attacks, i.e., hiding, creating, and altering objects. Evaluation results demonstrate the effectiveness of our attacks against four academic object detectors (YOLO V3/V4/V5 and Fast R-CNN), and one commercial detector (Apollo). We further introduce the concept of AMpLe attacks, a new class of system-level security vulnerabilities resulting from a combination of adversarial machine learning and physics-based injection of information-carrying signals into hardware.",
      "ISSN": "2375-1207",
      "ISBNs": "978-1-7281-8934-5",
      "DOI": "10.1109/SP40001.2021.00091",
      "Funding Information": "Analog Devices; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9519394",
      "IEEE_Terms": "Computer vision;Inertial sensors;Object detection;Detectors;Cameras;Acoustics;Hardware",
      "Article Citation Count": "12",
      "Reference Count": "59",
      "License": "IEEE",
      "Online Date": "26-Aug-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "An Empirical Study of Challenges in Converting Deep Learning Models",
      "Authors": "M. Openja; A. Nikanjam; A. H. Yahmed; F. Khomh; Z. M. J. Jiang",
      "Author Affiliations": "Polytechnique Montr√©al, Montreal, Quebec, Canada; Polytechnique Montr√©al, Montreal, Quebec, Canada; Polytechnique Montr√©al, Montreal, Quebec, Canada; Polytechnique Montr√©al, Montreal, Quebec, Canada; York University, Toronto, Ontario, Canada",
      "Publication Title": "2022 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "19-Dec-22",
      "Publication Year": "2022",
      "Start Page": "13",
      "End Page": "23",
      "Abstract": "There is an increase in deploying Deep Learning (DL)-based software systems in real-world applications. Usually, DL models are developed and trained using DL frameworks like TensorFlow and PyTorch. Each framework has its own internal mechanisms/formats to represent and train DL models (deep neural networks), and usually those formats cannot be recognized by other frameworks. Moreover, trained models are usually deployed in environments different from where they were developed. To solve the interoperability issue and make DL models compatible with different frameworks/environments, some exchange formats are introduced for DL models, like ONNX and CoreML. However, ONNX and CoreML were never empirically evaluated by the community to reveal their prediction accuracy, performance, and robustness after conversion. Poor accuracy or non-robust behavior of converted models may lead to poor quality of deployed DL-based software systems. We conduct, in this paper, the first empirical study to assess ONNX and CoreML for converting trained DL models. In our systematic approach, two popular DL frameworks, Keras and PyTorch, are used to train five widely used DL models on three popular datasets. The trained models are then converted to ONNX and CoreML and transferred to two runtime environments designated for such formats, to be evaluated. We investigate the prediction accuracy before and after conversion. Our results unveil that the prediction accuracy of converted models are at the same level of originals. The performance (time cost and memory consumption) of converted models are studied as well. The size of models are reduced after conversion, which can result in optimized DL-based software deployment. We also study the adversarial robustness of converted models to make sure about the robustness of deployed DL-based software. Leveraging the state-of-the-art adversarial attack approaches, converted models are generally assessed robust at the same level of originals. However, obtained results show that CoreML models are more vulnerable to adversarial attacks compared to ONNX. The general message of our findings is that DL developers should be cautious on the deployment of converted models that may 1) perform poorly while switching from one framework to another, 2) have challenges in robust deployment, or 3) run slowly, leading to poor quality of deployed DL-based software, including DL-based software maintenance tasks, like bug prediction.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-6654-7956-1",
      "DOI": "10.1109/ICSME55016.2022.00010",
      "Funding Information": "Natural Sciences and Engineering Research Council of Canada; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9978197",
      "Author_Keywords": "Empirical;Deep Learning;Converting Trained Models;Deploying ML Models;Robustness",
      "IEEE_Terms": "Deep learning;Analytical models;Software maintenance;Runtime environment;Systematics;Switches;Predictive models",
      "Article Citation Count": "8",
      "Reference Count": "40",
      "License": "IEEE",
      "Online Date": "19-Dec-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Learning to Reduce False Positives in Analytic Bug Detectors",
      "Authors": "A. Kharkar; R. Z. Moghaddam; M. Jin; X. Liu; X. Shi; C. Clement; N. Sundaresan",
      "Author Affiliations": "Microsoft, Redmond, Washington, USA; Microsoft, Redmond, Washington, USA; Microsoft, Redmond, Washington, USA; Microsoft, Redmond, Washington, USA; Microsoft, Redmond, Washington, USA; Microsoft, Redmond, Washington, USA; Microsoft, Redmond, Washington, USA",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "1307",
      "End Page": "1316",
      "Abstract": "Due to increasingly complex software design and rapid iterative development, code defects and security vulnerabilities are prevalent in modern software. In response, programmers rely on static analysis tools to regularly scan their codebases and find potential bugs. In order to maximize coverage, however, these tools generally tend to report a significant number of false positives, requiring developers to manually verify each warning. To address this problem, we propose a Transformer-based learning approach to identify false positive bug warnings. We demonstrate that our models can improve the precision of static analysis by 17.5%. In addition, we validated the generalizability of this approach across two major bug types: null dereference and resource leak.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3510153",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794136",
      "Author_Keywords": "datasets;neural networks;gaze detection;text tagging",
      "IEEE_Terms": "Training;Analytical models;Codes;Computer bugs;Static analysis;Detectors;Tagging",
      "Article Citation Count": "7",
      "Reference Count": "31",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Studying the Usage of Text-To-Text Transfer Transformer to Support Code-Related Tasks",
      "Authors": "A. Mastropaolo; S. Scalabrino; N. Cooper; D. Nader Palacio; D. Poshyvanyk; R. Oliveto; G. Bavota",
      "Author Affiliations": "SEART @ Software Institute, Universit√† della Svizzera italiana (USI), Switzerland; University of Molise, Italy; SEMERU @ Computer Science Department, William and Mary, USA; Computer Science Department, William and Mary, Williamsburg, VA, USA; SEMERU @ Computer Science Department, William and Mary, USA; SEMERU @ Computer Science Department, William and Mary, USA; SEART @ Software Institute, Universit√† della Svizzera italiana (USI), Switzerland",
      "Publication Title": "2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "7-May-21",
      "Publication Year": "2021",
      "Start Page": "336",
      "End Page": "347",
      "Abstract": "Deep learning (DL) techniques are gaining more and more attention in the software engineering community. They have been used to support several code-related tasks, such as automatic bug fixing and code comments generation. Recent studies in the Natural Language Processing (NLP) field have shown that the Text-To-Text Transfer Transformer (T5) architecture can achieve state-of-the-art performance for a variety of NLP tasks. The basic idea behind T5 is to first pre-train a model on a large and generic dataset using a self-supervised task (e.g., filling masked words in sentences). Once the model is pre-trained, it is fine-tuned on smaller and specialized datasets, each one related to a specific task (e.g., language translation, sentence classification). In this paper, we empirically investigate how the T5 model performs when pre-trained and fine-tuned to support code-related tasks. We pre-train a T5 model on a dataset composed of natural language English text and source code. Then, we fine-tune such a model by reusing datasets used in four previous works that used DL techniques to: (i) fix bugs, (ii) inject code mutants, (iii) generate assert statements, and (iv) generate code comments. We compared the performance of this single model with the results reported in the four original papers proposing DL-based solutions for those four tasks. We show that our T5 model, exploiting additional data for the self-supervised pre-training phase, can achieve performance improvements over the four baselines.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-0296-5",
      "DOI": "10.1109/ICSE43902.2021.00041",
      "Funding Information": "European Research Council; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9401982",
      "Author_Keywords": "Empirical software engineering;Deep Learning",
      "IEEE_Terms": "Deep learning;Computer bugs;Natural language processing;Software;Filling;Task analysis;Software engineering",
      "Article Citation Count": "64",
      "Reference Count": "69",
      "License": "IEEE",
      "Online Date": "7-May-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Learning a Metric for Code Readability",
      "Authors": "R. P. L. Buse; W. R. Weimer",
      "Author Affiliations": "University of Virginia, Charlottesville, VA, USA; University of Virginia, Charlottesville, VA, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "29-Jul-10",
      "Publication Year": "2010",
      "Volume": "36",
      "Issue": "4",
      "Start Page": "546",
      "End Page": "558",
      "Abstract": "In this paper, we explore the concept of code readability and investigate its relation to software quality. With data collected from 120 human annotators, we derive associations between a simple set of local code features and human notions of readability. Using those features, we construct an automated readability measure and show that it can be 80 percent effective and better than a human, on average, at predicting readability judgments. Furthermore, we show that this metric correlates strongly with three measures of software quality: code changes, automated defect reports, and defect log messages. We measure these correlations on over 2.2 million lines of code, as well as longitudinally, over many releases of selected projects. Finally, we discuss the implications of this study on programming language design and engineering practice. For example, our data suggest that comments, in and of themselves, are less important than simple blank lines to local judgments of readability.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2009.70",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5332232",
      "Author_Keywords": "Software readability;program understanding;machine learning;software maintenance;code metrics;FindBugs.",
      "IEEE_Terms": "Software quality;Humans;Software maintenance;Readability metrics;Documentation;Software measurement;Computer languages;Design engineering;Machine learning;Costs",
      "Article Citation Count": "216",
      "Reference Count": "41",
      "License": "IEEE",
      "Online Date": "13-Nov-09",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "SeqTrans: Automatic Vulnerability Fix Via Sequence to Sequence Learning",
      "Authors": "J. Chi; Y. Qu; T. Liu; Q. Zheng; H. Yin",
      "Author Affiliations": "Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Computer Science and Technology, Xian Jiaotong University, Xian, China; Department of Computer Science and Engineering, UC Riverside, Riverside, CA, USA; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Computer Science and Technology, Xian Jiaotong University, Xian, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Computer Science and Technology, Xian Jiaotong University, Xian, China; Department of Computer Science and Engineering, UC Riverside, Riverside, CA, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "14-Feb-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "2",
      "Start Page": "564",
      "End Page": "585",
      "Abstract": "Software vulnerabilities are now reported unprecedentedly due to the recent development of automated vulnerability hunting tools. However, fixing vulnerabilities still mainly depends on programmers‚Äô manual efforts. Developers need to deeply understand the vulnerability and affect the system‚Äôs functions as little as possible. In this paper, with the advancement of Neural Machine Translation (NMT) techniques, we provide a novel approach called SeqTrans to exploit historical vulnerability fixes to provide suggestions and automatically fix the source code. To capture the contextual information around the vulnerable code, we propose to leverage data-flow dependencies to construct code sequences and feed them into the state-of-the-art transformer model. The fine-tuning strategy has been introduced to overcome the small sample size problem. We evaluate SeqTrans on a dataset containing 1,282 commits that fix 624 CVEs in 205 Java projects. Results show that the accuracy of SeqTrans outperforms the latest techniques and achieves 23.3% in statement-level fix and 25.3% in CVE-level fix. In the meantime, we look deep inside the result and observe that the NMT model performs very well in certain kinds of vulnerabilities like CWE-287 (Improper Authentication) and CWE-863 (Incorrect Authorization).",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2022.3156637",
      "Funding Information": "National Key Research and Development Program of China(grant numbers:2018YFB1004500); National Natural Science Foundation of China(grant numbers:62002280,61632015,61772408,U1766215,61833015,61902306); National Natural Science Foundation of China(grant numbers:61721002); Innovation Research Team of Ministry of Education(grant numbers:IRT_17R86); China Knowledge Centre for Engineering Science and Technology; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9729554",
      "Author_Keywords": "Machine learning;neural machine translation;software engineering;vulnerability fix",
      "IEEE_Terms": "Maintenance engineering;Codes;Computer bugs;Predictive models;Transformers;Decoding;Training",
      "Article Citation Count": "7",
      "Reference Count": "104",
      "License": "IEEE",
      "Online Date": "7-Mar-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Accelerating Finite State Machine-Based Testing using Reinforcement Learning",
      "Authors": "U. C. T√ºrker; R. M. Hierons; K. El-Fakih; M. R. Mousavi; I. Y. Tyukin",
      "Author Affiliations": "School of Computing and Communications, Lancaster University, Lancaster, UK; Department of Computer Science, The University of Sheffield, Sheffield, UK; Department of Computer Science and Engineering, American University of Sharjah, UAE; Department of Informatics, Kings College London, UK; Department of Mathematics, Kings College London, UK",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Publication Year": "2024",
      "Volume": "PP",
      "Issue": "99",
      "Start Page": "1",
      "End Page": "22",
      "Abstract": "Testing is a crucial phase in the development of complex systems, and this has led to interest in automated test generation techniques based on state-based models. Many approaches use models that are types of finite state machine (FSM). Corresponding test generation algorithms typically require that certain test components, such as reset sequences (RSs) and preset distinguishing sequences (PDSs), have been produced for the FSM specification. Unfortunately, the generation of RSs and PDSs is computationally expensive, and this affects the scalability of such FSM-based test generation algorithms. This paper addresses this scalability problem by introducing a reinforcement learning framework: the $\\mathcal{Q}$-Graph framework for MBT. We show how this framework can be used in the generation of RSs and PDSs and consider both (potentially partial) timed and untimed models. The proposed approach was evaluated using three types of FSMs: randomly generated FSMs, FSMs from a benchmark, and an FSM of an Engine Status Manager for a printer. In experiments, the proposed approach was much faster and used much less memory than the state-of-the-art methods in computing PDSs and RSs.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2024.3358416",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10414288",
      "Author_Keywords": "Finite state machines;reset sequences;state identification sequences;reinforcement learning;Q-value function;software engineering/ software/program verification;software engineering/test design;software engineering/testing and debugging",
      "IEEE_Terms": "Test pattern generators;Scalability;Graphics processing units;Automata;Software systems;Engines;Real-time systems",
      "License": "IEEE",
      "Online Date": "25-Jan-24",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Early Access Articles"
    },
    {
      "Document Title": "NEUZZ: Efficient Fuzzing with Neural Program Smoothing",
      "Authors": "D. She; K. Pei; D. Epstein; J. Yang; B. Ray; S. Jana",
      "Author Affiliations": "Columbia University; Columbia University; Columbia University; Columbia University; Columbia University; Columbia University",
      "Publication Title": "2019 IEEE Symposium on Security and Privacy (SP)",
      "Date Added To Xplore": "16-Sep-19",
      "Publication Year": "2019",
      "Start Page": "803",
      "End Page": "817",
      "Abstract": "Fuzzing has become the de facto standard technique for finding software vulnerabilities. However, even state-of-the-art fuzzers are not very efficient at finding hard-to-trigger software bugs. Most popular fuzzers use evolutionary guidance to generate inputs that can trigger different bugs. Such evolutionary algorithms, while fast and simple to implement, often get stuck in fruitless sequences of random mutations. Gradient-guided optimization presents a promising alternative to evolutionary guidance. Gradient-guided techniques have been shown to significantly outperform evolutionary algorithms at solving high-dimensional structured optimization problems in domains like machine learning by efficiently utilizing gradients or higher-order derivatives of the underlying function. However, gradient-guided approaches are not directly applicable to fuzzing as real-world program behaviors contain many discontinuities, plateaus, and ridges where the gradient-based methods often get stuck. We observe that this problem can be addressed by creating a smooth surrogate function approximating the target program's discrete branching behavior. In this paper, we propose a novel program smoothing technique using surrogate neural network models that can incrementally learn smooth approximations of a complex, real-world program's branching behaviors. We further demonstrate that such neural network models can be used together with gradient-guided input generation schemes to significantly increase the efficiency of the fuzzing process. Our extensive evaluations demonstrate that NEUZZ significantly outperforms 10 state-of-the-art graybox fuzzers on 10 popular real-world programs both at finding new bugs and achieving higher edge coverage. NEUZZ found 31 previously unknown bugs (including two CVEs) that other fuzzers failed to find in 10 real-world programs and achieved 3X more edge coverage than all of the tested graybox fuzzers over 24 hour runs. Furthermore, NEUZZ also outperformed existing fuzzers on both LAVA-M and DARPA CGC bug datasets.",
      "ISSN": "2375-1207",
      "ISBNs": "978-1-5386-6660-9",
      "DOI": "10.1109/SP.2019.00052",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8835342",
      "Author_Keywords": "fuzzing;-neural-program-smoothing;-gradient-guided-mutation",
      "IEEE_Terms": "Optimization;Fuzzing;Computer bugs;Artificial neural networks;Smoothing methods;Evolutionary computation",
      "Article Citation Count": "66",
      "Reference Count": "89",
      "License": "IEEE",
      "Online Date": "16-Sep-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Chaff from the Wheat: Characterizing and Determining Valid Bug Reports",
      "Authors": "Y. Fan; X. Xia; D. Lo; A. E. Hassan",
      "Author Affiliations": "College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Faculty of Information Technology, Monash University, Melbourne, Australia; School of Information Systems, Singapore Management University, Singapore; School of Computing, Queen's University, Kingston, Canada",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "14-May-20",
      "Publication Year": "2020",
      "Volume": "46",
      "Issue": "5",
      "Start Page": "495",
      "End Page": "525",
      "Abstract": "Developers use bug reports to triage and fix bugs. When triaging a bug report, developers must decide whether the bug report is valid (i.e., a real bug). A large amount of bug reports are submitted every day, with many of them end up being invalid reports. Manually determining valid bug report is a difficult and tedious task. Thus, an approach that can automatically analyze the validity of a bug report and determine whether a report is valid can help developers prioritize their triaging tasks and avoid wasting time and effort on invalid bug reports. In this study, motivated by the above needs, we propose an approach which can determine whether a newly submitted bug report is valid. Our approach first extracts 33 features from bug reports. The extracted features are grouped along 5 dimensions, i.e., reporter experience, collaboration network, completeness, readability and text. Based on these features, we use a random forest classifier to identify valid bug reports. To evaluate the effectiveness of our approach, we experiment on large-scale datasets containing a total of 560,697 bug reports from five open source projects (i.e., Eclipse, Netbeans, Mozilla, Firefox and Thunderbird). On average, across the five datasets, our approach achieves an F1-score for valid bug reports and F1-score for invalid ones of 0.74 and 0.67, respectively. Moreover, our approach achieves an average AUC of 0.81. In terms of AUC and F1-scores for valid and invalid bug reports, our approach statistically significantly outperforms two baselines using features that are proposed by Zanetti et al. [104] . We also study the most important features that distinguish valid bug reports from invalid ones. We find that the textual features of a bug report and reporter's experience are the most important factors to distinguish valid bug reports from invalid ones.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2018.2864217",
      "Funding Information": "National Basic Research Program of China (973 Program)(grant numbers:2018YFB1003904); National Natural Science Foundation of China(grant numbers:61602403); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8428477",
      "Author_Keywords": "Bug report;feature generation;machine learning",
      "IEEE_Terms": "Computer bugs;Feature extraction;Collaboration;Forestry;Support vector machines;Task analysis;Software",
      "Article Citation Count": "54",
      "Reference Count": "109",
      "License": "IEEE",
      "Online Date": "7-Aug-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Linking Source Code to Untangled Change Intents",
      "Authors": "X. Liu; L. Huang; C. Li; V. Ng",
      "Author Affiliations": "Department of Computer Science and Engineering, Southern Methodist University, Dallas, TX, USA; Department of Computer Science and Engineering, Southern Methodist University, Dallas, TX, USA; Nanjing University, Nanjing, Jiangsu, CN; Human Language Technology Research Institute, University of Texas, Dallas, TX, USA",
      "Publication Title": "2018 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "11-Nov-18",
      "Publication Year": "2018",
      "Start Page": "393",
      "End Page": "403",
      "Abstract": "Previous work [13] suggests that tangled changes (i.e., different change intents aggregated in one single commit message) could complicate tracing to different change tasks when developers manage software changes. Identifying links from changed source code to untangled change intents could help developers solve this problem. Manually identifying such links requires lots of experience and review efforts, however. Unfortunately, there is no automatic method that provides this capability. In this paper, we propose AutoCILink, which automatically identifies code to untangled change intent links with a pattern-based link identification system (AutoCILink-P) and a supervised learning-based link classification system (AutoCILink-ML). Evaluation results demonstrate the effectiveness of both systems: the pattern-based AutoCILink-P and the supervised learning-based AutoCILink-ML achieve average accuracy of 74.6% and 81.2%, respectively.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-5386-7870-1",
      "DOI": "10.1109/ICSME.2018.00047",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8530046",
      "Author_Keywords": "Commit, Code change, Machine learning",
      "IEEE_Terms": "Software;Task analysis;Computer bugs;Machine learning;Cognition;Gold;Additives",
      "Article Citation Count": "2",
      "Reference Count": "42",
      "License": "IEEE",
      "Online Date": "11-Nov-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "An Investigation of Cross-Project Learning in Online Just-In-Time Software Defect Prediction",
      "Authors": "S. Tabassum; L. L. Minku; D. Feng; G. G. Cabral; L. Song",
      "Author Affiliations": "University of Birmingham, UK; University of Birmingham, UK; Xiliu Tech, China; Federal Rural University of Pernambuco, Brazil; University of Birmingham, UK",
      "Publication Title": "2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "21-Dec-20",
      "Publication Year": "2020",
      "Start Page": "554",
      "End Page": "565",
      "Abstract": "Just-In-Time Software Defect Prediction (JIT-SDP) is concerned with predicting whether software changes are defect-inducing or clean based on machine learning classifiers. Building such classifiers requires a sufficient amount of training data that is not available at the beginning of a software project. Cross-Project (CP) JIT-SDP can overcome this issue by using data from other projects to build the classifier, achieving similar (not better) predictive performance to classifiers trained on Within-Project (WP) data. However, such approaches have never been investigated in realistic online learning scenarios, where WP software changes arrive continuously over time and can be used to update the classifiers. It is unknown to what extent CP data can be helpful in such situation. In particular, it is unknown whether CP data are only useful during the very initial phase of the project when there is little WP data, or whether they could be helpful for extended periods of time. This work thus provides the first investigation of when and to what extent CP data are useful for JIT-SDP in a realistic online learning scenario. For that, we develop three different CP JIT-SDP approaches that can operate in online mode and be updated with both incoming CP and WP training examples over time. We also collect 2048 commits from three software repositories being developed by a software company over the course of 9 to 10 months, and use 19,8468 commits from 10 active open source GitHub projects being developed over the course of 6 to 14 years. The study shows that training classifiers with incoming CP+WP data can lead to improvements in G-mean of up to 53.90% compared to classifiers using only WP data at the initial stage of the projects. For the open source projects, which have been running for longer periods of time, using CP data to supplement WP data also helped the classifiers to reduce or prevent large drops in predictive performance that may occur over time, leading to up to around 40% better G-Mean during such periods. Such use of CP data was shown to be beneficial even after a large number of WP data were received, leading to overall G-means up to 18.5% better than those of WP classifiers.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-7121-6",
      "Funding Information": "EPSRC(grant numbers:EP/R006660/2); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9283981",
      "Author_Keywords": "Software defect prediction;cross-project learning;transfer learning;online learning;verification latency;concept drift;class imbalance",
      "IEEE_Terms": "Training;Filtering;Training data;Software;Data models;Software engineering;Software development management",
      "Article Citation Count": "6",
      "Reference Count": "35",
      "Online Date": "21-Dec-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Impact of Defect Instances for Successful Deep Learning-based Automatic Program Repair",
      "Authors": "M. Kim; Y. Kim; J. Heo; H. Jeong; S. Kim; E. Lee",
      "Author Affiliations": "Institute of Software Convergence, Sungkyunkwan University, Suwon, Republic of Korea; Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, Republic of Korea; Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, Republic of Korea; Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, Republic of Korea; SW Engineering Group, Mobile eXperience, Samsung Electronics, Suwon, Republic of Korea; College of Computing and Informatics, Sungkyunkwan University, Suwon, Republic of Korea",
      "Publication Title": "2022 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "19-Dec-22",
      "Publication Year": "2022",
      "Start Page": "419",
      "End Page": "423",
      "Abstract": "Deep learning-based automatic program repair (DL-APR) returns a patch code when given a defect code. Recent studies on DL-APR techniques have focused on the training phase to generate more accurate patches; however, a trained model cannot always generate an accurate patch for every new defect code, as the training dataset does not completely represent the new defects to be input in the future. DL-APR researchers should study a method to elicit the best performance on new inputs from the trained and deployed model. A new defect instance (i.e., defect codes and their context codes) is one of the crucial input data that determine the accuracy of the DL-APR, which can be changed and improved. We improve the quality of new input defect instances by focusing on the presence of noise tokens which compromise the defect instances‚Äô quality, thus impairing the accuracy of generated patches. This paper shows that 1) there are noise tokens which prevent correct patch generation (inference) in a new defect instance, and 2) it is necessary to mask these noise tokens to avoid their usage in inferencing patch codes. In order to validate these two assertions, we use a state-of-the-art DL-APR technique and a genetic algorithm to generate near-optimal defect instances which maximize the patch generation accuracy (i.e., the BLEU score) of 4,573 defect instances. Based on optimization results, we found that 1) noise tokens impair patch generation accuracy in approximately 49% of instances, and 2) if these tokens are precluded from inference by masking them, we can improve patch generation accuracy by 88%. The results suggest that future work is required to automatically remove noise tokens from new defect instances so that the trained patch generator generates better patches.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-6654-7956-1",
      "DOI": "10.1109/ICSME55016.2022.00051",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9978242",
      "Author_Keywords": "Deep learning;Automatic program repair;Optimization;Masking;Noise token",
      "IEEE_Terms": "Training;Software maintenance;Codes;Focusing;Maintenance engineering;Generators;Optimization",
      "Reference Count": "21",
      "License": "IEEE",
      "Online Date": "19-Dec-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "FixJS: A Dataset of Bug-fixing JavaScript Commits",
      "Authors": "V. Csuvik; L. Vid√°cs",
      "Author Affiliations": "Department of Software Engineering, MTA-SZTE Research Group on Artificial Intelligence University of Szeged, Szeged, Hungary; Department of Software Engineering, MTA-SZTE Research Group on Artificial Intelligence University of Szeged, Szeged, Hungary",
      "Publication Title": "2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "21-Jun-22",
      "Publication Year": "2022",
      "Start Page": "712",
      "End Page": "716",
      "Abstract": "The field of Automated Program Repair (APR) has received increasing attention in recent years both from the academic world and from leading IT companies. Its main goal is to repair software bugs automatically, thus reducing the cost of development and mainte-nance significantly. Recent works use state-of-the-art deep learning models to predict correct patches, for these teaching on a large amount of data is inevitable almost in every scenarios. Despite this, readily accessible data on the field is very scarce. To contribute to related research, we present FixJS, a dataset containing bug-fixing information of ~2 million commits. The commits were gathered from GitHub and processed locally to have both the buggy (before bug fixing commit) and fixed (after fix) version of the same program. We focused on JavaScript functions, as it is one of the most popular programming language globally and functions are first class objects there. The data includes more than 300,000 samples of such functions, including commit information, before/after states and 3 source code representations.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-4503-9303-4",
      "DOI": "10.1145/3524842.3528480",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796277",
      "Author_Keywords": "Automated Program Repair;Software engineering;Bug-fixing commits",
      "IEEE_Terms": "Deep learning;Costs;Computer bugs;Education;Maintenance engineering;Predictive models;Software",
      "Article Citation Count": "4",
      "Reference Count": "27",
      "Online Date": "21-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Simpler Hyperparameter Optimization for Software Analytics: Why, How, When?",
      "Authors": "A. Agrawal; X. Yang; R. Agrawal; R. Yedida; X. Shen; T. Menzies",
      "Author Affiliations": "Wayfair, Boston, MA, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "16-Aug-22",
      "Publication Year": "2022",
      "Volume": "48",
      "Issue": "8",
      "Start Page": "2939",
      "End Page": "2954",
      "Abstract": "How can we make software analytics simpler and faster? One method is to match the complexity of analysis to the intrinsic complexity of the data being explored. For example, hyperparameter optimizers find the control settings for data miners that improve the predictions generated via software analytics. Sometimes, very fast hyperparameter optimization can be achieved by ‚ÄúDODGE-ing‚Äù; i.e., simply steering way from settings that lead to similar conclusions. But when is it wise to use that simple approach and when must we use more complex (and much slower) optimizers? To answer this, we applied hyperparameter optimization to 120 SE data sets that explored bad smell detection, predicting Github issue close time, bug report analysis, defect prediction, and dozens of other non-SE problems. We find that the simple DODGE works best for data sets with low ‚Äúintrinsic dimensionality‚Äù ($\\mu _D\\approx 3$ŒºD‚âà3) and very poorly for higher-dimensional data ($\\mu _D > 8$ŒºD>8). Nearly all the SE data seen here was intrinsically low-dimensional, indicating that DODGE is applicable for many SE analytics tasks.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2021.3073242",
      "Funding Information": "National Science Foundation(grant numbers:CCF-1703487); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9405415",
      "Author_Keywords": "Software analytics;hyperparameter optimization;defect prediction;bad smell detection;issue close time;bug reports",
      "IEEE_Terms": "Software;Optimization;Clustering algorithms;Text mining;Measurement;Computer bugs;Task analysis",
      "Article Citation Count": "12",
      "Reference Count": "101",
      "License": "IEEE",
      "Online Date": "15-Apr-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "SniP: An Efficient Stack Tracing Framework for Multi-threaded Programs",
      "Authors": "A. KP; S. Kumar; D. Mishra; B. Panda",
      "Author Affiliations": "Indian Institute of Technology, Kanpur, India; Indian Institute of Technology, Kanpur, India; Indian Institute of Technology, Kanpur, India; Indian Institute of Technology, Bombay, India",
      "Publication Title": "2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "21-Jun-22",
      "Publication Year": "2022",
      "Start Page": "408",
      "End Page": "412",
      "Abstract": "Usage of the execution stack at run-time captures the dynamic state of programs and can be used to derive useful insights into the program behaviour. The stack usage information can be used to identify and debug performance and security aspects of applications. Binary run-time instrumentation techniques are well known to capture the memory access traces during program execution. Tracing the program in entirety and filtering out stack specific accesses is a commonly used technique for stack related analysis. However, applying vanilla tracing techniques (using tools like Intel Pin) for multi-threaded programs has challenges such as identifying the stack areas to perform efficient run-time tracing. In this paper, we introduce SniP, an open-source stack tracing framework for multi-threaded programs built around Intel's binary instrumentation tool Pin. SniP provides a framework for efficient run-time tracing of stack areas used by multi-threaded applications by identifying the stack areas dynamically. The targeted tracing capability of SniP is demonstrated using a range of multi-threaded applications to show its efficacy in terms of trace size and time to trace. Compared to full program tracing using Pin, SniP achieves up to 75x reduction in terms of trace file size and up to 24x reduction in time to trace. SniP complements existing trace based stack usage analysis tools and we demonstrate that SniP can be easily integrated with the analysis framework through different use-cases.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-4503-9303-4",
      "DOI": "10.1145/3524842.3528499",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796268",
      "Author_Keywords": "Multi-threaded programs;Run-time instrumentation;Stack tracing",
      "IEEE_Terms": "Filtering;Instruments;Linux;Debugging;Pins;Performance analysis;Security",
      "Reference Count": "25",
      "Online Date": "21-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Flakify: A Black-Box, Language Model-Based Predictor for Flaky Tests",
      "Authors": "S. Fatima; T. A. Ghaleb; L. Briand",
      "Author Affiliations": "School of EECS, University of Ottawa, Ottawa, ON, Canada; School of EECS, University of Ottawa, Ottawa, ON, Canada; School of EECS, University of Ottawa, Ottawa, ON, Canada",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "18-Apr-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "4",
      "Start Page": "1912",
      "End Page": "1927",
      "Abstract": "Software testing assures that code changes do not adversely affect existing functionality. However, a test case can be flaky, i.e., passing and failing across executions, even for the same version of the source code. Flaky test cases introduce overhead to software development as they can lead to unnecessary attempts to debug production or testing code. Besides rerunning test cases multiple times, which is time-consuming and computationally expensive, flaky test cases can be predicted using machine learning (ML) models, thus reducing the wasted cost of re-running and debugging these test cases. However, the state-of-the-art ML-based flaky test case predictors rely on pre-defined sets of features that are either project-specific, i.e., inapplicable to other projects, or require access to production code, which is not always available to software test engineers. Moreover, given the non-deterministic behavior of flaky test cases, it can be challenging to determine a complete set of features that could potentially be associated with test flakiness. Therefore, in this article, we propose Flakify, a black-box, language model-based predictor for flaky test cases. Flakify relies exclusively on the source code of test cases, thus not requiring to (a) access to production code (black-box), (b) rerun test cases, (c) pre-define features. To this end, we employed CodeBERT, a pre-trained language model, and fine-tuned it to predict flaky test cases using the source code of test cases. We evaluated Flakify on two publicly available datasets (FlakeFlagger and IDoFT) for flaky test cases and compared our technique with the FlakeFlagger approach, the best state-of-the-art ML-based, white-box predictor for flaky test cases, using two different evaluation procedures: (1) cross-validation and (2) per-project validation, i.e., prediction on new projects. Flakify achieved F1-scores of 79% and 73% on the FlakeFlagger dataset using cross-validation and per-project validation, respectively. Similarly, Flakify achieved F1-scores of 98% and 89% on the IDoFT dataset using the two validation procedures, respectively. Further, Flakify surpassed FlakeFlagger by 10 and 18 percentage points (pp) in terms of precision and recall, respectively, when evaluated on the FlakeFlagger dataset, thus reducing the cost bound to be wasted on unnecessarily debugging test cases and production code by the same percentages (corresponding to reduction rates of 25% and 64%). Flakify also achieved significantly higher prediction results when used to predict test cases on new projects, suggesting better generalizability over FlakeFlagger. Our results further show that a black-box version of FlakeFlagger is not a viable option for predicting flaky test cases.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2022.3201209",
      "Funding Information": "Huawei Technologies Canada; Mitacs; Canada Research Chairs; Natural Sciences and Engineering Research Council of Canada; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9866550",
      "Author_Keywords": "Flaky tests;software testing;black-box testing;natural language processing;CodeBERT",
      "IEEE_Terms": "Codes;Predictive models;Production;Computational modeling;Software testing;Software;Feature extraction",
      "Article Citation Count": "10",
      "Reference Count": "69",
      "License": "IEEE",
      "Online Date": "24-Aug-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Cybersecurity in the Era of Data Science: Examining New Adversarial Models",
      "Authors": "B. Yener; T. Gal",
      "Author Affiliations": "Department of Computer Science, Renssellaer Polytechnic Institute, Troy, NY, USA; Morgan Stanley",
      "Publication Title": "IEEE Security & Privacy",
      "Date Added To Xplore": "30-Oct-19",
      "Publication Year": "2019",
      "Volume": "17",
      "Issue": "6",
      "Start Page": "46",
      "End Page": "53",
      "Abstract": "The ever-increasing volume, variety, and velocity of threats dictates a big data problem in cybersecurity and necessitates deployment of AI and machine-learning (ML) algorithms. The limitations and vulnerabilities of AI/ML systems, combined with complexity of data, introduce a new adversarial model, which is defined and discussed in this article.",
      "ISSN": "1558-4046",
      "DOI": "10.1109/MSEC.2019.2907097",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8705390",
      "IEEE_Terms": "Data models;Malware;Artificial intelligence;Computer security;Big Data;Real-time systems",
      "Article Citation Count": "5",
      "Reference Count": "18",
      "License": "IEEE",
      "Online Date": "3-May-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Magazines"
    },
    {
      "Document Title": "Facilitating Coordination between Software Developers: A Study and Techniques for Timely and Efficient Recommendations",
      "Authors": "K. Blincoe; G. Valetto; D. Damian",
      "Author Affiliations": "Software Engineering Global Interaction Lab, University of Victoria, Victoria, BC, Canada; Fondazione Bruno Kessler, Trento, Italy; Software Engineering Global Interaction Lab, University of Victoria, Victoria, BC, Canada",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "13-Oct-15",
      "Publication Year": "2015",
      "Volume": "41",
      "Issue": "10",
      "Start Page": "969",
      "End Page": "985",
      "Abstract": "When software developers fail to coordinate, build failures, duplication of work, schedule slips and software defects can result. However, developers are often unaware of when they need to coordinate, and existing methods and tools that help make developers aware of their coordination needs do not provide timely or efficient recommendations. We describe our techniques to identify timely and efficient coordination recommendations, which we developed and evaluated in a study of coordination needs in the Mylyn software project. We describe how data obtained from tools that capture developer actions within their Integrated Development Environment (IDE) as they occur can be used to timely identify coordination needs; we also describe how properties of tasks coupled with machine learning can focus coordination recommendations to those that are more critical to the developers to reduce information overload and provide more efficient recommendations. We motivate our techniques through developer interviews and report on our quantitative analysis of coordination needs in the Mylyn project. Our results suggest that by leveraging IDE logging facilities, properties of tasks and machine learning techniques awareness tools could make developers aware of critical coordination needs in a timely way. We conclude by discussing implications for software engineering research and tool design.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2015.2431680",
      "Funding Information": "US National Science Foundation (NSF)(grant numbers:OCI-1221254); NECSIS; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7105409",
      "Author_Keywords": "Human Factors in Software Design;Management;Metrics/Measurement;Productivity;Programming Teams;Computer-supported cooperative work;human factors in software design;management;metrics/measurement;productivity;programming teams",
      "IEEE_Terms": "Software;Encoding;Interviews;Statistical analysis;Manuals;Accuracy;Correlation",
      "Article Citation Count": "13",
      "Reference Count": "70",
      "License": "IEEE",
      "Online Date": "11-May-15",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "CURE: Code-Aware Neural Machine Translation for Automatic Program Repair",
      "Authors": "N. Jiang; T. Lutellier; L. Tan",
      "Author Affiliations": "Purdue University, West Lafayette, USA; University of Waterloo, Waterloo, Canada; Purdue University, West Lafayette, USA",
      "Publication Title": "2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "7-May-21",
      "Publication Year": "2021",
      "Start Page": "1161",
      "End Page": "1173",
      "Abstract": "Automatic program repair (APR) is crucial to improve software reliability. Recently, neural machine translation (NMT) techniques have been used to automatically fix software bugs. While promising, these approaches have two major limitations. Their search space often does not contain the correct fix, and their search strategy ignores software knowledge such as strict code syntax. Due to these limitations, existing NMT-based techniques underperform the best template-based approaches. We propose CURE, a new NMT-based APR technique with three major novelties. First, CURE pre-trains a programming language (PL) model on a large software codebase to learn developer-like source code before the APR task. Second, CURE designs a new code-aware search strategy that finds more correct fixes by focusing on searching for compilable patches and patches that are close in length to the buggy code. Finally, CURE uses a subword tokenization technique to generate a smaller search space that contains more correct fixes. Our evaluation on two widely-used benchmarks shows that CURE correctly fixes 57 Defects4J bugs and 26 QuixBugs bugs, outperforming all existing APR techniques on both benchmarks.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-0296-5",
      "DOI": "10.1109/ICSE43902.2021.00107",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9401997",
      "Author_Keywords": "automatic program repair;software reliability",
      "IEEE_Terms": "Computer bugs;Maintenance engineering;Benchmark testing;Search problems;Software;Software reliability;Machine translation",
      "Article Citation Count": "91",
      "Reference Count": "89",
      "License": "IEEE",
      "Online Date": "7-May-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Localizing Multiple Faults in Simulink Models",
      "Authors": "B. Liu; Lucia; S. Nejati; L. Briand; T. Bruckmann",
      "Author Affiliations": "Universite du Luxembourg, Luxembourg, LU; Universite du Luxembourg, Luxembourg, LU; Universite du Luxembourg, Luxembourg, LU; Universite du Luxembourg, Luxembourg, LU; Delphi Automotive Systems, Luxembourg",
      "Publication Title": "2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER)",
      "Date Added To Xplore": "23-May-16",
      "Publication Year": "2016",
      "Volume": "1",
      "Start Page": "146",
      "End Page": "156",
      "Abstract": "As Simulink is a widely used language in the embedded industry, there is a growing need to support debugging activities for Simulink models. In this work, we propose an approach to localize multiple faults in Simulink models. Our approach builds on statistical debugging and is iterative. At each iteration, we identify and resolve one fault and re-test models to focus on localizing faults that might have been masked before. We use decision trees to cluster together failures that satisfy similar (logical) conditions on model blocks or inputs. We then present two alternative selection criteria to choose a cluster that is more likely to yield the best fault localization results among the clusters produced by our decision trees. Engineers are expected to inspect the ranked list obtained from the selected cluster to identify faults. We evaluate our approach on 240 multi-fault models obtained from three different industrial subjects. We compare our approach with two baselines: (1) Statistical debugging without clustering, and (2) State-of-the-art clustering-based statistical debugging. Our results show that our approach significantly reduces the number of blocks that engineers need to inspect in order to localize all faults, when compared with the two baselines. Furthermore, with our approach, there is less performance degradation than in the baselines when increasing the number of faults in the underlying models.",
      "ISBNs": "978-1-5090-1855-0",
      "DOI": "10.1109/SANER.2016.38",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7476638",
      "Author_Keywords": "Fault localization;statistical debugging;machine learning;decision trees;Simulink models",
      "IEEE_Terms": "Software packages;Debugging;Decision trees;Fault diagnosis;Adaptation models;Testing;Numerical models",
      "Article Citation Count": "18",
      "Reference Count": "41",
      "License": "IEEE",
      "Online Date": "23-May-16",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Tracking Buggy Files: New Efficient Adaptive Bug Localization Algorithm",
      "Authors": "M. Fejzer; J. Narƒôbski; P. Przymus; K. Stencel",
      "Author Affiliations": "Nicolaus Copernicus University in Toru≈Ñ, Torun, Poland; Nicolaus Copernicus University in Toru≈Ñ, Torun, Poland; Nicolaus Copernicus University in Toru≈Ñ, Torun, Poland; University of Warsaw, Warszawa, Poland",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "15-Jul-22",
      "Publication Year": "2022",
      "Volume": "48",
      "Issue": "7",
      "Start Page": "2557",
      "End Page": "2569",
      "Abstract": "Upon receiving a new bug report, developers need to find its cause in the source code. Bug localization can be helped by a tool that ranks all source files according to how likely they include the bug. This problem was thoroughly examined by numerous scientists. We introduce a novel adaptive bug localization algorithm. The concept behind it is based on new feature weighting approaches and an adaptive selection algorithm utilizing pointwise learn‚Äìto‚Äìrank method. The algorithm is evaluated on publicly available datasets, and is competitive in terms of accuracy and required computational resources compared to state‚Äìof‚Äìthe‚Äìart. Additionally, to improve reproducibility we provide extended datasets that include computed features and partial steps, and we also provide the source code.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2021.3064447",
      "Funding Information": "Narodowa Agencja Wymiany Akademickiej; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9372820",
      "Author_Keywords": "Bug reports;software maintenance;learning to rank",
      "IEEE_Terms": "Computer bugs;Location awareness;Software;History;Software algorithms;Machine learning algorithms;Training",
      "Article Citation Count": "4",
      "Reference Count": "47",
      "License": "CCBY",
      "Online Date": "8-Mar-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Automated Software Vulnerability Assessment with Concept Drift",
      "Authors": "T. H. M. Le; B. Sabir; M. A. Babar",
      "Author Affiliations": "School of Computer Science, The University of Adelaide, Adelaide, Australia; School of Computer Science, The University of Adelaide, Adelaide, Australia; School of Computer Science, The University of Adelaide, Adelaide, Australia",
      "Publication Title": "2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "29-Aug-19",
      "Publication Year": "2019",
      "Start Page": "371",
      "End Page": "382",
      "Abstract": "Software Engineering researchers are increasingly using Natural Language Processing (NLP) techniques to automate Software Vulnerabilities (SVs) assessment using the descriptions in public repositories. However, the existing NLP-based approaches suffer from concept drift. This problem is caused by a lack of proper treatment of new (out-of-vocabulary) terms for the evaluation of unseen SVs over time. To perform automated SVs assessment with concept drift using SVs' descriptions, we propose a systematic approach that combines both character and word features. The proposed approach is used to predict seven Vulnerability Characteristics (VCs). The optimal model of each VC is selected using our customized time-based cross-validation method from a list of eight NLP representations and six well-known Machine Learning models. We have used the proposed approach to conduct large-scale experiments on more than 100,000 SVs in the National Vulnerability Database (NVD). The results show that our approach can effectively tackle the concept drift issue of the SVs' descriptions reported from 2000 to 2018 in NVD even without retraining the model. In addition, our approach performs competitively compared to the existing word-only method. We also investigate how to build compact concept-drift-aware models with much fewer features and give some recommendations on the choice of classifiers and NLP representations for SVs assessment.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-7281-3412-3",
      "DOI": "10.1109/MSR.2019.00063",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8816739",
      "Author_Keywords": "software vulnerability;machine learning;multi-class classification;natural language processing;mining software repositories",
      "IEEE_Terms": "Training;Software;Natural language processing;Buildings;Feature extraction;Predictive models;Classification algorithms",
      "Article Citation Count": "19",
      "Reference Count": "58",
      "License": "IEEE",
      "Online Date": "29-Aug-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "BiLO-CPDP: Bi-Level Programming for Automated Model Discovery in Cross-Project Defect Prediction",
      "Authors": "K. Li; Z. Xiang; T. Chen; K. C. Tan",
      "Author Affiliations": "College of Computer Science and Engineering, UESTC, Chengdu, China; Department of Computer Science, University of Exeter, Exeter, UK; Department of Computer Science, Loughborough University, Louahborough, UK; Department of Computer Science, City University of Hong Kong, Hong Kong SAR",
      "Publication Title": "2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "24-Dec-20",
      "Publication Year": "2020",
      "Start Page": "573",
      "End Page": "584",
      "Abstract": "Cross-Project Defect Prediction (CPDP), which borrows data from similar projects by combining a transfer learner with a classifier, have emerged as a promising way to predict software defects when the available data about the target project is insufficient. However, developing such a model is challenge because it is difficult to determine the right combination of transfer learner and classifier along with their optimal hyper-parameter settings. In this paper, we propose a tool, dubbed BiLO-CPDP, which is the first of its kind to formulate the automated CPDP model discovery from the perspective of bi-level programming. In particular, the bi-level programming proceeds the optimization with two nested levels in a hierarchical manner. Specifically, the upper-level optimization routine is designed to search for the right combination of transfer learner and classifier while the nested lower-level optimization routine aims to optimize the corresponding hyper-parameter settings. To evaluate BiLO-CPDP, we conduct experiments on 20 projects to compare it with a total of 21 existing CPDP techniques, along with its single-level optimization variant and Auto-Sklearn, a state-of-the-art automated machine learning tool. Empirical results show that BiLO-CPDP champions better prediction performance than all other 21 existing CPDP techniques on 70% of the projects, while being overwhelmingly superior to Auto-Sklearn and its single-level optimization variant on all cases. Furthermore, the unique bi-level formalization in BiLO-CPDP also permits to allocate more budget to the upper-level, which significantly boosts the performance.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-4503-6768-4",
      "Funding Information": "UKRI(grant numbers:MR/S017062/1); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9285660",
      "Author_Keywords": "‚Ä¢ Software and its engineering ‚Üí Software creation and management;Software defect analysis;Cross-project defect prediction;transfer learning;classification techniques;automated parameter optimization;configurable software and tool",
      "IEEE_Terms": "Computational modeling;Tools;Programming;Predictive models;Software;Optimization;Tuning",
      "Reference Count": "52",
      "Online Date": "24-Dec-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Within-Project Defect Prediction of Infrastructure-as-Code Using Product and Process Metrics",
      "Authors": "S. Dalla Palma; D. Di Nucci; F. Palomba; D. A. Tamburri",
      "Author Affiliations": "Jheronimous Academy of Data Science, Tilburg University, Tilburg, The Netherlands; Jheronimous Academy of Data Science, Tilburg University, Tilburg, The Netherlands; Software Engineering (SeSa) Lab, University of Salerno, Fisciano, Italy; Jheronimous Academy of Data Science, Eindhoven University of Technology, Eindhoven, The Netherlands",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "14-Jun-22",
      "Publication Year": "2022",
      "Volume": "48",
      "Issue": "6",
      "Start Page": "2086",
      "End Page": "2104",
      "Abstract": "Infrastructure-as-code (IaC) is the DevOps practice enabling management and provisioning of infrastructure through the definition of machine-readable files, hereinafter referred to as IaC scripts. Similarly to other source code artefacts, these files may contain defects that can preclude their correct functioning. In this paper, we aim at assessing the role of product and process metrics when predicting defective IaC scripts. We propose a fully integrated machine-learning framework for IaC Defect Prediction, that allows for repository crawling, metrics collection, model building, and evaluation. To evaluate it, we analyzed 104 projects and employed five machine-learning classifiers to compare their performance in flagging suspicious defective IaC scripts. The key results of the study report Random Forest as the best-performing model, with a median AUC-PR of 0.93 and MCC of 0.80. Furthermore, at least for the collected projects, product metrics identify defective IaC scripts more accurately than process metrics. Our findings put a baseline for investigating IaC Defect Prediction and the relationship between the product and process metrics, and IaC scripts‚Äô quality.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2021.3051492",
      "Funding Information": "European Commission(grant numbers:825040 (RADON H2020),825480 (SODALITE H2020)); Schweizerischer Nationalfonds zur F√∂rderung der Wissenschaftlichen Forschung(grant numbers:PZ00P2 186090); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9321740",
      "Author_Keywords": "Infrastructure-as-code;defect prediction;empirical software engineering",
      "IEEE_Terms": "Measurement;Software;Predictive models;Machine learning;Radon;Cloud computing;Task analysis",
      "Article Citation Count": "23",
      "Reference Count": "52",
      "License": "CCBY",
      "Online Date": "13-Jan-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Are the Code Snippets What We Are Searching for? A Benchmark and an Empirical Study on Code Search with Natural-Language Queries",
      "Authors": "S. Yan; H. Yu; Y. Chen; B. Shen; L. Jiang",
      "Author Affiliations": "Shanghai Jiao Tong University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China; Singapore Management University, Singapore",
      "Publication Title": "2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "2-Apr-20",
      "Publication Year": "2020",
      "Start Page": "344",
      "End Page": "354",
      "Abstract": "Code search methods, especially those that allow programmers to raise queries in a natural language, plays an important role in software development. It helps to improve programmers' productivity by returning sample code snippets from the Internet and/or source-code repositories for their natural-language queries. Meanwhile, there are many code search methods in the literature that support natural-language queries. Difficulties exist in recognizing the strengths and weaknesses of each method and choosing the right one for different usage scenarios, because (1) the implementations of those methods and the datasets for evaluating them are usually not publicly available, and (2) some methods leverage different training datasets or auxiliary data sources and thus their effectiveness cannot be fairly measured and may be negatively affected in practical uses. To build a common ground for measuring code search methods, this paper builds CosBench, a dataset that consists of 1000 projects, 52 code-independent natural-language queries with ground truths, and a set of scripts for calculating four metrics on code research results. We have evaluated four IR (Information Retrieval)-based and two DL (Deep Learning)-based code search methods on CosBench. The empirical evaluation results clearly show the usefulness of the CosBench dataset and various strengths of each code search method. We found that DL-based methods are more suitable for queries on reusing code, and IR-based ones for queries on resolving bugs and learning API uses.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-7281-5143-4",
      "DOI": "10.1109/SANER48275.2020.9054840",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054840",
      "Author_Keywords": "natural-language code search;benchmarking;empirical study;information retrieval;machine learning;deep learning;word embedding",
      "IEEE_Terms": "Measurement;Training;Productivity;Learning systems;Codes;Search methods;Soft sensors",
      "Article Citation Count": "25",
      "Reference Count": "53",
      "License": "IEEE",
      "Online Date": "2-Apr-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "PURLTL: Mining LTL Specification from Imperfect Traces in Testing",
      "Authors": "B. Peng; P. Liang; T. Han; W. Luo; J. Du; H. Wan; R. Ye; Y. Zheng",
      "Author Affiliations": "Sun Yat-Sen University, Guangzhou, China; Sun Yat-Sen University, Guangzhou, China; Sun Yat-Sen University, Guangzhou, China; Sun Yat-Sen University, Guangzhou, China; Pazhou Lab, Guangdong University of Foreign Studies, Guangzhou, China; Sun Yat-Sen University, Guangzhou, China; Sun Yat-Sen University, Guangzhou, China; Sun Yat-Sen University, Guangzhou, China",
      "Publication Title": "2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "8-Nov-23",
      "Publication Year": "2023",
      "Start Page": "1766",
      "End Page": "1770",
      "Abstract": "Formal specifications are widely used in software testing approaches, while writing such specifications is a time-consuming job. Recently, a number of methods have been proposed to mine specifications from execution traces, typically in the form of linear temporal logic (LTL). However, existing works have the following disadvantages: (1) ignoring the negative impact of imperfect traces, which come from partial profiling, missing context information, or buggy programs; (2) relying on templates, resulting in limited expressiveness; (3) requesting negative traces, which are usually unavailable in practice. In this paper, we propose PURLTL, which is able to mine arbitrary LTL specifications from imperfect traces. To alleviate the search space explosion and the wrong search bias, we propose a neural-based method to search LTL formulae, which, intuitively, simulates LTL path checking through differentiable parameter operations. To solve the problem of lacking negative traces, we transform the problem into learning from positive and unlabeled samples, by means of data augmentation and applying positive and unlabeled learning to the training process. Experiments show that our approach surpasses the previous start-of-the-art (SOTA) approach by a large margin. Besides, the results suggest that our approach is not only robust with imperfect traces, but also does not rely on formula templates.",
      "ISSN": "2643-1572",
      "ISBNs": "979-8-3503-2996-4",
      "DOI": "10.1109/ASE56229.2023.00202",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:62276284,61976232,61876204); National Key Research and Development Program of China(grant numbers:2021YFA1000504); Guangzhou Science and Technology Project(grant numbers:202201011699); Fundamental Research Funds for the Central Universities; Sun Yat-sen University(grant numbers:23ptpy31); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298448",
      "Author_Keywords": "specification mining;machine learning",
      "IEEE_Terms": "Training;Software testing;Transforms;Writing;Data augmentation;Explosions;Formal specifications",
      "Reference Count": "18",
      "License": "IEEE",
      "Online Date": "8-Nov-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "FairTest: Discovering Unwarranted Associations in Data-Driven Applications",
      "Authors": "F. Tram√®r; V. Atlidakis; R. Geambasu; D. Hsu; J. -P. Hubaux; M. Humbert; A. Juels; H. Lin",
      "Author Affiliations": "Stanford; Columbia University; Columbia University; Columbia University; EPFL; Saarland University; Cornell Tech, Jacobs Institute; EPFL",
      "Publication Title": "2017 IEEE European Symposium on Security and Privacy (EuroS&P)",
      "Date Added To Xplore": "3-Jul-17",
      "Publication Year": "2017",
      "Start Page": "401",
      "End Page": "416",
      "Abstract": "In a world where traditional notions of privacy are increasingly challenged by the myriad companies that collect and analyze our data, it is important that decision-making entities are held accountable for unfair treatments arising from irresponsible data usage. Unfortunately, a lack of appropriate methodologies and tools means that even identifying unfair or discriminatory effects can be a challenge in practice. We introduce the unwarranted associations (UA) framework, a principled methodology for the discovery of unfair, discriminatory, or offensive user treatment in data-driven applications. The UA framework unifies and rationalizes a number of prior attempts at formalizing algorithmic fairness. It uniquely combines multiple investigative primitives and fairness metrics with broad applicability, granular exploration of unfair treatment in user subgroups, and incorporation of natural notions of utility that may account for observed disparities. We instantiate the UA framework in FairTest, the first comprehensive tool that helps developers check data-driven applications for unfair user treatment. It enables scalable and statistically rigorous investigation of associations between application outcomes (such as prices or premiums) and sensitive user attributes (such as race or gender). Furthermore, FairTest provides debugging capabilities that let programmers rule out potential confounders for observed unfair effects. We report on use of FairTest to investigate and in some cases address disparate impact, offensive labeling, and uneven rates of algorithmic error in four data-driven applications. As examples, our results reveal subtle biases against older populations in the distribution of error in a predictive health application and offensive racial labeling in an image tagger.",
      "ISBNs": "978-1-5090-5762-7",
      "DOI": "10.1109/EuroSP.2017.29",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7961993",
      "Author_Keywords": "Algorithmic Fairness;Systems;Statistics",
      "IEEE_Terms": "Computer bugs;Measurement;Tools;Testing;Medical services;Google;Machine learning algorithms",
      "Article Citation Count": "64",
      "Patent Citation Count": "1",
      "Reference Count": "59",
      "License": "IEEE",
      "Online Date": "3-Jul-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Inferring Program Transformations From Singular Examples via Big Code",
      "Authors": "J. Jiang; L. Ren; Y. Xiong; L. Zhang",
      "Author Affiliations": "Key Laboratory of High Confidence Software Technologies, Ministry of Education (PKU), Peking University, Beijing, China; Key Laboratory of High Confidence Software Technologies, Ministry of Education (PKU), Peking University, Beijing, China; Key Laboratory of High Confidence Software Technologies, Ministry of Education (PKU), Peking University, Beijing, China; University of Texas at Dallas, USA",
      "Publication Title": "2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "9-Jan-20",
      "Publication Year": "2019",
      "Start Page": "255",
      "End Page": "266",
      "Abstract": "Inferring program transformations from concrete program changes has many potential uses, such as applying systematic program edits, refactoring, and automated program repair. Existing work for inferring program transformations usually rely on statistical information over a potentially large set of program-change examples. However, in many practical scenarios we do not have such a large set of program-change examples. In this paper, we address the challenge of inferring a program transformation from one single example. Our core insight is that \"big code\" can provide effective guide for the generalization of a concrete change into a program transformation, i.e., code elements appearing in many files are general and should not be abstracted away. We first propose a framework for transformation inference, where programs are represented as hypergraphs to enable fine-grained generalization of transformations. We then design a transformation inference approach, GENPAT, that infers a program transformation based on code context and statistics from a big code corpus. We have evaluated GENPAT under two distinct application scenarios, systematic editing and program repair. The evaluation on systematic editing shows that GENPAT significantly outperforms a state-of-the-art approach, SYDIT, with up to 5.5x correctly transformed cases. The evaluation on program repair suggests that GENPAT has the potential to be integrated in advanced program repair tools-GENPAT successfully repaired 19 real-world bugs in the Defects4J benchmark by simply applying transformations inferred from existing patches, where 4 bugs have never been repaired by any existing technique. Overall, the evaluation results suggest that GENPAT is effective for transformation inference and can potentially be adopted for many different applications.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-7281-2508-4",
      "DOI": "10.1109/ASE.2019.00033",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952210",
      "Author_Keywords": "Pattern generation, Program adaptation, Code abstraction",
      "IEEE_Terms": "Computer bugs;Maintenance engineering;Systematics;Wrapping;Machine learning;DSL;Tools",
      "Article Citation Count": "40",
      "Reference Count": "63",
      "License": "IEEE",
      "Online Date": "9-Jan-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Context-Based Automated Approach for Method Name Consistency Checking and Suggestion",
      "Authors": "Y. Li; S. Wang; T. Nguyen",
      "Author Affiliations": "Department of Informatics, New Jersey Institute of Technology, New Jersey, USA; Department of Informatics, New Jersey Institute of Technology, New Jersey, USA; University of Texas at Dallas, Dallas, TX, USA",
      "Publication Title": "2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "7-May-21",
      "Publication Year": "2021",
      "Start Page": "574",
      "End Page": "586",
      "Abstract": "Misleading method names in software projects can confuse developers, which may lead to software defects and affect code understandability. In this paper, we present DeepName, a context-based, deep learning approach to detect method name inconsistencies and suggest a proper name for a method. The key departure point is the philosophy of \"Show Me Your Friends, I'll Tell You Who You Are\". Unlike the state-of-the-art approaches, in addition to the method's body, we also consider the interactions of the current method under study with the other ones including the caller and callee methods, and the sibling methods in the same enclosing class. The sequences of sub-tokens in the program entities' names in the contexts are extracted and used as the input for an RNN-based encoder-decoder to produce the representations for the current method. We modify that RNN model to integrate the copy mechanism and our newly developed component, called the non-copy mechanism, to emphasize on the possibility of a certain sub-token not to be copied to follow the current sub-token in the currently generated method name. We conducted several experiments to evaluate DeepName on large datasets with +14M methods. For consistency checking, DeepName improves the state-of-the-art approach by 2.1%, 19.6%, and 11.9% relatively in recall, precision, and F-score, respectively. For name suggestion, DeepName improves relatively over the state-of-the-art approaches in precision (1.8%‚Äì30.5%), recall (8.8%‚Äì46.1%), and F-score (5.2%‚Äì38.2%). To assess DeepName's usefulness, we detected inconsistent methods and suggested new method names in active projects. Among 50 pull requests, 12 were merged into the main branch. In total, in 30/50 cases, the team members agree that our suggested method names are more meaningful than the current names.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-0296-5",
      "DOI": "10.1109/ICSE43902.2021.00060",
      "Funding Information": "National Science Foundation; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9402103",
      "Author_Keywords": "Naturalness of Software;Deep Learning;Entity Name Suggestion;Inconsistent Method Name Checking",
      "IEEE_Terms": "Deep learning;Software;Software engineering",
      "Article Citation Count": "17",
      "Reference Count": "39",
      "License": "IEEE",
      "Online Date": "7-May-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Are We There Yet? Timing and Floating-Point Attacks on Differential Privacy Systems",
      "Authors": "J. Jin; E. McMurtry; B. I. P. Rubinstein; O. Ohrimenko",
      "Author Affiliations": "School of Computing and Information Systems, The University of Melbourne; Department of Computer Science, ETH Zurich; School of Computing and Information Systems, The University of Melbourne; School of Computing and Information Systems, The University of Melbourne",
      "Publication Title": "2022 IEEE Symposium on Security and Privacy (SP)",
      "Date Added To Xplore": "27-Jul-22",
      "Publication Year": "2022",
      "Start Page": "473",
      "End Page": "488",
      "Abstract": "Differential privacy is a de facto privacy framework that has seen adoption in practice via a number of mature software platforms. Implementation of differentially private (DP) mechanisms has to be done carefully to ensure end-to-end security guarantees. In this paper we study two implementation flaws in the noise generation commonly used in DP systems. First we examine the Gaussian mechanism‚Äôs susceptibility to a floating-point representation attack. The premise of this first vulnerability is similar to the one carried out by Mironov in 2011 against the Laplace mechanism. Our experiments show the attack‚Äôs success against DP algorithms, including deep learning models trained using differentially-private stochastic gradient descent. In the second part of the paper we study discrete counterparts of the Laplace and Gaussian mechanisms that were previously proposed to alleviate the shortcomings of floating-point representation of real numbers. We show that such implementations unfortunately suffer from another side channel: a novel timing attack. An observer that can measure the time to draw (discrete) Laplace or Gaussian noise can predict the noise magnitude, which can then be used to recover sensitive attributes. This attack invalidates differential privacy guarantees of systems implementing such mechanisms. We demonstrate that several commonly used, state-of-the-art implementations of differential privacy are susceptible to these attacks. We report success rates up to 92.56% for floating point attacks on DP-SGD, and up to 99.65% for end-to-end timing attacks on private sum protected with discrete Laplace. Finally, we evaluate and suggest partial mitigations.",
      "ISSN": "2375-1207",
      "ISBNs": "978-1-6654-1316-9",
      "DOI": "10.1109/SP46214.2022.9833672",
      "Funding Information": "University of Melbourne; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9833672",
      "Author_Keywords": "Differential-Privacy;Timing-Side-Channel;Floating-Point-Representation;Gaussian-Mechanisms;Laplace-Mechanisms",
      "IEEE_Terms": "Differential privacy;Privacy;Sensitivity;Stochastic processes;Observers;Libraries;Timing",
      "Article Citation Count": "3",
      "Reference Count": "55",
      "License": "IEEE",
      "Online Date": "27-Jul-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Learning Approximate Execution Semantics From Traces for Binary Function Similarity",
      "Authors": "K. Pei; Z. Xuan; J. Yang; S. Jana; B. Ray",
      "Author Affiliations": "Columbia University, New York, NY, USA; Purdue University, West Lafayette, IN, USA; Columbia University, New York, NY, USA; Columbia University, New York, NY, USA; Columbia University, New York, NY, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "18-Apr-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "4",
      "Start Page": "2776",
      "End Page": "2790",
      "Abstract": "Detecting semantically similar binary functions ‚Äì a crucial capability with broad security usages including vulnerability detection, malware analysis, and forensics ‚Äì requires understanding function behaviors and intentions. This task is challenging as semantically similar functions can be compiled to run on different architectures and with diverse compiler optimizations or obfuscations. Most existing approaches match functions based on syntactic features without understanding the functions‚Äô execution semantics. We present Trex, a transfer-learning-based framework, to automate learning approximate execution semantics explicitly from functions‚Äô traces collected via forced-execution (i.e., by violating the control flow semantics) and transfer the learned knowledge to match semantically similar functions. While it is known that forced-execution traces are too imprecise to be directly used to detect semantic similarity, our key insight is that these traces can instead be used to teach an ML model approximate execution semantics of diverse instructions and their compositions. We thus design a pretraining task, which trains the model to learn approximate execution semantics from the two modalities (i.e., forced-executed code and traces) of the function. We then finetune the pretrained model to match semantically similar functions. We evaluate Trex on 1,472,066 functions from 13 popular software projects, compiled to run on 4 architectures (x86, x64, ARM, and MIPS), and with 4 optimizations (O0-O3) and 5 obfuscations. Trex outperforms the state-of-the-art solutions by 7.8%, 7.2%, and 14.3% in cross-architecture, optimization, and obfuscation function matching, respectively, while running 8√ó faster. Ablation studies suggest that the pretraining significantly boosts the function matching performance, underscoring the importance of learning execution semantics. Our case studies demonstrate the practical use-cases of Trex ‚Äì on 180 real-world firmware images, Trex uncovers 14 vulnerabilities not disclosed by previous studies. We release the code and dataset of Trex at https://github.com/CUMLSec/trex.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2022.3231621",
      "Funding Information": "National Science Foundation(grant numbers:CCF-18-45893,CCF-18-22965,CCF-16-19123,CNS-18-42456,CNS-18-01426,CNS-16-18771,CNS-16-17670,CNS-15-64055,CNS-15-63843); ONR(grant numbers:N00014-17-1-2010,N00014-16-1-2263,N00014-17-1-2788); NSF CAREER; ARO Young Investigator; Google Faculty Fellowship; JP Morgan Faculty Research Award; DiDi Faculty Research Award; Google Cloud; Capital One Research; Amazon Web Services; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10002189",
      "Author_Keywords": "Binary analysis;large language models;software security",
      "IEEE_Terms": "Semantics;Task analysis;Computer architecture;Optimization;Codes;Behavioral sciences;Computational modeling",
      "Article Citation Count": "6",
      "Reference Count": "100",
      "License": "IEEE",
      "Online Date": "28-Dec-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "DexBERT: Effective, Task-Agnostic and Fine-Grained Representation Learning of Android Bytecode",
      "Authors": "T. Sun; K. Allix; K. Kim; X. Zhou; D. Kim; D. Lo; T. F. Bissyand√©; J. Klein",
      "Author Affiliations": "University of Luxembourg, Kirchberg, Luxembourg; University of Luxembourg, Kirchberg, Luxembourg; Singapore Management University, Singapore; Singapore Management University, Singapore; Kyungpook National University, Daegu, Republic of Korea; Singapore Management University, Singapore; University of Luxembourg, Kirchberg, Luxembourg; University of Luxembourg, Kirchberg, Luxembourg",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "18-Oct-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "10",
      "Start Page": "4691",
      "End Page": "4706",
      "Abstract": "The automation of an increasingly large number of software engineering tasks is becoming possible thanks to Machine Learning (ML). One foundational building block in the application of ML to software artifacts is the representation of these artifacts (e.g., source code or executable code) into a form that is suitable for learning. Traditionally, researchers and practitioners have relied on manually selected features, based on expert knowledge, for the task at hand. Such knowledge is sometimes imprecise and generally incomplete. To overcome this limitation, many studies have leveraged representation learning, delegating to ML itself the job of automatically devising suitable representations and selections of the most relevant features. Yet, in the context of Android problems, existing models are either limited to coarse-grained whole-app level (e.g., apk2vec) or conducted for one specific downstream task (e.g., smali2vec). Thus, the produced representation may turn out to be unsuitable for fine-grained tasks or cannot generalize beyond the task that they have been trained on. Our work is part of a new line of research that investigates effective, task-agnostic, and fine-grained universal representations of bytecode to mitigate both of these two limitations. Such representations aim to capture information relevant to various low-level downstream tasks (e.g., at the class-level). We are inspired by the field of Natural Language Processing, where the problem of universal representation was addressed by building Universal Language Models, such as BERT, whose goal is to capture abstract semantic information about sentences, in a way that is reusable for a variety of tasks. We propose DexBERT, a BERT-like Language Model dedicated to representing chunks of DEX bytecode, the main binary format used in Android applications. We empirically assess whether DexBERT is able to model the DEX language and evaluate the suitability of our model in three distinct class-level software engineering tasks: Malicious Code Localization, Defect Prediction, and Component Type Classification. We also experiment with strategies to deal with the problem of catering to apps having vastly different sizes, and we demonstrate one example of using our technique to investigate what information is relevant to a given task.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2023.3310874",
      "Funding Information": "Fonds National de la Recherche (FNR), Luxembourg(grant numbers:REPROCESS C21/IS/16344458); National Research Foundation of Korea (NRF); Korea government (MSIT)(grant numbers:2021R1A5A1021944,2021R1I1A3048013); National Cybersecurity Research and Development Programme(grant numbers:NCRP25-P03-NCR-TAU); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10237047",
      "Author_Keywords": "Representation learning;Android app analysis;code representation;malicious code localization;defect prediction",
      "IEEE_Terms": "Task analysis;Malware;Predictive models;Codes;Location awareness;Operating systems;Software engineering",
      "Article Citation Count": "1",
      "Reference Count": "93",
      "License": "CCBY",
      "Online Date": "1-Sep-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Human-in-the-Loop XAI-enabled Vulnerability Detection, Investigation, and Mitigation",
      "Authors": "T. N. Nguyen; R. Choo",
      "Author Affiliations": "Computer Science Department, University of Texas at Dallas, Richardson, USA; Department of Information Systems and Cyber Security, University of Texas-San Antonio, San Antonio, USA",
      "Publication Title": "2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "20-Jan-22",
      "Publication Year": "2021",
      "Start Page": "1210",
      "End Page": "1212",
      "Abstract": "The need for cyber resilience is increasingly important in our technology-dependent society, where computing systems, devices and data will continue to be the target of cyber attackers. Hence, we propose a conceptual framework called ‚ÄòHuman-in-the-Loop Explainable-AI-Enabled Vulnerability Detection, Investigation, and Mitigation‚Äô (HXAI-VDIM). Specifically, instead of resolving complex scenario of security vulnerabilities as an output of an AI/ML model, we integrate the security analyst or forensic investigator into the man-machine loop and leverage explainable AI (XAI) to combine both AI and Intelligence Assistant (IA) to amplify human intelligence in both proactive and reactive processes. Our goal is that HXAI-VDIM integrates human and machine in an interactive and iterative loop with security visualization that utilizes human intelligence to guide the XAI-enabled system and generate refined solutions.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-6654-0337-5",
      "DOI": "10.1109/ASE51524.2021.9678840",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9678840",
      "Author_Keywords": "Vulnerability Detection;Investigation;Mitigation;Human-in-the-Loop;Explainable AI",
      "IEEE_Terms": "Analytical models;Human intelligence;Forensics;Computational modeling;Security;Artificial intelligence;Man-machine systems",
      "Article Citation Count": "3",
      "Reference Count": "5",
      "License": "IEEE",
      "Online Date": "20-Jan-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Towards a software vulnerability prediction model using traceable code patterns and software metrics",
      "Authors": "K. Z. Sultana",
      "Author Affiliations": "Department of Computer Science and Engineering, Mississippi State University, MS, USA",
      "Publication Title": "2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "23-Nov-17",
      "Publication Year": "2017",
      "Start Page": "1022",
      "End Page": "1025",
      "Abstract": "Software security is an important aspect of ensuring software quality. The goal of this study is to help developers evaluate software security using traceable patterns and software metrics during development. The concept of traceable patterns is similar to design patterns but they can be automatically recognized and extracted from source code. If these patterns can better predict vulnerable code compared to traditional software metrics, they can be used in developing a vulnerability prediction model to classify code as vulnerable or not. By analyzing and comparing the performance of traceable patterns with metrics, we propose a vulnerability prediction model. This study explores the performance of some code patterns in vulnerability prediction and compares them with traditional software metrics. We use the findings to build an effective vulnerability prediction model. We evaluate security vulnerabilities reported for Apache Tomcat, Apache CXF and three stand-alone Java web applications. We use machine learning and statistical techniques for predicting vulnerabilities using traceable patterns and metrics as features. We found that patterns have a lower false negative rate and higher recall in detecting vulnerable code than the traditional software metrics.",
      "ISBNs": "978-1-5386-2684-9",
      "DOI": "10.1109/ASE.2017.8115724",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8115724",
      "IEEE_Terms": "Predictive models;Software metrics;Security;Tools;Software;Testing",
      "Article Citation Count": "13",
      "Reference Count": "14",
      "License": "IEEE",
      "Online Date": "23-Nov-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Nalin: learning from Runtime Behavior to Find Name-Value Inconsistencies in Jupyter Notebooks",
      "Authors": "J. Patra; M. Pradel",
      "Author Affiliations": "University of Stuttgart, Germany; University of Stuttgart, Germany",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "1469",
      "End Page": "1481",
      "Abstract": "Variable names are important to understand and maintain code. If a variable name and the value stored in the variable do not match, then the program suffers from a name-value inconsistency, which is due to one of two situations that developers may want to fix: Either a correct value is referred to through a misleading name, which negatively affects code understandability and maintainability, or the correct name is bound to a wrong value, which may cause unexpected runtime behavior. Finding name-value inconsistencies is hard because it requires an understanding of the meaning of names and knowledge about the values assigned to a variable at runtime. This paper presents Nalin, a technique to automatically detect name-value inconsistencies. The approach combines a dynamic analysis that tracks assignments of values to names with a neural machine learning model that predicts whether a name and a value fit together. To the best of our knowledge, this is the first work to formulate the problem of finding coding issues as a classification problem over names and runtime values. We apply Nalin to 106,652 real-world Python programs, where meaningful names are particularly important due to the absence of statically declared types. Our results show that the classifier detects name-value inconsistencies with high accuracy, that the warnings reported by Nalin have a precision of 80% and a recall of 76% w.r.t. a ground truth created in a user study, and that our approach complements existing techniques for finding coding issues.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3510144",
      "Funding Information": "European Research Council (ERC)(grant numbers:851895); German Research Foundation; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794092",
      "Author_Keywords": "Neural software analysis;identifier names;learning-based bug detection",
      "IEEE_Terms": "Analytical models;Runtime;Codes;Computer bugs;Machine learning;Predictive models;Encoding",
      "Article Citation Count": "2",
      "Reference Count": "60",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Homogeneous and Heterogeneous Feed-Forward XOR Physical Unclonable Functions",
      "Authors": "S. V. S. Avvaru; Z. Zeng; K. K. Parhi",
      "Author Affiliations": "Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, USA; Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, USA; Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, USA",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "7-Feb-20",
      "Publication Year": "2020",
      "Volume": "15",
      "Start Page": "2485",
      "End Page": "2498",
      "Abstract": "Physical unclonable functions (PUFs) are hardware security primitives that are used for device authentication and cryptographic key generation. Standard XOR PUFs typically contain multiple standard arbiter PUFs as components, and are more secure than standard arbiter PUFs or feed-forward (FF) arbiter PUFs (FF PUFs). This paper proposes design of feed-forward XOR PUFs (FFXOR PUFs) where each component PUF is a FF PUF. Various homogeneous and heterogeneous FFXOR PUFs are presented and evaluated in terms of four fundamental properties of PUFs: uniqueness, attack-resistance, reliability and randomness. Certain key issues pertaining to XOR PUFs such as their vulnerability to machine learning attacks and instability in responses are investigated. Other important challenges like the lack of uniqueness in FF PUFs and the asymmetry in FPGA arbiter PUFs are addressed and it is shown that FFXOR PUFs can naturally overcome these problems. It is shown that heterogeneous FFXOR PUFs (i.e., FFXOR PUFs with non-identical components) can be resilient to state-of-the-art machine learning attacks. We also present systematic reliability analysis of FFXOR PUFs and demonstrate that soft-response thresholding can be used as an effective countermeasure to overcome the degraded reliability bottleneck. Observations from simulations are further verified through hardware implementation of 64-bit FFXOR PUFs on Xilinx Artix-7 FPGA.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2020.2968113",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8963980",
      "Author_Keywords": "Hardware security;arbiter PUF;feed-forward PUF;XOR PUF;FPGA PUF;FFXOR PUFs;homogeneous;heterogeneous;reliability;uniqueness;security;attack-resistance;randomness",
      "IEEE_Terms": "Reliability;Standards;Delays;Field programmable gate arrays;Physical unclonable function;Machine learning",
      "Article Citation Count": "50",
      "Reference Count": "53",
      "License": "IEEE",
      "Online Date": "20-Jan-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Learning Seed-Adaptive Mutation Strategies for Greybox Fuzzing",
      "Authors": "M. Lee; S. Cha; H. Oh",
      "Author Affiliations": "Korea University; Sungkyunkwan University; Korea University",
      "Publication Title": "2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "14-Jul-23",
      "Publication Year": "2023",
      "Start Page": "384",
      "End Page": "396",
      "Abstract": "In this paper, we present a technique for learning seed-adaptive mutation strategies for fuzzers. The performance of mutation-based fuzzers highly depends on the mutation strategy that specifies the probability distribution of selecting mutation methods. As a result, developing an effective mutation strategy has received much attention recently, and program-adaptive techniques, which observe the behavior of the target program to learn the optimized mutation strategy per program, have become a trending approach to achieve better performance. They, however, still have a major limitation; they disregard the impacts of different characteristics of seed inputs which can lead to explore deeper program locations. To address this limitation, we present SEAMFUZZ, a novel fuzzing technique that automatically captures the characteristics of individual seed inputs and applies different mutation strategies for different seed inputs. By capturing the syntactic and semantic similarities between seed inputs, SEAMFUZZ clusters them into proper groups and learns effective mutation strategies tailored for each seed cluster by using the customized Thompson sampling algorithm. Experimental results show that SEAMFUZZ improves both the path-discovering and bug-finding abilities of state-of-the-art fuzzers on real-world programs.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-5701-9",
      "DOI": "10.1109/ICSE48619.2023.00043",
      "Funding Information": "Samsung Electronics Co., Ltd(grant numbers:IO201216-08209-01); Institute of Information & communications Technology Planning & Evaluation (IITP)(grant numbers:2020-0-01337); MSIT(Ministry of Science and ICT)(grant numbers:IITP-2023-2020-0-01819); National Research Foundation of Korea(NRF)(grant numbers:2021R1A5A1021944,NRF-2021R1C1C2006410,RS-2023-00208094); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172576",
      "Author_Keywords": "Fuzzing;Software Testing",
      "IEEE_Terms": "Semantics;Clustering algorithms;Syntactics;Fuzzing;Probability distribution;Behavioral sciences;Software engineering",
      "Article Citation Count": "2",
      "Reference Count": "49",
      "License": "IEEE",
      "Online Date": "14-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Evaluating the effectiveness of local explanation methods on source code-based defect prediction models",
      "Authors": "Y. Gao; Y. Zhu; Q. Yu",
      "Author Affiliations": "School of Computer Science Jiangsu Normal University, Xuzhou, Jiangsu, China; School of Computer Science Jiangsu Normal University, Xuzhou, Jiangsu, China; School of Computer Science Jiangsu Normal University, Xuzhou, Jiangsu, China",
      "Publication Title": "2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "21-Jun-22",
      "Publication Year": "2022",
      "Start Page": "640",
      "End Page": "645",
      "Abstract": "Interpretation has been considered as one of key factors for applying defect prediction in practice. As one way for interpretation, local explanation methods has been widely used for certain predictions on datasets of traditional features. There are also attempts to use local explanation methods on source code-based defect prediction models, but unfortunately, it will get poor results. Since it is unclear how effective those local explanation methods are, we evaluate such methods with automatic metrics which focus on local faithfulness and explanation precision. Based on the results of experiments, we find that the effectiveness of local explanation methods depends on the adopted defect prediction models. They are effective on token frequency-based models, while they may not be effective enough to explain all predictions of deep learning-based models. Besides, we also find that the hyperparameter of local explanation methods should be carefully optimized to get more precise and meaningful explanation.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-4503-9303-4",
      "DOI": "10.1145/3524842.3528472",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:62077029); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796250",
      "Author_Keywords": "Software Defect Prediction;Local Explanation;Explainable Machine Learning;LIME",
      "IEEE_Terms": "Measurement;Codes;Predictive models;Software;Data mining",
      "Article Citation Count": "1",
      "Reference Count": "31",
      "Online Date": "21-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Comments on ‚ÄúDropping Activation Outputs with Localized First-Layer Deep Network for Enhancing User Privacy and Data Security‚Äù",
      "Authors": "X. Tan; H. Li; L. Wang; Z. Xu",
      "Author Affiliations": "Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "17-Jul-20",
      "Publication Year": "2020",
      "Volume": "15",
      "Start Page": "3938",
      "End Page": "3939",
      "Abstract": "Inference based on deep learning models is usually implemented by exposing sensitive user data to the outside models, which of course gives rise to acute privacy concerns. To deal with these concerns, Dong et al. recently proposed an approach, namely the dropping-activation-outputs (DAO) first layer. This approach was claimed to be a non-invertible transformation, such that the privacy of user data could not be compromised. However, In this paper, we prove that the DAO first layer, in fact, can generally be inverted, and hence fails to preserve privacy. We also provide a countermeasure against the privacy vulnerabilities that we examined.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2020.2988156",
      "Funding Information": "National Key Research and Development Program of China(grant numbers:2017YFB0801900); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068271",
      "Author_Keywords": "Deep learning;data privacy",
      "IEEE_Terms": "Data privacy;Artificial neural networks;Data models;Computational modeling;Data security;Machine learning;Privacy",
      "Article Citation Count": "3",
      "Reference Count": "5",
      "License": "IEEE",
      "Online Date": "15-Apr-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "How can i improve my app? Classifying user reviews for software maintenance and evolution",
      "Authors": "S. Panichella; A. Di Sorbo; E. Guzman; C. A. Visaggio; G. Canfora; H. C. Gall",
      "Author Affiliations": "University of Zurich, Switzerland; Universita degli Studi del Sannio, Benevento, Campania, IT; +Technische Universitat Munchen, Garchinz, Germanv; Universita degli Studi del Sannio, Benevento, Campania, IT; Tuniversity of Sannio, Benevento, Italy; Tuniversity of Sannio, Benevento, Italy",
      "Publication Title": "2015 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "23-Nov-15",
      "Publication Year": "2015",
      "Start Page": "281",
      "End Page": "290",
      "Abstract": "App Stores, such as Google Play or the Apple Store, allow users to provide feedback on apps by posting review comments and giving star ratings. These platforms constitute a useful electronic mean in which application developers and users can productively exchange information about apps. Previous research showed that users feedback contains usage scenarios, bug reports and feature requests, that can help app developers to accomplish software maintenance and evolution tasks. However, in the case of the most popular apps, the large amount of received feedback, its unstructured nature and varying quality can make the identification of useful user feedback a very challenging task. In this paper we present a taxonomy to classify app reviews into categories relevant to software maintenance and evolution, as well as an approach that merges three techniques: (1) Natural Language Processing, (2) Text Analysis and (3) Sentiment Analysis to automatically classify app reviews into the proposed categories. We show that the combined use of these techniques allows to achieve better results (a precision of 75% and a recall of 74%) than results obtained using each technique individually (precision of 70% and a recall of 67%).",
      "ISBNs": "978-1-4673-7532-0",
      "DOI": "10.1109/ICSM.2015.7332474",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332474",
      "Author_Keywords": "User Reviews;Mobile Applications;Natural Language Processing;Sentiment Analysis;Text classification",
      "IEEE_Terms": "Taxonomy;Software maintenance;Feature extraction;Natural language processing;Mobile communication;Maintenance engineering;Text analysis",
      "Article Citation Count": "287",
      "Patent Citation Count": "2",
      "Reference Count": "39",
      "License": "IEEE",
      "Online Date": "23-Nov-15",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Actionable Analytics: Stop Telling Me What It Is; Please Tell Me What To Do",
      "Authors": "C. Tantithamthavorn; J. Jiarpakdee; J. Grundy",
      "Author Affiliations": "Monash University, Clayton, Victoria, Australia; Monash University, Clayton, Victoria, Australia; Monash University, Clayton, Victoria, Australia",
      "Publication Title": "IEEE Software",
      "Date Added To Xplore": "21-Jun-21",
      "Publication Year": "2021",
      "Volume": "38",
      "Issue": "4",
      "Start Page": "115",
      "End Page": "120",
      "Abstract": "The success of software projects depends on complex decision making (e.g., which tasks should a developer do first, who should perform this task, is the software of high quality, is a software system reliable and resilient enough to deploy, etc.). Bad decisions cost money (and reputation) so we need better tools for making better decisions. This article discusses the \"why\" and \"how\" of explainable and actionable software analytics. For the task of reducing the risk of software defects, we show initial results from a successful case study that offers more actionable software analytics. Also, we present an interactive tutorial on the subject of Explainable AI tools for SE in our Software Analytics Cookbook (https://xai4se.github.io/book/), and we discuss some open questions that need to be addressed.",
      "ISSN": "1937-4194",
      "DOI": "10.1109/MS.2021.3072088",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9460977",
      "IEEE_Terms": "Project management;Software development management;Decision making;Analytical models",
      "Article Citation Count": "18",
      "Reference Count": "11",
      "License": "IEEE",
      "Online Date": "21-Jun-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Magazines"
    },
    {
      "Document Title": "Contextuality of Code Representation Learning",
      "Authors": "Y. Li; S. Wang; T. N. Nguyen",
      "Author Affiliations": "Department of Informatics, New Jersey Institute of Technology, New Jersey, USA; Department of Informatics, New Jersey Institute of Technology, New Jersey, USA; Computer Science Department, The University of Texas at Dallas, Texas, USA",
      "Publication Title": "2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "8-Nov-23",
      "Publication Year": "2023",
      "Start Page": "548",
      "End Page": "559",
      "Abstract": "Advanced machine learning models (ML) have been successfully leveraged in several software engineering (SE) applications. The existing SE techniques have used the embedding models ranging from static to contextualized ones to build the vectors for program units. The contextualized vectors address a phenomenon in natural language texts called polysemy, which is the coexistence of different meanings of a word/phrase. However, due to different nature, program units exhibit the nature of mixed polysemy. Some code tokens and statements exhibit polysemy while other tokens (e.g., keywords, separators, and operators) and statements maintain the same meaning in different contexts. A natural question is whether static or contextualized embeddings fit better with the nature of mixed polysemy in source code. The answer to this question is helpful for the SE researchers in selecting the right embedding model. We conducted experiments on 12 popular sequence-/tree-/graph-based embedding models and on the samples of a dataset of 10,222 Java projects with +14M methods. We present several contextuality evaluation metrics adapted from natural-language texts to code structures to evaluate the embeddings from those models. Among several findings, we found that the models with higher contextuality help a bug detection model perform better than the static ones. Neither static nor contextualized embedding models fit well with the mixed polysemy nature of source code. Thus, we develop Hycode, a hybrid embedding model that fits better with the nature of mixed polysemy in source code.",
      "ISSN": "2643-1572",
      "ISBNs": "979-8-3503-2996-4",
      "DOI": "10.1109/ASE56229.2023.00029",
      "Funding Information": "US NSF(grant numbers:CNS-2120386); NSA(grant numbers:NCAE-C-002-2021); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298296",
      "Author_Keywords": "Code Representation Learning;Contextualized Embedding;Contextuality of Code Embedding",
      "IEEE_Terms": "Representation learning;Adaptation models;Codes;Source coding;Particle separators;Computer bugs;Natural languages",
      "Reference Count": "27",
      "License": "IEEE",
      "Online Date": "8-Nov-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Automatic Testing and Improvement of Machine Translation",
      "Authors": "Z. Sun; J. M. Zhang; M. Harman; M. Papadakis; L. Zhang",
      "Author Affiliations": "Key Laboratory of HCST, Peking University, MoE; University College London; Facebook London; University of Luxembourg; Key Laboratory of HCST, Peking University, MoE",
      "Publication Title": "2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "21-Dec-20",
      "Publication Year": "2020",
      "Start Page": "974",
      "End Page": "985",
      "Abstract": "This paper presents TransRepair, a fully automatic approach for testing and repairing the consistency of machine translation systems. TransRepair combines mutation with metamorphic testing to detect inconsistency bugs (without access to human oracles). It then adopts probability-reference or cross-reference to post-process the translations, in a grey-box or black-box manner, to repair the inconsistencies. Our evaluation on two state-of-the-art translators, Google Translate and Transformer, indicates that TransRepair has a high precision (99%) on generating input pairs with consistent translations. With these tests, using automatic consistency metrics and manual assessment, we find that Google Translate and Transformer have approximately 36% and 40% inconsistency bugs. Black-box repair fixes 28% and 19% bugs on average for Google Translate and Transformer. Grey-box repair fixes 30% bugs on average for Transformer. Manual inspection indicates that the translations repaired by our approach improve consistency in 87% of cases (degrading it in 2%), and that our repairs have better translation acceptability in 27% of the cases (worse in 8%).",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-7121-6",
      "Funding Information": "National Key Research and Development Program of China(grant numbers:2017YFB1001803); ERC(grant numbers:741278); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284046",
      "Author_Keywords": "machine translation;testing and repair;translation consistency",
      "IEEE_Terms": "Measurement;Computer bugs;Manuals;Maintenance engineering;Inspection;Internet;Software engineering",
      "Article Citation Count": "4",
      "Reference Count": "59",
      "Online Date": "21-Dec-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Visual Defect Detection of Metal Screws using a Deep Convolutional Neural Network",
      "Authors": "D. Sauter; C. Atik; C. Schenk; R. Buettner; H. Baumgartl",
      "Author Affiliations": "Aalen University, Aalen, Germany; Aalen University, Aalen, Germany; Aalen University, Aalen, Germany; Aalen University, Aalen, Germany; Aalen University, Aalen, Germany",
      "Publication Title": "2021 IEEE 45th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "9-Sep-21",
      "Publication Year": "2021",
      "Start Page": "303",
      "End Page": "311",
      "Abstract": "In the production of screws, manual methods are often still used to detect defects. This paper aims to use a convolutional neural network-based technique to detect whether defects in screws are caused during production. Our experimental results show that a detection accuracy of 96.67% can be achieved with the proposed technique. Among the defects considered are defects on the objects' surface (e.g., scratches, dents), structural defects like distorted object parts, or defects that manifest themselves by the absence of certain object parts. Our more efficient method can be used in the future for quality control in the manufacture of screws.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-6654-2463-9",
      "DOI": "10.1109/COMPSAC51774.2021.00050",
      "Funding Information": "Ministry of Education; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9529357",
      "Author_Keywords": "Metal Screw;Deep Learning;Convolutional Neural Network;Defect Detection",
      "IEEE_Terms": "Heating systems;Visualization;Instruction sets;Transfer learning;Metals;Production;Quality control",
      "Article Citation Count": "4",
      "Reference Count": "21",
      "License": "IEEE",
      "Online Date": "9-Sep-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "An Ontology-Based Approach to Automate Tagging of Software Artifacts",
      "Authors": "S. S. Alqahtani; J. Rilling",
      "Author Affiliations": "Department of Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada",
      "Publication Title": "2017 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)",
      "Date Added To Xplore": "11-Dec-17",
      "Publication Year": "2017",
      "Start Page": "169",
      "End Page": "174",
      "Abstract": "Context: Software engineering repositories contain a wealth of textual information such as source code comments, developers' discussions, commit messages and bug reports. These free form text descriptions can contain both direct and implicit references to security concerns. Goal: Derive an approach to extract security concerns from textual information that can yield several benefits, such as bug management (e.g., prioritization), bug triage or capturing zero-day attack. Method: Propose a fully automated classification and tagging approach that can extract security tags from these texts without the need for manual training data. Results: We introduce an ontology based Software Security Tagger Framework that can automatically identify and classify cybersecurity-related entities, and concepts in text of software artifacts. Conclusion: Our preliminary results indicate that the framework can successfully extract and classify cybersecurity knowledge captured in unstructured text found in software artifacts.",
      "ISBNs": "978-1-5090-4039-1",
      "DOI": "10.1109/ESEM.2017.25",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8170098",
      "Author_Keywords": "automated security concern classification;topic modeling;bug reports;tagging",
      "IEEE_Terms": "Computer bugs;Software;Ontologies;Tagging;Software engineering;Computer security",
      "Article Citation Count": "7",
      "Reference Count": "20",
      "License": "IEEE",
      "Online Date": "11-Dec-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Legion: Massively Composing Rankers for Improved Bug Localization at Adobe",
      "Authors": "D. Jarman; J. Berry; R. Smith; F. Thung; D. Lo",
      "Author Affiliations": "Adobe, Lehi, UT, USA; Adobe, Lehi, UT, USA; Adobe, Lehi, UT, USA; School of Information Systems, Singapore Management University, Singapore, Singapore; School of Information Systems, Singapore Management University, Singapore, Singapore",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "16-Aug-22",
      "Publication Year": "2022",
      "Volume": "48",
      "Issue": "8",
      "Start Page": "3010",
      "End Page": "3024",
      "Abstract": "Studies have estimated that, in industrial settings, developers spend between 30 and 90 percent of their time fixing bugs. As such, tools that assist in identifying the location of bugs provide value by reducing debugging costs. One such tool is BugLocator. This study initially aimed to determine if developers working on the Adobe Analytics product could use BugLocator. The initial results show that BugLocator achieves a similar accuracy on five of seven Adobe Analytics repositories and on open-source projects. However, these results do not meet the minimum applicability requirement deemed necessary by Adobe Analytics developers prior to possible adoption. Thus, we consequently examine how BugLocator can achieve the targeted accuracy with two extensions: (1) adding more data corpora, and (2) massively composing individual rankers consisting of augmented BugLocator instances trained on various combinations of corpora and parameter configurations with a Random Forest model. We refer to our final extension as Legion. On average, applying Legion to Adobe Analytics repositories results in at least one buggy file ranked in the top-ten recommendations 76.8 percent of the time for customer-reported bugs across all 7 repositories. This represents a substantial improvement over BugLocator of 36.4 percent, and satisfies the minimum applicability requirement. Additionally, our extensions boost Mean Average Precision by 107.7 percent, Mean Reciprocal Rank by 86.1 percent, Top 1 by 143.4 percent and Top 5 by 58.1 percent.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2021.3075215",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9415126",
      "Author_Keywords": "Bug localization;information retrieval;bug reports;data augmentation;ranker composition;industrial study",
      "IEEE_Terms": "Computer bugs;Location awareness;Tools;Debugging;Random forests;Programming;Information retrieval",
      "Article Citation Count": "2",
      "Reference Count": "65",
      "License": "IEEE",
      "Online Date": "23-Apr-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "UnGoML: Automated Classification of unsafe Usages in Go",
      "Authors": "A. -K. Wickert; C. Damke; L. Baumg√§rtner; E. H√ºllermeier; M. Mezini",
      "Author Affiliations": "Software Technology Group, Technische Universit√§t Darmstadt, Darmstadt, Germany; Institute of Informatics University of Munich, Munich, Germany; Software Technology Group, Technische Universit√§t Darmstadt, Darmstadt, Germany; Munich Center for Machine Learning Institute of Informatics, University of Munich, Munich, Germany; Hessian Center for Artificial Intelligence (hessian.AI) National Research Center for Applied Cybersecurity ATHENE Software Technology Group, Technische Universit√§t Darmstadt, Darmstadt, Germany",
      "Publication Title": "2023 IEEE/ACM 20th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "12-Jul-23",
      "Publication Year": "2023",
      "Start Page": "309",
      "End Page": "321",
      "Abstract": "The Go programming language offers strong protection from memory corruption. As an escape hatch of these protections, it provides the unsafe package. Previous studies identified that this unsafe package is frequently used in real-world code for several purposes, e.g., serialization or casting types. Due to the variety of these reasons, it may be possible to refactor specific usages to avoid potential vulnerabilities. However, the classification of unsafe usages is challenging and requires the context of the call and the program‚Äôs structure. In this paper, we present the first automated classifier for unsafe usages in Go, UnGoML, to identify what is done with the unsafe package and why it is used. For UnGoML, we built four custom deep learning classifiers trained on a manually labeled data set. We represent Go code as enriched control-flow graphs (CFGs) and solve the label prediction task with one single-vertex and three context-aware classifiers. All three context-aware classifiers achieve a top-1 accuracy of more than 86% for both dimensions, WHAT and WHY. Furthermore, in a set-valued conformal prediction setting, we achieve accuracies of more than 93% with mean label set sizes of 2 for both dimensions. Thus, UnGoML can be used to efficiently filter unsafe usages for use cases such as refactoring or a security audit. UnGoML: https://github.com/stg-tud/UnGoML Artifact: https://dx.doi.org/10.6084/m9.figshare.22293052",
      "ISSN": "2574-3864",
      "ISBNs": "979-8-3503-1184-6",
      "DOI": "10.1109/MSR59073.2023.00050",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10174087",
      "Author_Keywords": "graph neural networks;Go;unsafe package;classification;API-misuse",
      "IEEE_Terms": "Deep learning;Computer languages;Codes;Static analysis;Computer architecture;Software;Safety",
      "Reference Count": "47",
      "License": "IEEE",
      "Online Date": "12-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Will This Bug-Fixing Change Break Regression Testing?",
      "Authors": "X. Tang; S. Wang; K. Mao",
      "Author Affiliations": "State Key Laboratory of Computer Science, Chinese Academy of Sciences; Electrical and Computer Engineering, University of Waterloo, Canada; University College London, CREST Centre, UK",
      "Publication Title": "2015 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)",
      "Date Added To Xplore": "9-Nov-15",
      "Publication Year": "2015",
      "Start Page": "1",
      "End Page": "10",
      "Abstract": "Context: Software source code is frequently changed for fixing revealed bugs. These bug-fixing changes might introduce unintended system behaviors, which are inconsistent with scenarios of existing regression test cases, and consequently break regression testing. For validating the quality of changes, regression testing is a required process before submitting changes during the development of software projects. Our pilot study shows that 48.7% bug-fixing changes might break regression testing at first run, which means developers have to run regression testing at least a couple of times for 48.7% changes. Such process can be tedious and time consuming. Thus, before running regression test suite, finding these changes and corresponding regression test cases could be helpful for developers to quickly fix these changes and improve the efficiency of regression testing. Goal: This paper proposes bug- fixing change impact prediction (BFCP), for predicting whether a bug-fixing change will break regression testing or not before running regression test cases, by mining software change histories. Method: Our approach employs the machine learning algorithms and static call graph analysis technique. Given a bug-fixing change, BFCP first predicts whether it will break existing regression test cases; second, if the change is predicted to break regression test cases, BFCP can further identify the might-be-broken test cases. Results: Results of experiments on 552 real bug-fixing changes from four large open source projects show that BFCP could achieve prediction precision up to 83.3%, recall up to 92.3%, and F-score up to 81.4%. For identifying the might-be-broken test cases, BFCP could achieve 100% recall.",
      "ISSN": "1949-3789",
      "ISBNs": "978-1-4673-7899-4",
      "DOI": "10.1109/ESEM.2015.7321218",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7321218",
      "IEEE_Terms": "Testing;Measurement;Computer bugs;Software;Semantics;Predictive models;History",
      "Article Citation Count": "7",
      "Patent Citation Count": "1",
      "Reference Count": "42",
      "License": "IEEE",
      "Online Date": "9-Nov-15",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Understanding the Manipulation on Recommender Systems through Web Injection",
      "Authors": "Y. Zhang; J. Xiao; S. Hao; H. Wang; S. Zhu; S. Jajodia",
      "Author Affiliations": "Department of Electrical and Computer Engineering, University of Delaware, Newark, USA; Department of Computer Science, Boise State University, Boise, USA; Department of Computer Science, Old Dominion University, Norfolk, USA; Department of Electrical and Computer Engineering, Virginia Tech, Arlington, USA; Department of Computer Science and Engineering, Penn State University, University Park, USA; Center for Secure Information Systems, George Mason University, Fairfax, USA",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "16-Jul-20",
      "Publication Year": "2020",
      "Volume": "15",
      "Start Page": "3807",
      "End Page": "3818",
      "Abstract": "Recommender systems have been increasingly used in a variety of web services, providing a list of recommended items in which a user may have an interest. While important, recommender systems are vulnerable to various malicious attacks. In this paper, we study a new security vulnerability in recommender systems caused by web injection, through which malicious actors stealthily tamper any unprotected in-transit HTTP webpage content and force victims to visit specific items in some web services (even running HTTPS), e.g., YouTube. By doing so, malicious actors can promote their targeted items in those web services. To obtain a deeper understanding on the recommender systems of our interest (including YouTube, Yelp, Taobao, and 360 App market), we first conduct a measurement-based analysis on several real-world recommender systems by leveraging machine learning algorithms. Then, web injection is implemented in three different types of devices (i.e., computer, router, and proxy server) to investigate the scenarios where web injection could occur. Based on the implementation of web injection, we demonstrate that it is feasible and sometimes effective to manipulate the real-world recommender systems through web injection. We also present several countermeasures against such manipulations.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2019.2954737",
      "Funding Information": "Army Research Office(grant numbers:W911NF-13-1-0421,W911NF-19-1-0049); National Science Foundation(grant numbers:CNS-1618117,CNS-1822094); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907865",
      "Author_Keywords": "Recommender systems;recommendation manipulation;web injection",
      "IEEE_Terms": "Recommender systems;YouTube;Web services;Browsers;Pollution;Videos;History",
      "Article Citation Count": "5",
      "Reference Count": "40",
      "License": "IEEE",
      "Online Date": "20-Nov-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Feature Engineering-Based Detection of Buffer Overflow Vulnerability in Source Code Using Neural Networks",
      "Authors": "M. S. Akter; H. Shahriar; J. R. Cardenas; S. Iqbal Ahamed; A. Cuzzocrea",
      "Author Affiliations": "Department of Computer Science, Kennesaw State University, USA; Department of Information Technology, Kennesaw State University, USA; Department of Information Technology, Kennesaw State University, USA; Department of Computer Science, Marquette University, USA; iDEA Lab, University of Calabria, Italy",
      "Publication Title": "2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "2-Aug-23",
      "Publication Year": "2023",
      "Start Page": "765",
      "End Page": "776",
      "Abstract": "One of the most significant challenges in the field of software code auditing is the presence of vulnerabilities in software source code. Every year, more and more software flaws are discovered, either internally in proprietary code or publicly disclosed. These flaws are highly likely to be exploited and can lead to system compromise, data leakage, or denial of service. To create a large-scale machine learning system for function-level vulnerability identification, we utilized a sizable dataset of C and C++ open-source code containing millions of functions with potential buffer overflow exploits. We have developed an efficient and scalable vulnerability detection method based on neural network models that learn features extracted from the source codes. The source code is first converted into an intermediate representation to remove unnecessary components and shorten dependencies. We maintain the semantic and syntactic information using state-of-the-art word embedding algorithms such as GloVe and fastText. The embedded vectors are subsequently fed into neural networks such as LSTM, BiLSTM, LSTM-Autoencoder, word2vec, BERT, and GPT-2 to classify the possible vulnerabilities. Furthermore, we have proposed a neural network model that can overcome issues associated with traditional neural networks. We have used evaluation metrics such as F1 score, precision, recall, accuracy, and total execution time to measure the performance. We have conducted a comparative analysis between results derived from features containing a minimal text representation and semantic and syntactic information. We have found that all neural network models provide higher accuracy when we use semantic and syntactic information as features. However, this approach requires more execution time due to the added complexity of the word embedding algorithm. Moreover, our proposed model provides higher accuracy than LSTM, BiLSTM, LSTM-Autoencoder, word2vec and BERT models, and the same accuracy as the GPT-2 model with greater efficiency.",
      "ISSN": "0730-3157",
      "ISBNs": "979-8-3503-2697-0",
      "DOI": "10.1109/COMPSAC57700.2023.00106",
      "Funding Information": "National Science Foundation; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10196986",
      "Author_Keywords": "Cyber Security;Vulnerability Detection;Neural Networks;Feature Extraction",
      "IEEE_Terms": "Codes;Source coding;Computational modeling;Neural networks;Semantics;Bit error rate;Machine learning",
      "Reference Count": "40",
      "License": "IEEE",
      "Online Date": "2-Aug-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Detecting Privacy-Sensitive Code Changes with Language Modeling",
      "Authors": "G. Demirci; V. Murali; I. Ahmad; R. Rao; G. A. Aye",
      "Author Affiliations": "Meta Platforms, Inc, Menlo Park, CA, USA; Meta Platforms, Inc, Menlo Park, CA, USA; Meta Platforms, Inc, Menlo Park, CA, USA; Meta Platforms, Inc, Menlo Park, CA, USA; Meta Platforms, Inc, Menlo Park, CA, USA",
      "Publication Title": "2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "21-Jun-22",
      "Publication Year": "2022",
      "Start Page": "761",
      "End Page": "762",
      "Abstract": "At Meta, we work to incorporate privacy-by-design into all of our products and keep user information secure. We have created an ML model that detects code changes (‚Äúdiffs‚Äù) that have privacy-sensitive implications. At our scale of tens of thousands of engineers creating hundreds of thousands of diffs each month, we use automated tools for detecting such diffs. Inspired by recent studies on detecting defects [2], [3], [5] and security vulnerabilities [4], [6], [7], we use techniques from natural language processing to build a deep learning system for detecting privacy-sensitive code.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-4503-9303-4",
      "DOI": "10.1145/3524842.3528518",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796200",
      "Author_Keywords": "privacy;software;repository;change;detection;machine learning;privacy sensitive;neural networks",
      "IEEE_Terms": "Deep learning;Codes;Databases;Static analysis;Manuals;Feature extraction;Software",
      "Reference Count": "7",
      "Online Date": "21-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Implementation of the Database Machine Direct",
      "Authors": "H. Boral; D. J. Dewitt; D. Friedland; N. F. Jarrell; W. K. Wilkinson",
      "Author Affiliations": "Department of Computer Sciences, University of Wisconsin, Madison, WI, USA; Department of Computer Sciences, University of Wisconsin, Madison, WI, USA; School of Mathematics, Weizmann Institute of Science, Rehovot, Israel; Department of Computer Sciences, University of Wisconsin, Madison, WI, USA; Bell Laboratories, Inc., Murray Hill, NJ, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "18-Sep-06",
      "Publication Year": "1982",
      "Volume": "SE-8",
      "Issue": "6",
      "Start Page": "533",
      "End Page": "543",
      "Abstract": "DIRECT is a multiprocessor database machine designed and implemented at the University of Wisconsin. This paper describes our experiences with the implementation of DIRECT. We start with a brief overview of the original machine proposal and how it differs from what was actually implemented. We then describe the structure of the DIRECT software. This includes software on host computers that interfaces with the database machine; software on the back-end controller of DIRECT; and software executed by the query processors. In addition to describing the structure of the software we will attempt to motivate and justify its design and implementation. We also discuss a number of implementation issues (e.g., debugging of the code across several machines). We conclude the paper with a list of the \"lessons\" we have learned from this experience.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.1982.235882",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1702986",
      "Author_Keywords": "Associative processors;computer architecture;database machine;database management;parallel processors",
      "IEEE_Terms": "Database machines;Hardware;Computer architecture;Relational databases;Military computing;Aggregates;Proposals;Computer interfaces;Debugging;Software design",
      "Article Citation Count": "21",
      "Reference Count": "14",
      "License": "IEEE",
      "Online Date": "18-Sep-06",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "VarCLR: Variable Semantic Representation Pre-training via Contrastive Learning",
      "Authors": "Q. Chen; J. Lacomis; E. J. Schwartz; G. Neubig; B. Vasilescu; C. L. Goues",
      "Author Affiliations": "Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University Software Engineering Institute; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "2327",
      "End Page": "2339",
      "Abstract": "Variable names are critical for conveying intended program behavior. Machine learning-based program analysis methods use variable name representations for a wide range of tasks, such as suggesting new variable names and bug detection. Ideally, such methods could capture semantic relationships between names beyond syntactic similarity, e.g., the fact that the names average and mean are similar. Unfortunately, previous work has found that even the best of previous representation approaches primarily capture ‚Äúrelatedness‚Äù (whether two variables are linked at all), rather than ‚Äúsimilarity‚Äù (whether they actually have the same meaning). We propose Varclr, a new approach for learning semantic representations of variable names that effectively captures variable similarity in this stricter sense. We observe that this problem is an excellent fit for contrastive learning, which aims to minimize the distance between explicitly similar inputs, while maximizing the distance between dissimilar inputs. This requires labeled training data, and thus we construct a novel, weakly-supervised variable renaming dataset mined from GitHub edits. We show that Varclr enables the effective application of sophisticated, general-purpose language models like BERT, to variable name representation and thus also to related downstream tasks like variable name similarity search or spelling correction. Varclr produces models that significantly outperform the state-of-the-art on IDBENCH, an existing benchmark that explicitly captures variable similarity (as distinct from relatedness). Finally, we contribute a release of all data, code, and pre-trained models, aiming to provide a drop-in replacement for variable representations used in either existing or future program analyses that rely on variable names.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3510162",
      "Funding Information": "National Science Foundation(grant numbers:1815287,1910067); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793917",
      "IEEE_Terms": "Codes;Semantics;Computer bugs;Bit error rate;Training data;Syntactics;Data models",
      "Article Citation Count": "7",
      "Reference Count": "88",
      "License": "CCBY",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Enhancing Dynamic Symbolic Execution by Automatically Learning Search Heuristics",
      "Authors": "S. Cha; S. Hong; J. Bak; J. Kim; J. Lee; H. Oh",
      "Author Affiliations": "Department of Computer Science and Engineering, Sungkyunkwan University, Suwon, South Korea; Department of Computer Science and Engineering, Sungkyunkwan University, Suwon, South Korea; Department of Computer Science and Engineering, Sungkyunkwan University, Suwon, South Korea; Department of Computer Science and Engineering, Sungkyunkwan University, Suwon, South Korea; Department of Computer Science and Engineering, Sungkyunkwan University, Suwon, South Korea; Department of Computer Science and Engineering, Sungkyunkwan University, Suwon, South Korea",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "16-Sep-22",
      "Publication Year": "2022",
      "Volume": "48",
      "Issue": "9",
      "Start Page": "3640",
      "End Page": "3663",
      "Abstract": "We present a technique to automatically generate search heuristics for dynamic symbolic execution. A key challenge in dynamic symbolic execution is how to effectively explore the program's execution paths to achieve high code coverage in a limited time budget. Dynamic symbolic execution employs a search heuristic to address this challenge, which favors exploring particular types of paths that are most likely to maximize the final coverage. However, manually designing a good search heuristic is nontrivial and typically ends up with suboptimal and unstable outcomes. The goal of this paper is to overcome this shortcoming of dynamic symbolic execution by automatically learning search heuristics. We define a class of search heuristics, namely a parametric search heuristic, and present an algorithm that efficiently finds an optimal heuristic for each subject program. Experimental results with industrial-strength symbolic execution tools (e.g., KLEE) show that our technique can successfully generate search heuristics that significantly outperform existing manually-crafted heuristics in terms of branch coverage and bug-finding.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2021.3101870",
      "Funding Information": "Samsung Research Funding & Incubation Center of Samsung Electronics(grant numbers:SRFC-IT1701-51); Institute of Information & Communications Technology Planning & Evaluation; Ministry of Science and ICT, South Korea(grant numbers:2020-0-01337); ICT Creative Consilience program(grant numbers:IITP-2021-2020-0-01819); Institute for Information & communications Technology Planning & Evaluation; National Research Foundation of Korea(grant numbers:NRF-2021R1C1C2006410); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9507083",
      "Author_Keywords": "Dynamic symbolic execution;concolic testing;execution-generated testing;search heuristics;software testing",
      "IEEE_Terms": "Testing;Heuristic algorithms;Tools;Software testing;Search problems;Open source software;Software algorithms",
      "Article Citation Count": "5",
      "Reference Count": "78",
      "License": "IEEE",
      "Online Date": "4-Aug-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "MaGnn: Binary-Source Code Matching by Modality-Sharing Graph Convolution for Binary Provenance Analysis",
      "Authors": "W. Ou; S. H. H. Ding",
      "Author Affiliations": "School of Computing, Queen‚Äôs University, Kingston, Canada; School of Computing, Queen‚Äôs University, Kingston, Canada",
      "Publication Title": "2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "2-Aug-23",
      "Publication Year": "2023",
      "Start Page": "658",
      "End Page": "666",
      "Abstract": "The number and variety of binaries running on electrical devices, public clouds, and on-premise infrastructure have been increasing rapidly. Recent successful supply chain attacks indicate that even for binaries known to be developed by trustful developers, they can still contain malicious functionalities and copy-and-pasted vulnerabilities that pose security risks to operational systems and end users. By analyzing the origin of a target code, code provenance analysis helps to relieve such problem by revealing information about the origin of a binary sample such as the author or the included software bill-of-materials. Since in most cases source symbol information is removed during the compilation process, given a binary code sample, matching it to its corresponding source code could improve the accuracy and efficiency of the provenance analysis. Existing binary-source code matching methods focus on comparing manually selected code literals (e.g. the number of if/else statements). However, these methods suffer from the issue of generalizability and require significant manual efforts.Different from the previous methods, we propose a machine learning-based binary-source code matching system, MaGnn, which measures the consistency of an input binary-source code pair by automatically extracting high-dimensional feature representations of the input and calculating the functionality similarity. With the Siamese architecture that shares a unified encoder across two modalities, McGnn is able to calculate the similarity of the input binary-source code pair with the automatically-extracted functionality representations. With the graph convolution neural network as the representation encoder, MaGnn is able to learn and encode the functionality information of the input pairs from their graph features into high-dimensional representation vectors. We benchmark MaGnn with a state-of-the-art binary-source code matching method and two machine-learning models on six out-of-sample datasets collected from five real-world libraries. Our experiment results show that MaGnn outperforms the baselines on most out-of-sample datasets.",
      "ISSN": "0730-3157",
      "ISBNs": "979-8-3503-2697-0",
      "DOI": "10.1109/COMPSAC57700.2023.00091",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10196875",
      "Author_Keywords": "binary provenance;representation learning;binary source code matching;graph learning",
      "IEEE_Terms": "Codes;Convolution;Source coding;Supply chains;Neural networks;Symbols;Manuals",
      "Reference Count": "30",
      "License": "IEEE",
      "Online Date": "2-Aug-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "ACWRecommender: A Tool for Validating Actionable Warnings with Weak Supervision",
      "Authors": "Z. Xue; Z. Gao; X. Hu; S. Li",
      "Author Affiliations": "Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China",
      "Publication Title": "2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "8-Nov-23",
      "Publication Year": "2023",
      "Start Page": "1876",
      "End Page": "1880",
      "Abstract": "Static analysis tools have gained popularity among developers for finding potential bugs, but their widespread adoption is hindered by the accomnpanying high false alarm rates (up to 90%). To address this challenge, previous studies proposed the concept of actionable warnings, and apply machine-learning methods to distinguish actionable warnings from false alarms. Despite these efforts, our preliminary study suggests that the current methods used to collect actionable warnings are rather shaky and unreliable, resulting in a large proportion of invalid actionable warnings. In this work, we mined 68,274 reversions from Top-500 Github C repositories to create a substantia actionable warning dataset and assigned weak labels to each warning's likelihood of being a real bug. To automatically identify actionable warnings and recommend those with a high probability of being real bugs (AWHB), we propose a two-stage framework called ACWRecommender. In the first stage, our tool use a pre-trained model, i.e., UniXcoder, to identify actionable warnings from a huge number of SA tool's reported warnings. In the second stage, we rerank valid actionable warnings to the top by using weakly supervised learning. Experimental results showed that our tool outperformed several baselines for actionable warning detection (in terms of F1-score) and performed better for AWHB recommendation (in terms of nDCG and MRR). Additionaly, we also performed an in-the-wild evaluation, we manually validated 24 warnings out of 2,197 reported warnings on 10 randomly selected projects, 22 of which were confirmed by developers as real bugs, demonstrating the practical usage of our tool.",
      "ISSN": "2643-1572",
      "ISBNs": "979-8-3503-2996-4",
      "DOI": "10.1109/ASE56229.2023.00169",
      "Funding Information": "Shanghai Rising-Star Program(grant numbers:23YF1446900); National Science Foundation of China(grant numbers:62202341); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298325",
      "Author_Keywords": "Actionable warning recommendation;Static analysis;Weak supervision;Data mining",
      "IEEE_Terms": "Computer bugs;Supervised learning;Semantics;Static analysis;Machine learning;Data mining;History",
      "Reference Count": "12",
      "License": "IEEE",
      "Online Date": "8-Nov-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Multi-Granularity Detector for Vulnerability Fixes",
      "Authors": "T. G. Nguyen; T. Le-Cong; H. J. Kang; R. Widyasari; C. Yang; Z. Zhao; B. Xu; J. Zhou; X. Xia; A. E. Hassan; X. -B. D. Le; D. Lo",
      "Author Affiliations": "School of Computing and Information Systems, Singapore Management University, Singapore; School of Computing and Information Systems, Singapore Management University, Singapore; School of Computing and Information Systems, Singapore Management University, Singapore; School of Computing and Information Systems, Singapore Management University, Singapore; School of Computing and Information Systems, Singapore Management University, Singapore; School of Computing and Information Systems, Singapore Management University, Singapore; School of Computing and Information Systems, Singapore Management University, Singapore; Software Engineering Application Technology Lab, Shenzhen, Guangdong, China; Software Engineering Application Technology Lab, Shenzhen, Guangdong, China; School of Computing, Queen's University, Kingston, ON, Canada; School of Computing and Information Systems, The University of Melbourne, Parkville, VIC, Australia; School of Computing and Information Systems, Singapore Management University, Singapore",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "14-Aug-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "8",
      "Start Page": "4035",
      "End Page": "4057",
      "Abstract": "With the increasing reliance on Open Source Software, users are exposed to third-party library vulnerabilities. Software Composition Analysis (SCA) tools have been created to alert users of such vulnerabilities. SCA requires the identification of vulnerability-fixing commits. Prior works have proposed methods that can automatically identify such vulnerability-fixing commits. However, identifying such commits is highly challenging, as only a very small minority of commits are vulnerability fixing. Moreover, code changes can be noisy and difficult to analyze. We observe that noise can occur at different levels of detail, making it challenging to detect vulnerability fixes accurately. To address these challenges and boost the effectiveness of prior works, we propose MiDas (Multi-Granularity Detector for Vulnerability Fixes). Unique from prior works, MiDas constructs different neural networks for each level of code change granularity, corresponding to commit-level, file-level, hunk-level, and line-level, following their natural organization and then use an ensemble model combining all base models to output the final prediction. This design allows MiDas to better cope with the noisy and highly-imbalanced nature of vulnerability-fixing commit data. In addition, to reduce the human effort required to inspect code changes, we have designed an effort-aware adjustment for MiDas's outputs based on commit length. The evaluation result demonstrates that MiDas outperforms the current state-of-the-art baseline on both Java and Python-based datasets in terms of AUC by 4.9% and 13.7%, respectively. Furthermore, in terms of two effort-aware metrics, i.e., EffortCost@L and Popt@L, MiDas also performs better than the state-of-the-art baseline up to 28.2% and 15.9% on Java, 60% and 51.4% on Python, respectively.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2023.3281275",
      "Funding Information": "National Research Foundation, Singapore; National University of Singapore; National Satellite of Excellence in Trustworthy Software Systems (NSOE-TSS) office; Trustworthy Computing for Secure Smart Nation Grant(grant numbers:NSOE-TSS2020-02); Australian Research Council's Discovery Early Career Researcher Award(grant numbers:DE220101057); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10138621",
      "Author_Keywords": "Vulnerability-fixing commit classification;machine learning;deep learning;software security",
      "IEEE_Terms": "Codes;Task analysis;Security;Java;Libraries;Testing;Predictive models",
      "Article Citation Count": "1",
      "Reference Count": "106",
      "License": "IEEE",
      "Online Date": "30-May-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "An Empirical Study of Classifier Combination for Cross-Project Defect Prediction",
      "Authors": "Y. Zhang; D. Lo; X. Xia; J. Sun",
      "Author Affiliations": "College of Computer Science and Technology, Zhejiang University, Hangzhou, China; School of Information Systems, Singapore Management University, Singapore; School of Information Systems, Singapore Management University, Singapore; College of Computer Science and Technology, Zhejiang University, Hangzhou, China",
      "Publication Title": "2015 IEEE 39th Annual Computer Software and Applications Conference",
      "Date Added To Xplore": "24-Sep-15",
      "Publication Year": "2015",
      "Volume": "2",
      "Start Page": "264",
      "End Page": "269",
      "Abstract": "To help developers better allocate testing and debugging efforts, many software defect prediction techniques have been proposed in the literature. These techniques can be used to predict classes that are more likely to be buggy based on past history of buggy classes. These techniques work well as long as a sufficient amount of data is available to train a prediction model. However, there is rarely enough training data for new software projects. To deal with this problem, cross-project defect prediction, which transfers a prediction model trained using data from one project to another, has been proposed and is regarded as a new challenge for defect prediction. So far, only a few cross-project defect prediction techniques have been proposed. To advance the state-of-the-art, in this work, we investigate 7 composite algorithms, which integrate multiple machine learning classifiers, to improve cross-project defect prediction. To evaluate the performance of the composite algorithms, we perform experiments on 10 open source software systems from the PROMISE repository which contain a total of 5,305 instances labeled as defective or clean. We compare the composite algorithms with CODEP Logistic, which is the latest cross-project defect prediction algorithm proposed by Panichella et al., in terms of two standard evaluation metrics: cost effectiveness and F-measure. Our experiment results show that several algorithms outperform CODEP Logistic: Max performs the best in terms of F-measure and its average F-measure outperforms that of CODEP Logistic by 36.88%. Bagging J48 performs the best in terms of cost effectiveness and its average cost effectiveness outperforms that of CODEP Logistic by 15.34%.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-4673-6564-2",
      "DOI": "10.1109/COMPSAC.2015.58",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273627",
      "Author_Keywords": "Defect Prediction;Cross-Project;Classifier Combination",
      "IEEE_Terms": "Prediction algorithms;Predictive models;Software;Machine learning algorithms;Training;Decision trees;Measurement",
      "Article Citation Count": "66",
      "Reference Count": "30",
      "License": "IEEE",
      "Online Date": "24-Sep-15",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A novel software defect prediction method based on hierarchical neural network",
      "Authors": "H. Yu; X. Sun; Z. Zhou; G. Fan",
      "Author Affiliations": "Shanghai Key Laboratory of Computer Software Evaluating and Testing, East China University of Science and Technology, Shanghai, China; Department of Computer Science and Engineering, East China University of Science and Technology, Shanghai, China; Department of Computer Science and Engineering, East China University of Science and Technology, Shanghai, China; Shanghai Key Laboratory of Computer Software Evaluating and Testing, East China University of Science and Technology, Shanghai, China",
      "Publication Title": "2021 IEEE 45th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "9-Sep-21",
      "Publication Year": "2021",
      "Start Page": "366",
      "End Page": "375",
      "Abstract": "To ensure software reliability, software defect prediction (SDP) techniques are employed to help developers effectively allocate the testing resources. Recently, researchers utilized deep learning models to extract semantic features from abstract syntax tree (AST) of source code which showed a better prediction performance over metric-based methods. However, the existing file-level SDP models representing the AST as a flattened sequence could jeopardize the preservation of long-term dependency. In this paper, we propose a new Defect Prediction framework based on the Hierarchical Neural Network (DP-HNN). Our method makes use of the hierarchical structure of AST by splitting the large file-level AST into several subtrees according to certain AST nodes crucial to SDP task. These subtrees represented by node-level sequences are encoded separately and then serve as the elements of the subtree-level sequence. Finally, a multi-granularity fusion approach is performed in the subtree-level encoder to obtain the crucial features that represent the code file. Our proposed DP-HNN is aimed at capturing long-term dependency while preserving fine-grained local information. We conducted experiments on 11 open-source projects considering the cross-version and the mixed-version scenario of within-project SDP. Results show that on average, DP-HNN improves the state-of-the-art method by 14% and 3% on MCC and AUC scores respectively.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-6654-2463-9",
      "DOI": "10.1109/COMPSAC51774.2021.00059",
      "Funding Information": "National Natural Science Foundation of China; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9529567",
      "Author_Keywords": "software defect prediction;abstract syntax tree;hierarchical neural network",
      "IEEE_Terms": "Codes;Neural networks;Semantics;Syntactics;Predictive models;Feature extraction;Software reliability",
      "Article Citation Count": "2",
      "Reference Count": "43",
      "License": "IEEE",
      "Online Date": "9-Sep-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "SoftMon: A Tool to Compare Similar Open-source Software from a Performance Perspective",
      "Authors": "S. S. Singh; S. R. Sarangi",
      "Author Affiliations": "Computer Science and Engineering, IIT Delhi; Computer Science, IIT Delhi",
      "Publication Title": "2020 IEEE/ACM 17th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "20-Jun-23",
      "Publication Year": "2020",
      "Start Page": "397",
      "End Page": "408",
      "Abstract": "Over the past two decades, a rich ecosystem of open-source software has evolved. For every type of application, there are a wide variety of alternatives. We observed that even if different applications that perform similar tasks and compiled with the same versions of the compiler and the libraries, they perform very differently while running on the same system. Sadly prior work in this area that compares two code bases for similarities does not help us in finding the reasons for the differences in performance. In this paper, we develop a tool, SoftMon, that can compare the codebases of two separate applications and pinpoint the exact set of functions that are disproportionately responsible for differences in performance. Our tool uses machine learning and NLP techniques to analyze why a given open-source application has a lower performance as compared to its peers, design bespoke applications that can incorporate specific innovations (identified by SoftMon) in competing applications, and diagnose performance bugs. In this paper, we compare a wide variety of large open-source programs such as image editors, audio players, text editors, PDF readers, mail clients and even full-fledged operating systems (OSs). In all cases, our tool was able to pinpoint a set of at the most 10‚Äì15 functions that are responsible for the differences within 200 seconds. A subsequent manual analysis assisted by our graph visualization engine helps us find the reasons. We were able to validate most of the reasons by correlating them with subsequent observations made by developers or from existing technical literature. The manual phase of our analysis is limited to 30 minutes (tested with human subjects).",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-4503-7517-7",
      "DOI": "10.1145/3379597.3387444",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10148752",
      "Author_Keywords": "Software comparison;Performance debugging;NLP based matching",
      "IEEE_Terms": "Visualization;Technological innovation;Codes;Operating systems;Manuals;Machine learning;Libraries",
      "Reference Count": "83",
      "Online Date": "20-Jun-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Capturing Contextual Relationships of Buggy Classes for Detecting Quality-Related Bugs",
      "Authors": "R. Krasniqi; H. Do",
      "Author Affiliations": "Dept. of Computer Science and Eng., University of North Texas, Denton, TX, USA; Dept. of Computer Science and Eng., University of North Texas, Denton, TX, USA",
      "Publication Title": "2023 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "11-Dec-23",
      "Publication Year": "2023",
      "Start Page": "375",
      "End Page": "379",
      "Abstract": "Quality concerns are critical for addressing system-wide issues related to reliability, security, and performance, among others. However, these concerns often become scattered across the codebase, making it challenging for software developers to effectively address quality bugs. In this paper, we propose a holistic approach to detecting and clustering quality-related content hidden within the codebase. By leveraging the Hierarchical Dirichlet Process (HDP) and complementary techniques such as information retrieval and machine learning, including structural and textual analysis, we create a meaningful hierarchy that detects classes containing relevant information for addressing quality bugs. This approach allows us to uncover rich synergies between complex structured artifacts and infer bug-fixing classes for repairing quality bugs. The reported results show that our approach improves over the state-of-the-art achieving a high precision of 83%, recall of 82%, and F1 score of 83%.",
      "ISSN": "2576-3148",
      "ISBNs": "979-8-3503-2783-0",
      "DOI": "10.1109/ICSME58846.2023.00048",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10336297",
      "Author_Keywords": "Quality Bugs;Hierarchical Topic Modeling;Vector Space Model;Contextual Relationships",
      "IEEE_Terms": "Software maintenance;Computer bugs;Machine learning;Information retrieval;Software reliability;Security;Context modeling",
      "Reference Count": "34",
      "License": "IEEE",
      "Online Date": "11-Dec-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "An Empirical Investigation on the Performance of Domain Adaptation for T5 Code Completion",
      "Authors": "D. Fukumoto; Y. Kashiwa; T. Hirao; K. Fujiwara; H. Iida",
      "Author Affiliations": "Nara Institute of Science and Technology, Japan; Nara Institute of Science and Technology, Japan; Nara Institute of Science and Technology, Japan; Tokyo City University, Japan; Nara Institute of Science and Technology, Japan",
      "Publication Title": "2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "15-May-23",
      "Publication Year": "2023",
      "Start Page": "693",
      "End Page": "697",
      "Abstract": "Code completion has the benefit of improving coding speed and reducing the chance of inducing bugs. In recent years, DL-based code completion techniques have been proposed. In particular, pre-trained models have shown outstanding performance because they can complete code by considering the context before and after it is completed. While the model can generate the set of candidate codes, some of those might need to be modified by developers because projects can have different coding rules.In this study, to complete code that fits a specific project appropriately, we train the CodeT5 model with additional data from the target project. This fine-tuning approach is called do-main adaptation, and is often used in neural machine translation. Our preliminary experiment observes that our domain-adapted model improves 5.3% of the perfect prediction rate and, 3.4% of the edit distance rate, compared to the fine-tuned model with the out-of-domain dataset. Furthermore, we discover that the improvement is greater with a larger repository size. The model that is trained with a small dataset, however, hardly improves or performs worse.",
      "ISSN": "2640-7574",
      "ISBNs": "978-1-6654-5278-6",
      "DOI": "10.1109/SANER56733.2023.00073",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10123593",
      "Author_Keywords": "code completion;CodeT5;domain adaptation;fine-tuning;transfer-learning",
      "IEEE_Terms": "Adaptation models;Codes;Computer bugs;Predictive models;Encoding;Data models;Software",
      "Article Citation Count": "2",
      "Reference Count": "22",
      "License": "IEEE",
      "Online Date": "15-May-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "The Python/C API: Evolution, Usage Statistics, and Bug Patterns",
      "Authors": "M. Hu; Y. Zhang",
      "Author Affiliations": "Lab for Intelligent Networking and Knowledge Engineering (LINKE), University of Science and Technology of China, Hefei, China; Lab for Intelligent Networking and Knowledge Engineering (LINKE), University of Science and Technology of China, Hefei, China",
      "Publication Title": "2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "2-Apr-20",
      "Publication Year": "2020",
      "Start Page": "532",
      "End Page": "536",
      "Abstract": "Python has become one of the most popular programming languages in the era of data science and machine learning, especially for its diverse libraries and extension modules. Python front-end with C/C++ native implementation achieves both productivity and performance, almost becoming the standard structure for many mainstream software systems. However, feature discrepancies between two languages can pose many security hazards in the interface layer using the Python/C API. In this paper, we applied static analysis to reveal the evolution and usage statistics of the Python/C API, and provided a summary and classification of its 10 bug patterns with empirical bug instances from Pillow, a widely used Python imaging library. Our toolchain can be easily extended to access different types of syntactic bug-finding checkers. And our systematical taxonomy to classify bugs can guide the construction of more highly automated and high-precision bug-finding tools.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-7281-5143-4",
      "DOI": "10.1109/SANER48275.2020.9054835",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054835",
      "Author_Keywords": "Python/C API;Static analysis;Evolution analysis;Fact extraction;Bug pattern",
      "IEEE_Terms": "Productivity;Computer bugs;Taxonomy;Static analysis;Syntactics;Software systems;Libraries",
      "Article Citation Count": "10",
      "Reference Count": "23",
      "License": "IEEE",
      "Online Date": "2-Apr-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Software Engineering for Data Analytics",
      "Authors": "M. Kim",
      "Author Affiliations": "University of California, Los Angeles",
      "Publication Title": "IEEE Software",
      "Date Added To Xplore": "19-Jun-20",
      "Publication Year": "2020",
      "Volume": "37",
      "Issue": "4",
      "Start Page": "36",
      "End Page": "42",
      "Abstract": "We are at an inflection point where software engineering meets the data-centric world of big data, machine learning, and artificial intelligence. In this article, I summarize findings from studies of professional data scientists and discuss my perspectives on open research problems to improve data-centric software development.",
      "ISSN": "1937-4194",
      "DOI": "10.1109/MS.2020.2985775",
      "Funding Information": "National Science Foundation(grant numbers:1764077); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9056482",
      "IEEE_Terms": "Big Data;Software engineering;Data analysis;Debugging;Artificial intelligence;Software engineering;Software testing",
      "Article Citation Count": "5",
      "Reference Count": "14",
      "License": "IEEE",
      "Online Date": "3-Apr-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Magazines"
    },
    {
      "Document Title": "Template-Guided Concolic Testing via Online Learning",
      "Authors": "S. Cha; S. Lee; H. Oh",
      "Author Affiliations": "Korea University, Republic of Korea; Korea University, Republic of Korea; Korea University, Republic of Korea",
      "Publication Title": "2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "17-Feb-20",
      "Publication Year": "2018",
      "Start Page": "408",
      "End Page": "418",
      "Abstract": "We present template-guided concolic testing, a new technique for effectively reducing the search space in concolic testing. Addressing the path-explosion problem has been a significant challenge in concolic testing. Diverse search heuristics have been proposed to mitigate this problem but using search heuristics alone is not sufficient to substantially improve code coverage for real-world programs. The goal of this paper is to complement existing techniques and achieve higher coverage by exploiting templates in concolic testing. In our approach, a template is a partially symbolized input vector whose job is to reduce the search space. However, choosing a right set of templates is nontrivial and significantly affects the final performance of our approach. We present an algorithm that automatically learns useful templates online, based on data collected from previous runs of concolic testing. The experimental results with open-source programs show that our technique achieves greater branch coverage and finds bugs more effectively than conventional concolic testing.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-4503-5937-5",
      "DOI": "10.1145/3238147.3238227",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8999998",
      "Author_Keywords": "Concolic Testing;Online Learning",
      "Article Citation Count": "5",
      "Reference Count": "31",
      "Online Date": "17-Feb-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "HVLearn: Automated Black-Box Analysis of Hostname Verification in SSL/TLS Implementations",
      "Authors": "S. Sivakorn; G. Argyros; K. Pei; A. D. Keromytis; S. Jana",
      "Author Affiliations": "Department of Computer Science, Columbia University, New York, USA; Department of Computer Science, Columbia University, New York, USA; Department of Computer Science, Columbia University, New York, USA; Department of Computer Science, Columbia University, New York, USA; Department of Computer Science, Columbia University, New York, USA",
      "Publication Title": "2017 IEEE Symposium on Security and Privacy (SP)",
      "Date Added To Xplore": "26-Jun-17",
      "Publication Year": "2017",
      "Start Page": "521",
      "End Page": "538",
      "Abstract": "SSL/TLS is the most commonly deployed family of protocols for securing network communications. The security guarantees of SSL/TLS are critically dependent on the correct validation of the X.509 server certificates presented during the handshake stage of the SSL/TLS protocol. Hostname verification is a critical component of the certificate validation process that verifies the remote server's identity by checking if the hostname of the server matches any of the names present in the X.509 certificate. Hostname verification is a highly complex process due to the presence of numerous features and corner cases such as wildcards, IP addresses, international domain names, and so forth. Therefore, testing hostname verification implementations present a challenging task. In this paper, we present HVLearn, a novel black-box testing framework for analyzing SSL/TLS hostname verification implementations, which is based on automata learning algorithms. HVLearn utilizes a number of certificate templates, i.e., certificates with a common name (CN) set to a specific pattern, in order to test different rules from the corresponding specification. For each certificate template, HVLearn uses automata learning algorithms to infer a Deterministic Finite Automaton (DFA) that describes the set of all hostnames that match the CN of a given certificate. Once a model is inferred for a certificate template, HVLearn checks the model for bugs by finding discrepancies with the inferred models from other implementations or by checking against regular-expression-based rules derived from the specification. The key insight behind our approach is that the acceptable hostnames for a given certificate template form a regular language. Therefore, we can leverage automata learning techniques to efficiently infer DFA models that accept the corresponding regular language. We use HVLearn to analyze the hostname verification implementations in a number of popular SSL/TLS libraries and applications written in a diverse set of languages like C, Python, and Java. We demonstrate that HVLearn can achieve on average 11.21% higher code coverage than existing black/gray-box fuzzing techniques. By comparing the DFA models inferred by HVLearn, we found 8 unique violations of the RFC specifications in the tested hostname verification implementations. Several of these violations are critical and can render the affected implementations vulnerable to active man-in-the-middle attacks.",
      "ISSN": "2375-1207",
      "ISBNs": "978-1-5090-5533-3",
      "DOI": "10.1109/SP.2017.46",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7958596",
      "IEEE_Terms": "Testing;Servers;IP networks;Learning automata;Security;Protocols;Electronic mail",
      "Article Citation Count": "41",
      "Reference Count": "61",
      "License": "IEEE",
      "Online Date": "26-Jun-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Weakness in Depth: A Voting Machine's Demise",
      "Authors": "J. Epstein",
      "Author Affiliations": "SRI International",
      "Publication Title": "IEEE Security & Privacy",
      "Date Added To Xplore": "4-Jun-15",
      "Publication Year": "2015",
      "Volume": "13",
      "Issue": "3",
      "Start Page": "55",
      "End Page": "58",
      "Abstract": "Every voting system examined over the past decade has had severe security vulnerabilities. Virginia's government recently examined the AVS WinVote and learned that the vulnerabilities are more serious than any other voting system, allowing complete exploitation over a Wi-Fi network. The combination of vulnerabilities exhibits \"weakness in depth,\" rather than the \"defense in depth\" frequently suggested as a model. The lessons learned are applicable to other emerging technologies, including the Internet of Things.",
      "ISSN": "1558-4046",
      "DOI": "10.1109/MSP.2015.46",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7118082",
      "Author_Keywords": "voting;elections;software assurance;Wi-Fi;passwords;security",
      "IEEE_Terms": "Computer networks;Software development;Voting;IEEE 802.11 Standards;Electronic voting",
      "Article Citation Count": "9",
      "Reference Count": "13",
      "License": "IEEE",
      "Online Date": "4-Jun-15",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Magazines"
    },
    {
      "Document Title": "MuDelta: Delta-Oriented Mutation Testing at Commit Time",
      "Authors": "W. Ma; T. Titcheu Chekam; M. Papadakis; M. Harman",
      "Author Affiliations": "SnT, University of Luxembourg, Luxembourg; SnT, University of Luxembourg, Esch-sur-Alzette, Luxembourg; SnT, University of Luxembourg, Luxembourg; Facebook and University College London, UK",
      "Publication Title": "2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "7-May-21",
      "Publication Year": "2021",
      "Start Page": "897",
      "End Page": "909",
      "Abstract": "To effectively test program changes using mutation testing, one needs to use mutants that are relevant to the altered program behaviours. In view of this, we introduce MuDelta, an approach that identifies commit-relevant mutants; mutants that affect and are affected by the changed program behaviours. Our approach uses machine learning applied on a combined scheme of graph and vector-based representations of static code features. Our results, from 50 commits in 21 Coreutils programs, demonstrate a strong prediction ability of our approach; yielding 0.80 (ROC) and 0.50 (PR Curve) AUC values with 0.63 and 0.32 precision and recall values. These predictions are significantly higher than random guesses, 0.20 (PR-Curve) AUC, 0.21 and 0.21 precision and recall, and subsequently lead to strong relevant tests that kill 45%more relevant mutants than randomly sampled mutants (either sampled from those residing on the changed component(s) or from the changed lines). Our results also show that MuDelta selects mutants with 27% higher fault revealing ability in fault introducing commits. Taken together, our results corroborate the conclusion that commit-based mutation testing is suitable and promising for evolving software.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-0296-5",
      "DOI": "10.1109/ICSE43902.2021.00086",
      "Funding Information": "European Research Council; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9402071",
      "Author_Keywords": "mutation testing;commit-relevant mutants;continuous integration;regression testing;machine learning",
      "IEEE_Terms": "Machine learning;Software;Testing;Software engineering",
      "Article Citation Count": "7",
      "Reference Count": "66",
      "License": "IEEE",
      "Online Date": "7-May-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Graph-based Incident Aggregation for Large-Scale Online Service Systems",
      "Authors": "Z. Chen; J. Liu; Y. Su; H. Zhang; X. Wen; X. Ling; Y. Yang; M. R. Lyu",
      "Author Affiliations": "The Chinese University of Hong Kong, Hong Kong, China; The Chinese University of Hong Kong, Hong Kong, China; The Chinese University of Hong Kong, Hong Kong, China; The University of Newcastle, NSW, Australia; Huawei, China; Huawei, China; Huawei, China; The Chinese University of Hong Kong, Hong Kong, China",
      "Publication Title": "2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "20-Jan-22",
      "Publication Year": "2021",
      "Start Page": "430",
      "End Page": "442",
      "Abstract": "As online service systems continue to grow in terms of complexity and volume, how service incidents are managed will significantly impact company revenue and user trust. Due to the cascading effect, cloud failures often come with an overwhelming number of incidents from dependent services and devices. To pursue efficient incident management, related incidents should be quickly aggregated to narrow down the problem scope. To this end, in this paper, we propose GRLIA, an incident aggregation framework based on graph representation learning over the cascading graph of cloud failures. A representation vector is learned for each unique type of incident in an unsupervised and unified manner, which is able to simultaneously encode the topological and temporal correlations among incidents. Thus, it can be easily employed for online incident aggregation. In particular, to learn the correlations more accurately, we try to recover the complete scope of failures‚Äô cascading impact by leveraging fine-grained system monitoring data, i.e., Key Performance Indicators (KPIs). The proposed framework is evaluated with real-world incident data collected from a large-scale online service system of Huawei Cloud. The experimental results demonstrate that GRLIA is effective and outperforms existing methods. Furthermore, our framework has been successfully deployed in industrial practice.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-6654-0337-5",
      "DOI": "10.1109/ASE51524.2021.9678746",
      "Funding Information": "Research and Development; Australian Research Council; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9678746",
      "Author_Keywords": "Cloud computing;online service systems;incident management;graph representation learning",
      "IEEE_Terms": "Representation learning;Correlation;Power system protection;Key performance indicator;Companies;Complexity theory;Power system faults",
      "Article Citation Count": "5",
      "Reference Count": "46",
      "License": "IEEE",
      "Online Date": "20-Jan-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Classifying Software Changes: Clean or Buggy?",
      "Authors": "S. Kim; E. J. Whitehead,; Y. Zhang",
      "Author Affiliations": "Massachusetts Institute of Technology, Cambridge, MA, USA; NA; University of California, Santa Cruz, CA, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "31-Mar-08",
      "Publication Year": "2008",
      "Volume": "34",
      "Issue": "2",
      "Start Page": "181",
      "End Page": "196",
      "Abstract": "This paper introduces a new technique for finding latent software bugs called change classification. Change classification uses a machine learning classifier to determine whether a new software change is more similar to prior buggy changes, or clean changes. In this manner, change classification predicts the existence of bugs in software changes. The classifier is trained using features (in the machine learning sense) extracted from the revision history of a software project, as stored in its software configuration management repository. The trained classifier can classify changes as buggy or clean with 78% accuracy and 65% buggy change recall (on average). Change classification has several desirable qualities: (1) the prediction granularity is small (a change to a single file), (2) predictions do not require semantic information about the source code, (3) the technique works for a broad array of project types and programming languages, and (4) predictions can be made immediately upon completion of a change. Contributions of the paper include a description of the change classification approach, techniques for extracting features from source code and change histories, a characterization of the performance of change classification across 12 open source projects, and evaluation of the predictive power of different groups of features.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2007.70773",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4408585",
      "Author_Keywords": "Software maintenance;Metrics/Measurement;Clustering;classification;and association rules;Configuration Management;Data mining;Software maintenance;Metrics/Measurement;Clustering;classification;and association rules;Configuration Management;Data mining",
      "IEEE_Terms": "Computer bugs;Machine learning;Open source software;Classification algorithms;History;Data mining;Feature extraction;Software debugging;Project management;Computer languages",
      "Article Citation Count": "445",
      "Patent Citation Count": "9",
      "Reference Count": "56",
      "License": "IEEE",
      "Online Date": "31-Mar-08",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Mithra: Anomaly Detection as an Oracle for Cyberphysical Systems",
      "Authors": "A. Afzal; C. Le Goues; C. S. Timperley",
      "Author Affiliations": "School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "11-Nov-22",
      "Publication Year": "2022",
      "Volume": "48",
      "Issue": "11",
      "Start Page": "4535",
      "End Page": "4552",
      "Abstract": "Testing plays an essential role in ensuring the safety and quality of cyberphysical systems (CPSs). One of the main challenges in automated and software-in-the-loop simulation testing of CPSs is defining effective oracles that can check that a given system conforms to expectations of desired behavior. Manually specifying such oracles can be tedious, complex, and error-prone, and so techniques for automatically learning oracles are attractive. Characteristics of CPSs, such as limited or no access to source code, behavior that is non-deterministic and sensitive to noise, and that the system may respond differently to input based on its context introduce considerable challenges for automated oracle learning. We present Mithra, a novel, unsupervised oracle learning technique for CPSs that operates on existing telemetry data. It uses a three-step multivariate time series clustering to discover the set of unique, correct behaviors for a CPS, which it uses to construct robust oracles. We instantiate our proposed technique for ArduPilot, a popular, open-source autopilot software. On a set of 24 bugs, we show that Mithra effectively identifies buggy executions with few false positives and outperforms AR-SI, a state-of-the-art CPS oracle learning technique. We demonstrate Mithra‚Äôs wider applicability by applying it to an autonomous racer built for the Robot Operating System.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2021.3120680",
      "Funding Information": "Air Force Research Laboratory(grant numbers:#FA8750- 15-2-0075); Defense Advanced Research Projects Agency(grant numbers:#FA8750-16-2-0042,NSF-1563797); Air Force Research Laboratory(grant numbers:19-PAF00747); National Science Foundation(grant numbers:#CCF-1750116); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9576615",
      "Author_Keywords": "Robotics and autonomous systems;cyberphysical systems testing;anomaly detection;oracle learning;clustering;Mithra",
      "IEEE_Terms": "Computer bugs;Codes;Testing;Telemetry;Splines (mathematics);Sensors;Sensor systems",
      "Article Citation Count": "5",
      "Reference Count": "120",
      "License": "IEEE",
      "Online Date": "15-Oct-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "VoltageIDS: Low-Level Communication Characteristics for Automotive Intrusion Detection System",
      "Authors": "W. Choi; K. Joo; H. J. Jo; M. C. Park; D. H. Lee",
      "Author Affiliations": "Graduate School of Information Security, Korea University, Seoul, South Korea; Graduate School of Information Security, Korea University, Seoul, South Korea; Department of Computer and Information System, University of Pennsylvania, Philadelphia, PA, USA; Graduate School of Information Security, Korea University, Seoul, South Korea; Graduate School of Information Security, Korea University, Seoul, South Korea",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "16-Apr-18",
      "Publication Year": "2018",
      "Volume": "13",
      "Issue": "8",
      "Start Page": "2114",
      "End Page": "2129",
      "Abstract": "The proliferation of computerized functions aimed at enhancing drivers' safety and convenience has increased the number of vehicular attack surfaces accordingly. The fundamental vulnerability is caused by the fact that the controller area network protocol, a de facto standard for in-vehicle networks, does not support message origin authentication. Several methods to resolve this problem have been suggested. However, most of them require modification of the CAN protocol and have their own vulnerabilities. In this paper, we focus on securing in-vehicle CAN networks, proposing a novel automotive intrusion detection system (so-called VoltageIDS). The system leverages the inimitable characteristics of an electrical CAN signal as a fingerprint of the electronic control units. The noteworthy contributions are that VoltageIDS does not require any modification of the current system and has been validated on actual vehicles while driving on the road. VoltageIDS is also the first automotive intrusion detection system capable of distinguishing between errors and the bus-off attack. Our experimental results on a CAN bus prototype and on real vehicles show that VoltageIDS detects intrusions in the in-vehicle CAN network. Moreover, we evaluate VoltageIDS while a vehicle is moving.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2018.2812149",
      "Funding Information": "Samsung Research Funding and the Incubation Center for Future Technology(grant numbers:SRFC-TB1403-51); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8306904",
      "Author_Keywords": "Controller area network;electronic control unit;automotive IDS;fingerprinting",
      "IEEE_Terms": "Automotive engineering;Protocols;Intrusion detection;Clocks;Message authentication;Electric variables;Telematics",
      "Article Citation Count": "178",
      "Reference Count": "59",
      "License": "IEEE",
      "Online Date": "5-Mar-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Auditing Buffer Overflow Vulnerabilities Using Hybrid Static-Dynamic Analysis",
      "Authors": "B. M. Padmanabhuni; H. B. Kuan Tan",
      "Author Affiliations": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Sch. of Electr. & Electron. Eng., Nanyang Technological University, Singapore, Singapore, SG",
      "Publication Title": "2014 IEEE 38th Annual Computer Software and Applications Conference",
      "Date Added To Xplore": "22-Sep-14",
      "Publication Year": "2014",
      "Start Page": "394",
      "End Page": "399",
      "Abstract": "Despite being studied for more than two decades buffer overflow vulnerabilities are still frequently reported in programs. In this paper, we propose a hybrid approach that combines static and dynamic program analysis to audit buffer overflows. Using simple rules, test data are generated to automatically confirm some of the vulnerabilities through dynamic analysis and the remaining cases are predicted by mining static code attributes. Confirmed cases can be directly fixed without further verification whereas predicted cases need to be manually reviewed to confirm existence of vulnerabilities. Since our approach combines the strengths of static and dynamic analyses, it results in an overall accuracy improvement. In our evaluation of approach using the standard benchmark suite, our classifiers achieved a recall over 92% and precision greater than 81%. The dynamic analysis component confirmed 51% of known vulnerabilities along with reporting 2 new bugs, thereby reducing by half, otherwise needed manual auditing effort.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-4799-3575-8",
      "DOI": "10.1109/COMPSAC.2014.62",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6899241",
      "Author_Keywords": "Vulnerability;auditing;buffer overflow;data mining;static code attributes;input validation;static and dynamic analysis",
      "IEEE_Terms": "Buffer overflows;Data mining;Arrays;Input variables;Accuracy;Benchmark testing;Predictive models",
      "Article Citation Count": "3",
      "Reference Count": "8",
      "License": "IEEE",
      "Online Date": "22-Sep-14",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "DualSC: Automatic Generation and Summarization of Shellcode via Transformer and Dual Learning",
      "Authors": "G. Yang; X. Chen; Y. Zhou; C. Yu",
      "Author Affiliations": "School of Information Science and Technology, Nantong University, China; School of Information Science and Technology, Nantong University, China; School of Information Science and Technology, Nantong University, China; School of Information Science and Technology, Nantong University, China",
      "Publication Title": "2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "21-Jul-22",
      "Publication Year": "2022",
      "Start Page": "361",
      "End Page": "372",
      "Abstract": "A shellcode is a small piece of code and it is executed to exploit a software vulnerability, which allows the target computer to execute arbitrary commands from the attacker through a code injection attack. Similar to the purpose of automated vulnerability generation techniques, the automated generation of shellcode can generate attack instructions, which can be used to detect vulnerabilities and implement defensive measures. While the automated summarization of shellcode can help users unfamiliar with shellcode and network information security understand the intent of shellcode attacks. In this study, we propose a novel approach DualSC to solve the automatic shellcode generation and summarization tasks. Specifically, we formalize automatic shellcode generation and summarization as dual tasks, use a shallow Transformer for model construction, and design a normalization method Adjust_QKNorm to adapt these low-resource tasks (i.e., insufficient training data). Finally, to alleviate the out-of-vocabulary problem, we propose a rule-based repair component to improve the performance of automatic shellcode generation. In our empirical study, we select a high-quality corpus Shellcode_IA32 as our empirical subject. This corpus was gathered from two real-world projects based on the line-by-line granularity. We first compare DualSC with six state-of-the-art baselines from the code generation and code summarization domains in terms of four performance measures. The comparison results show the competitiveness of DualSC. Then, we verify the effectiveness of the component setting in DualSC. Finally, we conduct a human study to further verify the effectiveness of DualSC.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-6654-3786-8",
      "DOI": "10.1109/SANER53432.2022.00052",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:61872263); Chinese Academy of Sciences(grant numbers:2020-MS-07); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9825869",
      "Author_Keywords": "Program comprehension;Shellcode generation;Shellcode summarization;Shallow Transformer;Dual learning",
      "IEEE_Terms": "Codes;Design methodology;Conferences;Training data;Information security;Maintenance engineering;Transformers",
      "Article Citation Count": "12",
      "Reference Count": "75",
      "License": "IEEE",
      "Online Date": "21-Jul-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "How to ‚ÄúDODGE‚Äù Complex Software Analytics",
      "Authors": "A. Agrawal; W. Fu; D. Chen; X. Shen; T. Menzies",
      "Author Affiliations": "Wayfair, Boston, MA, USA; Landing.AI, Palo Alto, CA, USA; Facebook, Menlo Park, California, USA; North Carolina State University, Raleigh, NC, USA; North Carolina State University, Raleigh, NC, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "14-Oct-21",
      "Publication Year": "2021",
      "Volume": "47",
      "Issue": "10",
      "Start Page": "2182",
      "End Page": "2194",
      "Abstract": "Machine learning techniques applied to software engineering tasks can be improved by hyperparameter optimization, i.e., automatic tools that find good settings for a learner's control parameters. We show that such hyperparameter optimization can be unnecessarily slow, particularly when the optimizers waste time exploring ‚Äúredundant tunings‚Äù, i.e., pairs of tunings which lead to indistinguishable results. By ignoring redundant tunings, DODGE($\\mathcal {E})$E), a tuning tool, runs orders of magnitude faster, while also generating learners with more accurate predictions than seen in prior state-of-the-art approaches.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2019.2945020",
      "Funding Information": "National Science Foundation(grant numbers:#1703487); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854183",
      "Author_Keywords": "Software analytics;hyperparameter optimization;defect prediction;text mining",
      "IEEE_Terms": "Tuning;Text mining;Software;Task analysis;Optimization;Software engineering;Tools",
      "Article Citation Count": "26",
      "Reference Count": "70",
      "License": "IEEE",
      "Online Date": "1-Oct-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "ConPredictor: Concurrency Defect Prediction in Real-World Applications",
      "Authors": "T. Yu; W. Wen; X. Han; J. H. Hayes",
      "Author Affiliations": "Department of Computer Science, University of Kentucky, Lexington, KY; Department of Computer Science, University of Kentucky, Lexington, KY; Department of Computer Science, University of Kentucky, Lexington, KY; Department of Computer Science, University of Kentucky, Lexington, KY",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "12-Jun-19",
      "Publication Year": "2019",
      "Volume": "45",
      "Issue": "6",
      "Start Page": "558",
      "End Page": "575",
      "Abstract": "Concurrent programs are difficult to test due to their inherent non-determinism. To address this problem, testing often requires the exploration of thread schedules of a program; this can be time-consuming when applied to real-world programs. Software defect prediction has been used to help developers find faults and prioritize their testing efforts. Prior studies have used machine learning to build such predicting models based on designed features that encode the characteristics of programs. However, research has focused on sequential programs; to date, no work has considered defect prediction for concurrent programs, with program characteristics distinguished from sequential programs. In this paper, we present ConPredictor, an approach to predict defects specific to concurrent programs by combining both static and dynamic program metrics. Specifically, we propose a set of novel static code metrics based on the unique properties of concurrent programs. We also leverage additional guidance from dynamic metrics constructed based on mutation analysis. Our evaluation on four large open source projects shows that ConPredictor improved both within-project defect prediction and cross-project defect prediction compared to traditional features.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2018.2791521",
      "Funding Information": "National Science Foundation(grant numbers:CCF-1464032,CCF-1652149,CCF-1511117); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8252721",
      "Author_Keywords": "Concurrency;defect prediction;software quality;software metrics",
      "IEEE_Terms": "Concurrent computing;Predictive models;Software;Programming;Testing;Synchronization",
      "Article Citation Count": "22",
      "Reference Count": "100",
      "License": "IEEE",
      "Online Date": "9-Jan-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Automatic Detection of Outdated Comments During Code Changes",
      "Authors": "Z. Liu; H. Chen; X. Chen; X. Luo; F. Zhou",
      "Author Affiliations": "School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; Institute of Advanced Technology, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Information Security, Guilin University of Electronic Technology, Guilin, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China",
      "Publication Title": "2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "22-Jun-18",
      "Publication Year": "2018",
      "Volume": "01",
      "Start Page": "154",
      "End Page": "163",
      "Abstract": "Comments are used as standard practice in software development to increase the readability of code and to express programmers' intentions in a more explicit manner. Nevertheless, keeping comments up-to-date is often neglected for programmers. In this paper, we proposed a machine learning based method for detecting the comments that should be changed during code changes. We utilized 64 features, taking the code before and after changes, comments and the relationship between the code and comments into account. Experimental results show that 74.6% of outdated comments can be detected using our method, and 77.2% of our detected outdated comments are real comments which require to be updated. In addition, the experimental results indicate that our model can help developers to discover outdated comments in historical versions of existing projects.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-5386-2667-2",
      "DOI": "10.1109/COMPSAC.2018.00028",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8377652",
      "Author_Keywords": "Outdated Comment Detection;Random Forest;Code Changes",
      "IEEE_Terms": "Tools;Feature extraction;Maintenance engineering;Computer bugs;Open source software;Java",
      "Article Citation Count": "12",
      "Reference Count": "23",
      "License": "IEEE",
      "Online Date": "22-Jun-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Evolutionary Optimization of Software Quality Modeling with Multiple Repositories",
      "Authors": "Y. Liu; T. M. Khoshgoftaar; N. Seliya",
      "Author Affiliations": "The J. Whitney Bunting School of Business, Georgia College and State University, Milledgeville, GA, USA; Department of Computer and Electrical Engineering and Computer Science, Florida Atlantic University, Boca Raton, FL, USA; Computer and Information Science Department, University of Michigan, Dearborn, Dearborn, MI, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "29-Nov-10",
      "Publication Year": "2010",
      "Volume": "36",
      "Issue": "6",
      "Start Page": "852",
      "End Page": "864",
      "Abstract": "A novel search-based approach to software quality modeling with multiple software project repositories is presented. Training a software quality model with only one software measurement and defect data set may not effectively encapsulate quality trends of the development organization. The inclusion of additional software projects during the training process can provide a cross-project perspective on software quality modeling and prediction. The genetic-programming-based approach includes three strategies for modeling with multiple software projects: Baseline Classifier, Validation Classifier, and Validation-and-Voting Classifier. The latter is shown to provide better generalization and more robust software quality models. This is based on a case study of software metrics and defect data from seven real-world systems. A second case study considers 17 different (nonevolutionary) machine learners for modeling with multiple software data sets. Both case studies use a similar majority-voting approach for predicting fault-proneness class of program modules. It is shown that the total cost of misclassification of the search-based software quality models is consistently lower than those of the non-search-based models. This study provides clear guidance to practitioners interested in exploiting their organization's software measurement data repositories for improved software quality modeling.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2010.51",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5467094",
      "Author_Keywords": "Genetic programming;optimization;software quality;defects;machine learning;software measurement.",
      "IEEE_Terms": "Software quality;Software measurement;Predictive models;Software metrics;Electronic mail;Genetic programming;Robustness;Costs;Machine learning;Software engineering",
      "Article Citation Count": "108",
      "Reference Count": "48",
      "License": "IEEE",
      "Online Date": "20-May-10",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "A Quantitative Analysis Framework for Recurrent Neural Network",
      "Authors": "X. Du; X. Xie; Y. Li; L. Ma; Y. Liu; J. Zhao",
      "Author Affiliations": "Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Kyushu University, Japan; Nanyang Technological University, Singapore; Kyushu University, Japan",
      "Publication Title": "2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "9-Jan-20",
      "Publication Year": "2019",
      "Start Page": "1062",
      "End Page": "1065",
      "Abstract": "Recurrent neural network (RNN) has achieved great success in processing sequential inputs for applications such as automatic speech recognition, natural language processing and machine translation. However, quality and reliability issues of RNNs make them vulnerable to adversarial attacks and hinder their deployment in real-world applications. In this paper, we propose a quantitative analysis framework - DeepStellar - to pave the way for effective quality and security analysis of software systems powered by RNNs. DeepStellar is generic to handle various RNN architectures, including LSTM and GRU, scalable to work on industrial-grade RNN models, and extensible to develop customized analyzers and tools. We demonstrated that, with DeepStellar, users are able to design efficient test generation tools, and develop effective adversarial sample detectors. We tested the developed applications on three real RNN models, including speech recognition and image classification. DeepStellar outperforms existing approaches three hundred times in generating defect-triggering tests and achieves 97% accuracy in detecting adversarial attacks. A video demonstration which shows the main features of DeepStellar is available at: https://sites.google.com/view/deepstellar/tool-demo.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-7281-2508-4",
      "DOI": "10.1109/ASE.2019.00102",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952565",
      "Author_Keywords": "recurrent neural netwrod;model abstraction;quantitative analysis;similarity metrics;coverage criteria",
      "IEEE_Terms": "Testing;Tools;Training data;Statistical analysis;Recurrent neural networks;Security;Computer architecture",
      "Article Citation Count": "5",
      "Reference Count": "18",
      "License": "IEEE",
      "Online Date": "9-Jan-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Text Filtering and Ranking for Security Bug Report Prediction",
      "Authors": "F. Peters; T. T. Tun; Y. Yu; B. Nuseibeh",
      "Author Affiliations": "Lero - The Irish Software Research Centre, University of Limerick, Limerick, Ireland; Department of Computing and Communications, The Open University, Milton Keynes, United Kingdom; Department of Computing and Communications, The Open University, Milton Keynes, United Kingdom; Lero - The Irish Software Research Centre, University of Limerick, Limerick, Ireland",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "12-Jun-19",
      "Publication Year": "2019",
      "Volume": "45",
      "Issue": "6",
      "Start Page": "615",
      "End Page": "631",
      "Abstract": "Security bug reports can describe security critical vulnerabilities in software products. Bug tracking systems may contain thousands of bug reports, where relatively few of them are security related. Therefore finding unlabelled security bugs among them can be challenging. To help security engineers identify these reports quickly and accurately, text-based prediction models have been proposed. These can often mislabel security bug reports due to a number of reasons such as class imbalance, where the ratio of non-security to security bug reports is very high. More critically, we have observed that the presence of security related keywords in both security and non-security bug reports can lead to the mislabelling of security bug reports. This paper proposes FARSEC, a framework for filtering and ranking bug reports for reducing the presence of security related keywords. Before building prediction models, our framework identifies and removes non-security bug reports with security related keywords. We demonstrate that FARSEC improves the performance of text-based prediction models for security bug reports in 90 percent of cases. Specifically, we evaluate it with 45,940 bug reports from Chromium and four Apache projects. With our framework, we mitigate the class imbalance issue and reduce the number of mislabelled security bug reports by 38 percent.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2017.2787653",
      "Funding Information": "Science Foundation Ireland(grant numbers:13/RC/2094); H2020 European Research Council(grant numbers:291652 - ASAP); EPSRC; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240740",
      "Author_Keywords": "Security cross words;security related keywords;security bug reports;text filtering;ranking;prediction models;transfer learning",
      "IEEE_Terms": "Security;Computer bugs;Predictive models;Software;Data models;Measurement;Buildings",
      "Article Citation Count": "39",
      "Reference Count": "50",
      "License": "IEEE",
      "Online Date": "27-Dec-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Improving fault localization for Simulink models using search-based testing and prediction models",
      "Authors": "B. Liu; Lucia; S. Nejati; L. C. Briand",
      "Author Affiliations": "SnT Centre, University of Luxembourg, Luxembourg; SnT Centre, University of Luxembourg, Luxembourg; SnT Centre, University of Luxembourg, Luxembourg; SnT Centre, University of Luxembourg, Luxembourg",
      "Publication Title": "2017 IEEE 24th International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "23-Mar-17",
      "Publication Year": "2017",
      "Start Page": "359",
      "End Page": "370",
      "Abstract": "One promising way to improve the accuracy of fault localization based on statistical debugging is to increase diversity among test cases in the underlying test suite. In many practical situations, adding test cases is not a cost-free option because test oracles are developed manually or running test cases is expensive. Hence, we require to have test suites that are both diverse and small to improve debugging. In this paper, we focus on improving fault localization of Simulink models by generating test cases. We identify three test objectives that aim to increase test suite diversity. We use these objectives in a search-based algorithm to generate diversified but small test suites. To further minimize test suite sizes, we develop a prediction model to stop test generation when adding test cases is unlikely to improve fault localization. We evaluate our approach using three industrial subjects. Our results show (1) the three selected test objectives are able to significantly improve the accuracy of fault localization for small test suite sizes, and (2) our prediction model is able to maintain almost the same fault localization accuracy while reducing the average number of newly generated test cases by more than half.",
      "ISBNs": "978-1-5090-5501-2",
      "DOI": "10.1109/SANER.2017.7884636",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7884636",
      "Author_Keywords": "Fault localization;Simulink models;search-based testing;test suite diversity;supervised learning",
      "IEEE_Terms": "Software packages;Debugging;Computational modeling;Ranking (statistics);Predictive models;Testing;Adaptation models",
      "Article Citation Count": "29",
      "Reference Count": "86",
      "License": "IEEE",
      "Online Date": "23-Mar-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Data Quality: Some Comments on the NASA Software Defect Datasets",
      "Authors": "M. Shepperd; Q. Song; Z. Sun; C. Mair",
      "Author Affiliations": "Department of IS and Computing, Brunel University, Uxbridge, UK; Department of Computer Science, Xian Jiaotong University, China; Department of Computer Science, Xian Jiaotong University, China; Graduate School, London College of Fashion, University of Arts, London, UK",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "28-Aug-13",
      "Publication Year": "2013",
      "Volume": "39",
      "Issue": "9",
      "Start Page": "1208",
      "End Page": "1215",
      "Abstract": "Background--Self-evidently empirical analyses rely upon the quality of their data. Likewise, replications rely upon accurate reporting and using the same rather than similar versions of datasets. In recent years, there has been much interest in using machine learners to classify software modules into defect-prone and not defect-prone categories. The publicly available NASA datasets have been extensively used as part of this research. Objective--This short note investigates the extent to which published analyses based on the NASA defect datasets are meaningful and comparable. Method--We analyze the five studies published in the IEEE Transactions on Software Engineering since 2007 that have utilized these datasets and compare the two versions of the datasets currently in use. Results--We find important differences between the two versions of the datasets, implausible values in one dataset and generally insufficient detail documented on dataset preprocessing. Conclusions--It is recommended that researchers 1) indicate the provenance of the datasets they use, 2) report any preprocessing in sufficient detail to enable meaningful replication, and 3) invest effort in understanding the data prior to applying machine learners.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2013.11",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6464273",
      "Author_Keywords": "Empirical software engineering;data quality;machine learning;defect prediction",
      "IEEE_Terms": "NASA;Software;PROM;Educational institutions;Sun;Communities;Abstracts",
      "Article Citation Count": "372",
      "Reference Count": "21",
      "License": "IEEE",
      "Online Date": "18-Feb-13",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "JITLine: A Simpler, Better, Faster, Finer-grained Just-In-Time Defect Prediction",
      "Authors": "C. Pornprasit; C. K. Tantithamthavorn",
      "Author Affiliations": "Monash University, Melbourne, Australia; Monash University, Melbourne, Australia",
      "Publication Title": "2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "28-Jun-21",
      "Publication Year": "2021",
      "Start Page": "369",
      "End Page": "379",
      "Abstract": "A Just-In-Time (JIT) defect prediction model is a classifier to predict if a commit is defect-introducing. Recently, CC2Vec-a deep learning approach for Just-In-Time defect prediction-has been proposed. However, CC2Vec requires the whole dataset (i.e., training + testing) for model training, assuming that all unlabelled testing datasets would be available beforehand, which does not follow the key principles of just-in-time defect predictions. Our replication study shows that, after excluding the testing dataset for model training, the F-measure of CC2Vec is decreased by 38.5% for OpenStack and 45.7% for Qt, highlighting the negative impact of excluding the testing dataset for Just-In-Time defect prediction. In addition, CC2Vec cannot perform fine-grained predictions at the line level (i.e., which lines are most risky for a given commit). In this paper, we propose JITLine-a Just-In-Time defect prediction approach for predicting defect-introducing commits and identifying lines that are associated with that defect-introducing commit (i.e., defective lines). Through a case study of 37,524 commits from OpenStack and Qt, we find that our JITLine approach is at least 26%-38% more accurate (F-measure), 17%-51% more cost-effective (PCI@20%LOC), 70-100 times faster than the state-of-the-art approaches (i.e., CC2Vec and DeepJIT) and the fine-grained predictions at the line level by our approach are 133%-150% more accurate (Top-10 Accuracy) than the baseline NLP approach. Therefore, our JITLine approach may help practitioners to better prioritize defect-introducing commits and better identify defective lines.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-7281-8710-5",
      "DOI": "10.1109/MSR52588.2021.00049",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9463103",
      "Author_Keywords": "Software Quality Assurance;Just In Time Defect Prediction;Explainable AI",
      "IEEE_Terms": "Training;Deep learning;Computational modeling;Predictive models;Software;Data mining;Artificial intelligence",
      "Article Citation Count": "45",
      "Reference Count": "44",
      "License": "IEEE",
      "Online Date": "28-Jun-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "DAPSTEP: Deep Assignee Prediction for Stack Trace Error rePresentation",
      "Authors": "D. Sushentsev; A. Khvorov; R. Vasiliev; Y. Golubev; T. Bryksin",
      "Author Affiliations": "HSE University, JetBrains, Saint Petersburg, Russia; HSE University, JetBrains, Saint Petersburg, Russia; JetBrains, Saint Petersburg, Russia; JetBrains Research, Saint Petersburg, Russia; JetBrains Research, HSE University, Saint Petersburg, Russia",
      "Publication Title": "2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "21-Jul-22",
      "Publication Year": "2022",
      "Start Page": "184",
      "End Page": "195",
      "Abstract": "The task of finding the best developer to fix a bug is called bug triage. Most of the existing approaches consider the bug triage task as a classification problem, however, classification is not appropriate when the sets of classes change over time (as developers often do in a project). Furthermore, to the best of our knowledge, all the existing models use textual sources of information, i.e., bug descriptions, which are not always available. In this work, we explore the applicability of existing solutions for the bug triage problem when stack traces are used as the main data source of bug reports. Additionally, we reformulate this task as a ranking problem and propose new deep learning models to solve it. The models are based on a bidirectional recurrent neural network with attention and on a convolutional neural network, with the weights of the models optimized using a ranking loss function. To improve the quality of ranking, we propose using additional information from version control system annotations. Two approaches are proposed for extracting features from annotations: manual and using an additional neural network. To evaluate our models, we collected two datasets of real-world stack traces. Our experiments show that the proposed models outperform existing models adapted to handle stack traces. To facilitate further research in this area, we publish the source code of our models and one of the collected datasets.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-6654-3786-8",
      "DOI": "10.1109/SANER53432.2022.00033",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9825806",
      "Author_Keywords": "bug triage;stack traces;neural networks",
      "IEEE_Terms": "Deep learning;Adaptation models;Recurrent neural networks;Annotations;Soft sensors;Computer bugs;Feature extraction",
      "Reference Count": "51",
      "License": "IEEE",
      "Online Date": "21-Jul-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Performance tuning for automotive Software Fault Prediction",
      "Authors": "H. Altinger; S. Herbold; F. Schneemann; J. Grabowski; F. Wotawa",
      "Author Affiliations": "Audi Electronics Venture GmbH, Gaimersheim, Germany; Institute of Computer Science, University of G√∂ttingen, G√∂ttingen, Germany; Audi Electronics Venture GmbH, Gaimersheim, Germany; Institute of Computer Science, University of G√∂ttingen, G√∂ttingen, Germany; Institute for Software Technology, Graz University of Technology, Graz, Austria",
      "Publication Title": "2017 IEEE 24th International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "23-Mar-17",
      "Publication Year": "2017",
      "Start Page": "526",
      "End Page": "530",
      "Abstract": "Fault prediction on high quality industry grade software often suffers from strong imbalanced class distribution due to a low bug rate. Previous work reports on low predictive performance, thus tuning parameters is required. As the State of the Art recommends sampling methods for imbalanced learning, we analyse effects when under- and oversampling the training data evaluated on seven different classification algorithms. Our results demonstrate settings to achieve higher performance values but the various classifiers are influenced in different ways. Furthermore, not all performance reports can be tuned at the same time.",
      "ISBNs": "978-1-5090-5501-2",
      "DOI": "10.1109/SANER.2017.7884667",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7884667",
      "IEEE_Terms": "Niobium;Software;Computer bugs;Automotive engineering;Training;Radio frequency;Software algorithms",
      "Article Citation Count": "11",
      "Reference Count": "36",
      "License": "IEEE",
      "Online Date": "23-Mar-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Astraea: Grammar-Based Fairness Testing",
      "Authors": "E. Soremekun; S. Udeshi; S. Chattopadhyay",
      "Author Affiliations": "Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg; Singapore University of Technology and Design, Singapore; Singapore University of Technology and Design, Singapore",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "9-Dec-22",
      "Publication Year": "2022",
      "Volume": "48",
      "Issue": "12",
      "Start Page": "5188",
      "End Page": "5211",
      "Abstract": "Software often produces biased outputs. In particular, machine learning (ML) based software is known to produce erroneous predictions when processing discriminatory inputs. Such unfair program behavior can be caused by societal bias. In the last few years, Amazon, Microsoft and Google have provided software services that produce unfair outputs, mostly due to societal bias (e.g., gender or race). In such events, developers are saddled with the task of conducting fairness testing. Fairness testing is challenging; developers are tasked with generating discriminatory inputs that reveal and explain biases. We propose a grammar-based fairness testing approach (called Astraea) which leverages context-free grammars to generate discriminatory inputs that reveal fairness violations in software systems. Using probabilistic grammars, Astraea also provides fault diagnosis by isolating the cause of observed software bias. Astraea‚Äôs diagnoses facilitate the improvement of ML fairness. Astraea was evaluated on 18 software systems that provide three major natural language processing (NLP) services. In our evaluation, Astraea generated fairness violations at a rate of about 18%. Astraea generated over 573K discriminatory test cases and found over 102K fairness violations. Furthermore, Astraea improves software fairness by about 76% via model-retraining, on average.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2022.3141758",
      "Funding Information": "University of Luxembourg, Ezekiel Soremekun; University of Luxembourg(grant numbers:AUDACITY-2019-Laiwyers); OneConnect Financial(grant numbers:RGOCFT2001); Singapore Ministry of Education; MOE(grant numbers:MOE2018-T2-1-098); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9678017",
      "Author_Keywords": "software fairness;machine learning;natural language processing;software testing;program debugging",
      "IEEE_Terms": "Testing;Grammar;Task analysis;Sentiment analysis;Test pattern generators;Software testing;Software systems",
      "Article Citation Count": "3",
      "Reference Count": "88",
      "License": "IEEE",
      "Online Date": "11-Jan-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Where Should We Fix This Bug? A Two-Phase Recommendation Model",
      "Authors": "D. Kim; Y. Tao; S. Kim; A. Zeller",
      "Author Affiliations": "Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Kowloon, Hong Kong; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Kowloon, Hong Kong; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Kowloon, Hong Kong; Universit√§t des Saarlandes-Informatik, Germany",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "28-Oct-13",
      "Publication Year": "2013",
      "Volume": "39",
      "Issue": "11",
      "Start Page": "1597",
      "End Page": "1610",
      "Abstract": "To support developers in debugging and locating bugs, we propose a two-phase prediction model that uses bug reports' contents to suggest the files likely to be fixed. In the first phase, our model checks whether the given bug report contains sufficient information for prediction. If so, the model proceeds to predict files to be fixed, based on the content of the bug report. In other words, our two-phase model \"speaks up\" only if it is confident of making a suggestion for the given bug report; otherwise, it remains silent. In the evaluation on the Mozilla \"Firefox\" and \"Core\" packages, the two-phase model was able to make predictions for almost half of all bug reports; on average, 70 percent of these predictions pointed to the correct files. In addition, we compared the two-phase model with three other prediction models: the Usual Suspects, the one-phase model, and BugScout. The two-phase model manifests the best prediction performance.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2013.24",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6517844",
      "Author_Keywords": "Bug reports;machine learning;patch file prediction",
      "IEEE_Terms": "Predictive models;Feature extraction;Computer bugs;Software;Computational modeling;Data mining;Noise",
      "Article Citation Count": "119",
      "Patent Citation Count": "1",
      "Reference Count": "66",
      "License": "IEEE",
      "Online Date": "21-May-13",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "D-ACT: Towards Diff-Aware Code Transformation for Code Review Under a Time-Wise Evaluation",
      "Authors": "C. Pornprasit; C. Tantithamthavorn; P. Thongtanunam; C. Chen",
      "Author Affiliations": "Monash University, Australia; Monash University, Australia; Monash University, Australia; Monash University, Australia",
      "Publication Title": "2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "15-May-23",
      "Publication Year": "2023",
      "Start Page": "296",
      "End Page": "307",
      "Abstract": "Code review is a software quality assurance practice, yet remains time-consuming (e.g., due to slow feedback from reviewers). Recent Neural Machine Translation (NMT)-based code transformation approaches were proposed to automatically generate an approved version of changed methods for a given submitted patch. The existing approaches could change code tokens in any area in a changed method. However, not all code tokens need to be changed. Intuitively, the changed code tokens in the method should be paid more attention to than the others as they are more prone to be defective. In this paper, we present an NMT-based Diff-Aware Code Transformation approach (DACT) by leveraging token-level change information to enable the NMT models to better focus on the changed tokens in a changed method. We evaluate our D-ACT and the baseline approaches based on a time-wise evaluation (that is ignored by the existing work) with 5,758 changed methods. Under the time-wise evaluation scenario, our results show that (1) D-ACT can correctly transform 107 - 245 changed methods, which is at least 62% higher than the existing approaches; (2) the performance of the existing approaches drops by 57% to 94% when the time-wise evaluation is ignored; and (3) D-ACT is improved by 17% - 82% with an average of 29% when considering the token-level change information. Our results suggest that (1) NMT-based code transformation approaches for code review should be evaluated under the time-wise evaluation; and (2) the token-level change information can substantially improve the performance of NMTbased code transformation approaches for code review.",
      "ISSN": "2640-7574",
      "ISBNs": "978-1-6654-5278-6",
      "DOI": "10.1109/SANER56733.2023.00036",
      "Funding Information": "Australian Research Council; Australian Research Council; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10123643",
      "Author_Keywords": "Modern Code Review;Deep Learning;Neural Machine Translation",
      "IEEE_Terms": "Codes;Transforms;Software quality;Internet;Machine translation;Smart phones",
      "Article Citation Count": "1",
      "Reference Count": "58",
      "License": "IEEE",
      "Online Date": "15-May-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Credential Usage Study: Flow-Aware Leakage Detection in Open-Source Projects",
      "Authors": "R. Han; H. Gong; S. Ma; J. Li; C. Xu; E. Bertino; S. Nepal; Z. Ma; J. Ma",
      "Author Affiliations": "School of Cyber Engineering, Xidian University, Xi‚Äôan, China; Faculty of Engineering, The University of Sydney, Sydney, NSW, Australia; School of Engineering and Information System, University of New South Wales, Sydney, NSW, Australia; Zhiyuan College, Shanghai Jiao Tong University, Shanghai, China; School of Computer Science, Faculty of Engineering and IT, The University of Sydney, Darlington, NSW, Australia; Department of Computer Science, Purdue University, West Lafayette, IN, USA; Commonwealth Scientific and Industrial Research, Sydney, NSW, Australia; School of Cyber Engineering, Xidian University, Xi‚Äôan, China; School of Cyber Engineering, Xidian University, Xi‚Äôan, China",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "21-Nov-23",
      "Publication Year": "2024",
      "Volume": "19",
      "Start Page": "722",
      "End Page": "734",
      "Abstract": "Authentication and cryptography are critical security functions and, thus, are very often included as part of code. These functions require using credentials, such as passwords, security tokens, and cryptographic keys. However, developers often incorrectly implement/use credentials in their code because of a lack of secure coding skills. This paper analyzes open-source projects concerning the correct use of security credentials. We developed a semantic-rich, language-independent analysis approach for analyzing many projects automatically. We implemented a detection tool, SEAGULL, to automatically check open-source projects based on string literal and code structure information. Instead of analyzing the entire project code, which might result in path explosion when constructing data and control dependencies, SEAGULL pinpoints all literal constants to identify credential candidates and then analyzes the code snippets correlated to these candidates. SEAGULL accurately identifies the leaked credentials by obtaining semantic and syntax information about the code. We applied SEAGULL to 377 open-source projects. SEAGULL successfully reported 19 real-world credential leakages out of those projects. Our analysis shows that some developers protected or erased the credentials in the current project versions, but previously used credentials can still be extracted from the project‚Äôs historical versions. Although the implementations of credential leakages seem to be fixed in the current projects, attackers could successfully log into accounts if developers keep using the same credentials as before. Additionally, we found that such credential leakages still affect some projects. By exploiting leaked credentials, attackers can log into particular accounts.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2023.3326985",
      "Funding Information": "National Natural Science Foundation of China (Key Program)(grant numbers:62232013); Major Research Plan of the National Natural Science Foundation of China(grant numbers:92267204,92167203); Natural Science Basis Research Plan in Shaanxi Province of China(grant numbers:2022JM-338); Fundamental Research Funds for the Central Universities(grant numbers:XJSJ23185); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10292698",
      "Author_Keywords": "Credential leakage;bug detection;static code analysis",
      "IEEE_Terms": "Codes;Source coding;Passwords;Authentication;Semantics;Java;Machine learning",
      "Reference Count": "56",
      "License": "IEEE",
      "Online Date": "23-Oct-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "LineVD: Statement-level Vulnerability Detection using Graph Neural Networks",
      "Authors": "D. Hin; A. Kan; H. Chen; M. A. Babar",
      "Author Affiliations": "CREST - The Centre for Research on Engineering Software Technologies, University of Adelaide Cyber Security Cooperative Research Centre, Adelaide, Australia; AWS AI Labs*, Adelaide, SA, Australia; CREST - The Centre for Research on Engineering Software Technologies, University of Adelaide Cyber Security Cooperative Research Centre, Adelaide, Australia; CREST - The Centre for Research on Engineering Software Technologies, University of Adelaide Cyber Security Cooperative Research Centre, Adelaide, Australia",
      "Publication Title": "2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "21-Jun-22",
      "Publication Year": "2022",
      "Start Page": "596",
      "End Page": "607",
      "Abstract": "Current machine-learning based software vulnerability detection methods are primarily conducted at the function-level. However, a key limitation of these methods is that they do not indicate the specific lines of code contributing to vulnerabilities. This limits the ability of developers to efficiently inspect and interpret the predictions from a learnt model, which is crucial for integrating machine-learning based tools into the software development work-flow. Graph-based models have shown promising performance in function-level vulnerability detection, but their capability for statement-level vulnerability detection has not been extensively explored. While interpreting function-level predictions through explainable AI is one promising direction, we herein consider the statement-level software vulnerability detection task from a fully supervised learning perspective. We propose a novel deep learning framework, LineVD, which formulates statement-level vulnerability detection as a node classification task. LineVD leverages control and data dependencies between statements using graph neural networks, and a transformer-based model to encode the raw source code tokens. In particular, by addressing the conflicting outputs between function-level and statement-level information, LineVD significantly improve the prediction performance without vulnerability status for function code. We have conducted extensive experi-ments against a large-scale collection of real-world C/C++ vulnerabilities obtained from multiple real-world projects, and demonstrate an increase of 105% in F1-score over the current state-of-the-art.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-4503-9303-4",
      "DOI": "10.1145/3524842.3527949",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796269",
      "Author_Keywords": "Software Vulnerability Detection;Program Representation;Deep Learning",
      "IEEE_Terms": "Deep learning;Training;Codes;Supervised learning;Predictive models;Transformers;Feature extraction",
      "Article Citation Count": "19",
      "Reference Count": "62",
      "Online Date": "21-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "VELVET: a noVel Ensemble Learning approach to automatically locate VulnErable sTatements",
      "Authors": "Y. Ding; S. Suneja; Y. Zheng; J. Laredo; A. Morari; G. Kaiser; B. Ray",
      "Author Affiliations": "Columbia University; IBM Research; IBM Research; IBM Research; IBM Research; Columbia University; Columbia University",
      "Publication Title": "2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "21-Jul-22",
      "Publication Year": "2022",
      "Start Page": "959",
      "End Page": "970",
      "Abstract": "Automatically locating vulnerable statements in source code is crucial to assure software security and alleviate developers' debugging efforts. This becomes even more important in today's software ecosystem, where vulnerable code can flow easily and unwittingly within and across software repositories like GitHub. Across such millions of lines of code, traditional static and dynamic approaches struggle to scale. Although existing machine-learning-based approaches look promising in such a setting, most work detects vulnerable code at a higher granularity ‚Äì at the method or file level. Thus, developers still need to inspect a significant amount of code to locate the vulnerable statement(s) that need to be fixed. This paper presents Velvet, a novel ensemble learning approach to locate vulnerable statements. Our model combines graph-based and sequence-based neural networks to successfully capture the local and global context of a program graph and effectively understand code semantics and vulnerable patterns. To study Velvet's effectiveness, we use an off-the-shelf synthetic dataset and a recently published real-world dataset. In the static analysis setting, where vulnerable functions are not detected in advance, Velvet achieves 4.5√ó better performance than the baseline static analyzers on the real-world data. For the isolated vulnerability localization task, where we assume the vulnerability of a function is known while the specific vulnerable statement is unknown, we compare Velvet with several neural networks that also attend to local and global context of code. Velvet achieves 99.6% and 43.6% top-1 accuracy over synthetic data and real-world data, respectively, outperforming the baseline deep learning models by 5.3-29.0%.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-6654-3786-8",
      "DOI": "10.1109/SANER53432.2022.00114",
      "Funding Information": "NSF(grant numbers:CCF-2107405,CCF-1845893,CCF-1815494,IIS-2040961); IBM; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9825786",
      "Author_Keywords": "Security Bugs;Vulnerability Localization;Ensemble Learning;Transformer Model;Graph Neural Network",
      "IEEE_Terms": "Location awareness;Codes;Neural networks;Static analysis;Software;Data models;Security",
      "Article Citation Count": "8",
      "Reference Count": "60",
      "License": "IEEE",
      "Online Date": "21-Jul-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Software Requirements Ecosystem: Linking Forum, Issue Tracker, and FAQs for Requirements Management",
      "Authors": "J. Tizard; P. Devine; H. Wang; K. Blincoe",
      "Author Affiliations": "Human Aspects of Software Engineering Lab, University of Auckland, Auckland, New Zealand; Human Aspects of Software Engineering Lab, University of Auckland, Auckland, New Zealand; Human Aspects of Software Engineering Lab, University of Auckland, Auckland, New Zealand; Human Aspects of Software Engineering Lab, University of Auckland, Auckland, New Zealand",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "18-Apr-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "4",
      "Start Page": "2381",
      "End Page": "2393",
      "Abstract": "User feedback is an important resource in modern software development, often containing requirements that help address user concerns and desires for a software product. The feedback in online channels is a recent focus for software engineering researchers, with multiple studies proposing automatic analysis tools. In this work, we investigate the product forums of two large open source software projects. Through a quantitative analysis, we show that forum feedback is often manually linked to related issue tracker entries and product documentation. By linking feedback to their existing documentation, development teams enhance their understanding of known issues, and direct their users to known solutions. We discuss how the links between forum, issue tracker, and product documentation form a requirements ecosystem that has not been identified in the previous literature. We apply state-of-the-art deep-learning to automatically match forum posts with related issue tracker entries. Our approach identifies requirement matches with a mean average precision of 58.9% and hit ratio of 82.2%. Additionally, we apply deep-learning using an innovative clustering technique, achieving promising performance when matching forum posts to related product documentation. We discuss the possible applications of these automated techniques to support the flow of requirements between forum, issue tracker, and product documentation.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2022.3219458",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9940985",
      "Author_Keywords": "Requirements engineering;machine learning;natural language processing;deep learning;open source software;user feedback;software engineering",
      "IEEE_Terms": "Software;Documentation;Computer bugs;Open source software;Ecosystems;Browsers;Software engineering",
      "Article Citation Count": "1",
      "Reference Count": "44",
      "License": "IEEE",
      "Online Date": "7-Nov-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Measuring Code Quality to Improve Specification Mining",
      "Authors": "C. Le Goues; W. Weimer",
      "Author Affiliations": "Department of Computer Science, University of Virginia, Charlottesville, VA, USA; Department of Computer Science, University of Virginia, Charlottesville, VA, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "30-Jan-12",
      "Publication Year": "2012",
      "Volume": "38",
      "Issue": "1",
      "Start Page": "175",
      "End Page": "190",
      "Abstract": "Formal specifications can help with program testing, optimization, refactoring, documentation, and, most importantly, debugging and repair. However, they are difficult to write manually, and automatic mining techniques suffer from 90-99 percent false positive rates. To address this problem, we propose to augment a temporal-property miner by incorporating code quality metrics. We measure code quality by extracting additional information from the software engineering process and using information from code that is more likely to be correct, as well as code that is less likely to be correct. When used as a preprocessing step for an existing specification miner, our technique identifies which input is most indicative of correct program behavior, which allows off-the-shelf techniques to learn the same number of specifications using only 45 percent of their original input. As a novel inference technique, our approach has few false positives in practice (63 percent when balancing precision and recall, 3 percent when focused on precision), while still finding useful specifications (e.g., those that find many bugs) on over 1.5 million lines of code.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2011.5",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5680914",
      "Author_Keywords": "Specification mining;machine learning;software engineering;code metrics;program understanding.",
      "IEEE_Terms": "Software measurement;Refactoring;Data mining;Maintenance engineering;Cloning;Optimization",
      "Article Citation Count": "28",
      "Reference Count": "61",
      "License": "IEEE",
      "Online Date": "6-Jan-11",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Commit Classification Into Software Maintenance Activities: A Systematic Literature Review",
      "Authors": "T. Heriƒçko; B. ≈†umak",
      "Author Affiliations": "Faculty of Electrical Engineering and Computer Science, University of Maribor, Maribor, Slovenia; Faculty of Electrical Engineering and Computer Science, University of Maribor, Maribor, Slovenia",
      "Publication Title": "2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "2-Aug-23",
      "Publication Year": "2023",
      "Start Page": "1646",
      "End Page": "1651",
      "Abstract": "Commits represent an essential part of software development practices, serving as the means for collaboration and management of software changes made to a software project‚Äôs codebase. Changes are necessary for the survival of software, for instance, to fix faults, address security vulnerabilities, meet new functional requirements, and improve software performance. To aid software research and practice, several research endeavors attempted to automate the process of identifying the nature of the maintenance tasks performed in a commit based on the data associated with the commit. This paper presents a systematic literature review of supervised-learning-based models for commit classification into maintenance activities. Through the study selection process, 19 primary studies were identified, published between 2008 and 2023 in various journals and conference proceedings. For the independent variables for classification, features extracted from commit messages are prevalent, followed by features extracted from source code and commit metadata. In the majority of existing studies, multi-class classification approaches are used, whereas multi-label approaches are considered rarely. The most commonly used classification algorithms include Decision Tree, Random Forest, Naive Bayes, and Neural Network. Several datasets exist, consisting mainly of commits from different open-source projects based on the Java programming language. Some research gaps and open challenges were identified that can guide future research efforts.",
      "ISSN": "0730-3157",
      "ISBNs": "979-8-3503-2697-0",
      "DOI": "10.1109/COMPSAC57700.2023.00254",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10196916",
      "Author_Keywords": "systematic literature review;machine learning;supervised learning;software change;code repositories;software maintenance",
      "IEEE_Terms": "Adaptation models;Systematics;Computational modeling;Bibliographies;Source coding;Supervised learning;Maintenance engineering",
      "Reference Count": "33",
      "License": "IEEE",
      "Online Date": "2-Aug-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Equity and Privacy: More Than Just a Tradeoff",
      "Authors": "D. Pujol; A. Machanavajjhala",
      "Author Affiliations": "Duke University; Duke University and Tumult Labs",
      "Publication Title": "IEEE Security & Privacy",
      "Date Added To Xplore": "28-Oct-21",
      "Publication Year": "2021",
      "Volume": "19",
      "Issue": "6",
      "Start Page": "93",
      "End Page": "97",
      "Abstract": "Organizations large and small collect information about individuals and groups and then want to share insights from this data to inform research and policy making. For instance, hospitals release deidentified data to innovate on disease detection and mitigation. Internet companies train and release machine learning (ML) models as a service for a variety of classification tasks. Government agencies distribute statistical data to enable research and policy making. However, releasing data, even in ‚Äúanonymous‚Äù or aggregated form, creates vulnerabilities to privacy attacks that can result in individuals‚Äô sensitive details being revealed.",
      "ISSN": "1558-4046",
      "DOI": "10.1109/MSEC.2021.3105773",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9592826",
      "IEEE_Terms": "Privacy;Data privacy;Organizational aspects;Information security;Machine learning;Business practices;Internet;Data security",
      "Article Citation Count": "6",
      "Reference Count": "8",
      "License": "IEEE",
      "Online Date": "28-Oct-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Magazines"
    },
    {
      "Document Title": "Metamorphic Testing on Multi-module UAV Systems",
      "Authors": "R. Li; H. Liu; G. Lou; X. Zheng; X. Liu; T. Y. Chen",
      "Author Affiliations": "Swinburne University of Technology, Melbourne, VIC, Australia; Swinburne University of Technology, Melbourne, VIC, Australia; Macquaire University, Sydney, NSW, Australia; Macquaire University, Sydney, NSW, Australia; Deakin University, Melbourne, VIC, Australia; Swinburne University of Technology, Melbourne, VIC, Australia",
      "Publication Title": "2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "20-Jan-22",
      "Publication Year": "2021",
      "Start Page": "1171",
      "End Page": "1173",
      "Abstract": "Recent years have seen a rapid development of machine learning based multi-module unmanned aerial vehicle (UAV) systems. To address the oracle problem in autonomous systems, numerous studies have been conducted to use metamorphic testing to automatically generate test scenes for various modules, e.g., those in self-driving cars. However, as most of the studies are based on unit testing including end-to-end model-based testing, a similar testing approach may not be equally effective for UAV systems where multiple modules are working closely together. Therefore, in this paper, instead of unit testing, we propose a novel metamorphic system testing framework for UAV, named MSTU, to detect the defects in multi-module UAV systems. A preliminary evaluation plan to apply MSTU on an emerging autonomous multi-module UAV system is also presented to demonstrate the feasibility of the proposed testing framework.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-6654-0337-5",
      "DOI": "10.1109/ASE51524.2021.9678841",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9678841",
      "Author_Keywords": "Metamorphic testing;Multi-module UAV system;System testing;Software testing and verification",
      "IEEE_Terms": "System testing;Autonomous systems;Machine learning;Autonomous aerial vehicles;Autonomous automobiles;Testing;Software engineering",
      "Article Citation Count": "4",
      "Reference Count": "15",
      "License": "IEEE",
      "Online Date": "20-Jan-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Software-Repair Robot Based on Continual Learning",
      "Authors": "B. Baudry; Z. Chen; K. Etemadi; H. Fu; D. Ginelli; S. Kommrusch; M. Martinez; M. Monperrus; J. Ron; H. Ye; Z. Yu",
      "Author Affiliations": "KTH Royal Institute of Technology; KTH Royal Institute of Technology; KTH Royal Institute of Technology; KTH Royal Institute of Technology; University of Milano-Bicocca; Colorado State University; Universit√© Polytechnique Hauts-de-France; KTH Royal Institute of Technology; KTH Royal Institute of Technology; KTH Royal Institute of Technology; Shandong University",
      "Publication Title": "IEEE Software",
      "Date Added To Xplore": "21-Jun-21",
      "Publication Year": "2021",
      "Volume": "38",
      "Issue": "4",
      "Start Page": "28",
      "End Page": "35",
      "Abstract": "Software bugs are common, and correcting them accounts for a significant portion of the costs in the software development and maintenance process. In this article, we discuss R-Hero, our novel system for learning how to fix bugs based on continual training.",
      "ISSN": "1937-4194",
      "DOI": "10.1109/MS.2021.3070743",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9393494",
      "IEEE_Terms": "Maintenance engineering;Computer bugs;Software development management;Bot (Internet);Training data;Machine learning",
      "Article Citation Count": "6",
      "Reference Count": "19",
      "License": "IEEE",
      "Online Date": "1-Apr-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Magazines"
    },
    {
      "Document Title": "An Empirical Comparison of Model Validation Techniques for Defect Prediction Models",
      "Authors": "C. Tantithamthavorn; S. McIntosh; A. E. Hassan; K. Matsumoto",
      "Author Affiliations": "Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Japan; Department of Electrical and Computer Engineering, Montreal, QC, Canada; School of Computing, Queen‚Äôs University, Kingston, ON, Canada; Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Japan",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "9-Jan-17",
      "Publication Year": "2017",
      "Volume": "43",
      "Issue": "1",
      "Start Page": "1",
      "End Page": "18",
      "Abstract": "Defect prediction models help software quality assurance teams to allocate their limited resources to the most defect-prone modules. Model validation techniques, such as $k$ -fold cross-validation, use historical data to estimate how well a model will perform in the future. However, little is known about how accurate the estimates of model validation techniques tend to be. In this paper, we investigate the bias and variance of model validation techniques in the domain of defect prediction. Analysis of 101 public defect datasets suggests that 77 percent of them are highly susceptible to producing unstable results‚Äì - selecting an appropriate model validation technique is a critical experimental design choice. Based on an analysis of 256 studies in the defect prediction literature, we select the 12 most commonly adopted model validation techniques for evaluation. Through a case study of 18 systems, we find that single-repetition holdout validation tends to produce estimates with 46-229 percent more bias and 53-863 percent more variance than the top-ranked model validation techniques. On the other hand, out-of-sample bootstrap validation yields the best balance between the bias and variance of estimates in the context of our study. Therefore, we recommend that future defect prediction studies avoid single-repetition holdout validation, and instead, use out-of-sample bootstrap validation.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2016.2584050",
      "Funding Information": "JSPS; Advancing Strategic International Networks to Accelerate the Circulation of Talented Researchers; Interdisciplinary Global Networks for Accelerating Theory and Practice in Software Ecosystem; JSPS Fellows(grant numbers:16J03360); Natural Sciences and Engineering Research Council of Canada¬†(NSERC); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7497471",
      "Author_Keywords": "Defect prediction models;model validation techniques;bootstrap validation;cross validation;holdout validation",
      "IEEE_Terms": "Predictive models;Data models;Analytical models;Context;Context modeling;Software;Logistics",
      "Article Citation Count": "343",
      "Reference Count": "5",
      "License": "IEEE",
      "Online Date": "22-Jun-16",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Deep Face Representations for Differential Morphing Attack Detection",
      "Authors": "U. Scherhag; C. Rathgeb; J. Merkle; C. Busch",
      "Author Affiliations": "da/sec‚ÄîBiometrics and Internet Security Research Group, Hochschule Darmstadt, Darmstadt, Germany; da/sec‚ÄîBiometrics and Internet Security Research Group, Hochschule Darmstadt, Darmstadt, Germany; Security Networks AG, Essen, Germany; da/sec‚ÄîBiometrics and Internet Security Research Group, Hochschule Darmstadt, Darmstadt, Germany",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "3-Jul-20",
      "Publication Year": "2020",
      "Volume": "15",
      "Start Page": "3625",
      "End Page": "3639",
      "Abstract": "The vulnerability of facial recognition systems to face morphing attacks is well known. Many different approaches for morphing attack detection (MAD) have been proposed in the scientific literature. However, the MAD algorithms proposed so far have mostly been trained and tested on datasets whose distributions of image characteristics are either very limited (e.g., only created with a single morphing tool) or rather unrealistic (e.g., no print-scan transformation). As a consequence, these methods easily overfit on certain image types and the results presented cannot be expected to apply to real-world scenarios. For example, the results of the latest NIST FRVT MORPH show that the majority of submitted MAD algorithms lacks robustness and performance when considering unseen and challenging datasets. In this work, subsets of the FERET and FRGCv2 face databases are used to create a realistic database for training and testing of MAD algorithms, containing a large number of ICAO-compliant bona fide facial images, corresponding unconstrained probe images, and morphed images created with four different face morphing tools. Furthermore, multiple post-processings are applied on the reference images, e.g., print-scan and JPEG2000 compression. On this database, previously proposed differential morphing algorithms are evaluated and compared. In addition, the application of deep face representations for differential MAD algorithms is investigated. It is shown that algorithms based on deep face representations can achieve very high detection performance (less than 3% D-EER) and robustness with respect to various post-processings. Finally, the limitations of the developed methods are analyzed.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2020.2994750",
      "Funding Information": "German Federal Ministry of Education and Research; Hessen State Ministry for Higher Education, Research and the Arts within their joint support of the ATHENE (National Research Center for Applied Cybersecurity); Federal Office of Information Security (BSI) through the FACETRUST Project; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9093905",
      "Author_Keywords": "Biometrics;face recognition;morphing attacks;morphing attack detection;differential attack detection;deep face representation",
      "IEEE_Terms": "Face;Databases;Probes;Face recognition;Feature extraction;Neural networks;Forensics",
      "Article Citation Count": "73",
      "Reference Count": "56",
      "License": "CCBY",
      "Online Date": "14-May-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Exploring the integration of user feedback in automated testing of Android applications",
      "Authors": "G. Grano; A. Ciurumelea; S. Panichella; F. Palomba; H. C. Gall",
      "Author Affiliations": "Department of Informatics, University of Zurich, Switzerland; Department of Informatics, University of Zurich, Switzerland; Department of Informatics, University of Zurich, Switzerland; Department of Informatics, University of Zurich, Switzerland; Department of Informatics, University of Zurich, Switzerland",
      "Publication Title": "2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "5-Apr-18",
      "Publication Year": "2018",
      "Start Page": "72",
      "End Page": "83",
      "Abstract": "The intense competition characterizing mobile application's marketplaces forces developers to create and maintain high-quality mobile apps in order to ensure their commercial success and acquire new users. This motivated the research community to propose solutions that automate the testing process of mobile apps. However, the main problem of current testing tools is that they generate redundant and random inputs that are insufficient to properly simulate the human behavior, thus leaving feature and crash bugs undetected until they are encountered by users. To cope with this problem, we conjecture that information available in user reviews-that previous work showed as effective for maintenance and evolution problems-can be successfully exploited to identify the main issues users experience while using mobile applications, e.g., GUI problems and crashes. In this paper we provide initial insights into this direction, investigating (i) what type of user feedback can be actually exploited for testing purposes, (ii) how complementary user feedback and automated testing tools are, when detecting crash bugs or errors and (iii) whether an automated system able to monitor crash-related information reported in user feedback is sufficiently accurate. Results of our study, involving 11,296 reviews of 8 mobile applications, show that user feedback can be exploited to provide contextual details about errors or exceptions detected by automated testing tools. Moreover, they also help detecting bugs that would remain uncovered when rely on testing tools only. Finally, the accuracy of the proposed automated monitoring system demonstrates the feasibility of our vision, i.e., integrate user feedback into testing process.",
      "ISBNs": "978-1-5386-4969-5",
      "DOI": "10.1109/SANER.2018.8330198",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8330198",
      "Author_Keywords": "Automated Software Testing;Mobile Applications;User Reviews Analysis",
      "IEEE_Terms": "Testing;Tools;Computer bugs;Androids;Humanoid robots;Mobile applications",
      "Article Citation Count": "29",
      "Reference Count": "51",
      "License": "IEEE",
      "Online Date": "5-Apr-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "SQAPlanner: Generating Data-Informed Software Quality Improvement Plans",
      "Authors": "D. Rajapaksha; C. Tantithamthavorn; J. Jiarpakdee; C. Bergmeir; J. Grundy; W. Buntine",
      "Author Affiliations": "Faculty of Information Technology, Monash University, Melbourne, VIC, Australia; Faculty of Information Technology, Monash University, Melbourne, VIC, Australia; Faculty of Information Technology, Monash University, Melbourne, VIC, Australia; Faculty of Information Technology, Monash University, Melbourne, VIC, Australia; Faculty of Information Technology, Monash University, Melbourne, VIC, Australia; Faculty of Information Technology, Monash University, Melbourne, VIC, Australia",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "16-Aug-22",
      "Publication Year": "2022",
      "Volume": "48",
      "Issue": "8",
      "Start Page": "2814",
      "End Page": "2835",
      "Abstract": "Software Quality Assurance (SQA) planning aims to define proactive plans, such as defining maximum file size, to prevent the occurrence of software defects in future releases. To aid this, defect prediction models have been proposed to generate insights as the most important factors that are associated with software quality. Such insights that are derived from traditional defect models are far from actionable‚Äîi.e., practitioners still do not know what they should do or avoid to decrease the risk of having defects, and what is the risk threshold for each metric. A lack of actionable guidance and risk threshold can lead to inefficient and ineffective SQA planning processes. In this paper, we investigate the practitioners‚Äô perceptions of current SQA planning activities, current challenges of such SQA planning activities, and propose four types of guidance to support SQA planning. We then propose and evaluate our AI-Driven SQAPlanner approach, a novel approach for generating four types of guidance and their associated risk thresholds in the form of rule-based explanations for the predictions of defect prediction models. Finally, we develop and evaluate a visualization for our SQAPlanner approach. Through the use of qualitative survey and empirical evaluation, our results lead us to conclude that SQAPlanner is needed, effective, stable, and practically applicable. We also find that 80 percent of our survey respondents perceived that our visualization is more actionable. Thus, our SQAPlanner paves a way for novel research in actionable software analytics‚Äîi.e., generating actionable guidance on what should practitioners do and not do to decrease the risk of having defects to support SQA planning.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2021.3070559",
      "Funding Information": "Australian Research Council(grant numbers:DE200100941); Australian Research Council(grant numbers:DE190100045); Australian Research Council(grant numbers:FL190100035); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9394771",
      "Author_Keywords": "Software quality assurance;SQA planning;actionable software analytics;explainable AI",
      "IEEE_Terms": "Planning;Software;Predictive models;Visualization;Tools;Artificial intelligence;Software quality",
      "Article Citation Count": "19",
      "Reference Count": "59",
      "License": "IEEE",
      "Online Date": "2-Apr-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "AI and the Ethics of Automating Consent",
      "Authors": "M. L. Jones; E. Kaufman; E. Edenberg",
      "Author Affiliations": "Georgetown University; Georgetown University; Georgetown University",
      "Publication Title": "IEEE Security & Privacy",
      "Date Added To Xplore": "25-Jun-18",
      "Publication Year": "2018",
      "Volume": "16",
      "Issue": "3",
      "Start Page": "64",
      "End Page": "72",
      "Abstract": "AI systems collect, process, and generate data in ways that further exacerbate many long-documented problems with online consent, most notably issues of providing adequate notice, choice, and withdrawal to users. The unpredictable and even unimaginable use of data by AI systems is considered a feature, not a bug. Yet this feature creates problems for notifying users as well as assessing when consent might be required based on potential uses, harms, and consequences. This article investigates whether these problems impact morally transformative consent in AI systems. We argue that while supplementing consent with further mechanization, digitization, and intelligence‚Äîeither through proffering notification on behalf of the consentee or choosing and communicating consent by the consenter‚Äîmay improve take-it-or-leave-it notice and choice consent regimes, the goal for AI consent should be one of partnership development between parties, built on responsive design and continual consent.",
      "ISSN": "1558-4046",
      "DOI": "10.1109/MSP.2018.2701155",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8395123",
      "Author_Keywords": "privacy;automation;consent;governance;AI;ethics;AI ethics",
      "IEEE_Terms": "Artificial intelligence;Ethics;Privacy;Data protection;Computer security;Information exchange",
      "Article Citation Count": "18",
      "Reference Count": "16",
      "License": "IEEE",
      "Online Date": "25-Jun-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Magazines"
    },
    {
      "Document Title": "Re-evaluating method-level bug prediction",
      "Authors": "L. Pascarella; F. Palomba; A. Bacchelli",
      "Author Affiliations": "Delft University of Technology, The Netherlands; University of Zurich, Switzerland; University of Zurich, Switzerland",
      "Publication Title": "2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "5-Apr-18",
      "Publication Year": "2018",
      "Start Page": "592",
      "End Page": "601",
      "Abstract": "Bug prediction is aimed at supporting developers in the identification of code artifacts more likely to be defective. Researchers have proposed prediction models to identify bug prone methods and provided promising evidence that it is possible to operate at this level of granularity. Particularly, models based on a mixture of product and process metrics, used as independent variables, led to the best results. In this study, we first replicate previous research on method-level bug prediction on different systems/timespans. Afterwards, we reflect on the evaluation strategy and propose a more realistic one. Key results of our study show that the performance of the method-level bug prediction model is similar to what previously reported also for different systems/timespans, when evaluated with the same strategy. However-when evaluated with a more realistic strategy-all the models show a dramatic drop in performance exhibiting results close to that of a random classifier. Our replication and negative results indicate that method-level bug prediction is still an open challenge.",
      "ISBNs": "978-1-5386-4969-5",
      "DOI": "10.1109/SANER.2018.8330264",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8330264",
      "Author_Keywords": "empirical software engineering;bug prediction;replication;negative results",
      "IEEE_Terms": "Computer bugs;Measurement;Predictive models;Software systems;Complexity theory;History",
      "Article Citation Count": "12",
      "Reference Count": "92",
      "License": "IEEE",
      "Online Date": "5-Apr-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Automatic Recovery of Missing Issue Type Labels",
      "Authors": "F. Elzanaty; C. Rezk; S. Lijbrink; W. van Bergen; M. Cote; S. McIntosh",
      "Author Affiliations": "Electrical and Computer Engineering, McGill University, Montreal, QC, Canada; McGill University; Shopify, Inc.; Shopify, Inc.; Shopify, Inc.; University of Waterloo",
      "Publication Title": "IEEE Software",
      "Date Added To Xplore": "19-Apr-21",
      "Publication Year": "2021",
      "Volume": "38",
      "Issue": "3",
      "Start Page": "35",
      "End Page": "42",
      "Abstract": "Ag ile software organizations empower developers to make appropriate decisions rather than enforce adherence to a process, resulting in incomplete and noisy data in software archives. Since software analytics techniques are trained using this data, automated techniques are required to recover it.",
      "ISSN": "1937-4194",
      "DOI": "10.1109/MS.2020.3004060",
      "Funding Information": "Natural Sciences and Engineering Research Council of Canada(grant numbers:EGP/531224-2018); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121712",
      "IEEE_Terms": "Data models;Computer bugs;Organizations;Feature extraction;Manuals;Training",
      "Article Citation Count": "5",
      "Reference Count": "14",
      "License": "IEEE",
      "Online Date": "19-Jun-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Magazines"
    },
    {
      "Document Title": "ComboDroid: Generating High-Quality Test Inputs for Android Apps via Use Case Combinations",
      "Authors": "J. Wang; Y. Jiang; C. Xu; C. Cao; X. Ma; J. Lu",
      "Author Affiliations": "Department of Computer Science and Technology, State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; Department of Computer Science and Technology, State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; Department of Computer Science and Technology, State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; Department of Computer Science and Technology, State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; Department of Computer Science and Technology, State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China; Department of Computer Science and Technology, State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China",
      "Publication Title": "2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "21-Dec-20",
      "Publication Year": "2020",
      "Start Page": "469",
      "End Page": "480",
      "Abstract": "Android apps demand high-quality test inputs, whose generation remains an open challenge. Existing techniques fall short on exploring complex app functionalities reachable only by a long, meaningful, and effective test input. Observing that such test inputs can usually be decomposed into relatively independent short use cases, this paper presents ComboDroid, a fundamentally different Android app testing framework. ComboDroid obtains use cases for manifesting a specific app functionality (either manually provided or automatically extracted), and systematically enumerates the combinations of use cases, yielding high-quality test inputs. The evaluation results of ComboDroid on real-world apps are encouraging. Our fully automatic variant outperformed the best existing technique APE by covering 4.6% more code (APE only outperformed Monkey by 2.1%), and revealed four previously unknown bugs in extensively tested subjects. Our semi-automatic variant boosts the manual use cases obtained with little manual labor, achieving a comparable coverage (only 3.2% less) with a white-box human testing expert.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-7121-6",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9283926",
      "Author_Keywords": "Software testing;mobile apps",
      "IEEE_Terms": "Computer bugs;Manuals;Software;Testing;Software engineering",
      "Article Citation Count": "3",
      "Reference Count": "69",
      "Online Date": "21-Dec-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Reflection on ‚ÄúAn Exploratory Study on Exception Handling Bugs in Java Programs‚Äù",
      "Authors": "F. Ebert; F. Castor; A. Serebrenik",
      "Author Affiliations": "Federal University of Pernambuco, Brazil; Federal University of Pernambuco, Brazil; Eindhoven University of Technology, The Netherlands",
      "Publication Title": "2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "2-Apr-20",
      "Publication Year": "2020",
      "Start Page": "552",
      "End Page": "556",
      "Abstract": "Exception handling is a feature provided by most mainstream programming languages, and typically involves constructs to throw and handle error signals. On the one hand, early work has argued extensively about the benefits of exception handling, such as promoting modularity by defining how exception handlers can be implemented and maintained independently of the normal behavior of the system and easing but localization. On the other hand, some studies argue that exception handling can make the programming languages unnecessarily complex and promote the introduction of subtle bugs in programs. In 2015 we published a paper describing a study investigating the prevalence and nature of exception handling bugs in two large, widely adopted Java systems. This study also confronted its findings about real exception handling bugs with the perceptions of developers about those bugs, also accounting for bugs not related to exception handling. The goal of this reflection paper is to investigate the state of the art in exception handling research, with a particular emphasis on exception handling bugs, and how our paper has influenced other studies in the area. We found that our paper was cited by 33 articles, and all themes for future work we raised in our paper have been tackled by other studies in the short span of five years.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-7281-5143-4",
      "DOI": "10.1109/SANER48275.2020.9054791",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054791",
      "Author_Keywords": "Exception handling;bugs;reflection study",
      "IEEE_Terms": "Location awareness;Java;Computer languages;Conferences;Computer bugs;Reflection;Software",
      "Article Citation Count": "2",
      "Reference Count": "48",
      "License": "IEEE",
      "Online Date": "2-Apr-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "SATune: A Study-Driven Auto-Tuning Approach for Configurable Software Verification Tools",
      "Authors": "U. Koc; A. Mordahl; S. Wei; J. S. Foster; A. A. Porter",
      "Author Affiliations": "Department of Computer Science, University of Maryland, College Park, MD, USA; Department of Computer Science, The University of Texas at Dallas, Richardson, TX, USA; Department of Computer Science, The University of Texas at Dallas, Richardson, TX, USA; Department of Computer Science, Tufts University, Medford, MA, USA; Department of Computer Science, University of Maryland, College Park, MD, USA",
      "Publication Title": "2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "20-Jan-22",
      "Publication Year": "2021",
      "Start Page": "330",
      "End Page": "342",
      "Abstract": "Many program verification tools can be customized via run-time configuration options that trade off performance, precision, and soundness. However, in practice, users often run tools under their default configurations, because understanding these tradeoffs requires significant expertise. In this paper, we ask how well a single, default configuration can work in general, and we propose SATune, a novel tool for automatically configuring program verification tools for given target programs. To answer our question, we gathered a dataset that runs four well-known program verification tools against a range of C and Java benchmarks, with results labeled as correct, incorrect, or inconclusive (e.g., timeout). Examining the dataset, we find there is generally no one-size-fits-all best configuration. Moreover, a statistical analysis shows that many individual configuration options do not have simple tradeoffs: they can be better or worse depending on the program.Motivated by these results, we developed SATune, which constructs configurations using a meta-heuristic search. The search is guided by a surrogate fitness function trained on our dataset. We compare the performance of SATune to three baselines: a single configuration with the most correct results in our dataset; the most precise configuration followed by the most correct configuration (if needed); and the most precise configuration followed by random search (also if needed). We find that SATune outperforms these approaches by completing more correct tasks with high precision. In summary, our work shows that good configurations for verification tools are not simple to find, and SATune takes an important step towards automating the process of finding them.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-6654-0337-5",
      "DOI": "10.1109/ASE51524.2021.9678761",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9678761",
      "Author_Keywords": "Empirical software engineering;software analysisvtesting;verification;validation",
      "IEEE_Terms": "Java;Statistical analysis;Benchmark testing;Software;Task analysis;Software engineering",
      "Article Citation Count": "2",
      "Reference Count": "75",
      "License": "IEEE",
      "Online Date": "20-Jan-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Data Set of Program Invariants and Error Paths",
      "Authors": "D. Beyer",
      "Author Affiliations": "LMU, Munich, Germany",
      "Publication Title": "2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "29-Aug-19",
      "Publication Year": "2019",
      "Start Page": "111",
      "End Page": "115",
      "Abstract": "The analysis of correctness proofs and counterexamples of program source code is an important way to gain insights into methods that could make it easier in the future to find invariants to prove a program correct or to find bugs. The availability of high-quality data is often a limiting factor for researchers who want to study real program invariants and real bugs. The described data set provides a large collection of concrete verification results, which can be used in research projects as data source or for evaluation purposes. Each result is made available as verification witness, which represents either program invariants that were used to prove the program correct (correctness witness) or an error path to replay the actual bug (violation witness). The verification results are taken from actual verification runs on 10522 verification problems, using the 31 verification tools that participated in the 8th edition of the International Competition on Software Verification (SV-COMP). The collection contains a total of 125720 verification witnesses together with various meta data and a map to relate a witness to the C program that it originates from. Data set is available at: https://doi.org/10.5281/zenodo.2559175.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-7281-3412-3",
      "DOI": "10.1109/MSR.2019.00026",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8816801",
      "Author_Keywords": "Invariant Mining, Program Comprehension, Formal Verification, Model Checking, Program Analysis, Verification Witnesses, Program Invariants, Error Paths, Bugs",
      "IEEE_Terms": "Software;Tools;Metadata;Computer bugs;Benchmark testing;Automata;Standards",
      "Article Citation Count": "1",
      "Reference Count": "43",
      "License": "IEEE",
      "Online Date": "29-Aug-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Prediction of Bug Inducing Commits Using Metrics Trend Analysis",
      "Authors": "P. Parul; K. Kontogiannis; C. Brealey",
      "Author Affiliations": "Computer Science Dept., Western University, London, ON, Canada; Dept. of Electr. Eng. & Comp. Sci., York University, Toronto, ON, Canada; IBM Toronto Lab, IBM Canada, Toronto, ON, Canada",
      "Publication Title": "2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "2-Aug-23",
      "Publication Year": "2023",
      "Start Page": "830",
      "End Page": "839",
      "Abstract": "Continuous software engineering advocates a release-small, release-often process model, where new functionality is added to a system very frequently and in small increments. In such a process model, it is important to be able to identify as early as possible, and every time a change is introduced, whether the system has entered a state where faults are more likely to occur. In this paper, we present a method that is based on process, quality, and source code metrics to evaluate the likelihood that an imminent bug inducing commit is highly probable. More specifically, the method analyzes the correlations, and the rate of change of selected structural and quality metrics. The findings from the SonarQube Technical Debt open-source dataset indicate that before bug inducing commits, metrics which otherwise are not corelated, suddenly exhibit a high correlation or high rate of metric value change. This metric behavior can then be used as a predictor for a imminent bug inducing commit. The technique is programing language agnostic, as it is based on metrics which are extracted without the use of specialized parsers, and can be applied to forewarn developers that a file, or a collection of files, has entered a state where faults are highly probable.",
      "ISSN": "0730-3157",
      "ISBNs": "979-8-3503-2697-0",
      "DOI": "10.1109/COMPSAC57700.2023.00112",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10196950",
      "Author_Keywords": "Fault prediction;process metrics;quality metrics;quantitative analysis",
      "IEEE_Terms": "Measurement;Correlation;Statistical analysis;Source coding;Computer bugs;Market research;Software",
      "Reference Count": "42",
      "License": "IEEE",
      "Online Date": "2-Aug-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Hyperparameter Optimization for AST Differencing",
      "Authors": "M. Martinez; J. -R. Falleri; M. Monperrus",
      "Author Affiliations": "Universitat Polit√®cnica de Catalunya, CP, Barcelona, Spain; CNRS, Bordeaux INP, LaBRI, Univ. Bordeaux, Talence, France; KTH Royal Institute of Technology, Sweden",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "16-Oct-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "10",
      "Start Page": "4814",
      "End Page": "4828",
      "Abstract": "Computing the differences between two versions of the same program is an essential task for software development and software evolution research. AST differencing is the most advanced way of doing so, and an active research area. Yet, AST differencing algorithms rely on configuration parameters that may have a strong impact on their effectiveness. In this paper, we present a novel approach named DAT (D iff Auto Tuning) for hyperparameter optimization of AST differencing. We thoroughly state the problem of hyper-configuration for AST differencing. We evaluate our data-driven approach DAT to optimize the edit-scripts generated by the state-of-the-art AST differencing algorithm named GumTree in different scenarios. DAT is able to find a new configuration for GumTree that improves the edit-scripts in 21.8% of the evaluated cases.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2023.3315935",
      "Funding Information": "Ministerio de Ciencia e Innovaci√≥n(grant numbers:RYC2021-031523-I); GAISSA Spanish research(grant numbers:TED2021-130923B-I00); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10286467",
      "Author_Keywords": "Software evolution;Tree differencing;Abstract Syntax Trees (AST);hyperparameter optimization, edit-script",
      "IEEE_Terms": "Training;Software algorithms;Computer bugs;Syntactics;Maintenance engineering;Hyperparameter optimization;Software",
      "Reference Count": "55",
      "License": "IEEE",
      "Online Date": "16-Oct-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "TRADER: Trace Divergence Analysis and Embedding Regulation for Debugging Recurrent Neural Networks",
      "Authors": "G. Tao; S. Ma; Y. Liu; Q. Xu; X. Zhang",
      "Author Affiliations": "Purdue University; Rutgers University; Purdue University; Purdue University; Purdue University",
      "Publication Title": "2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "21-Dec-20",
      "Publication Year": "2020",
      "Start Page": "986",
      "End Page": "998",
      "Abstract": "Recurrent Neural Networks (RNN) can deal with (textual) input with various length and hence have a lot of applications in software systems and software engineering applications. RNNs depend on word embeddings that are usually pre-trained by third parties to encode textual inputs to numerical values. It is well known that problematic word embeddings can lead to low model accuracy. In this paper, we propose a new technique to automatically diagnose how problematic embeddings impact model performance, by comparing model execution traces from correctly and incorrectly executed samples. We then leverage the diagnosis results as guidance to harden/repair the embeddings. Our experiments show that TRADER can consistently and effectively improve accuracy for real world models and datasets by 5.37% on average, which represents substantial improvement in the literature of RNN models.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-7121-6",
      "Funding Information": "DARPA(grant numbers:FA8650-15-C-7562); NSF(grant numbers:1748764,1901242,1910300); ONR(grant numbers:N000141410468,N000141712947); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284017",
      "IEEE_Terms": "Analytical models;Recurrent neural networks;Software algorithms;Software systems;Regulation;Numerical models;Software engineering",
      "Article Citation Count": "1",
      "Reference Count": "103",
      "Online Date": "21-Dec-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "ApacheJIT: A Large Dataset for Just-In-Time Defect Prediction",
      "Authors": "H. Keshavarz; M. Nagappan",
      "Author Affiliations": "David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, Ontario, Canada; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, Ontario, Canada",
      "Publication Title": "2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "21-Jun-22",
      "Publication Year": "2022",
      "Start Page": "191",
      "End Page": "195",
      "Abstract": "In this paper, we present ApacheJIT, a large dataset for Just-In-Time (JIT) defect prediction. ApacheJIT consists of clean and bug-inducing software changes in 14 popular Apache projects. ApacheJIT has a total of 106,674 commits (28,239 bug-inducing and 78,435 clean commits). Having a large number of commits makes ApacheJIT a suitable dataset for machine learning JIT models, especially deep learning models that require large training sets to effectively generalize the patterns present in the historical data to future data.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-4503-9303-4",
      "DOI": "10.1145/3524842.3527996",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796180",
      "Author_Keywords": "Defect Prediction;Software Engineering;Dataset",
      "IEEE_Terms": "Training;Deep learning;Computer bugs;Predictive models;Data models;Software;Data mining",
      "Article Citation Count": "4",
      "Reference Count": "26",
      "Online Date": "21-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Concept-Based Classification of Software Defect Reports",
      "Authors": "S. Patil",
      "Author Affiliations": "Dept. of Computer Science and Engg., IIT Madras, India",
      "Publication Title": "2017 IEEE/ACM 14th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "3-Jul-17",
      "Publication Year": "2017",
      "Start Page": "182",
      "End Page": "186",
      "Abstract": "Automatic identification of the defect type from the textual description of a software defect can significantly speed-up as well as improve the software defect management life-cycle. This has been recognized in the research community and multiple solutions based on supervised learning approach have been proposed in the recent literature. However, these approaches need significant amount of labeled training data for use in real-life projects. In this paper, we propose to use Explicit Semantic Analysis (ESA) to carry out concept-based classification of software defect reports. We compute the \"semantic similarity\" between the defect type labels and the defect report in a concept space spanned by Wikipedia articles and then, assign the defect type which has the highest similarity with the defect report. This approach helps us to circumvent the problem of dependence on labeled training data. Experimental results show that using concept-based classification is a promising approach for software defect classification to avoid the expensive process of creating labeled training data and yet get accuracy comparable to the traditional supervised learning approaches. To the best of our knowledge, this is the first use of Wikipedia and ESA for software defect classification problem.",
      "ISBNs": "978-1-5386-1544-7",
      "DOI": "10.1109/MSR.2017.20",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7962367",
      "Author_Keywords": "Software Defect Classification;Explicit Semantic Analysis;Mining Software Respositories;Text Data Mining",
      "IEEE_Terms": "Software;Encyclopedias;Electronic publishing;Internet;Training data;Semantics",
      "Article Citation Count": "3",
      "Reference Count": "12",
      "License": "IEEE",
      "Online Date": "3-Jul-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Unleashing the Power of Compiler Intermediate Representation to Enhance Neural Program Embeddings",
      "Authors": "Z. Li; P. Ma; H. Wang; S. Wang; Q. Tang; S. Nie; S. Wu",
      "Author Affiliations": "The Hong Kong University of Science and Technology, Hong Kong SAR; The Hong Kong University of Science and Technology, Hong Kong SAR; The Hong Kong University of Science and Technology, Hong Kong SAR; The Hong Kong University of Science and Technology, Hong Kong SAR; Tencent Security Keen Lab, China; Tencent Security Keen Lab, China; Tencent Security Keen Lab, China",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "2253",
      "End Page": "2265",
      "Abstract": "Neural program embeddings have demonstrated considerable promise in a range of program analysis tasks, including clone identification, program repair, code completion, and program synthesis. However, most existing methods generate neural program embeddings di-rectly from the program source codes, by learning from features such as tokens, abstract syntax trees, and control flow graphs. This paper takes a fresh look at how to improve program embed-dings by leveraging compiler intermediate representation (IR). We first demonstrate simple yet highly effective methods for enhancing embedding quality by training embedding models alongside source code and LLVM IR generated by default optimization levels (e.g., -02). We then introduce IRGEN, a framework based on genetic algorithms (GA), to identify (near-)optimal sequences of optimization flags that can significantly improve embedding quality. We use IRGEN to find optimal sequences of LLVM optimization flags by performing GA on source code datasets. We then extend a popular code embedding model, CodeCMR, by adding a new objective based on triplet loss to enable a joint learning over source code and LLVM IR. We benchmark the quality of embedding using a rep-resentative downstream application, code clone detection. When CodeCMR was trained with source code and LLVM IRs optimized by findings of IRGEN, the embedding quality was significantly im-proved, outperforming the state-of-the-art model, CodeBERT, which was trained only with source code. Our augmented CodeCMR also outperformed CodeCMR trained over source code and IR optimized with default optimization levels. We investigate the properties of optimization flags that increase embedding quality, demonstrate IRGEN's generalization in boosting other embedding models, and establish IRGEN's use in settings with extremely limited training data. Our research and findings demonstrate that a straightforward addition to modern neural code embedding models can provide a highly effective enhancement.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3510217",
      "Funding Information": "CCF-Tencent Open Research Fund; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793906",
      "Author_Keywords": "program embedding;deep learing;compiler technique",
      "IEEE_Terms": "Training;Codes;Program processors;Cloning;Training data;Syntactics;Task analysis",
      "Article Citation Count": "3",
      "Reference Count": "106",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "SYMTUNER: Maximizing the Power of Symbolic Execution by Adaptively Tuning External Parameters",
      "Authors": "S. Cha; M. Lee; S. Lee; H. Oh",
      "Author Affiliations": "Sungkyunkwan University, Republic of Korea; Korea University, Republic of Korea; Korea University, Republic of Korea; Korea University, Republic of Korea",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "2068",
      "End Page": "2079",
      "Abstract": "We present SYMTUNER, a novel technique to automatically tune external parameters of symbolic execution. Practical symbolic execution tools have important external parameters (e.g., symbolic arguments, seed input) that critically affect their performance. Due to the huge parameter space, however, manually customizing those parameters is notoriously difficult even for experts. As a consequence, symbolic execution tools have typically been used in a suboptimal manner that, for example, simply relies on the default parameter settings of the tools and loses the opportunity for better performance. In this paper, we aim to change this situation by automatically configuring symbolic execution parameters. With Symtuner that takes parameter spaces to be tuned, symbolic executors are run without manual parameter configurations; instead, appropriate parameter values are learned and adjusted during symbolic execution. To achieve this, we present a learning algorithm that observes the behavior of symbolic execution and accordingly updates the sampling probability of each parameter space. We evaluated Symtuner with KLEE on 12 open-source C programs. The results show that Symtuner increases branch coverage of KLEE by 56% on average and finds 8 more bugs than KLEE with its default parameters over the latest releases of the programs.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3510185",
      "Funding Information": "Institute of Information & communications Technology Planning & Evaluation (IITP); National Research Foundation of Korea (NRF); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794116",
      "Author_Keywords": "Symbolic Execution;Software Testing",
      "IEEE_Terms": "Computer bugs;Manuals;Behavioral sciences;Tuning;Open source software;Software engineering",
      "Reference Count": "66",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Automatic Extraction of Opinion-Based Q&A from Online Developer Chats",
      "Authors": "P. Chatterjee; K. Damevski; L. Pollock",
      "Author Affiliations": "University of Delaware, Newark, DE, USA; Virginia Commonwealth University, Richmond, VA, USA; University of Delaware, Newark, DE, USA",
      "Publication Title": "2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "7-May-21",
      "Publication Year": "2021",
      "Start Page": "1260",
      "End Page": "1272",
      "Abstract": "Virtual conversational assistants designed specifically for software engineers could have a huge impact on the time it takes for software engineers to get help. Research efforts are focusing on virtual assistants that support specific software development tasks such as bug repair and pair programming. In this paper, we study the use of online chat platforms as a resource towards collecting developer opinions that could potentially help in building opinion Q&A systems, as a specialized instance of virtual assistants and chatbots for software engineers. Opinion Q&A has a stronger presence in chats than in other developer communications, thus mining them can provide a valuable resource for developers in quickly getting insight about a specific development topic (e.g., What is the best Java library for parsing JSON?). We address the problem of opinion Q&A extraction by developing automatic identification of opinion-asking questions and extraction of participants' answers from public online developer chats. We evaluate our automatic approaches on chats spanning six programming communities and two platforms. Our results show that a heuristic approach to opinion-asking questions works well (.87 precision), and a deep learning approach customized to the software domain outperforms heuristics-based, machine-learning-based and deep learning for answer extraction in community question answering.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-0296-5",
      "DOI": "10.1109/ICSE43902.2021.00115",
      "Funding Information": "National Science Foundation; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9402078",
      "Author_Keywords": "opinion question-answering system;public chats;opinion-asking question;answer extraction",
      "IEEE_Terms": "Deep learning;Virtual assistants;Programming;Maintenance engineering;Software;Task analysis;Software engineering",
      "Article Citation Count": "10",
      "Reference Count": "81",
      "License": "IEEE",
      "Online Date": "7-May-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Explaining Software Bugs Leveraging Code Structures in Neural Machine Translation",
      "Authors": "P. Mahbub; O. Shuvo; M. M. Rahman",
      "Author Affiliations": "Department of Computer Science, Dalhousie University, Nova Scotia, Canada; Department of Computer Science, Dalhousie University, Nova Scotia, Canada; Department of Computer Science, Dalhousie University, Nova Scotia, Canada",
      "Publication Title": "2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "14-Jul-23",
      "Publication Year": "2023",
      "Start Page": "640",
      "End Page": "652",
      "Abstract": "Software bugs claim ‚âà 50 % of development time and cost the global economy billions of dollars. Once a bug is reported, the assigned developer attempts to identify and understand the source code responsible for the bug and then corrects the code. Over the last five decades, there has been significant research on automatically finding or correcting software bugs. However, there has been little research on automatically explaining the bugs to the developers, which is essential but a highly challenging task. In this paper, we propose Bugsplainer, a transformer-based generative model, that generates natural language explanations for software bugs by learning from a large corpus of bug-fix commits. Bugsplainer can leverage structural information and buggy patterns from the source code to generate an explanation for a bug. Our evaluation using three performance metrics shows that Bugsplainer can generate understandable and good explanations according to Google's standard, and can outperform multiple baselines from the literature. We also conduct a developer study involving 20 participants where the explanations from Bugsplainer were found to be more accurate, more precise, more concise and more useful than the baselines.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-5701-9",
      "DOI": "10.1109/ICSE48619.2023.00063",
      "Funding Information": "Dalhousie University; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172643",
      "Author_Keywords": "software bug;bug explanation;software engineering;software maintenance;natural language processing;deep learning;transformers",
      "IEEE_Terms": "Measurement;Codes;Source coding;Computer bugs;Natural languages;Transformers;Software",
      "Article Citation Count": "5",
      "Reference Count": "63",
      "License": "IEEE",
      "Online Date": "14-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Causality-Based Neural Network Repair",
      "Authors": "B. Sun; J. Sun; L. H. Pham; T. Shi",
      "Author Affiliations": "Singapore Management University; Singapore Management University; Singapore Management University; Huawei Singapore",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "338",
      "End Page": "349",
      "Abstract": "Neural networks have had discernible achievements in a wide range of applications. The wide-spread adoption also raises the concern of their dependability and reliability. Similar to traditional decision-making programs, neural networks can have defects that need to be repaired. The defects may cause unsafe behaviors, raise security concerns or unjust societal impacts. In this work, we address the problem of repairing a neural network for desirable properties such as fairness and the absence of backdoor. The goal is to construct a neural network that satisfies the property by (minimally) adjusting the given neural network's parameters (i.e., weights). Specifically, we propose CARE (CAusality-based REpair), a causality-based neural network repair technique that 1) performs causality-based fault localization to identify the ‚Äòguilty‚Äô neurons and 2) optimizes the parameters of the identified neurons to reduce the misbehavior. We have empirically evaluated CARE on various tasks such as backdoor removal, neural network repair for fairness and safety properties. Our experiment results show that CARE is able to repair all neural networks efficiently and effectively. For fairness repair tasks, CARE successfully improves fairness by 61.91 % on average. For backdoor removal tasks, CARE reduces the attack success rate from over 98% to less than 1 %. For safety property repair tasks, CARE reduces the property violation rate to less than 1 %. Results also show that thanks to the causality-based fault localization, CARE's repair focuses on the misbehavior and preserves the accuracy of the neural networks.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3510080",
      "Funding Information": "Huawei International(grant numbers:TC20210714014); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793926",
      "Author_Keywords": "Machine Learning with and for SE;Program Repair;Fault Localization",
      "IEEE_Terms": "Location awareness;Fault diagnosis;Neurons;Maintenance engineering;Safety;Behavioral sciences;Security",
      "Article Citation Count": "9",
      "Reference Count": "73",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Identification of an IoT Device Model in the Home Domain Using IPFIX Records",
      "Authors": "N. Okui; M. Nakahara; Y. Miyake; A. Kubota",
      "Author Affiliations": "KDDI Research, Inc, Saitama, Japan; KDDI Research, Inc, Saitama, Japan; KDDI Research, Inc, Saitama, Japan; KDDI Research, Inc, Saitama, Japan",
      "Publication Title": "2022 IEEE 46th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "10-Aug-22",
      "Publication Year": "2022",
      "Start Page": "583",
      "End Page": "592",
      "Abstract": "With the widespread adoption of the Internet of Things (loT), a large number of diverse devices are now con-nected to the internet, and the number and variety of these devices are expected to increase in the future. Various manu-facturers have entered the consumer loT (home loT) market, and users can purchase a wide variety of devices such as smart speakers, network cameras, and home appliances. Some loT devices with security vulnerabilities have been reported, and the number of cyberattacks targeting loT devices is increasing, so the use of loT devices may involve security risks. One way to protect users and networks from such security risks to loT devices is to identify and manage loT devices connected to the network. This allows us to detect devices that pose a security risk. This research discusses development and evaluation of a method to estimate the models of loT devices connected to a home gateway using communication data sent from the devices. With regard to traffic data, IPFIX, a standard for flow information, is used for communication packets captured on the home gateway. By using IPFIX, the number of data records was reduced to approximately 11% compared to the number of traffic packets. Since IPFIX does not have information on the application layer in the TCP/IP model, the information available from IPFIX records is limited compared to traffic packets. Our method was evaluated using the traffic data of 25 different loT devices released by 19 vendors and obtained 98.48% precision.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-6654-8810-5",
      "DOI": "10.1109/COMPSAC54236.2022.00104",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9842469",
      "Author_Keywords": "IoT device identification;IPFIX;time window;machine learning",
      "IEEE_Terms": "Training data;TCPIP;Logic gates;Data models;Software;Object recognition;Security",
      "Article Citation Count": "2",
      "Reference Count": "39",
      "License": "IEEE",
      "Online Date": "10-Aug-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Defect Detection of Metal Nuts Applying Convolutional Neural Networks",
      "Authors": "D. Sauter; A. Schmitz; F. Dikici; H. Baumgartl; R. Buettner",
      "Author Affiliations": "Aalen University, Aalen, Germany; Aalen University, Aalen, Germany; Aalen University, Aalen, Germany; Aalen University, Aalen, Germany; Aalen University, Aalen, Germany",
      "Publication Title": "2021 IEEE 45th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "9-Sep-21",
      "Publication Year": "2021",
      "Start Page": "248",
      "End Page": "257",
      "Abstract": "Since the human inspection of small metal parts is complex, time-consuming and prone to human error, a convolutional neural network for the detection of defects on metal nuts was developed in order to grant fast and robust quality controls. For this approach, we built an image classification algorithm based on the Xception architecture. The evaluation of the trained model is robust and achieves reliable results after applying a hold-out 5-fold cross-validation. Implementing this algorithm on the MVTec Anomaly Detection dataset outperforms the existing benchmark on defect detection for metal nuts with a balanced accuracy of 90.00% and a value of 0.99 for the area under the curve.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-6654-2463-9",
      "DOI": "10.1109/COMPSAC51774.2021.00043",
      "Funding Information": "Ministry of Education; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9529439",
      "Author_Keywords": "CNN;quality assessment;deep learning;Xception",
      "IEEE_Terms": "Manufacturing industries;Image recognition;Computational modeling;Metals;Quality control;Computer architecture;Inspection",
      "Article Citation Count": "3",
      "Reference Count": "63",
      "License": "IEEE",
      "Online Date": "9-Sep-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Learning from examples: generation and evaluation of decision trees for software resource analysis",
      "Authors": "R. W. Selby; A. A. Porter",
      "Author Affiliations": "Department of Information and Computer Science., University of California, Irvine, CA, USA; Department of Information and Computer Science., University of California, Irvine, CA, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "6-Aug-02",
      "Publication Year": "1988",
      "Volume": "14",
      "Issue": "12",
      "Start Page": "1743",
      "End Page": "1757",
      "Abstract": "A general solution method for the automatic generation of decision (or classification) trees is investigated. The approach is to provide insights through in-depth empirical characterization and evaluation of decision trees for one problem domain, specifically, that of software resource data analysis. The purpose of the decision trees is to identify classes of objects (software modules) that had high development effort, i.e. in the uppermost quartile relative to past data. Sixteen software systems ranging from 3000 to 112000 source lines have been selected for analysis from a NASA production environment. The collection and analysis of 74 attributes (or metrics), for over 4700 objects, capture a multitude of information about the objects: development effort, faults, changes, design style, and implementation style. A total of 9600 decision trees are automatically generated and evaluated. The analysis focuses on the characterization and evaluation of decision tree accuracy, complexity, and composition. The decision trees correctly identified 79.3% of the software modules that had high development effort or faults, on the average across all 9600 trees. The decision trees generated from the best parameter combinations correctly identified 88.4% of the modules on the average. Visualization of the results is emphasized, and sample decision trees are included.<>",
      "ISSN": "1939-3520",
      "DOI": "10.1109/32.9061",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9061",
      "IEEE_Terms": "Decision trees;Machine learning;Fault diagnosis;Classification tree analysis;Data analysis;Software systems;NASA;Information analysis;Termination of employment;Analysis of variance",
      "Article Citation Count": "161",
      "Patent Citation Count": "1",
      "Reference Count": "56",
      "License": "IEEE",
      "Online Date": "6-Aug-02",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "UDA-DP: Unsupervised Domain Adaptation for Software Defect Prediction",
      "Authors": "X. Huang; Y. Wu; H. Liu; Y. Li; H. Yu; D. Guo; Z. Wu",
      "Author Affiliations": "Peking University, Beijing, China; Peking University, Beijing, China; Peking University, Beijing, China; Peking University, Beijing, China; Peking University, Beijing, China; Peking University, Beijing, China; Peking University, Beijing, China",
      "Publication Title": "2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "15-May-23",
      "Publication Year": "2023",
      "Start Page": "308",
      "End Page": "318",
      "Abstract": "Software defect prediction can automatically locate defective code modules to focus testing resources better. Traditional defect prediction methods mainly focus on manually designing features, which are input into machine learning classifiers to identify defective code. However, there are mainly two problems in prior works. First manually designing features is time consuming and unable to capture the semantic information of programs, which is an important capability for accurate defect prediction. Second the labeled data is limited along with severe class imbalance, affecting the performance of defect prediction.In response to the above problems, we first propose a new unsupervised domain adaptation method using pseudo labels for defect prediction(UDA-DP). Compared to manually designed features, it can automatically extract defective features from source programs to save time and contain more semantic information of programs. Moreover, unsupervised domain adaptation using pseudo labels is a kind of transfer learning, which is effective in leveraging rich information of limited data, alleviating the problem of insufficient data.Experiments with 10 open source projects from the PROMISE data set show that our proposed UDA-DP method outperforms the state-of-the-art methods for both within-project and cross-project defect predictions. Our code and data are available at https://github.com/xsarvin/UDA-DP.",
      "ISSN": "2640-7574",
      "ISBNs": "978-1-6654-5278-6",
      "DOI": "10.1109/SANER56733.2023.00037",
      "Funding Information": "Ant Group; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10123459",
      "Author_Keywords": "Within-project defect prediction;cross-project defect prediction;match-filter module;dual-channel attention model",
      "IEEE_Terms": "Analytical models;Adaptation models;Codes;Semantics;Transfer learning;Predictive models;Feature extraction",
      "Article Citation Count": "1",
      "Reference Count": "47",
      "License": "IEEE",
      "Online Date": "15-May-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Human-in-the-Loop Automatic Program Repair",
      "Authors": "C. Geethal; M. B√∂hme; V. -T. Pham",
      "Author Affiliations": "Monash University, Clayton, VIC, Australia; Monash University, Clayton, VIC, Australia; The University of Melbourne, Carlton, VIC, Australia",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "17-Oct-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "10",
      "Start Page": "4526",
      "End Page": "4549",
      "Abstract": "learn2fix is a human-in-the-loop interactive program repair technique, which can be applied when no bug oracle‚Äîexcept the user who is reporting the bug‚Äîis available. This approach incrementally learns the condition under which the bug is observed by systematic negotiation with the user. In this process, learn2fix generates alternative test inputs and sends some of those to the user for obtaining their labels. A limited query budget is assigned to the user for this task. A query is a Yes/No question: ‚ÄúWhen executing this alternative test input, the program under test produces the following output; is the bug observed?‚Äù. Using the labelled test inputs, learn2fix incrementally learns an automatic bug oracle to predict the user's response. A classification algorithm in machine learning is used for this task. Our key challenge is to maximise the oracle's accuracy in predicting the tests that expose the bug given a practical, small budget of queries. After learning the automatic oracle, an existing program repair tool attempts to repair the bug using the alternative tests that the user has labelled. Our experiments demonstrate that learn2fix trains a sufficiently accurate automatic oracle with a reasonably low labelling effort (lt. 20 queries), and the oracles represented by interpolation-based classifiers produce more accurate predictions than those represented by approximation-based classifiers. Given the user-labelled test inputs, generated using the interpolation-based approach, the GenProg and Angelix automatic program repair tools produce patches that pass a much larger proportion of validation tests than the manually constructed test suites provided by the repair benchmark.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2023.3305052",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10225252",
      "Author_Keywords": "Automated test oracles;semi-automatic program repair;classification algorithms;active machine learning",
      "IEEE_Terms": "Maintenance engineering;Computer bugs;Labeling;Classification algorithms;Human in the loop;Fuzzing;Training",
      "Reference Count": "70",
      "License": "CCBYNCND",
      "Online Date": "21-Aug-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Gamma: Revisiting Template-Based Automated Program Repair Via Mask Prediction",
      "Authors": "Q. Zhang; C. Fang; T. Zhang; B. Yu; W. Sun; Z. Chen",
      "Author Affiliations": "State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China; State Key Laboratory for Novel Software Technology, Nanjing University, China",
      "Publication Title": "2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "8-Nov-23",
      "Publication Year": "2023",
      "Start Page": "535",
      "End Page": "547",
      "Abstract": "Automated program repair (APR) aims to fix software bugs without manual debugging efforts and plays a crucial role in software development and maintenance. Template-based APR has been widely investigated and shown promising results. However, it is challenging for template-based APR to select the appropriate donor code, which is an important repair ingredient for generating candidate patches. Inappropriate donor code may cause plausible but incorrect patch generation even with correct fix patterns, limiting the repair performance. In this paper, we aim to revisit template-based APR, and propose Gamma, to directly leverage large pre-trained language models for donor code generation. Our main insight is that instead of retrieving donor code in the local buggy file, we can directly predict the correct code tokens based on the context code snippets and repair patterns by a cloze task. Specifically, (1) Gamma revises a variety of fix templates from state-of-the-art template-based APR techniques (i.e., TBar) and transforms them into mask patterns. (2) Gamma adopts a pre-trained language model to predict the correct code for masked code as a fill-in-the-blank task. Although our idea is general and can be built on various existing pre-trained language models, we have implemented Gamma as a practical APR tool based on the recent UniXcoder model. The experimental results demonstrate that Gamma correctly repairs 82 bugs on Defects4J-v1.2, which achieves 20.59% (14 bugs) and 26.15% (17 bugs) improvement over the previous state-of-the-art template-based approach TBar and learning-based one Recoder. Furthermore, Gamma repairs 45 bugs and 22 bugs from the additional Defects4J-v2.0 and QuixBugs, indicating the generalizability of Gamma in addressing the dataset overfitting issue. We also prove that adopting other pre-trained language models can provide substantial advancement, e.g., CodeBERT-based and ChatGPT-based Gamma is able to fix 80 and 67 bugs on Defects4J-v1.2, indicating the scalability of Gamma. Overall, our study highlights the promising future of adopting pre-trained models to generate correct patches on top of fix patterns in practice.",
      "ISSN": "2643-1572",
      "ISBNs": "979-8-3503-2996-4",
      "DOI": "10.1109/ASE56229.2023.00063",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:61932012,62141215); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298335",
      "Author_Keywords": "Automated Program Repair;Fix Pattern;Pretrained Model;LLM4SE",
      "IEEE_Terms": "Codes;Scalability;Computer bugs;Transforms;Manuals;Maintenance engineering;Predictive models",
      "Article Citation Count": "2",
      "Reference Count": "66",
      "License": "IEEE",
      "Online Date": "8-Nov-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Neutaint: Efficient Dynamic Taint Analysis with Neural Networks",
      "Authors": "D. She; Y. Chen; A. Shah; B. Ray; S. Jana",
      "Author Affiliations": "Columbia University; Columbia University; Columbia University; Columbia University; Columbia University",
      "Publication Title": "2020 IEEE Symposium on Security and Privacy (SP)",
      "Date Added To Xplore": "30-Jul-20",
      "Publication Year": "2020",
      "Start Page": "1527",
      "End Page": "1543",
      "Abstract": "Dynamic taint analysis (DTA) is widely used by various applications to track information flow during runtime execution. Existing DTA techniques use rule-based taint-propagation, which is neither accurate (i.e., high false positive rate) nor efficient (i.e., large runtime overhead). It is hard to specify taint rules for each operation while covering all corner cases correctly. Moreover, the overtaint and undertaint errors can accumulate during the propagation of taint information across multiple operations. Finally, rule-based propagation requires each operation to be inspected before applying the appropriate rules resulting in prohibitive performance overhead on large real-world applications.In this work, we propose Neutaint, a novel end-to-end approach to track information flow using neural program embeddings. The neural program embeddings model the target's programs computations taking place between taint sources and sinks, which automatically learns the information flow by observing a diverse set of execution traces. To perform lightweight and precise information flow analysis, we utilize saliency maps to reason about most influential sources for different sinks. Neutaint constructs two saliency maps, a popular machine learning approach to influence analysis, to summarize both coarse-grained and fine-grained information flow in the neural program embeddings.We compare Neutaint with 3 state-of-the-art dynamic taint analysis tools. The evaluation results show that Neutaint can achieve 68% accuracy, on average, which is 10% improvement while reducing 40√ó runtime overhead over the second-best taint tool Libdft on 6 real world programs. Neutaint also achieves 61% more edge coverage when used for taint-guided fuzzing indicating the effectiveness of the identified influential bytes. We also evaluate Neutaint's ability to detect real world software attacks. The results show that Neutaint can successfully detect different types of vulnerabilities including buffer/heap/integer overflows, division by zero, etc. Lastly, Neutaint can detect 98.7% of total flows, the highest among all taint analysis tools.",
      "ISSN": "2375-1207",
      "ISBNs": "978-1-7281-3497-0",
      "DOI": "10.1109/SP40000.2020.00022",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9152790",
      "IEEE_Terms": "Tools;Fuzzing;Runtime;Neural networks;Security;Performance analysis;Task analysis",
      "Article Citation Count": "18",
      "Reference Count": "64",
      "License": "IEEE",
      "Online Date": "30-Jul-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Syntactic Versus Semantic Similarity of Artificial and Real Faults in Mutation Testing Studies",
      "Authors": "M. Ojdanic; A. Garg; A. Khanfir; R. Degiovanni; M. Papadakis; Y. Le Traon",
      "Author Affiliations": "University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg; University of Luxembourg, Luxembourg",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "17-Jul-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "7",
      "Start Page": "3922",
      "End Page": "3938",
      "Abstract": "Fault seeding is typically used in empirical studies to evaluate and compare test techniques. Central to these techniques lies the hypothesis that artificially seeded faults involve some form of realistic properties and thus provide realistic experimental results. In an attempt to strengthen realism, a recent line of research uses machine learning techniques, such as deep learning and Natural Language Processing, to seed faults that look like (syntactically) real ones, implying that fault realism is related to syntactic similarity. This raises the question of whether seeding syntactically similar faults indeed results in semantically similar faults and, more generally whether syntactically dissimilar faults are far away (semantically) from the real ones. We answer this question by employing 4 state-of-the-art fault-seeding techniques (PiTest - a popular mutation testing tool, IBIR - a tool with manually crafted fault patterns, DeepMutation - a learning-based fault seeded framework and $\\mu$ŒºBERT - a mutation testing tool based on the pre-trained language model CodeBERT) that operate in a fundamentally different way, and demonstrate that syntactic similarity does not reflect semantic similarity. We also show that 65.11%, 76.44%, 61.39% and 9.76% of the real faults of Defects4J V2 are semantically resembled by PiTest, IBIR, $\\mu$ŒºBERT and DeepMutation faults, respectively.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2023.3277564",
      "Funding Information": "Luxembourg National Research Fund(grant numbers:C19/IS/13646587/RASoRS,PayPal); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10136793",
      "Author_Keywords": "Fault injection;fault seeding;machine learning;mutation testing;semantic model;syntactic distance",
      "IEEE_Terms": "Syntactics;Semantics;Testing;Measurement;Codes;Bit error rate;Pattern matching",
      "Article Citation Count": "1",
      "Reference Count": "57",
      "License": "CCBY",
      "Online Date": "26-May-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Detecting JVM JIT Compiler Bugs via Exploring Two-Dimensional Input Spaces",
      "Authors": "H. Jia; M. Wen; Z. Xie; X. Guo; R. Wu; M. Sun; K. Chen; H. Jin",
      "Author Affiliations": "School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Informatics, Xiamen University, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, China; School of Computer Science and Technology, Huazhong University of Science and Technology, China",
      "Publication Title": "2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "14-Jul-23",
      "Publication Year": "2023",
      "Start Page": "43",
      "End Page": "55",
      "Abstract": "Java Virtual Machine (JVM) is the fundamental software system that supports the interpretation and execution of Java bytecode. To support the surging performance demands for the increasingly complex and large-scale Java programs, Just-In-Time (JIT) compiler was proposed to perform sophisticated runtime optimization. However, this inevitably induces various bugs, which are becoming more pervasive over the decades and can often cause significant consequences. To facilitate the design of effective and efficient testing techniques to detect JIT compiler bugs. This study first performs a preliminary study aiming to understand the characteristics of JIT compiler bugs and the corresponding triggering test cases. Inspired by the empirical findings, we propose JOpFuzzer, a new JVM testing approach with a specific focus on JIT compiler bugs. The main novelty of JOpFuzzer is embodied in three aspects. First, besides generating new seeds, JOpFuzzer also searches for diverse configurations along the new dimension of optimization options. Second, JOpFuzzer learns the correlations between various code features and different optimization options to guide the process of seed mutation and option exploration. Third, it leverages the profile data, which can reveal the program execution information, to guide the fuzzing process. Such nov-elties enable JOpFuzzer to effectively and efficiently explore the two-dimensional input spaces. Extensive evaluation shows that JOpFuzzer outperforms the state-of-the-art approaches in terms of the achieved code coverages. More importantly, it has detected 41 bugs in OpenJDK, and 25 of them have already been confirmed or fixed by the corresponding developers.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-5701-9",
      "DOI": "10.1109/ICSE48619.2023.00016",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172514",
      "Author_Keywords": "JVM;JIT Compiler;JVM Testing",
      "IEEE_Terms": "Java;Codes;Runtime;Computer bugs;Fuzzing;Software systems;Virtual machining",
      "Article Citation Count": "1",
      "Reference Count": "43",
      "License": "IEEE",
      "Online Date": "14-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Suggesting Natural Method Names to Check Name Consistencies",
      "Authors": "S. Nguyen; H. Phan; T. Le; T. N. Nguyen",
      "Author Affiliations": "Univ. of Texas, Dallas, USA; Iowa State Univ., USA; U. of Eng. & Tech., Vietnam; Univ. of Texas, Dallas, USA",
      "Publication Title": "2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "21-Dec-20",
      "Publication Year": "2020",
      "Start Page": "1372",
      "End Page": "1384",
      "Abstract": "Misleading names of the methods in a project or the APIs in a software library confuse developers about program functionality and API usages, leading to API misuses and defects. In this paper, we introduce MNire, a machine learning approach to check the consistency between the name of a given method and its implementation. MNire first generates a candidate name and compares the current name against it. If the two names are sufficiently similar, we consider the method as consistent. To generate the method name, we draw our ideas and intuition from an empirical study on the nature of method names in a large dataset. Our key finding is that high proportions of the tokens of method names can be found in the three contexts of a given method including its body, the interface (the method's parameter types and return type), and the enclosing class' name. Even when such tokens are not there, MNire uses the contexts to predict the tokens due to the high likelihoods of their co-occurrences. Our unique idea is to treat the name generation as an abstract summarization on the tokens collected from the names of the program entities in the three above contexts. We conducted several experiments to evaluate MNire in method name consistency checking and in method name recommending on large datasets with +14M methods. In detecting inconsistency method names, MNire improves the state-of-the-art approach by 10.4% and 11% relatively in recall and precision, respectively. In method name recommendation, MNire improves relatively over the state-of-the-art technique, code2vec, in both recall (18.2% higher) and precision (11.1% higher). To assess MNire's usefulness, we used it to detect inconsistent methods and suggest new names in several active, GitHub projects. We made 50 pull requests (PRs) and received 42 responses. Among them, five PRs were merged into the main branch, and 13 were approved for later merging. In total, in 31/42 cases, the developer teams agree that our suggested names are more meaningful than the current names, showing MNire'S usefulness.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-7121-6",
      "Funding Information": "National Science Foundation (NSF)(grant numbers:CCF-1723215); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284075",
      "Author_Keywords": "Naturalness of Source Code;Program Entity Name Suggestion;Deep Learning",
      "IEEE_Terms": "Software libraries;Merging;Machine learning;Software development management",
      "Article Citation Count": "3",
      "Reference Count": "50",
      "Online Date": "21-Dec-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "The Art, Science, and Engineering of Fuzzing: A Survey",
      "Authors": "V. J. M. Man√®s; H. Han; C. Han; S. K. Cha; M. Egele; E. J. Schwartz; M. Woo",
      "Author Affiliations": "KAIST Cyber Security Research Center, Daejeon, Korea; KAIST, Daejeon, Korea; Naver Corp., Daejeon, Korea; KAIST, Daejeon, Korea; Boston University, Boston, MA, USA; Software Engineering Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "11-Nov-21",
      "Publication Year": "2021",
      "Volume": "47",
      "Issue": "11",
      "Start Page": "2312",
      "End Page": "2331",
      "Abstract": "Among the many software testing techniques available today, fuzzing has remained highly popular due to its conceptual simplicity, its low barrier to deployment, and its vast amount of empirical evidence in discovering real-world software vulnerabilities. At a high level, fuzzing refers to a process of repeatedly running a program with generated inputs that may be syntactically or semantically malformed. While researchers and practitioners alike have invested a large and diverse effort towards improving fuzzing in recent years, this surge of work has also made it difficult to gain a comprehensive and coherent view of fuzzing. To help preserve and bring coherence to the vast literature of fuzzing, this paper presents a unified, general-purpose model of fuzzing together with a taxonomy of the current fuzzing literature. We methodically explore the design decisions at every stage of our model fuzzer by surveying the related literature and innovations in the art, science, and engineering that make modern-day fuzzers effective.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2019.2946563",
      "Funding Information": "Institute of Information & communications Technology Planning & Evaluation(grant numbers:2019-0-01697); Development of Automated Vulnerability Discovery Technologies for Blockchain Platform Security; Siemens; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8863940",
      "Author_Keywords": "Software security;automated software testing;fuzzing;fuzz testing",
      "IEEE_Terms": "Fuzzing;Security;Computer bugs;Terminology",
      "Article Citation Count": "148",
      "Reference Count": "250",
      "License": "IEEE",
      "Online Date": "11-Oct-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "TAPInspector: Safety and Liveness Verification of Concurrent Trigger-Action IoT Systems",
      "Authors": "Y. Yu; J. Liu",
      "Author Affiliations": "National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Cybersecurity, Northwestern Polytechnical University, Xi‚Äôan, China; National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Cybersecurity, Northwestern Polytechnical University, Xi‚Äôan, China",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "25-Oct-22",
      "Publication Year": "2022",
      "Volume": "17",
      "Start Page": "3773",
      "End Page": "3788",
      "Abstract": "Trigger-action programming (TAP) is a popular end-user programming framework that can simplify the Internet of Things (IoT) automation with simple trigger-action rules. However, it also introduces new security and safety threats. A lot of advanced techniques have been proposed to address this problem. Rigorously reasoning about the security of a TAP-based IoT system requires a well-defined model and verification method both against rule semantics and physical-world features, e.g., concurrency, rule latency, extended action, tardy attributes, and connection-based rule interactions, which has been missing until now. By analyzing these features, we find 9 new types of rule interaction vulnerabilities and validate them on two commercial IoT platforms. We then present TAPInspector, a novel system to detect these interaction vulnerabilities in concurrent TAP-based IoT systems. It automatically extracts TAP rules from IoT apps, translates them into a hybrid model by model slicing and state compression, and performs semantic analysis and model checking with various safety and liveness properties. Our experiments corroborate that TAPInspector is practical: it identifies 533 violations related to rule interaction from 1108 real-world market IoT apps and is at least 60000 times faster than the baseline without optimization.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2022.3214084",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:62202387); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2021A1515110279); Natural Science Basic Research Program of Shaanxi(grant numbers:2022JQ-611); Fundamental Research Funds for the Central Universities(grant numbers:D5000210588); Jiangsu Provincial Double‚ÄìInnovation Doctor Program(grant numbers:JSSCBS20220949); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9916292",
      "Author_Keywords": "Trigger-action rule;concurrent model;rule latency;liveness property;model checking;Internet of Things",
      "IEEE_Terms": "Internet of Things;Security;Safety;Semantics;Delays;Analytical models;Model checking",
      "Article Citation Count": "4",
      "Reference Count": "47",
      "License": "IEEE",
      "Online Date": "12-Oct-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Linear-time Temporal Logic guided Greybox Fuzzing",
      "Authors": "R. Meng; Z. Dong; J. Li; I. Beschastnikh; A. Roychoudhury",
      "Author Affiliations": "National University of Singapore, Singapore; Fudan University China; National University of Singapore, Singapore; University of British Columbia, Canada; National University of Singapore, Singapore",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "1343",
      "End Page": "1355",
      "Abstract": "Software model checking as well as runtime verification are verification techniques which are widely used for checking temporal properties of software systems. Even though they are property verification techniques, their common usage in practice is in ‚Äúbug finding‚Äù, that is, finding violations of temporal properties. Motivated by this observation and leveraging the recent progress in fuzzing, we build a greybox fuzzing framework to find violations of Linear-time Temporal Logic (LTL) properties. Our framework takes as input a sequential program written in C/C++, and an LTL property. It finds violations, or counterexample traces, of the LTL property in stateful software systems; however, it does not achieve verification. Our work substantially extends directed greybox fuzzing to witness arbitrarily complex event or-derings. We note that existing directed greybox fuzzing approaches are limited to witnessing reaching a location or witnessing simple event orderings like use-after-free. At the same time, compared to model checkers, our approach finds the counterexamples faster, thereby finding more counterexamples within a given time budget. Our LTL-FUZZER tool, built on top of the AFL fuzzer, is shown to be effective in detecting bugs in well-known protocol implementations, such as OpenSSL and Telnet. We use LTL-FUZZER to reproduce known vulnerabilities (CVEs), to find 15 zero-day bugs by checking properties extracted from RFCs (for which 12 CVEs have been assigned), and to find violations of both safety as well as liveness properties in real-world protocol implementations. Our work represents a practical advance over software model checkers - while simultaneously representing a conceptual advance over existing greybox fuzzers. Our work thus provides a starting point for understanding the unexplored synergies among software model checking, runtime verification and greybox fuzzing.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3510082",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794100",
      "IEEE_Terms": "Runtime;Protocols;Computer bugs;Fuzzing;Model checking;Software systems;Safety",
      "Article Citation Count": "2",
      "Reference Count": "71",
      "License": "CCBY",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "RIBDetector: an RFC-guided Inconsistency Bug Detecting Approach for Protocol Implementations",
      "Authors": "J. Chen; F. Li; M. Xu; J. Zhou; W. Huo",
      "Author Affiliations": "Institute of Information Engineering, Chinese Academy of Sciences, China; Institute of Information Engineering, Chinese Academy of Sciences, China; Institute of Information Engineering, Chinese Academy of Sciences, China; Institute of Information Engineering, Chinese Academy of Sciences, China; Institute of Information Engineering, Chinese Academy of Sciences, China",
      "Publication Title": "2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "21-Jul-22",
      "Publication Year": "2022",
      "Start Page": "641",
      "End Page": "651",
      "Abstract": "The implementations of network protocols must comply with rules described in their Request For Comments (RFC) Standards. Developers' misunderstanding or negligence of RFCs may bring in inconsistency bugs, which could further cause incorrect behaviors, interoperability issues, or critical security implications. Detecting such bugs is difficult as they usually result in silent erroneous effect. Prior work on RFC-directed inconsistency bug detection usually deal with a certain protocol or ad-hoc properties in RFCs. In this paper, we present RIBDetector, an approach focusing on statically and efficiently locating inconsistency bugs that could be triggered by hand-crafted network packets in protocol implementations. Given an implementation, its corresponding RFCs and a user-provided configuration file, our approach automatically extracts rules about packet format, state transition and error handling from RFCs into a uniform format which dictates condition checks that must be performed before taking particular operations. Then we leverage common programming conventions to identify corresponding locations of the conditions and operations in implementations and use a light-weight predominator-based algorithm to detect violations of RFC rules. We implemented a prototype of RIBDetector and demonstrated its efficacy by applying it on 14 implementations of 5 network protocols. For implementations varying in size from 1.5 to 141.3 KLOC, RIBDetector consumes 17.57 seconds on average to finish its analysis. We have detected 23 new inconsistency bugs, 6 of which are confirmed and fixed by developers.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-6654-3786-8",
      "DOI": "10.1109/SANER53432.2022.00081",
      "Funding Information": "Chinese Academy of Sciences; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9825875",
      "Author_Keywords": "Network protocol;RFC;inconsistency bug",
      "IEEE_Terms": "Protocols;Conferences;Computer bugs;Focusing;Prototypes;Programming;Software",
      "Reference Count": "43",
      "License": "IEEE",
      "Online Date": "21-Jul-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Search4Code: Code Search Intent Classification Using Weak Supervision",
      "Authors": "N. Rao; C. Bansal; J. Guan",
      "Author Affiliations": "Microsoft Research; Microsoft Research; Microsoft",
      "Publication Title": "2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "28-Jun-21",
      "Publication Year": "2021",
      "Start Page": "575",
      "End Page": "579",
      "Abstract": "Developers use search for various tasks such as finding code, documentation, debugging information, etc. In particular, web search is heavily used by developers for finding code examples and snippets during the coding process. Recently, natural language based code search has been an active area of research. However, the lack of real-world large-scale datasets is a significant bottleneck. In this work, we propose a weak supervision based approach for detecting code search intent in search queries for C# and Java programming languages. We evaluate the approach against several baselines on a real-world dataset comprised of over 1 million queries mined from Bing web search engine and show that the CNN based model can achieve an accuracy of 77% and 76% for C# and Java respectively. Furthermore, we are also releasing Search4Code, the first large-scale real-world dataset of code search queries mined from Bing web search engine. We hope that the dataset will aid future research on code search.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-7281-8710-5",
      "DOI": "10.1109/MSR52588.2021.00077",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9463144",
      "Author_Keywords": "code search;weak supervision",
      "IEEE_Terms": "Java;Natural languages;Documentation;Debugging;Software;Encoding;C# languages",
      "Article Citation Count": "6",
      "Reference Count": "30",
      "License": "IEEE",
      "Online Date": "28-Jun-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Using Bandit Algorithms for Selecting Feature Reduction Techniques in Software Defect Prediction",
      "Authors": "M. Tsunoda; A. Monden; K. Toda; A. Tahir; K. E. Bennin; K. Nakasai; M. Nagura; K. Matsumoto",
      "Author Affiliations": "Kindai University, Higashi-osaka, Japan; Okayama University, Okayama, Japan; Fukuoka Institute of Tech., Fukuoka, Japan; Massey University, Palmerston North, NZ; Wageningen UR, Wageningen, Netherlands; Kumamoto College, NIT, Kirishima, Japan; Nanzan University, Nagoya, Japan; NAIST, Ikoma, Japan",
      "Publication Title": "2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "21-Jun-22",
      "Publication Year": "2022",
      "Start Page": "670",
      "End Page": "681",
      "Abstract": "Background: Selecting a suitable feature reduction technique, when building a defect prediction model, can be challenging. Different techniques can result in the selection of different independent variables which have an impact on the overall performance of the prediction model. To help in the selection, previous studies have assessed the impact of each feature reduction technique using different datasets. However, there are many reduction techniques, and therefore some of the well-known techniques have not been assessed by those studies. Aim: The goal of the study is to select a high-accuracy reduction technique from several candidates without preliminary assessments. Method: We utilized bandit algorithm (BA) to help with the selection of best features reduction technique for a list of candidates. To select the best feature reduction technique, BA evaluates the prediction accuracy of the candidates, comparing testing results of different modules with their prediction results. By substituting the reduction technique for the prediction method, BA can then be used to select the best reduction technique. In the experiment, we evaluated the performance of BA to select suitable reduction technique. We performed cross version defect prediction using 14 datasets. As feature reduction techniques, we used two assessed and two non-assessed techniques. Results: Using BA, the prediction accuracy was higher or equivalent than existing approaches on average, compared with techniques selected based on an assessment. Conclusions: BA can have larger impact on improving prediction models by helping not only on selecting suitable models, but also in selecting suitable feature reduction techniques.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-4503-9303-4",
      "DOI": "10.1145/3524842.3529093",
      "Funding Information": "Japan Society for the Promotion of Science(grant numbers:20H05706); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796258",
      "Author_Keywords": "Software fault prediction;online optimization;variable selection;external validity",
      "IEEE_Terms": "Degradation;Software testing;Heuristic algorithms;Software algorithms;Buildings;Predictive models;Prediction algorithms",
      "Article Citation Count": "6",
      "Reference Count": "37",
      "Online Date": "21-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Reference Architecture for Social Media Intelligence Applications in the Cloud",
      "Authors": "I. D. Addo; D. Do; R. Ge; S. I. Ahamed",
      "Author Affiliations": "Marquette University, Milwaukee, WI, USA; Marquette University, Milwaukee, WI, USA; Marquette University, Milwaukee, WI, USA; Marquette University, Milwaukee, WI, USA",
      "Publication Title": "2015 IEEE 39th Annual Computer Software and Applications Conference",
      "Date Added To Xplore": "24-Sep-15",
      "Publication Year": "2015",
      "Volume": "2",
      "Start Page": "906",
      "End Page": "913",
      "Abstract": "As the social media upsurge of today continues to mount, opportunities to derive collective intelligence from online social networking (OSN) content sources are inevitably expected to grow. While enterprise organizations and research institutions make a dash for identifying rich insights and opportunities to tap into the millions of conversations and user profile relationships exposed by this new social-influenced big data phenomenon, architectural concerns regarding the storage and processing of large datasets unearthed by OSNs, along with performance, scalability, fault-tolerance, security, privacy, and high-availability solutions have become an area of concern for social media intelligence (SMI) solutions. In this literature, we present a reference architecture, for designing SMI solutions. In addition, we showcase two key case studies for SMI applications built on this architecture. Our selected case studies are focused on the analysis of User-Generated Content (i.e. With Sentiment Analysis in Twitter data) and Social Graph Influence (i.e. In a Facebook-influenced Movie Recommendations solution). We evaluate the 'goodness-of-fit' in applying our model to these case study solutions and present results from our performance evaluation of these cloud-hosted solutions across multiple cloud providers like Amazon AWS, Microsoft Azure and Google Cloud.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-4673-6564-2",
      "DOI": "10.1109/COMPSAC.2015.128",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273722",
      "Author_Keywords": "Reference Architecture;Social Media Intelligence;Social Insights;Big Data Analysis;Social Data Science;Cloud Architecture;Collective Intelligence",
      "IEEE_Terms": "Media;Cloud computing;Motion pictures;Computer architecture;Facebook;Big data;Scalability",
      "Article Citation Count": "3",
      "Reference Count": "32",
      "License": "IEEE",
      "Online Date": "24-Sep-15",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Empirical Study in using Version Histories for Change Risk Classification",
      "Authors": "M. Kiehn; X. Pan; F. Camci",
      "Author Affiliations": "Advanced Micro Devices, Inc., Canada; Advanced Micro Devices, Inc., Canada; Amazon, Austin, USA",
      "Publication Title": "2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "29-Aug-19",
      "Publication Year": "2019",
      "Start Page": "58",
      "End Page": "62",
      "Abstract": "Many techniques have been proposed for mining software repositories, predicting code quality and evaluating code changes. Prior work has established links between code ownership and churn metrics, and software quality at file and directory level based on changes that fix bugs. Other metrics have been used to evaluate individual code changes based on preceding changes that induce fixes. This paper combines the two approaches in an empirical study of assessing risk of code changes using established code ownership and churn metrics with fix inducing changes on a large proprietary code repository. We establish a machine learning model for change risk classification which achieves average precision of 0.76 using metrics from prior works and 0.90 using a wider array of metrics. Our results suggest that code ownership metrics can be applied in change risk classification models based on fix inducing changes.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-7281-3412-3",
      "DOI": "10.1109/MSR.2019.00018",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8816740",
      "Author_Keywords": "Change risk;code ownership;file metrics;machine learning",
      "IEEE_Terms": "Measurement;Feature extraction;Predictive models;Computer bugs;Analytical models;Software quality",
      "Reference Count": "14",
      "License": "IEEE",
      "Online Date": "29-Aug-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Code Review Knowledge Perception: Fusing Multi-Features for Salient-Class Location",
      "Authors": "Y. Huang; N. Jia; X. Chen; K. Hong; Z. Zheng",
      "Author Affiliations": "School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Management Science and Engineering, Hebei GEO University, Shijiazhuang, China; Guangdong Key Laboratory for Big Data Analysis and Simulation of Public Opinion, School of Communication and Design, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "16-May-22",
      "Publication Year": "2022",
      "Volume": "48",
      "Issue": "5",
      "Start Page": "1463",
      "End Page": "1479",
      "Abstract": "Code review is a common software engineering practice of practical importance to reduce software defects. Review today is often with the help of specialized tools, such as Gerrit. However, even in a tool-supported code review involves a significant amount of human effort to understand the code change, because the information required to inspect code changes may distribute across multiple files that reviewers are not familiar with. Code changes are often organized as commits for review. In this paper, we found that most of the commits contain a salient class(es), which is saliently modified and causes the modification of the rest classes in a commit. Our user studies confirmed that identifying the salient class in a commit can facilitate reviewers in understanding code change. Inspired by the effectiveness of machine learning techniques in the classification field, we model the salient class identification as a binary classification problem and a number of discriminative features is extracted for a commit and used to characterize the salience of a class. The experiments results show that our approach achieves an accuracy of 88 percent. A user study with industrial developers shows that our approach can really improve the efficiency of reviewers understanding code changes in a reviewing scenario without using comment.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2020.3021902",
      "Funding Information": "National Key R&D Program of China(grant numbers:2018YFB1004800); National Natural Science Foundation of China(grant numbers:61902441,61722214,61672545); Key-Area Research and Development Program of Guangdong Province(grant numbers:2020B010164002); Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2020A1515010973); China Postdoctoral Science Foundation(grant numbers:2018M640855); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9186620",
      "Author_Keywords": "Code review;code comprehension;code change;code discriminative features;code commit",
      "IEEE_Terms": "Feature extraction;Semantics;Tools;Couplings;Open source software;Knowledge engineering",
      "Article Citation Count": "7",
      "Reference Count": "56",
      "License": "IEEE",
      "Online Date": "4-Sep-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "CounterFault: Value-Based Fault Localization by Modeling and Predicting Counterfactual Outcomes",
      "Authors": "A. Podgurski; Y. K√º√ß√ºk",
      "Author Affiliations": "Department of Computer and Data Sciences, Case Western Reserve University, Cleveland, OH, USA; Department of Computer and Data Sciences, Case Western Reserve University, Cleveland, OH, USA",
      "Publication Title": "2020 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "2-Nov-20",
      "Publication Year": "2020",
      "Start Page": "382",
      "End Page": "393",
      "Abstract": "This paper presents a new, flexible approach to automatically localizing faults in software, named CounterFault. It uses a form of causal inference called counterfactual prediction to predict the effect, on the success or failure of an execution Ex, of intervening at a statement s to set an assignment target A to a value a that is not actually assigned to A in Ex but that could be if s or Ex was modified. CounterFault generates this prediction without actually modifying s or Ex, by employing a very flexible non-parametric statistical or machine learning model (e.g., a random forest). CounterFault applies this basic idea to estimate, with minimal confounding bias, the average causal effects on program failures of different changes in the values assigned to program variables, and these estimates are then employed to derive suspiciousness scores, which are used to assist developers in localizing faults. This paper also reports on an empirical evaluation of CounterFault involving the widely used Defects4J evaluation framework, which contains real software faults, as well as several other Java numerical programs. CounterFault is compared empirically with two other value-based fault localization techniques and four of the best performing coverage-based techniques. The results indicate that CounterFault is more effective than the competing techniques.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-7281-5619-4",
      "DOI": "10.1109/ICSME46990.2020.00044",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240635",
      "Author_Keywords": "fault localization, causal inference, counterfactual outcome, causal effect, confounding bias, software engineering, statistical fault localization, causal inference methodology",
      "IEEE_Terms": "Software maintenance;Java;Conferences;Predictive models;Numerical models;Random forests",
      "Article Citation Count": "6",
      "Reference Count": "51",
      "License": "IEEE",
      "Online Date": "2-Nov-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "CBUA: A Probabilistic, Predictive, and Practical Approach for Evaluating Test Suite Effectiveness",
      "Authors": "P. Zhang; Y. Li; W. Ma; Y. Yang; L. Chen; H. Lu; Y. Zhou; B. Xu",
      "Author Affiliations": "State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "15-Mar-22",
      "Publication Year": "2022",
      "Volume": "48",
      "Issue": "3",
      "Start Page": "1067",
      "End Page": "1096",
      "Abstract": "Knowing the effectiveness of a test suite is essential for many activities such as assessing the test adequacy of code and guiding the generation of new test cases. Mutation testing is a commonly used defect injection technique for evaluating the effectiveness of a test suite. However, it is usually computationally expensive, as a large number of mutants (buggy versions) are needed to be generated from a production code under test and executed against the test suite. In order to reduce the expensive testing cost, recent studies proposed to use supervised models to predict the effectiveness of a test suite without executing the test suite against the mutants. Nonetheless, the training of such a supervised model requires labeled data, which still depends on the costly mutant execution. Furthermore, existing models are based on traditional supervised learning techniques, which assume that the training and testing data come from the same distribution. But, in practice, software systems are subject to considerable concept drifts, i.e., the same distribution assumption usually does not hold. This can lead to inaccurate predictions of a learned supervised model on the target code as time progresses. To tackle these problems, in this paper, we propose a Coverage-Based Unsupervised Approach (CBUA) for evaluating the effectiveness of a test suite. Given a production code under test, the corresponding mutants, and a test suite, CBUA first collects the coverage information of the mutated statements in the target production code under the execution of the test suite. Then, CBUA employs coverage to estimate the probability of each mutant being alive. As such, a mutation score is computed to evaluate the test suite effectiveness and the predicted labels (i.e., killed or alive) are obtained. The whole process only requires a one-time execution of the test suite against the target production code, without involving any mutant execution and any training data. CBUA can ensure the score monotonicity property (i.e., adding test cases to a test suite does not decrease its mutation score), which may be violated by a supervised approach. The experimental results show that CBUA is very competitive with the state-of-the-art supervised approaches in prediction accuracy. In particular, CBUA is shown to be more effective in finding mutants that are covered but not killed by a test suite, which is helpful in identifying the weaknesses in the current test suite and generating new test cases accordingly. Since CBUA is an easy-to-implement approach with a low cost, we suggest that it should be used as a baseline approach for comparison when any novel prediction approach is proposed in future studies.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2020.3010361",
      "Funding Information": "National Key Research and Development Program of China(grant numbers:2018YFB1003901); National Natural Science Foundation of China(grant numbers:61772259,61872177,61832009,61772263); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9144443",
      "Author_Keywords": "Effectiveness;test suites;coverage;unsupervised model;mutation testing",
      "IEEE_Terms": "Testing;Predictive models;Production;Data models;Computational modeling;Training;Training data",
      "Article Citation Count": "7",
      "Reference Count": "54",
      "License": "IEEE",
      "Online Date": "20-Jul-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "What Makes Good In-Context Demonstrations for Code Intelligence Tasks with LLMs?",
      "Authors": "S. Gao; X. -C. Wen; C. Gao; W. Wang; H. Zhang; M. R. Lyu",
      "Author Affiliations": "School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, China; School of Big Data and Software Engineering, Chongqing University, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, China",
      "Publication Title": "2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "8-Nov-23",
      "Publication Year": "2023",
      "Start Page": "761",
      "End Page": "773",
      "Abstract": "Pre-trained models of source code have gained widespread popularity in many code intelligence tasks. Recently, with the scaling of the model and corpus size, large language models have shown the ability of in-context learning (ICL). ICL employs task instructions and a few examples as demonstrations, and then inputs the demonstrations to the language models for making predictions. This new learning paradigm is training-free and has shown impressive performance in various natural language processing and code intelligence tasks. However, the performance of ICL heavily relies on the quality of demonstrations, e.g., the selected examples. It is important to systematically investigate how to construct a good demonstration for code-related tasks. In this paper, we empirically explore the impact of three key factors on the performance of ICL in code intelligence tasks: the selection, order, and number of demonstration examples. We conduct extensive experiments on three code intelligence tasks including code summarization, bug fixing, and program synthesis. Our experimental results demonstrate that all the above three factors dramatically impact the performance of ICL in code intelligence tasks. Additionally, we summarize our findings and provide takeaway suggestions on how to construct effective demonstrations, taking into account these three perspectives. We also show that a carefully-designed demonstration based on our findings can lead to substantial improvements over widely-used demonstration construction methods, e.g., improving BLEU-4, EM, and EM by at least 9.90%, 175.96%, and 50.81% on code summarization, bug fixing, and program synthesis, respectively.",
      "ISSN": "2643-1572",
      "ISBNs": "979-8-3503-2996-4",
      "DOI": "10.1109/ASE56229.2023.00109",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:62002084); Natural Science Foundation of Guangdong Province(grant numbers:2023A1515011959); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298329",
      "IEEE_Terms": "Codes;Source coding;Computer bugs;Predictive models;Natural language processing;Task analysis;Software engineering",
      "Article Citation Count": "1",
      "Reference Count": "68",
      "License": "IEEE",
      "Online Date": "8-Nov-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Building effective defect-prediction models in practice",
      "Authors": "A. G. Koru; H. Liu",
      "Author Affiliations": "University of Maryland, Baltimore, USA; University of Maryland, Baltimore, USA",
      "Publication Title": "IEEE Software",
      "Date Added To Xplore": "31-Oct-05",
      "Publication Year": "2005",
      "Volume": "22",
      "Issue": "6",
      "Start Page": "23",
      "End Page": "29",
      "Abstract": "Defective software modules cause software failures, increase development and maintenance costs, and decrease customer satisfaction. Effective defect prediction models can help developers focus quality assurance activities on defect-prone modules and thus improve software quality by using resources more efficiently. These models often use static measures obtained from source code, mainly size, coupling, cohesion, inheritance, and complexity measures, which have been associated with risk factors, such as defects and changes.",
      "ISSN": "1937-4194",
      "DOI": "10.1109/MS.2005.149",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1524911",
      "Author_Keywords": "software quality;software metrics",
      "IEEE_Terms": "Predictive models;Size measurement;Testing;Software measurement;Software maintenance;Costs;Software quality;Performance analysis;NASA;Machine learning",
      "Article Citation Count": "120",
      "Patent Citation Count": "1",
      "Reference Count": "10",
      "License": "IEEE",
      "Online Date": "31-Oct-05",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Magazines"
    },
    {
      "Document Title": "IoT Malware Analysis",
      "Authors": "V. Clincy; H. Shahriar",
      "Author Affiliations": "Department of Computer Science; Department of Information Technology, Kennesaw State University, Marietta, GA, USA",
      "Publication Title": "2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "9-Jul-19",
      "Publication Year": "2019",
      "Volume": "1",
      "Start Page": "920",
      "End Page": "921",
      "Abstract": "IoT devices can be used to fulfil many of our daily tasks. IoT could be wearable devices, home appliances, or even light bulbs. With the introduction of this new technology, however, vulnerabilities are being introduced and can be leveraged or exploited by malicious users. One common vehicle of exploitation is malicious software, or malware. Malware can be extremely harmful and compromise the confidentiality, integrity and availability (CIA triad) of information systems. This paper analyzes the types of malware attacks, introduce some mitigation approaches and discusses future challenges.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-7281-2607-4",
      "DOI": "10.1109/COMPSAC.2019.00141",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8754110",
      "Author_Keywords": "IoT;Malware analysis;Ollydebug",
      "IEEE_Terms": "Malware;Blockchain;Image recognition;Machine learning;Security;Conferences",
      "Article Citation Count": "15",
      "Reference Count": "8",
      "License": "IEEE",
      "Online Date": "9-Jul-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "TkT: Automatic Inference of Timed and Extended Pushdown Automata",
      "Authors": "F. Pastore; D. Micucci; M. Guzman; L. Mariani",
      "Author Affiliations": "SnT Centre - University of Luxembourg, Luxembourg, Luxembourg; Department of Informatics, Systems, and COmmunications, University of Milano - Bicocca, Milano, Italy; Department of Informatics, Systems, and COmmunications, University of Milano - Bicocca, Milano, Italy; Department of Informatics, Systems, and COmmunications, University of Milano - Bicocca, Milano, Italy",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "14-Feb-22",
      "Publication Year": "2022",
      "Volume": "48",
      "Issue": "2",
      "Start Page": "617",
      "End Page": "636",
      "Abstract": "To mitigate the cost of manually producing and maintaining models capturing software specifications, specification mining techniques can be exploited to automatically derive up-to-date models that faithfully represent the behavior of software systems. So far, specification mining solutions focused on extracting information about the functional behavior of the system, especially in the form of models that represent the ordering of the operations. Well-known examples are finite state models capturing the usage protocol of software interfaces and temporal rules specifying relations among system events. Although the functional behavior of a software system is a primary aspect of concern, there are several other non-functional characteristics that must be typically addressed jointly with the functional behavior of a software system. Efficiency is one of the most relevant characteristics. Indeed, an application that delivers the right functionalities with an inefficient implementation may fail to satisfy the expectations of its users. Interestingly, the timing behavior is strongly dependent on the functional behavior of a software system. For instance, the timing of an operation depends on the functional complexity and size of the computation that is performed. Consequently, models that combine the functional and timing behaviors, as well as their dependencies, are extremely important to precisely reason on the behavior of software systems. In this paper, we address the challenge of generating models that capture both the functional and timing behavior of a software system from execution traces. The result is the Timed k-Tail (TkT) specification mining technique, which can mine finite state models that capture such an interplay: the functional behavior is represented by the possible order of the events accepted by the transitions, while the timing behavior is represented through clocks and clock constraints of different nature associated with transitions. Our empirical evaluation with several libraries and applications shows that TkT can generate accurate models, capable of supporting the identification of timing anomalies due to overloaded environment and performance faults. Furthermore, our study shows that TkT outperforms state-of-the-art techniques in terms of scalability and accuracy of the mined models.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2020.2998527",
      "Funding Information": "H2020 Learn; ERC(grant numbers:646867); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9103630",
      "Author_Keywords": "Specification mining;dynamic analysis;trace analysis;model inference;timed automata;performance analysis",
      "IEEE_Terms": "Automata;Clocks;Software systems;Timing;Data mining;Computational modeling",
      "Article Citation Count": "3",
      "Reference Count": "57",
      "License": "IEEE",
      "Online Date": "29-May-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Better Data Labelling With EMBLEM (and how that Impacts Defect Prediction)",
      "Authors": "H. Tu; Z. Yu; T. Menzies",
      "Author Affiliations": "Computer Science, North Carolina State University College of Engineering, Raleigh, NC, USA; Computer Science, North Carolina State University College of Engineering, Raleigh, NC, USA; Computer Science, North Carolina State University College of Engineering, Raleigh, NC, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "10-Jan-22",
      "Publication Year": "2022",
      "Volume": "48",
      "Issue": "1",
      "Start Page": "278",
      "End Page": "294",
      "Abstract": "Standard automatic methods for recognizing problematic development commits can be greatly improved via the incremental application of human+artificial expertise. In this approach, called EMBLEM, an AI tool first explore the software development process to label commits that are most problematic. Humans then apply their expertise to check those labels (perhaps resulting in the AI updating the support vectors within their SVM learner). We recommend this human+AI partnership, for several reasons. When a new domain is encountered, EMBLEM can learn better ways to label which comments refer to real problems. Also, in studies with 9 open source software projects, labelling via EMBLEM's incremental application of human+AI is at least an order of magnitude cheaper than existing methods ($\\approx$‚âà eight times). Further, EMBLEM is very effective. For the data sets explored here, EMBLEM better labelling methods significantly improved $P_{opt}20$Popt20 and G-scores performance in nearly all the projects studied here.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2020.2986415",
      "Funding Information": "National Science Foundation(grant numbers:#1826574,#1931425); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9064604",
      "Author_Keywords": "Human-in-the-loop AI;data labelling;defect prediction;software analytics",
      "IEEE_Terms": "Labeling;Computer bugs;Data models;Software;Support vector machines;Standards;Task analysis",
      "Article Citation Count": "15",
      "Reference Count": "119",
      "License": "IEEE",
      "Online Date": "13-Apr-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Researcher Bias: The Use of Machine Learning in Software Defect Prediction",
      "Authors": "M. Shepperd; D. Bowes; T. Hall",
      "Author Affiliations": "Brunel University, Uxbridge, Middlesex, United Kingdom; Science and Technology Research Institute, University of Hertfordshire, Hatfield, Hertfordshire, United Kingdom; Brunel University, Uxbridge, Middlesex, United Kingdom",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "16-Jun-14",
      "Publication Year": "2014",
      "Volume": "40",
      "Issue": "6",
      "Start Page": "603",
      "End Page": "616",
      "Abstract": "Background. The ability to predict defect-prone software components would be valuable. Consequently, there have been many empirical studies to evaluate the performance of different techniques endeavouring to accomplish this effectively. However no one technique dominates and so designing a reliable defect prediction model remains problematic. Objective. We seek to make sense of the many conflicting experimental results and understand which factors have the largest effect on predictive performance. Method. We conduct a meta-analysis of all relevant, high quality primary studies of defect prediction to determine what factors influence predictive performance. This is based on 42 primary studies that satisfy our inclusion criteria that collectively report 600 sets of empirical prediction results. By reverse engineering a common response variable we build a random effects ANOVA model to examine the relative contribution of four model building factors (classifier, data set, input metrics and researcher group) to model prediction performance. Results. Surprisingly we find that the choice of classifier has little impact upon performance (1.3 percent) and in contrast the major (31 percent) explanatory factor is the researcher group. It matters more who does the work than what is done. Conclusion. To overcome this high level of researcher bias, defect prediction researchers should (i) conduct blind analysis, (ii) improve reporting protocols and (iii) conduct more intergroup studies in order to alleviate expertise issues. Lastly, research is required to determine whether this bias is prevalent in other applications domains.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2014.2322358",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6824804",
      "Author_Keywords": "Software defect prediction;meta-analysis;researcher bias",
      "IEEE_Terms": "Software;Predictive models;Correlation;Data models;Buildings;Software engineering;Measurement",
      "Article Citation Count": "245",
      "Reference Count": "53",
      "License": "IEEE",
      "Online Date": "3-Jun-14",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "PreciseBugCollector: Extensible, Executable and Precise Bug-Fix Collection: Solution for Challenge 8: Automating Precise Data Collection for Code Snippets with Bugs, Fixes, Locations, and Types",
      "Authors": "Y. He; Z. Chen; C. Le Goues",
      "Author Affiliations": "Carnegie Mellon University, Pittsburgh, US; KTH Royal Institute of Technology, Stockholm, Sweden; Carnegie Mellon University, Pittsburgh, US",
      "Publication Title": "2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "8-Nov-23",
      "Publication Year": "2023",
      "Start Page": "1899",
      "End Page": "1910",
      "Abstract": "Bug datasets are vital for enabling deep learning techniques to address software maintenance tasks related to bugs. However, existing bug datasets suffer from precise and scale limitations: they are either small-scale but precise with manual validation or large-scale but imprecise with simple commit message processing. In this paper, we introduce Precise-BugCollector, a precise, multi -language bug collection approach that overcomes these two limitations. PreciseBugCollector is based on two novel components: a) A bug tracker to map the codebase repositories with external bug repositories to trace bug type information, and b) A bug injector to generate project-specific bugs by injecting noise into the correct codebases and then executing them against their test suites to obtain test failure messages. We implement PreciseBugCollector against three sources: 1) A bug tracker that links to the national vulnerability data set (NVD) to collect general-wise vulnerabilities, 2) A bug tracker that links to OSS-Fuzz to collect general-wise bugs, and 3) A bug injector based on 16 injection rules to generate project-wise bugs. To date, PreciseBugCollector comprises 1057818 bugs extracted from 2968 open-source projects. Of these, 12602 bugs are sourced from bug repositories (NVD and OSS-Fuzz), while the remaining 1045216 project-specific bugs are generated by the bug injector. Considering the challenge objectives, we argue that a bug injection approach is highly valuable for the industrial setting, since project-specific bugs align with domain knowledge, share the same codebase, and adhere to the coding style employed in industrial projects.",
      "ISSN": "2643-1572",
      "ISBNs": "979-8-3503-2996-4",
      "DOI": "10.1109/ASE56229.2023.00163",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298528",
      "Author_Keywords": "Bug datasets;Program repair;Software testing and debugging",
      "IEEE_Terms": "Industries;Deep learning;Training;Location awareness;Software maintenance;Computer bugs;Manuals",
      "Reference Count": "67",
      "License": "IEEE",
      "Online Date": "8-Nov-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Automated Program Repair in the Era of Large Pre-trained Language Models",
      "Authors": "C. S. Xia; Y. Wei; L. Zhang",
      "Author Affiliations": "University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign; University of Illinois, Urbana-Champaign",
      "Publication Title": "2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "14-Jul-23",
      "Publication Year": "2023",
      "Start Page": "1482",
      "End Page": "1494",
      "Abstract": "Automated Program Repair (APR) aims to help developers automatically patch software bugs. However, current state-of-the-art traditional and learning-based APR techniques face the problem of limited patch variety, failing to fix complicated bugs. This is mainly due to the reliance on bug-fixing datasets to craft fix templates (traditional) or directly predict potential patches (learning-based). Large Pre-Trained Language Models (LLMs), trained using billions of text/code tokens, can potentially help avoid this issue. Very recently, researchers have directly leveraged LLMs for APR without relying on any bug-fixing datasets. Meanwhile, such existing work either failed to include state-of-the-art LLMs or was not evaluated on realistic datasets. Thus, the true power of modern LLMs on the important APR problem is yet to be revealed. In this work, we perform the first extensive study on directly applying LLMs for APR. We select 9 recent state-of-the-art LLMs, including both generative and infilling models, ranging from 125M to 20B in size. We designed 3 different repair settings to evaluate the different ways we can use LLMs to generate patches: 1) generate the entire patch function, 2) fill in a chunk of code given the prefix and suffix 3) output a single line fix. We apply the LLMs under these repair settings on 5 datasets across 3 different languages and compare different LLMs in the number of bugs fixed, generation speed and compilation rate. We also compare the LLMs against recent state-of-the-art APR tools. Our study demonstrates that directly applying state-of-the-art LLMs can already substantially outperform all existing APR techniques on all our datasets. Among the studied LLMs, the scaling effect exists for APR where larger models tend to achieve better performance. Also, we show for the first time that suffix code after the buggy line (adopted in infilling-style APR) is important in not only generating more fixes but more patches with higher compilation rate. Besides patch generation, the LLMs consider correct patches to be more natural than other ones, and can even be leveraged for effective patch ranking or patch correctness checking. Lastly, we show that LLM-based APR can be further substantially boosted via: 1) increasing the sample size, and 2) incorporating fix template information.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-5701-9",
      "DOI": "10.1109/ICSE48619.2023.00129",
      "Funding Information": "NSF(grant numbers:CCF-2131943,CCF-2141474); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172803",
      "Author_Keywords": "Automated Program Repair;Machine Learning",
      "IEEE_Terms": "Codes;Computer bugs;Maintenance engineering;Software;Distance measurement;Task analysis;Faces",
      "Article Citation Count": "15",
      "Reference Count": "89",
      "License": "IEEE",
      "Online Date": "14-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Information Leakage-Aware Computer-Aided Cyber-Physical Manufacturing",
      "Authors": "S. R. Chhetri; S. Faezi; M. A. Al Faruque",
      "Author Affiliations": "Department of Electrical Engineering and Computer Science, University of California at Irvine, Irvine, CA, USA; Department of Electrical Engineering and Computer Science, University of California at Irvine, Irvine, CA, USA; Department of Electrical Engineering and Computer Science, University of California at Irvine, Irvine, CA, USA",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "2-May-18",
      "Publication Year": "2018",
      "Volume": "13",
      "Issue": "9",
      "Start Page": "2333",
      "End Page": "2344",
      "Abstract": "Cyber-physical additive manufacturing systems consist of tight integration of cyber and physical domains. This union, however, induces new cross-domain vulnerabilities that pose unique security challenges. One of these challenges is preventing confidentiality breach, caused by physical-to-cyber domain attacks. In this form of attack, attackers utilize the side-channels (such as acoustics, power, electromagnetic emissions, and so on) in the physical-domain to estimate and steal cyber-domain data (such as G/M-codes). Since these emissions depend on the physical structure of the system, one way to minimize the information leakage is to modify the physical-domain. However, this process can be costly due to added hardware modification. Instead, we propose a novel methodology that allows the cyber-domain tools [such as computer aided-manufacturing (CAM)] to be aware of the existing information leakage. Then, we propose to change either machine process or product design parameters in the cyber-domain to minimize the information leakage. Our methodology aids the existing cyber-domain and physical-domain security solution by utilizing the cross-domain relationship. We have implemented our methodology in a fused-deposition modeling-based Cartesian additive manufacturing system. Our methodology achieves reduction of mutual information by 24.94% in acoustic side-channel, 32.91% in power side-channel, 32.29% in magnetic side-channel, and 55.65% in vibration side-channel. As a case study, to help understand the implication of mutual information drop, we have also presented the calculation of success rate and the reconstruction of the 3D object based on an attack model. For the given attack model, our leakage-aware CAM tool decreases the success rate of an attacker by 8.74% and obstructs the reconstruction of finer geometry details.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2018.2818659",
      "Funding Information": "NSF CPS(grant numbers:CNS-1546993); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8322219",
      "Author_Keywords": "Cyber-physical systems;confidentiality;security;information leakage;manufacturing",
      "IEEE_Terms": "Three-dimensional displays;Tools;Three-dimensional printing;Solid modeling;Mutual information;Security;Geometry",
      "Article Citation Count": "18",
      "Reference Count": "41",
      "License": "IEEE",
      "Online Date": "22-Mar-18",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "An Empirical Study on Fine-Tuning Large Language Models of Code for Automated Program Repair",
      "Authors": "K. Huang; X. Meng; J. Zhang; Y. Liu; W. Wang; S. Li; Y. Zhang",
      "Author Affiliations": "University of Chinese Academy of Sciences, Bejiing, China; Beihang University, Beijing, China; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; University of Chinese Academy of Sciences, Bejiing, China; Zhongguancun Laboratory, Beijing, China; University of Chinese Academy of Sciences, Bejiing, China",
      "Publication Title": "2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "8-Nov-23",
      "Publication Year": "2023",
      "Start Page": "1162",
      "End Page": "1174",
      "Abstract": "The advent of large language models (LLMs) has opened up new opportunities for automated program repair (APR). In particular, some recent studies have explored how to leverage large language models of code (LLMCs) for program repair tasks and show promising results. However, most of them adopt the zero/few-shot learning paradigm for APR, which directly use LLMCs to generate the possibly correct code given its surrounding context. Though effective, the repair capabilities of LLMCs based on the fine-tuning paradigm have yet to be extensively explored. Also, it remains unknown whether LLMCs have the potential to repair more complicated bugs (e.g., multi-hunk bugs). To fill the gap, in this work, we conduct a comprehensive study on the program repair capability of LLMCs in the fine-tuning paradigm. We select 5 popular LLMCs with representative pre-training architectures, including CodeBERT, GraphCode-BERT, PLBART, CodeT5, and UniX coder. We consider 3 typical program repair scenarios (i.e., bugs, vulnerabilities, and errors) involving 3 programming languages (i.e., Java, $\\mathrm{C}/\\mathrm{C}++$, and JavaScript). Notably, we take both single-hunk and multi-hunk bugs/vulnerabilities into account. We then fine-tune them on widely-used datasets and compare them with existing state-of-the-art APR tools. We also investigate the impact of different design choices, which include code abstractions, code representations, and model evaluation metrics. Our experimental results show that LLMCs in the fine-tuning paradigm can significantly outperform previous state-of-the-art APR tools. Through in-depth analysis, we provide insights into choosing appropriate strategies to guide LLMCs for better performance. Lastly, we reveal several limitations of LLMCs for APR and make suggestions for future research on LLMC-based APR.",
      "ISSN": "2643-1572",
      "ISBNs": "979-8-3503-2996-4",
      "DOI": "10.1109/ASE56229.2023.00181",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298532",
      "Author_Keywords": "Automated Program Repair;Large Language Models of Code;Neural Machine Translation;Fine-Tuning",
      "IEEE_Terms": "Measurement;Java;Computer languages;Codes;Computer bugs;Maintenance engineering;Benchmark testing",
      "Reference Count": "70",
      "License": "IEEE",
      "Online Date": "8-Nov-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Invalidator: Automated Patch Correctness Assessment Via Semantic and Syntactic Reasoning",
      "Authors": "T. Le-Cong; D. -M. Luong; X. B. D. Le; D. Lo; N. -H. Tran; B. Quang-Huy; Q. -T. Huynh",
      "Author Affiliations": "School of Computing and Information Systems, The University of Melbourne, Parkville, VIC, Australia; School of Information and Communication Technology, Hanoi University of Science and Technology, Ha Noi, Vietnam; School of Computing and Information Systems, The University of Melbourne, Parkville, VIC, Australia; School of Computing and Information Systems, Singapore Management University, Singapore; School of Information and Communication Technology, Hanoi University of Science and Technology, Ha Noi, Vietnam; School of Information and Communication Technology, Hanoi University of Science and Technology, Ha Noi, Vietnam; School of Information and Communication Technology, Hanoi University of Science and Technology, Ha Noi, Vietnam",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "13-Jun-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "6",
      "Start Page": "3411",
      "End Page": "3429",
      "Abstract": "Automated program repair (APR) faces the challenge of test overfitting, where generated patches pass validation tests but fail to generalize. Existing methods for patch assessment involve generating new tests or manual inspection, which can be time-consuming or biased. In this paper, we propose a novel technique, Invalidator, to automatically assess the correctness of APR-generated patches via semantic and syntactic reasoning. Invalidator leverages program invariants to reason about program semantics while also capturing program syntax through language semantics learned from a large code corpus using a pre-trained language model. Given a buggy program and the developer-patched program, Invalidator infers likely invariants on both programs. Then, Invalidator determines that an APR-generated patch overfits if: (1) it violates correct specifications or (2) maintains erroneous behaviors from the original buggy program. In case our approach fails to determine an overfitting patch based on invariants, Invalidator utilizes a trained model from labeled patches to assess patch correctness based on program syntax. The benefit of Invalidator is threefold. First, Invalidator leverages both semantic and syntactic reasoning to enhance its discriminative capability. Second, Invalidator does not require new test cases to be generated, but instead only relies on the current test suite and uses invariant inference to generalize program behaviors. Third, Invalidator is fully automated. Experimental results demonstrate that Invalidator outperforms existing methods in terms of Accuracy and F-measure, correctly identifying 79% of overfitting patches and detecting 23% more overfitting patches than the best baseline.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2023.3255177",
      "Funding Information": "Australian Research Council(grant numbers:DE220101057); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10066209",
      "Author_Keywords": "Automated patch correctness assessment;automated program repair;code representations;overfitting problem;program invariants",
      "IEEE_Terms": "Syntactics;Semantics;Maintenance engineering;Cognition;Manuals;Codes;Source coding",
      "Article Citation Count": "1",
      "Reference Count": "79",
      "License": "IEEE",
      "Online Date": "10-Mar-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Hidden Electricity Theft by Exploiting Multiple-Pricing Scheme in Smart Grids",
      "Authors": "Y. Liu; T. Liu; H. Sun; K. Zhang; P. Liu",
      "Author Affiliations": "Ministry of Education Key Lab for Intelligent Networks and Network Security, School of Cyber Science and Engineering, Xi‚Äôan Jiaotong University, Xi‚Äôan, China; Ministry of Education Key Lab for Intelligent Networks and Network Security, School of Cyber Science and Engineering, Xi‚Äôan Jiaotong University, Xi‚Äôan, China; Ministry of Education Key Lab for Intelligent Networks and Network Security, School of Cyber Science and Engineering, Xi‚Äôan Jiaotong University, Xi‚Äôan, China; Department of Information Engineering, The Chinese University of Hong Kong, Hong Kong; Ministry of Education Key Lab for Intelligent Networks and Network Security, School of Cyber Science and Engineering, Xi‚Äôan Jiaotong University, Xi‚Äôan, China",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "7-Feb-20",
      "Publication Year": "2020",
      "Volume": "15",
      "Start Page": "2453",
      "End Page": "2468",
      "Abstract": "With the development of demand response technologies, the pricing scheme in smart grids is moving from flat pricing to multiple pricing (MP), which facilitates the energy saving at the consumer side. However, the flexible pricing policy may be exploited for the stealthy reduction of utility bills. In this paper, we present a hidden electricity theft (HET) attack by exploiting the emerging MP scheme. The basic idea is that attackers can tamper with smart meters to cheat the utility that some electricity is consumed under a lower price. To construct the HET attack, we propose an optimization problem aiming at maximizing the attack profits while evading current detection methods, and design two algorithms to conduct the attack on smart meters. Moreover, we disclose and exploit several new vulnerabilities of smart meters to demonstrate the feasibility of HET attacks. To protect smart grids against HET attacks, we propose several defense and detection countermeasures, including selective protection on smart meters, limiting the attack cycle, and updating the billing mechanism. Extensive experiments on a real data set demonstrate that the attack could cause high economic losses, and the proposed countermeasures could effectively mitigate the attack's impact at a low cost.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2020.2965276",
      "Funding Information": "National Basic Research Program of China (973 Program)(grant numbers:2018YFB0803501); National Natural Science Foundation of China(grant numbers:61772408,U1766215,U1736205,61721002,61632015); Fundamental Research Funds for the Central Universities; Hong Kong SAR Research Grants Council (RGC) General Research Fund (GRF)(grant numbers:14208019,14208818); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8954835",
      "Author_Keywords": "Smart grids;security;hidden electricity theft;multiple pricing;countermeasures",
      "IEEE_Terms": "Smart meters;Pricing;Security;Companies;Smart grids;Meters;Support vector machines",
      "Article Citation Count": "31",
      "Reference Count": "38",
      "License": "IEEE",
      "Online Date": "9-Jan-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Template-based Neural Program Repair",
      "Authors": "X. Meng; X. Wang; H. Zhang; H. Sun; X. Liu; C. Hu",
      "Author Affiliations": "SKLSDE Lab, Beihang University, Beijing, China; SKLSDE Lab, Beihang University, Beijing, China; Chongqing University, Chongqing, China; SKLSDE Lab, Beihang University, Beijing, China; SKLSDE Lab, Beihang University, Beijing, China; SKLSDE Lab, Beihang University, Beijing, China",
      "Publication Title": "2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "14-Jul-23",
      "Publication Year": "2023",
      "Start Page": "1456",
      "End Page": "1468",
      "Abstract": "In recent years, template-based and NMT-based automated program repair methods have been widely studied and achieved promising results. However, there are still disadvantages in both methods. The template-based methods cannot fix the bugs whose types are beyond the capabilities of the templates and only use the syntax information to guide the patch synthesis, while the NMT-based methods intend to generate the small range of fixed code for better performance and may suffer from the OOV (Out-of-vocabulary) problem. To solve these problems, we propose a novel template-based neural program repair approach called TENURE to combine the template-based and NMT- based methods. First, we build two large-scale datasets for 35 fix templates from template-based method and one special fix template (single-line code generation) from NMT-based method, respectively. Second, the encoder-decoder models are adopted to learn deep semantic features for generating patch intermediate representations (IRs) for different templates. The optimized copy mechanism is also used to alleviate the OOV problem. Third, based on the combined patch IRs for different templates, three tools are developed to recover real patches from the patch IRs, replace the unknown tokens, and filter the patch candidates with compilation errors by leveraging the project-specific information. On Defects4J-vl.2, TENURE can fix 79 bugs and 52 bugs with perfect and Ochiai fault localization, respectively. It is able to repair 50 and 32 bugs as well on Defects4J-v2.0. Compared with the existing template-based and NMT-based studies, TENURE achieves the best performance in all experiments.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-5701-9",
      "DOI": "10.1109/ICSE48619.2023.00127",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172686",
      "Author_Keywords": "automated program repair;fix templates;neural machine translation;deep learning",
      "IEEE_Terms": "Location awareness;Codes;Source coding;Computer bugs;Semantics;Maintenance engineering;Benchmark testing",
      "Article Citation Count": "4",
      "Reference Count": "55",
      "License": "IEEE",
      "Online Date": "14-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Runtime Recovery of Web Applications under Zero-Day ReDoS Attacks",
      "Authors": "Z. Bai; K. Wang; H. Zhu; Y. Cao; X. Jin",
      "Author Affiliations": "Johns Hopkins University; Peking University; Johns Hopkins University; Johns Hopkins University; Peking University",
      "Publication Title": "2021 IEEE Symposium on Security and Privacy (SP)",
      "Date Added To Xplore": "26-Aug-21",
      "Publication Year": "2021",
      "Start Page": "1575",
      "End Page": "1588",
      "Abstract": "Regular expression denial of service (ReDoS)‚Äî which exploits the super-linear running time of matching regular expressions against carefully crafted inputs‚Äîis an emerging class of DoS attacks to web services. One challenging question for a victim web service under ReDoS attacks is how to quickly recover its normal operation after ReDoS attacks, especially these zero-day ones exploiting previously unknown vulnerabilities.In this paper, we present RegexNet, the first payload-based, automated, reactive ReDoS recovery system for web services. RegexNet adopts a learning model, which is updated constantly in a feedback loop during runtime, to classify payloads of upcoming requests including the request contents and database query responses. If detected as a cause leading to ReDoS, RegexNet migrates those requests to a sandbox and isolates their execution for a fast, first-measure recovery.We have implemented a RegexNet prototype and integrated it with HAProxy and Node.js. Evaluation results show that RegexNet is effective in recovering the performance of web services against zero-day ReDoS attacks, responsive on reacting to attacks in sub-minute, and resilient to different ReDoS attack types including adaptive ones that are designed to evade RegexNet on purpose.",
      "ISSN": "2375-1207",
      "ISBNs": "978-1-7281-8934-5",
      "DOI": "10.1109/SP40001.2021.00077",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9519496",
      "Author_Keywords": "Regular expression Denial of Service (ReDoS);Deep Neural Networks;Adversarial Machine Learning;Online Feedback Loop",
      "IEEE_Terms": "Feedback loop;Privacy;Runtime;Databases;Prototypes;Web servers;Data models",
      "Article Citation Count": "6",
      "Reference Count": "53",
      "License": "IEEE",
      "Online Date": "26-Aug-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Automatically Assessing Code Understandability",
      "Authors": "S. Scalabrino; G. Bavota; C. Vendome; M. Linares-V√°squez; D. Poshyvanyk; R. Oliveto",
      "Author Affiliations": "University of Molise, Campobasso, CB, Italy; Universit√† della Svizzera italiana(USI), Lugano, Switzerland; Miami University, Oxford, OH, USA; Universidad de los Andes, Bogota, Colombia; College of William & Mary, Williamsburg, VA, USA; University of Molise, Campobasso, CB, Italy",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "16-Mar-21",
      "Publication Year": "2021",
      "Volume": "47",
      "Issue": "3",
      "Start Page": "595",
      "End Page": "613",
      "Abstract": "Understanding software is an inherent requirement for many maintenance and evolution tasks. Without a thorough understanding of the code, developers would not be able to fix bugs or add new features timely. Measuring code understandability might be useful to guide developers in writing better code, and could also help in estimating the effort required to modify code components. Unfortunately, there are no metrics designed to assess the understandability of code snippets. In this work, we perform an extensive evaluation of 121 existing as well as new code-related, documentation-related, and developer-related metrics. We try to (i) correlate each metric with understandability and (ii) build models combining metrics to assess understandability. To do this, we use 444 human evaluations from 63 developers and we obtained a bold negative result: none of the 121 experimented metrics is able to capture code understandability, not even the ones assumed to assess quality attributes apparently related, such as code readability and complexity. While we observed some improvements while combining metrics in models, their effectiveness is still far from making them suitable for practical applications. Finally, we conducted interviews with five professional developers to understand the factors that influence their ability to understand code snippets, aiming at identifying possible new metrics.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2019.2901468",
      "Funding Information": "SNF project JITRA(grant numbers:172479); National Science Foundation(grant numbers:CCF-1525902); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8651396",
      "Author_Keywords": "Software metrics;code understandability;empirical study;negative result",
      "IEEE_Terms": "Complexity theory;Software;Computer bugs;Readability metrics;Software measurement;Indexes",
      "Article Citation Count": "40",
      "Reference Count": "55",
      "License": "IEEE",
      "Online Date": "24-Feb-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "FlakeFlagger: Predicting Flakiness Without Rerunning Tests",
      "Authors": "A. Alshammari; C. Morris; M. Hilton; J. Bell",
      "Author Affiliations": "George Mason University, Fairfax, VA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Northeastern University, Boston, MA, USA",
      "Publication Title": "2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "7-May-21",
      "Publication Year": "2021",
      "Start Page": "1572",
      "End Page": "1584",
      "Abstract": "When developers make changes to their code, they typically run regression tests to detect if their recent changes (re) introduce any bugs. However, many tests are flaky, and their outcomes can change non-deterministically, failing without apparent cause. Flaky tests are a significant nuisance in the development process, since they make it more difficult for developers to trust the outcome of their tests, and hence, it is important to know which tests are flaky. The traditional approach to identify flaky tests is to rerun them multiple times: if a test is observed both passing and failing on the same code, it is definitely flaky. We conducted a very large empirical study looking for flaky tests by rerunning the test suites of 24 projects 10,000 times each, and found that even with this many reruns, some previously identified flaky tests were still not detected. We propose FlakeFlagger, a novel approach that collects a set of features describing the behavior of each test, and then predicts tests that are likely to be flaky based on similar behavioral features. We found that FlakeFlagger correctly labeled as flaky at least as many tests as a state-of-the-art flaky test classifier, but that FlakeFlagger reported far fewer false positives. This lower false positive rate translates directly to saved time for researchers and developers who use the classification result to guide more expensive flaky test detection processes. Evaluated on our dataset of 23 projects with flaky tests, FlakeFlagger outperformed the prior approach (by F1 score) on 16 projects and tied on 4 projects. Our results indicate that this approach can be effective for identifying likely flaky tests prior to running time-consuming flaky test detectors.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-0296-5",
      "DOI": "10.1109/ICSE43902.2021.00140",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9402098",
      "Author_Keywords": "regression testing;flaky tests;reliability",
      "IEEE_Terms": "Computer bugs;Detectors;Testing;Software engineering",
      "Article Citation Count": "28",
      "Reference Count": "59",
      "License": "IEEE",
      "Online Date": "7-May-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Predicting Bugs by Monitoring Developers During Task Execution",
      "Authors": "G. Laudato; S. Scalabrino; N. Novielli; F. Lanubile; R. Oliveto",
      "Author Affiliations": "STAKE Lab, University of Molise, Italy; STAKE Lab, University of Molise, Italy; University of Bari, Italy; University of Bari, Italy; STAKE Lab, University of Molise, Italy",
      "Publication Title": "2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "14-Jul-23",
      "Publication Year": "2023",
      "Start Page": "1",
      "End Page": "13",
      "Abstract": "Knowing which parts of the source code will be defective can allow practitioners to better allocate testing resources. For this reason, many approaches have been proposed to achieve this goal. Most state-of-the-art predictive models rely on product and process metrics, i.e., they predict the defectiveness of a component by considering what developers did. However, there is still limited evidence of the benefits that can be achieved in this context by monitoring how developers complete a development task. In this paper, we present an empirical study in which we aim at understanding whether measuring human aspects on developers while they write code can help predict the introduction of defects. First, we introduce a new developer-based model which relies on behavioral, psychophysical, and control factors that can be measured during the execution of development tasks. Then, we run a controlled experiment involving 20 software developers to understand if our developer-based model is able to predict the introduction of bugs. Our results show that a developer-based model is able to achieve a similar accuracy compared to a state-of-the-art code-based model, i.e., a model that uses only features measured from the source code. We also observed that by combining the models it is possible to obtain the best results (84% accuracy).",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-5701-9",
      "DOI": "10.1109/ICSE48619.2023.00100",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172756",
      "Author_Keywords": "bug prediction;human aspects of software engineering;biometric sensors;empirical software engineering",
      "IEEE_Terms": "Training;Codes;Source coding;Computer bugs;Predictive models;Software;Behavioral sciences",
      "Article Citation Count": "1",
      "Reference Count": "81",
      "License": "IEEE",
      "Online Date": "14-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "An Empirical Comparison of Model-Agnostic Techniques for Defect Prediction Models",
      "Authors": "G. Lee; S. U. -J. Lee",
      "Author Affiliations": "Department of Coumputer Science and Engineering, Hanyang University, Ansan, Republic of Korea; Department of Coumputer Science and Engineering, Hanyang University, Ansan, Republic of Korea",
      "Publication Title": "2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "15-May-23",
      "Publication Year": "2023",
      "Start Page": "179",
      "End Page": "189",
      "Abstract": "Recently, software defect prediction studies have attempted to make black-box defect prediction models explainable and actionable. State-of-the-art defect prediction studies have utilized various model-agnostic techniques derived from the explainable AI domain as key tools to make the predictions easier for practitioners to understand. However, it has not been sufficiently investigated whether there is inconsistent information within local explanations generated by different model-agnostic techniques when interpreting a defect prediction. If local explanations generated by heterogeneous model-agnostic techniques consist of different information, the derivable insights to understand and act upon defect predictions becomes less viable and it may cause ineffective or even incorrect defect corrections. In this research, we empirically analyzed 323,844 local explanations generated by three different model-agnostic techniques: (1) LIME, (2) SHAP, and (3) BreakDown. These local explanations were analyzed in terms of how the contributions of features were distributed, how the contributions were ranked, and whether the contributions were contradictory. We concluded that (i) different model-agnostic techniques provide practitioners with local explanations where average contributions of the top-ranked features are different; (ii) different model-agnostic techniques provide practitioners with local explanations consisting of different contribution rankings and inconsistent contribution directions of top-ranked features. Therefore, we recommend that practitioners should avoid using model-agnostic techniques interchangeably and must perform a multi-faceted manual validation when planning actions based on the local explanations.",
      "ISSN": "2640-7574",
      "ISBNs": "978-1-6654-5278-6",
      "DOI": "10.1109/SANER56733.2023.00026",
      "Funding Information": "Hanyang University; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10123486",
      "Author_Keywords": "Explainable Software Analytics;Software Quality Assurance;Defect Prediction Models;Model-Agnostic Technique",
      "IEEE_Terms": "Radio frequency;Analytical models;Visualization;Electric breakdown;Software algorithms;Manuals;Predictive models",
      "Reference Count": "36",
      "License": "IEEE",
      "Online Date": "15-May-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Security Code Recommendations for Smart Contract",
      "Authors": "X. Zhou; Y. Chen; H. Guo; X. Chen; Y. Huang",
      "Author Affiliations": "School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Software Engineering, Sun Yat-sen University, Zhuhai, China; School of Communication and Design, Sun Yat-sen University, Guangzhou, China; School of Software Engineering, Sun Yat-sen University, Zhuhai, China",
      "Publication Title": "2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "15-May-23",
      "Publication Year": "2023",
      "Start Page": "190",
      "End Page": "200",
      "Abstract": "A smart contract is a self-executing program that is stored on the blockchain and runs when predetermined conditions are satisfied. Many frequent transactions involving asset transfers rely on smart contracts deployed on the blockchain, making them highly vulnerable to attack, thus it is essential to ensure the security of smart contracts. Since the smart contract is immutable once deployed, developers must try their best to fix existing vulnerabilities in advance to ensure security. Current approaches for automatic program repair on the smart contracts have mainly adopted the heuristic search algorithms or defined patterns to fix several well-defined types of vulnerabilities. They can only provide security code recommendations for developers in specific scenarios. We explore more general automated program repair of smart contracts in software history.To pave the way for studying code changes related to bug fix of smart contracts in software history, we present a labeled public dataset for method-level program repair task, containing over 12 typical insecure code patterns. Unlike bugs in traditional software, the vulnerabilities of smart contracts are more associated with access control and conditional statements as smart contracts pertain to financial assets. For this problem, we devise a novel double-encoder network and use a code representation designed for the smart contract based on syntax information to repair program. By implementing and evaluating our approach on new dataset comprised of over 10,000 program pairs, we demonstrate the superiority of our approach in both qualitative and quantitative aspects.",
      "ISSN": "2640-7574",
      "ISBNs": "978-1-6654-5278-6",
      "DOI": "10.1109/SANER56733.2023.00027",
      "Funding Information": "Research and Development; National Natural Science Foundation of China; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10123449",
      "Author_Keywords": "program repair;smart contract;empirical soft-ware engineering",
      "IEEE_Terms": "Codes;Smart contracts;Computer bugs;Maintenance engineering;Syntactics;Software;Blockchains",
      "Reference Count": "36",
      "License": "IEEE",
      "Online Date": "15-May-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Novel Approach For Search-Based Program Repair",
      "Authors": "L. Trujillo; O. M. Villanueva; D. E. Hernandez",
      "Author Affiliations": "Tecnl√≥gico Nacional de M√©xico/IT de Tijuana; Tecnl√≥gico Nacional de M√©xico/IT de Tijuana; Posgrado en Ciencias de la Ingenier√≠a, Tecnologico Nacional de Mexico, Tijuana, Mexico",
      "Publication Title": "IEEE Software",
      "Date Added To Xplore": "21-Jun-21",
      "Publication Year": "2021",
      "Volume": "38",
      "Issue": "4",
      "Start Page": "36",
      "End Page": "42",
      "Abstract": "By shifting how program patches are evaluated-away from quality and toward novelty-the novelty search technique increases a bug-repair system?s ability to explore the solution space, produce more viable patches, and repair more bugs.",
      "ISSN": "1937-4194",
      "DOI": "10.1109/MS.2021.3070552",
      "Funding Information": "Consejo Nacional de Ciencia y Tecnolog√≠a(grant numbers:797252); Tecnologico Nacional de M√©xico(grant numbers:8027.20-P); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9393496",
      "IEEE_Terms": "Computer bugs;Search problems;Maintenance engineering;Linear programming;Statistics;Space exploration",
      "Article Citation Count": "2",
      "Reference Count": "13",
      "License": "IEEE",
      "Online Date": "1-Apr-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Magazines"
    },
    {
      "Document Title": "Multi-Contingency Cascading Analysis of Smart Grid Based on Self-Organizing Map",
      "Authors": "J. Yan; Y. Zhu; H. He; Y. Sun",
      "Author Affiliations": "Department of Electrical, Computer and Biomedical Engineering, University of Rhode Island, Kingston, RI, USA; Department of Electrical, Computer and Biomedical Engineering, University of Rhode Island, Kingston, RI, USA; Department of Electrical, Computer and Biomedical Engineering, University of Rhode Island, Kingston, RI, USA; Department of Electrical, Computer and Biomedical Engineering, University of Rhode Island, Kingston, RI, USA",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "11-Mar-13",
      "Publication Year": "2013",
      "Volume": "8",
      "Issue": "4",
      "Start Page": "646",
      "End Page": "656",
      "Abstract": "In the study of power grid security, the cascading failure analysis in multi-contingency scenarios has been a challenge due to its topological complexity and computational cost. Both network analyses and load ranking methods have their own limitations. In this paper, based on self-organizing map (SOM), we propose an integrated approach combining spatial feature (distance)-based clustering with electrical characteristics (load) to assess the vulnerability and cascading effect of multiple component sets in the power grid. Using the clustering result from SOM, we choose sets of heavy-loaded initial victims to perform attack schemes and evaluate the subsequent cascading effect of their failures, and this SOM-based approach effectively identifies the more vulnerable sets of substations than those from the traditional load ranking and other clustering methods. As a result, this new approach provides an efficient and reliable technique to study the power system failure behavior in cascading effect of critical component failure.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2013.2249065",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6471214",
      "Author_Keywords": "Attack;failure cascading;feature clustering;power grid security;self-organizing map;smart grid",
      "IEEE_Terms": "Power grids;Power system faults;Power system protection;Substations;Neurons;Computational modeling;Lattices",
      "Article Citation Count": "66",
      "Reference Count": "55",
      "License": "IEEE",
      "Online Date": "26-Feb-13",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Towards Semi-automatic Bug Triage and Severity Prediction Based on Topic Model and Multi-feature of Bug Reports",
      "Authors": "G. Yang; T. Zhang; B. Lee",
      "Author Affiliations": "Department of Computer Science, University of Seoul, Seoul, Korea; Department of Computer Science, University of Seoul, Seoul, Korea; Department of Computer Science, University of Seoul, Seoul, Korea",
      "Publication Title": "2014 IEEE 38th Annual Computer Software and Applications Conference",
      "Date Added To Xplore": "22-Sep-14",
      "Publication Year": "2014",
      "Start Page": "97",
      "End Page": "106",
      "Abstract": "Bug fixing is an essential activity in the software maintenance, because most of the software systems have unavoidable defects. When new bugs are submitted, triagers have to find and assign appropriate developers to fix the bugs. However, if the bugs are at first assigned to inappropriate developers, they may later have to be reassigned to other developers. That increases the time and cost for fixing bugs. Therefore, finding appropriate developers becomes a key to bug resolution. When triagers assign a new bug report, it is necessary to decide how quickly the bug report should be addressed. Thus, the bug severity is an important factor in bug fixing. In this paper, we propose a novel method for the bug triage and bug severity prediction. First, we extract topic(s) from historical bug reports in the bug repository and find bug reports related to each topic. When a new bug report arrives, we decide the topic(s) to which the report belongs. Then we utilize multi-feature to identify corresponding reports that have the same multi-feature (e.g., Component, product, priority and severity) with the new bug report. Thus, given a new bug report, we are able to recommend the most appropriate developer to fix each bug and predict its severity. To evaluate our approach, we not only measured the effectiveness of our study by using about 30,000 golden bug reports extracted from three open source projects (Eclipse, Mozilla, and Net beans), but also compared some related studies. The results show that our approach is likely to effectively recommend the appropriate developer to fix the given bug and predict its severity.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-4799-3575-8",
      "DOI": "10.1109/COMPSAC.2014.16",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6899206",
      "Author_Keywords": "bug triage;severity prediction;topic model;multi-feature;corrective software maintenance",
      "IEEE_Terms": "Computer bugs;Predictive models;Social network services;Vectors;Software;Accuracy;Feature extraction",
      "Article Citation Count": "65",
      "Reference Count": "25",
      "License": "IEEE",
      "Online Date": "22-Sep-14",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "FECAR: A Feature Selection Framework for Software Defect Prediction",
      "Authors": "S. Liu; X. Chen; W. Liu; J. Chen; Q. Gu; D. Chen",
      "Author Affiliations": "State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; School of Computer Science and Technology, Nantong University, Nantong, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China",
      "Publication Title": "2014 IEEE 38th Annual Computer Software and Applications Conference",
      "Date Added To Xplore": "22-Sep-14",
      "Publication Year": "2014",
      "Start Page": "426",
      "End Page": "435",
      "Abstract": "Software defect prediction can classify new software entities into either buggy or clean. However the effectiveness of existing methods is influenced by irrelevant and redundant features. In this paper, we propose a new feature selection framework FECAR using Feature Clustering And feature Ranking. This framework firstly partitions original features into k clusters based on FF-Correlation measure. Then it selects relevant features from each cluster based on FC-Relevance measure. In empirical study, we choose Symmetric Uncertainty as FF-Correlation measure, and choose Information Gain, Chi-Square, and Relief as three different FC-Relevance measures. Based on some real projects Eclipse and NASA, we implemented our framework and performed empirical studies to investigate the redundancy rate and the performance of the trained defect predictors. Final results verify the effectiveness of our proposed framework and further provide a guideline for achieving cost-effective feature selection when using our framework.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-4799-3575-8",
      "DOI": "10.1109/COMPSAC.2014.66",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6899245",
      "Author_Keywords": "Software Defect Prediction;Feature Selection;Feature Clustering;Feature Ranking",
      "IEEE_Terms": "Software;Gain measurement;Redundancy;Clustering algorithms;Measurement uncertainty;Complexity theory",
      "Article Citation Count": "38",
      "Reference Count": "33",
      "License": "IEEE",
      "Online Date": "22-Sep-14",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "On the Use of Hidden Markov Model to Predict the Time to Fix Bugs",
      "Authors": "M. Habayeb; S. S. Murtaza; A. Miranskyy; A. B. Bener",
      "Author Affiliations": "Department of Mechanical and Industrial Engineering, Ryerson University, Toronto, Ontario, Canada; Department of Mechanical and Industrial Engineering, Ryerson University, Toronto, Ontario, Canada; Department of Computer Science, Ryerson University, Toronto, Ontario, Canada; Department of Mechanical and Industrial Engineering, Ryerson University, Toronto, Ontario, Canada",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "9-Dec-18",
      "Publication Year": "2018",
      "Volume": "44",
      "Issue": "12",
      "Start Page": "1224",
      "End Page": "1244",
      "Abstract": "A significant amount of time is spent by software developers in investigating bug reports. It is useful to indicate when a bug report will be closed, since it would help software teams to prioritise their work. Several studies have been conducted to address this problem in the past decade. Most of these studies have used the frequency of occurrence of certain developer activities as input attributes in building their prediction models. However, these approaches tend to ignore the temporal nature of the occurrence of these activities. In this paper, a novel approach using Hidden Markov Models and temporal sequences of developer activities is proposed. The approach is empirically demonstrated in a case study using eight years of bug reports collected from the Firefox project. Our proposed model correctly identifies bug reports with expected bug fix times. We also compared our proposed approach with the state of the art technique in the literature in the context of our case study. Our approach results in approximately 33 percent higher F-measure than the contemporary technique based on the Firefox project data.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2017.2757480",
      "Funding Information": "NSERC(grant numbers:402003-2012); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8052546",
      "Author_Keywords": "Bug repositories;temporal activities;time to fix a bug;hidden markov model",
      "IEEE_Terms": "Computer bugs;Hidden Markov models;Predictive models;Software quality;Data science;Stochastic processes",
      "Article Citation Count": "31",
      "Reference Count": "42",
      "License": "IEEE",
      "Online Date": "28-Sep-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Metrics Towards Measuring Cyber Agility",
      "Authors": "J. D. Mireles; E. Ficke; J. -H. Cho; P. Hurley; S. Xu",
      "Author Affiliations": "Department of Computer Science, The University of Texas at San Antonio, San Antonio, TX, USA; Department of Computer Science, The University of Texas at San Antonio, San Antonio, TX, USA; Department of Computer Science, Virginia Tech, Blacksburg, VA, USA; U.S. Air Force Research Laboratory, Rome, NY, USA; Department of Computer Science, The University of Texas at San Antonio, San Antonio, TX, USA",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "31-Jul-19",
      "Publication Year": "2019",
      "Volume": "14",
      "Issue": "12",
      "Start Page": "3217",
      "End Page": "3232",
      "Abstract": "In cyberspace, evolutionary strategies are commonly used by both attackers and defenders. For example, an attacker's strategy often changes over the course of time, as new vulnerabilities are discovered and/or mitigated. Similarly, a defender's strategy changes over time. These changes may or may not be in direct response to a change in the opponent's strategy. In any case, it is important to have a set of quantitative metrics to characterize and understand the effectiveness of attackers' and defenders' evolutionary strategies, which reflect their cyber agility. Despite its clear importance, few systematic metrics have been developed to quantify the cyber agility of attackers and defenders. In this paper, we propose the first metric framework for measuring cyber agility in terms of the effectiveness of the dynamic evolution of cyber attacks and defenses. The proposed framework is generic and applicable to transform any relevant, quantitative, and/or conventional static security metrics (e.g., false positives and false negatives) into dynamic metrics to capture dynamics of system behaviors. In order to validate the usefulness of the proposed framework, we conduct case studies on measuring the evolution of cyber attacks and defenses using two real-world datasets. We discuss the limitations of the current work and identify future research directions.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2019.2912551",
      "Funding Information": "U.S. Department of Defense; Army Research Office(grant numbers:W911NF-17-1-0566); Army Research Laboratory(grant numbers:W911NF-17-2-0127); National Science Foundation(grant numbers:1814825); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8695107",
      "Author_Keywords": "Security metrics;agility metrics;cyber agility;cyber maneuverability;measurements;attack;defense",
      "IEEE_Terms": "Time measurement;Cyberattack;Systematics;Current measurement",
      "Article Citation Count": "26",
      "Reference Count": "54",
      "License": "IEEE",
      "Online Date": "22-Apr-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "A Universal Data Augmentation Approach for Fault Localization",
      "Authors": "H. Xie; Y. Lei; M. Yan; Y. Yu; X. Xia; X. Mao",
      "Author Affiliations": "School of Big Data & Software Engineering, Chongqing University, Chongqing, China; School of Big Data & Software Engineering, Chongqing University, Chongqing, China; School of Big Data & Software Engineering, Chongqing University, Chongqing, China; National University of Defense Technology, Changsha, China; Software Engineering Application Technology Lab, Huawei, China; National University of Defense Technology, Changsha, China",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "48",
      "End Page": "60",
      "Abstract": "Data is the fuel to models, and it is still applicable in fault localization (FL). Many existing elaborate FL techniques take the code coverage matrix and failure vector as inputs, expecting the techniques could find the correlation between program entities and failures. However, the input data is high-dimensional and extremely imbalanced since the real-world programs are large in size and the number of failing test cases is much less than that of passing test cases, which are posing severe threats to the effectiveness of FL techniques. To overcome the limitations, we propose Aeneas, a universal data augmentation approach that generAtes synthesized failing test cases from reduced feature sace for more precise fault localization. Specifically, to improve the effectiveness of data augmentation, Aeneas applies a revised principal component analysis (PCA) first to generate reduced feature space for more concise representation of the original coverage matrix, which could also gain efficiency for data synthesis. Then, Aeneas handles the imbalanced data issue through generating synthesized failing test cases from the reduced feature space through conditional variational autoencoder (CVAE). To evaluate the effectiveness of Aeneas, we conduct large-scale experiments on 458 versions of 10 programs (from ManyBugs, SIR, and Defects4J) by six state-of-the-art FL techniques. The experimental results clearly show that Aeneas is statistically more effective than baselines, e.g., our approach can improve the six original methods by 89% on average under the Top-1 accuracy.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3510136",
      "Funding Information": "National Key Research and Development Project of China(grant numbers:2020YFB1711900); National Defense Basic Scientific Research Project(grant numbers:WDZC20 205500308); Fundamental Research Funds for the Central Universities(grant numbers:2021CDJQY-018); National Natural Science Foundation of China(grant numbers:62002034); Natural Science Foundation of Chongqing(grant numbers:cstc2021jcyj-msxmX0538); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793942",
      "Author_Keywords": "Fault Localization;Imbalanced Data;Data Augmentation",
      "IEEE_Terms": "Location awareness;Correlation;Codes;Pipelines;Feature extraction;Data models;Fuels",
      "Article Citation Count": "9",
      "Reference Count": "73",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Can I Solve It? Identifying APIs Required to Complete OSS Tasks",
      "Authors": "F. Santos; I. Wiese; B. Trinkenreich; I. Steinmacher; A. Sarma; M. A. Gerosa",
      "Author Affiliations": "Northern Arizona University, USA; Universidade Tecnol√≥gica Federal do Paran√°, Brazil; Northern Arizona University, USA; Northern Arizona University, USA; Oregon State University, USA; Northern Arizona University, USA",
      "Publication Title": "2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "28-Jun-21",
      "Publication Year": "2021",
      "Start Page": "346",
      "End Page": "257",
      "Abstract": "Open Source Software projects add labels to open issues to help contributors choose tasks. However, manually labeling issues is time-consuming and error-prone. Current automatic approaches for creating labels are mostly limited to classifying issues as a bug/non-bug. In this paper, we investigate the feasibility and relevance of labeling issues with the domain of the APIs required to complete the tasks. We leverage the issues‚Äô description and the project history to build prediction models, which resulted in precision up to 82% and recall up to 97.8%. We also ran a user study (n=74) to assess these labels‚Äô relevancy to potential contributors. The results show that the labels were useful to participants in choosing tasks, and the API-domain labels were selected more often than the existing architecture-based labels. Our results can inspire the creation of tools to automatically label issues, helping developers to find tasks that better match their skills.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-7281-8710-5",
      "DOI": "10.1109/MSR52588.2021.00047",
      "Funding Information": "National Science Foundation; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9463078",
      "Author_Keywords": "API identification;Labelling;Tagging;Skills;Multi-Label Classification;Mining Software Repositories;Case Study",
      "IEEE_Terms": "Industries;Tools;Predictive models;Prediction algorithms;Data models;Labeling;History",
      "Article Citation Count": "8",
      "Reference Count": "63",
      "License": "IEEE",
      "Online Date": "28-Jun-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Two-stage cost-sensitive local models for heterogeneous cross-project defect prediction",
      "Authors": "Y. Huang; X. Xu",
      "Author Affiliations": "Department of Computer Science and Engineering, Shanghai Key Laboratory of Trustworthy Computing, East China University of Science and Technology, Shanghai, China; Department of Computer Science and Engineering, Shanghai Key Laboratory of Trustworthy Computing, East China University of Science and Technology, Shanghai, China",
      "Publication Title": "2022 IEEE 46th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "10-Aug-22",
      "Publication Year": "2022",
      "Start Page": "819",
      "End Page": "828",
      "Abstract": "Software defect prediction is an active topic in the field of software engineering. Cross-project defect prediction (CPDP) adopts the defect data set of the source project to predict the defects of the target project. However, the metrics of the source project and those of the target project are often different, and the traditional CPDP has certain limitations at this time. To address the inconsistency of source and target metrics, researchers propose heterogeneous cross-project defect prediction (HCPDP). To improve the performance of the HCPDP, we propose new Two-stage Cost-sensitive Local Models (TCLM). TCLM aims to improve on the problem of feature selection, linear inseparability of heterogeneous data, class imbalance and data adoption problems in HCPDP. Firstly, in the feature selection stage, we add cost information to improve the feature selection algorithm. Then, KCCA (Kernel Canonical Correlation Analysis) is used to project and map the heterogeneous data into a common feature space so as to mitigate the problem of inconsistent feature sets of the source and the target projects. Secondly, in the model training stage, we adopt local models to improve the performance, and introduce cost information to deal with the class imbalance problem. To verify the effectiveness of the TCLM method, we conduct large-scale empirical study on 24 projects in the AEEEM, PROMISE, NASA, and Relink datasets. Experimental results show that TCLM indeed outperforms the previous work. Therefore, we recommend using the TCLM method to build an HCPDP model.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-6654-8810-5",
      "DOI": "10.1109/COMPSAC54236.2022.00132",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9842718",
      "Author_Keywords": "heterogeneous cross-project defect prediction;cost-sensitive;class imbalance;local models",
      "IEEE_Terms": "Training;Measurement;Costs;Computational modeling;NASA;Software quality;Predictive models",
      "Article Citation Count": "2",
      "Reference Count": "55",
      "License": "IEEE",
      "Online Date": "10-Aug-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Mitigating False Positive Static Analysis Warnings: Progress, Challenges, and Opportunities",
      "Authors": "Z. Guo; T. Tan; S. Liu; X. Liu; W. Lai; Y. Yang; Y. Li; L. Chen; W. Dong; Y. Zhou",
      "Author Affiliations": "State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; Beijing Bytedance Network Technology Company Ltd., Beijing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; College of Computer Science, National University of Defense Technology, Changsha, Hunan, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "12-Dec-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "12",
      "Start Page": "5154",
      "End Page": "5188",
      "Abstract": "Static analysis (SA) tools can generate useful static warnings to reveal the problematic code snippets in a software system without dynamically executing the corresponding source code. In the literature, static warnings are of paramount importance because they can easily indicate specific types of software defects in the early stage of a software development process, which accordingly reduces the maintenance costs by a substantial margin. Unfortunately, due to the conservative approximations of such SA tools, a large number of false positive (FP for short) warnings (i.e., they do not indicate real bugs) are generated, making these tools less effective. During the past two decades, therefore, many false positive mitigation (FPM for short) approaches have been proposed so that more accurate and critical warnings can be delivered to developers. This paper offers a detailed survey of research achievements on the topic of FPM. Given the collected 130 surveyed papers, we conduct a comprehensive investigation from five different perspectives. First, we reveal the research trends of this field. Second, we classify the existing FPM approaches into five different types and then present the concrete research progress. Third, we analyze the evaluation system applied to examine the performance of the proposed approaches in terms of studied SA tools, evaluation scenarios, performance indicators, and collected datasets, respectively. Fourth, we summarize the four types of empirical studies relating to SA warnings to exploit the insightful findings that are helpful to reduce FP warnings. Finally, we sum up 10 challenges unresolved in the literature from the aspects of systematicness, effectiveness, completeness, and practicability and outline possible research opportunities based on three emerging techniques in the future.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2023.3329667",
      "Funding Information": "Natural Science Foundation of China(grant numbers:62172205,62072194,62172202,62272221,62032019); National Key Research and Development Program of China(grant numbers:2022YFB4501903); Natural Science Foundation of Jiangsu Province(grant numbers:SBK2023022696); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10305541",
      "Author_Keywords": "Static warnings;false positives;defects;static analysis tools;software quality assurance",
      "IEEE_Terms": "Surveys;Software;Static analysis;Software quality;Codes;Computer bugs;Market research",
      "Reference Count": "186",
      "License": "IEEE",
      "Online Date": "2-Nov-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Morest: Model-based RESTful API Testing with Execution Feedback",
      "Authors": "Y. Liu; Y. Li; G. Deng; Y. Liu; R. Wan; R. Wu; D. Ji; S. Xu; M. Bao",
      "Author Affiliations": "Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Huawei Cloud Computing Technologies Co., Ltd, China; Huawei Cloud Computing Technologies Co., Ltd, China; Huawei Technologies Co., Ltd, China; Huawei Cloud Computing Technologies Co., Ltd, China; Huawei Cloud Computing Technologies Co., Ltd, China",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "1406",
      "End Page": "1417",
      "Abstract": "RESTful APIs are arguably the most popular endpoints for accessing Web services. Blackbox testing is one of the emerging techniques for ensuring the reliability of RESTful APIs. The major challenge in testing RESTful APIs is the need for correct sequences of API operation calls for in-depth testing. To build meaningful operation call sequences, researchers have proposed techniques to learn and utilize the API dependencies based on OpenAPI specifications. However, these techniques either lack the overall awareness of how all the APIs are connected or the flexibility of adaptively fixing the learned knowledge. In this paper, we propose Morest, a model-based RESTful API testing technique that builds and maintains a dynamically updating RESTful-service Property Graph (RPG) to model the behaviors of RESTful-services and guide the call sequence generation. We empirically evaluated Morest and the results demonstrate that Morest can successfully request an average of 152.66%-232.45% more API operations, cover 26.16%-103.24% more lines of code, and detect 40.64%-215.94% more bugs than state-of-the-art techniques. In total, we applied Morest to 6 real-world projects and found 44 bugs (13 of them cannot be detected by existing approaches). Specifically, 2 of the confirmed bugs are from Bitbucket, a famous code management service with more than 6 million users.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3510133",
      "Funding Information": "National Research Foundation(grant numbers:NRF2018NCR-NCR005-0001); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794107",
      "Author_Keywords": "RESTful service;model-based testing",
      "IEEE_Terms": "Adaptation models;Codes;Web services;Computer bugs;Restful API;Behavioral sciences;Reliability",
      "Article Citation Count": "3",
      "Reference Count": "49",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Understanding the (In)Security of Cross-side Face Verification Systems in Mobile Apps: A System Perspective",
      "Authors": "X. Zhang; H. Ye; Z. Huang; X. Ye; Y. Cao; Y. Zhang; M. Yang",
      "Author Affiliations": "Fudan University, Shanghai, China; Fudan University, Shanghai, China; Fudan University, Shanghai, China; Fudan University, Shanghai, China; Johns Hopkins University, Baltimore, USA; Fudan University, Shanghai, China; Fudan University, Shanghai, China",
      "Publication Title": "2023 IEEE Symposium on Security and Privacy (SP)",
      "Date Added To Xplore": "21-Jul-23",
      "Publication Year": "2023",
      "Start Page": "934",
      "End Page": "950",
      "Abstract": "Face Verification Systems (FVSes) are more and more deployed by real-world mobile applications (apps) to verify a human‚Äôs claimed identity. One popular type of FVSes is called cross-side FVS (XFVS), which splits the FVS functionality into two sides: one at a mobile phone to take pictures or videos and the other at a trusted server for verification. Prior works have studied the security of XFVSes from the machine learning perspective, i.e., whether the learning models used by XFVSes are robust to adversarial attacks. However, the security of other parts of XFVSes, especially the design and implementation of the verification procedure used by XFVSes, is not well understood.In this paper, we conduct the first measurement study on the security of real-world XFVSes used by popular mobile apps from a system perspective. More specifically, we design and implement a semi-automated system, called XFVSChecker, to detect XFVSes in mobile apps and then inspect their compliance with four security properties. Our evaluation reveals that most of existing XFVS apps, including those with billions of downloads, are vulnerable to at least one of four types of attacks. These attacks require only easily available attack prerequisites, such as one photo of the victim, to pose significant security risks, including complete account takeover, identity fraud and financial loss. Our findings result in 14 Chinese National Vulnerability Database (CNVD) IDs and one of them, particularly CNVD-2021-86899, is awarded the most valuable vulnerability in 2021 among all the reported vulnerabilities to CNVD.",
      "ISSN": "2375-1207",
      "ISBNs": "978-1-6654-9336-9",
      "DOI": "10.1109/SP46215.2023.10179474",
      "Funding Information": "Research and Development; National Natural Science Foundation of China; Shanghai Rising-Star Program; National Science Foundation; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10179474",
      "Author_Keywords": "Mobile-Security;Face-Verification;System-Perspective",
      "IEEE_Terms": "Privacy;Machine learning;Mobile applications;Internet;Fraud;Security;Servers",
      "Article Citation Count": "1",
      "Reference Count": "87",
      "License": "IEEE",
      "Online Date": "21-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "(Partial) Program Dependence Learning",
      "Authors": "A. Yadavally; T. N. Nguyen; W. Wang; S. Wang",
      "Author Affiliations": "Computer Science Department, The University of Texas at Dallas, Texas, USA; Computer Science Department, The University of Texas at Dallas, Texas, USA; Department of Informatics, New Jersey Institute of Technology, New Jersey, USA; Department of Informatics, New Jersey Institute of Technology, New Jersey, USA",
      "Publication Title": "2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "14-Jul-23",
      "Publication Year": "2023",
      "Start Page": "2501",
      "End Page": "2513",
      "Abstract": "Code fragments from developer forums often migrate to applications due to the code reuse practice. Owing to the incomplete nature of such programs, analyzing them to early determine the presence of potential vulnerabilities is challenging. In this work, we introduce NeuralPDA, a neural network-based program dependence analysis tool for both complete and partial programs. Our tool efficiently incorporates intra-statement and inter-statement contextual features into statement representations, thereby modeling program dependence analysis as a statement-pair dependence decoding task. In the empirical evaluation, we report that NeuralPDA predicts the CFG and PDG edges in complete Java and C/C++ code with combined F-scores of 94.29% and 92.46%, respectively. The F-score values for partial Java and C/C++ code range from 94.29%-97.17% and 92.46%-96.01%, respectively. We also test the usefulness of the PDGs predicted by NeuralPDA (i.e., PDG*) on the downstream task of method-level vulnerability detection. We discover that the performance of the vulnerability detection tool utilizing PDG* is only 1.1% less than that utilizing the PDGs generated by a program analysis tool. We also report the detection of 14 real-world vulnerable code snippets from StackOverflow by a machine learning-based vulnerability detection tool that employs the PDGs predicted by NeuralPDA for these code snippets.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-5701-9",
      "DOI": "10.1109/ICSE48619.2023.00209",
      "Funding Information": "US National Science Foundation (NSF)(grant numbers:CNS-2120386); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172603",
      "Author_Keywords": "neural partial program analysis;neural program dependence analysis;neural networks;deep learning",
      "IEEE_Terms": "Java;Analytical models;Codes;Image edge detection;Neural networks;Decoding;Task analysis",
      "Reference Count": "55",
      "License": "IEEE",
      "Online Date": "14-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Where Is the Road for Issue Reports Classification Based on Text Mining?",
      "Authors": "Q. Fan; Y. Yu; G. Yin; T. Wang; H. Wang",
      "Author Affiliations": "College of Computer, National University of Defence Technology, Changsha, China; College of Computer, National University of Defence Technology, Changsha, China; College of Computer, National University of Defence Technology, Changsha, China; College of Computer, National University of Defence Technology, Changsha, China; College of Computer, National University of Defence Technology, Changsha, China",
      "Publication Title": "2017 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)",
      "Date Added To Xplore": "11-Dec-17",
      "Publication Year": "2017",
      "Start Page": "121",
      "End Page": "130",
      "Abstract": "Currently, open source projects receive various kinds of issues daily, because of the extreme openness of Issue Tracking System (ITS) in GitHub. ITS is a labor-intensive and time-consuming task of issue categorization for project managers. However, a contributor is only required a short textual abstract to report an issue in GitHub. Thus, most traditional classification approaches based on detailed and structured data (e.g., priority, severity, software version and so on) are difficult to adopt. In this paper, issue classification approaches on a large-scale dataset, including 80 popular projects and over 252,000 issue reports collected from GitHub, were investigated. First, four traditional text-based classification methods and their performances were discussed. Semantic perplexity (i.e., an issues description confuses bug-related sentences with nonbug-related sentences) is a crucial factor that affects the classification performances based on quantitative and qualitative study. Finally, A two-stage classifier framework based on the novel metrics of semantic perplexity of issue reports was designed. Results show that our two-stage classification can significantly improve issue classification performances.",
      "ISBNs": "978-1-5090-4039-1",
      "DOI": "10.1109/ESEM.2017.19",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8170092",
      "Author_Keywords": "issue tracking system;machine learning technique;mining software repositories",
      "IEEE_Terms": "Computer bugs;Software;Data mining;Feature extraction;Semantics;Measurement",
      "Article Citation Count": "31",
      "Reference Count": "34",
      "License": "IEEE",
      "Online Date": "11-Dec-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "An Empirical Examination of the Relationship between Code Smells and Merge Conflicts",
      "Authors": "I. Ahmed; C. Brindescu; U. A. Mannan; C. Jensen; A. Sarma",
      "Author Affiliations": "School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR, USA; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR, USA; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR, USA; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR, USA; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR, USA",
      "Publication Title": "2017 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)",
      "Date Added To Xplore": "11-Dec-17",
      "Publication Year": "2017",
      "Start Page": "58",
      "End Page": "67",
      "Abstract": "Background: Merge conflicts are a common occurrence in software development. Researchers have shown the negative impact of conflicts on the resulting code quality and the development workflow. Thus far, no one has investigated the effect of bad design (code smells) on merge conflicts. Aims: We posit that entities that exhibit certain types of code smells are more likely to be involved in a merge conflict. We also postulate that code elements that are both \"smelly\" and involved in a merge conflict are associated with other undesirable effects (more likely to be buggy). Method: We mined 143 repositories from GitHub and recreated 6,979 merge conflicts to obtain metrics about code changes and conflicts. We categorized conflicts into semantic or non-semantic, based on whether changes affected the Abstract Syntax Tree. For each conflicting change, we calculate the number of code smells and the number of future bug-fixes associated with the affected lines of code. Results: We found that entities that are smelly are three times more likely to be involved in merge conflicts. Method-level code smells (Blob Operation and Internal Duplication) are highly correlated with semantic conflicts. We also found that code that is smelly and experiences merge conflicts is more likely to be buggy. Conclusion: Bad code design not only impacts maintainability, it also impacts the day to day operations of a project, such as merging contributions, and negatively impacts the quality of the resulting code. Our findings indicate that research is needed to identify better ways to support merge conflict resolution to minimize its effect on code quality.",
      "ISBNs": "978-1-5090-4039-1",
      "DOI": "10.1109/ESEM.2017.12",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8170085",
      "Author_Keywords": "Code Smell;Merge Conflict;Empirical Analysis;Machine Learning",
      "IEEE_Terms": "Software;Merging;Computer bugs;Tools;Software measurement;Semantics",
      "Article Citation Count": "26",
      "Reference Count": "68",
      "License": "IEEE",
      "Online Date": "11-Dec-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Detecting duplicate bug reports with software engineering domain knowledge",
      "Authors": "K. Aggarwal; T. Rutgers; F. Timbers; A. Hindle; R. Greiner; E. Stroulia",
      "Author Affiliations": "Department of Computing Science, University of Alberta, Edmonton, Canada; Department of Computing Science, University of Alberta, Edmonton, Canada; Department of Computing Science, University of Alberta, Edmonton, Canada; Department of Computing Science, University of Alberta, Edmonton, Canada; Department of Computing Science, University of Alberta, Edmonton, Canada; Department of Computing Science, University of Alberta, Edmonton, Canada",
      "Publication Title": "2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER)",
      "Date Added To Xplore": "9-Apr-15",
      "Publication Year": "2015",
      "Start Page": "211",
      "End Page": "220",
      "Abstract": "In previous work by Alipour et al., a methodology was proposed for detecting duplicate bug reports by comparing the textual content of bug reports to subject-specific contextual material, namely lists of software-engineering terms, such as non-functional requirements and architecture keywords. When a bug report contains a word in these word-list contexts, the bug report is considered to be associated with that context and this information tends to improve bug-deduplication methods. In this paper, we propose a method to partially automate the extraction of contextual word lists from software-engineering literature. Evaluating this software-literature context method on real-world bug reports produces useful results that indicate this semi-automated method has the potential to substantially decrease the manual effort used in contextual bug deduplication while suffering only a minor loss in accuracy.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-4799-8469-5",
      "DOI": "10.1109/SANER.2015.7081831",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7081831",
      "Author_Keywords": "duplicate bug reports;information retrieval;software engineering textbooks;machine learning;software literature;documentation",
      "IEEE_Terms": "Feature extraction;Context;Computer bugs;Documentation;Androids;Humanoid robots;Accuracy",
      "Article Citation Count": "25",
      "Reference Count": "20",
      "License": "IEEE",
      "Online Date": "9-Apr-15",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Modular Edge-/Cloud-Solution for Automated Error Detection of Industrial Hairpin Weldings using Convolutional Neural Networks",
      "Authors": "J. Vater; P. Schlaak; A. Knoll",
      "Author Affiliations": "BMW Group; BMW Group; Technical University of Munich",
      "Publication Title": "2020 IEEE 44th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "22-Sep-20",
      "Publication Year": "2020",
      "Start Page": "505",
      "End Page": "510",
      "Abstract": "The traction battery and the electric motor are the most important components of the electrified powertrain. To increase the energy efficiency of the electric motor, wound copper wires are being replaced by coated rectangular copper wires, so-called hairpins. Hence, to connect the hairpins conductively, they must be welded together. However, such new production processes are unknown compared with classic motor production. Therefore, this research aims to integrate Industry 4.0 techniques, such as cloud and edge computing, and advanced data analysis in the production process to better understand and optimize the manufacturing processes. Welding defects are classified with the help of a convolutional neural network (CNN) (predictive analysis) and, depending on the defect, a recommended course of action for reworking (prescriptive analysis) is given. However, the application of such complex algorithms as neural networks to large amounts of data requires huge computing resources. Therefore, a modular combination of an edge and cloud architecture is proposed in this paper. Furthermore, a pure cloud solution is compared with the edge solution.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-7281-7303-0",
      "DOI": "10.1109/COMPSAC48688.2020.0-202",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9202655",
      "Author_Keywords": "cloud computing;edge computing;machine learning;convolutional neural network;electric motor;hairpin;predictive analytics;prescriptive analytics",
      "IEEE_Terms": "Welding;Image edge detection;Real-time systems;Cloud computing;Edge computing;Stators",
      "Article Citation Count": "6",
      "Reference Count": "11",
      "License": "IEEE",
      "Online Date": "22-Sep-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "DeepVD: Toward Class-Separation Features for Neural Network Vulnerability Detection",
      "Authors": "W. Wang; T. N. Nguyen; S. Wang; Y. Li; J. Zhang; A. Yadavally",
      "Author Affiliations": "Department of Informatics, New Jersey Institute of Technology, New Jersey, USA; Computer Science Department, The University of Texas at Dallas, Texas, USA; Department of Informatics, New Jersey Institute of Technology, New Jersey, USA; Department of Informatics, New Jersey Institute of Technology, New Jersey, USA; Computer Science Department, University of Illinois Urbana-Champaign, Illinois, USA; Computer Science Department, The University of Texas at Dallas, Texas, USA",
      "Publication Title": "2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "14-Jul-23",
      "Publication Year": "2023",
      "Start Page": "2249",
      "End Page": "2261",
      "Abstract": "The advances of machine learning (ML) including deep learning (DL) have enabled several approaches to implicitly learn vulnerable code patterns to automatically detect software vulnerabilities. A recent study showed that despite successes, the existing ML/DL-based vulnerability detection (VD) models are limited in the ability to distinguish between the two classes of vulnerability and benign code. We propose DeepVD, a graph-based neural network VD model that emphasizes on class-separation features between vulnerability and benign code. DeepVDleverages three types of class-separation features at different levels of abstraction: statement types (similar to Part-of-Speech tagging), Post-Dominator Tree (covering regular flows of execution), and Exception Flow Graph (covering the exception and error-handling flows). We conducted several experiments to evaluate DeepVD in a real-world vulnerability dataset of 303 projects with 13,130 vulnerable methods. Our results show that DeepVD relatively improves over the state-of-the-art ML/DL-based VD approaches 13%‚Äì29.6% in precision, 15.6%‚Äì28.9% in recall, and 16.4%‚Äì25.8% in F-score. Our ablation study confirms that our designed features and components help DeepVDachieve high class-separability for vulnerability and benign code.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-5701-9",
      "DOI": "10.1109/ICSE48619.2023.00189",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172789",
      "Author_Keywords": "neural vulnerability detection;graph neural network;class separation",
      "IEEE_Terms": "Deep learning;Codes;Neural networks;Tagging;Feature extraction;Software;Flow graphs",
      "Article Citation Count": "1",
      "Reference Count": "58",
      "License": "IEEE",
      "Online Date": "14-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Automated Recovery of Issue-Commit Links Leveraging Both Textual and Non-textual Data",
      "Authors": "P. R. Mazrae; M. Izadi; A. Heydarnoori",
      "Author Affiliations": "Computer Engineering Department, Sharif University of Technology; Computer Engineering Department, Sharif University of Technology; Computer Engineering Department, Sharif University of Technology",
      "Publication Title": "2021 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "24-Nov-21",
      "Publication Year": "2021",
      "Start Page": "263",
      "End Page": "273",
      "Abstract": "An issue report documents the discussions around required changes in issue-tracking systems, while a commit contains the change itself in the version control systems. Recovering links between issues and commits can facilitate many software evolution tasks such as bug localization, defect prediction, software quality measurement, and software documentation. A previous study on over half a million issues from GitHub reports only about 42.2% of issues are manually linked by developers to their pertinent commits. Automating the linking of commit-issue pairs can contribute to the improvement of the said tasks. By far, current state-of-the-art approaches for automated commit-issue linking suffer from low precision, leading to unreliable results, sometimes to the point that imposes human supervision on the predicted links. The low performance gets even more severe when there is a lack of textual information in either commits or issues. Current approaches are also proven computationally expensive. We propose Hybrid-Linker, an enhanced approach that overcomes such limitations by exploiting two information channels; (1) a non-textual-based component that operates on non-textual, automatically recorded information of the commit-issue pairs to predict a link, and (2) a textual-based one which does the same using textual information of the commit-issue pairs. Then, combining the results from the two classifiers, Hybrid-Linker makes the final prediction. Thus, every time one component falls short in predicting a link, the other component fills the gap and improves the results. We evaluate Hybrid-Linker against competing approaches, namely FRLink and DeepLink on a dataset of 12 projects. Hybrid-Linker achieves 90.1%, 87.8%, and 88.9% based on recall, precision, and F-measure, respectively. It also outperforms FRLink and DeepLink by 31.3%, and 41.3%, regarding the F-measure. Moreover, the proposed approach exhibits extensive improvements in terms of performance as well. Finally, our source code and data are publicly available.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-6654-2882-8",
      "DOI": "10.1109/ICSME52107.2021.00030",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9609165",
      "Author_Keywords": "Link Recovery;Issue Report;Commit;Software Maintenance;Machine Learning;Ensemble Methods",
      "IEEE_Terms": "Location awareness;Software maintenance;Current measurement;Conferences;Software quality;Documentation;Control systems",
      "Article Citation Count": "5",
      "Reference Count": "22",
      "License": "IEEE",
      "Online Date": "24-Nov-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "ViDeZZo: Dependency-aware Virtual Device Fuzzing",
      "Authors": "Q. Liu; F. Toffalini; Y. Zhou; M. Payer",
      "Author Affiliations": "Zhejiang University; EPFL; Zhejiang University; EPFL",
      "Publication Title": "2023 IEEE Symposium on Security and Privacy (SP)",
      "Date Added To Xplore": "21-Jul-23",
      "Publication Year": "2023",
      "Start Page": "3228",
      "End Page": "3245",
      "Abstract": "A virtual machine interacts with its host environment through virtual devices, driven by virtual device messages, e.g., I/O operations. By issuing crafted messages, an adversary can exploit a vulnerability in a virtual device to escape the virtual machine, gaining host access. Even though hundreds of bugs in virtual devices have been discovered, coverage-based virtual device fuzzers hardly consider intra-message dependencies (a field in a virtual device message may be dependent on another field) and inter-message dependencies (a message may depend on a previously issued message), thus resulting in limited scalability or efficiency.ViDeZZo, our new dependency-aware fuzzing framework for virtual devices, overcomes the limitations of existing virtual device fuzzers by annotating intra-message dependencies with a lightweight grammar, and by self-learning inter-message dependencies with new mutation rules. Specifically, ViDeZZo annotates message dependencies and applies three categories of message mutators. This approach avoids heavy manual effort to analyze specifications and speeds up the slow exploration by satisfying dependencies, resulting in a scalable and efficient fuzzer that boosts bug discovery in virtual devices.In our evaluation, ViDeZZo covers two hypervisors, four architectures, five device categories, and 28 virtual devices, and reaches competitive coverage faster. Moreover, ViDeZZo successfully finds 24 existing and 28 new bugs across diverse bug types. We are actively engaging with the community with 7 of our submitted patches already accepted.",
      "ISSN": "2375-1207",
      "ISBNs": "978-1-6654-9336-9",
      "DOI": "10.1109/SP46215.2023.10179354",
      "Funding Information": "National Natural Science Foundation of China; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10179354",
      "Author_Keywords": "Hypervisor;Virtual-device;Fuzzing",
      "IEEE_Terms": "Privacy;Virtual machine monitors;Codes;Scalability;Computer bugs;Manuals;Fuzzing",
      "Article Citation Count": "1",
      "Reference Count": "37",
      "License": "IEEE",
      "Online Date": "21-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Improving Software Maintenance Using Process Mining and Predictive Analytics",
      "Authors": "M. Gupta; A. Serebrenik; P. Jalote",
      "Author Affiliations": "IIIT Delhi, India; Eindhoven University of Technology, The Netherlands; IIIT Delhi, India",
      "Publication Title": "2017 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "7-Nov-17",
      "Publication Year": "2017",
      "Start Page": "681",
      "End Page": "686",
      "Abstract": "This research focuses on analyzing and improving maintenance process by exploring novel applications of process mining and predictive analytics. We analyze the software maintenance process by applying process mining on software repositories, and address the identified inefficiencies using predictive analytics. To drive our research, we engage with practitioners from large, global IT companies and emphasize on the practical usability of the proposed solution approaches, which are evaluated by conducting a series of case studies on open source and commercial projects.",
      "ISBNs": "978-1-5386-0992-7",
      "DOI": "10.1109/ICSME.2017.39",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094481",
      "Author_Keywords": "Process Mining;Qualitative Study;Machine Learning;IT Support Process;Bug Detection",
      "IEEE_Terms": "Data mining;Software maintenance;Companies;Maintenance engineering;Object recognition;Clocks",
      "Article Citation Count": "7",
      "Reference Count": "25",
      "License": "IEEE",
      "Online Date": "7-Nov-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "GiveMeLabeledIssues: An Open Source Issue Recommendation System",
      "Authors": "J. Vargovich; F. Santos; J. Penney; M. A. Gerosa; I. Steinmacher",
      "Author Affiliations": "School of Informatics, Computing, and Cyber Systems, Northern Arizona University, Flagstaff, United States; School of Informatics, Computing, and Cyber Systems, Northern Arizona University, Flagstaff, United States; School of Informatics, Computing, and Cyber Systems, Northern Arizona University, Flagstaff, United States; School of Informatics, Computing, and Cyber Systems, Northern Arizona University, Flagstaff, United States; School of Informatics, Computing, and Cyber Systems, Northern Arizona University, Flagstaff, United States",
      "Publication Title": "2023 IEEE/ACM 20th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "12-Jul-23",
      "Publication Year": "2023",
      "Start Page": "402",
      "End Page": "406",
      "Abstract": "Developers often struggle to navigate an Open Source Software (OSS) project‚Äôs issue-tracking system and find a suitable task. Proper issue labeling can aid task selection, but current tools are limited to classifying the issues according to their type (e.g., bug, question, good first issue, feature, etc.). In contrast, this paper presents a tool (GiveMeLabeledIssues) that mines project repositories and labels issues based on the skills required to solve them. We leverage the domain of the APIs involved in the solution (e.g., User Interface (UI), Test, Databases (DB), etc.) as a proxy for the required skills. GiveMeLabeledIssues facilitates matching developers‚Äô skills to tasks, reducing the burden on project maintainers. The tool obtained a precision of 83.9% when predicting the API domains involved in the issues. The replication package contains instructions on executing the tool and including new projects. A demo video is available at https://www.youtube.com/watch?v=ic2quUue7i8",
      "ISSN": "2574-3864",
      "ISBNs": "979-8-3503-1184-6",
      "DOI": "10.1109/MSR59073.2023.00061",
      "Funding Information": "National Science Foundation; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10174101",
      "Author_Keywords": "Open Source Software;Machine Learning;Label;Tag;Task;Issue Tracker",
      "IEEE_Terms": "Navigation;Databases;Computer bugs;User interfaces;Labeling;Data mining;Task analysis",
      "Article Citation Count": "2",
      "Reference Count": "26",
      "License": "IEEE",
      "Online Date": "12-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Improvement of Min-Entropy Evaluation Based on Pruning and Quantized Deep Neural Network",
      "Authors": "H. Li; J. Zhang; Z. Li; J. Liu; Y. Wang",
      "Author Affiliations": "Key Laboratory of Advanced Transducers and Intelligent Control System, Ministry of Education of China, College of Physics and Optoelectronics, Taiyuan University of Technology, Taiyuan, China; Key Laboratory of Advanced Transducers and Intelligent Control System, Ministry of Education of China, College of Physics and Optoelectronics, Taiyuan University of Technology, Taiyuan, China; China Electric Power Research Institute, Beijing, China; Nations Technology Company Ltd, Shenzhen, China; Advanced Institute of Photonic Technology, Guangdong University of Technology, Guangzhou, China",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "7-Feb-23",
      "Publication Year": "2023",
      "Volume": "18",
      "Start Page": "1410",
      "End Page": "1420",
      "Abstract": "In the field of information security, the unpredictability of random numbers plays determinant role according to the security of cryptographic systems. However, limited by the capability of pattern recognition and data mining, statistical-based methods for random number security assessment can only detect whether there are obvious statistical flaws in random sequences. In recent years, some machine learning-based techniques such as deep neural networks and prediction-based methods applied to random number security have exhibited superior performance. Concurrently, the proposed deep learning models bring out issues of large number of parameters, high storage space occupation and complex computation. In this paper, for the challenge of random number security analysis: building high-performance predictive models, we propose an effective analysis method based on pruning and quantized deep neural network. Firstly, we train a temporal pattern attention-based long short-term memory (TPA-LSTM) model with complex structure and good prediction performance. Secondly, through pruning and quantization operations, the complexity and storage space occupation of the TPA-LSTM model were reduced. Finally, we retrain the network to find the best model and evaluate the effectiveness of this method using various simulated data sets with known min-entropy values. By comparing with related work, the TPA-LSTM model provides more accurate estimates: the relative error is less than 0.43%. In addition, the model weight parameters are reduced by more than 98% and quantized to 2 bits (compression over 175x) without accuracy loss.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2023.3240859",
      "Funding Information": "National Key Research and Development Program of China(grant numbers:2019YFB1803500); National Natural Science Foundation of China(grant numbers:62045009,61731014); Natural Science Foundation of Shanxi Province(grant numbers:202103021224038,20210302123185); International Cooperation of Key Research and Development Program of Shanxi Province(grant numbers:201903D421012); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10032186",
      "Author_Keywords": "Min-entropy;TPA-LSTM;random number;pruning;quantization",
      "IEEE_Terms": "Security;Predictive models;Entropy;Deep learning;Data models;Quantization (signal);Neural networks",
      "Article Citation Count": "6",
      "Reference Count": "39",
      "License": "IEEE",
      "Online Date": "30-Jan-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Security Vulnerabilities and Countermeasures for Target Localization in Bio-NanoThings Communication Networks",
      "Authors": "A. Giaretta; S. Balasubramaniam; M. Conti",
      "Author Affiliations": "Department of Mathematics, University of Padua, Padua, Italy; Nano Communication Centre, Tampere University of Technology, Tampere, Finland; Department of Mathematics, University of Padua, Padua, Italy",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "19-May-17",
      "Publication Year": "2016",
      "Volume": "11",
      "Issue": "4",
      "Start Page": "665",
      "End Page": "676",
      "Abstract": "The emergence of molecular communication has provided an avenue for developing biological nanonetworks. Synthetic biology is a platform that enables reprogramming cells, which we refer to as Bio-NanoThings, that can be assembled to create nanonetworks. In this paper, we focus on specific Bio-NanoThings, i.e, bacteria, where engineering their ability to emit or sense molecules can result in functionalities, such as cooperative target localization. Although this opens opportunities, e.g., for novel healthcare applications of the future, this can also lead to new problems, such as a new form of bioterrorism. In this paper, we investigate the disruptions that malicious Bio-NanoThings (M-BNTs) can create for molecular nanonetworks. In particular, we introduce two types of attacks: 1) blackhole and 2) sentry attacks. In blackhole attack M-BNTs emit attractant chemicals to draw-in the legitimate Bio-NanoThings (L-BNTs) from searching for their target, while in the sentry attack, the M-BNTs emit repellents to disperse the L-BNTs from reaching their target. We also present a countermeasure that L-BNTs can take to be resilient to the attacks, where we consider two forms of decision processes that includes Bayes‚Äô rule as well as a simple threshold approach. We run a thorough set of simulations to assess the effectiveness of the proposed attacks as well as the proposed countermeasure. Our results show that the attacks can significantly hinder the regular behavior of Bio-NanoThings, while the countermeasures are effective for protecting against such attacks.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2015.2505632",
      "Funding Information": "Academy of Finland FiDiPro (Finnish Distinguished Professor) program, for the Project ‚ÄúNanocommunication Networks,‚Äù 2012-2016; Finnish Academy Research Fellow program(grant numbers:284531); TENACE PRIN Project 20103P34XC funded by the Italian MIUR; Project ‚ÄúTackling Mobile Malware with Innovative Machine Learning Techniques‚Äù funded by the University of Padua; Marie Curie Fellowship through the European Commission(grant numbers:PCIG11-GA-2012-321980); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7347397",
      "Author_Keywords": "Molecular Communication;Internet of Nano Things;Security;Bioterrorism;Molecular communication;Internet of Nano Things;security;bioterrorism",
      "IEEE_Terms": "Nanobioscience;Microorganisms;Bioterrorism;Biological system modeling;Molecular communication;Chemicals",
      "Article Citation Count": "41",
      "Reference Count": "37",
      "License": "IEEE",
      "Online Date": "4-Dec-15",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Improving Fault Localization by Integrating Value and Predicate Based Causal Inference Techniques",
      "Authors": "Y. K√º√ß√ºk; T. A. D. Henderson; A. Podgurski",
      "Author Affiliations": "Case Western Reserve University; Google Inc, Mountain View, CA, USA; Department of Computer and Data Sciences, Case Western Reserve University, Cleveland, OH, USA",
      "Publication Title": "2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "7-May-21",
      "Publication Year": "2021",
      "Start Page": "649",
      "End Page": "660",
      "Abstract": "Statistical fault localization (SFL) techniques use execution profiles and success/failure information from software executions, in conjunction with statistical inference, to automatically score program elements based on how likely they are to be faulty. SFL techniques typically employ one type of profile data: either coverage data, predicate outcomes, or variable values. Most SFL techniques actually measure correlation, not causation, between profile values and success/failure, and so they are subject to confounding bias that distorts the scores they produce. This paper presents a new SFL technique, named UniVal, that uses causal inference techniques and machine learning to integrate information about both predicate outcomes and variable values to more accurately estimate the true failure-causing effect of program statements. UniVal was empirically compared to several coverage-based, predicate-based, and value-based SFL techniques on 800 program versions with real faults.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-0296-5",
      "DOI": "10.1109/ICSE43902.2021.00066",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9402143",
      "Author_Keywords": "Software Engineering;Software Fault Localization;Causal Inference;Fault Localization;Statistical Fault Localization",
      "IEEE_Terms": "Location awareness;Correlation;Machine learning;Software;Numerical models;Distortion measurement;Software engineering",
      "Article Citation Count": "17",
      "Reference Count": "63",
      "License": "IEEE",
      "Online Date": "7-May-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Understanding and Facilitating the Co-Evolution of Production and Test Code",
      "Authors": "S. Wang; M. Wen; Y. Liu; Y. Wang; R. Wu",
      "Author Affiliations": "Department of Computer Science and Engineering, Guangdong Provincial Key Laboratory of Brain-inspired Intelligent Computation, Southern University of Science and Technology, Shenzhen, China; School of Cyber Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; Department of Computer Science and Engineering, Guangdong Provincial Key Laboratory of Brain-inspired Intelligent Computation, Southern University of Science and Technology, Shenzhen, China; Software College, Northeastern University, Shenyang, China; School of Informatics, Xiamen University, Xiamen, China",
      "Publication Title": "2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "11-May-21",
      "Publication Year": "2021",
      "Start Page": "272",
      "End Page": "283",
      "Abstract": "Software products frequently evolve. When the production code undergoes major changes such as feature addition or removal, the corresponding test code typically should co-evolve. Otherwise, the outdated test may be ineffective in revealing faults or cause spurious test failures, which could confuse developers and waste QA resources. Despite its importance, maintaining such co-evolution can be time- and resource-consuming. Existing work has disclosed that, in practice, test code often fails to co-evolve with the production code. To facilitate the co-evolution of production and test code, this work explores how to automatically identify outdated tests. To gain insights into the problem, we conducted an empirical study on 975 open-source Java projects. By manually analyzing and comparing the positive cases, where the test code co-evolves with the production code, and the negative cases, where the co-evolution is not observed, we found that various factors (e.g., the different language constructs modified in the production code) can determine whether the test code should be updated. Guided by the empirical findings, we proposed a machine-learning based approach, SITAR, that holistically considers different factors to predict test changes. We evaluated SITAR on 20 popular Java projects. These results show that SITAR, under the within-project setting, can reach an average precision and recall of 81.4% and 76.1%, respectively, for identifying test code that requires update, which significantly outperforms rule-based baseline methods. SITAR can also achieve promising results under the cross-project setting and multiclass prediction, which predicts the exact change types of test code.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-7281-9630-5",
      "DOI": "10.1109/SANER50967.2021.00033",
      "Funding Information": "National Natural Science Foundation of China; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9425945",
      "Author_Keywords": "Software evolution;test maintenance;mining software repositories",
      "IEEE_Terms": "Java;Conferences;Semantics;Production;Machine learning;Syntactics;Feature extraction",
      "Article Citation Count": "6",
      "Reference Count": "46",
      "License": "IEEE",
      "Online Date": "11-May-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "How (Not) to Find Bugs: The Interplay Between Merge Conflicts, Co-Changes, and Bugs",
      "Authors": "L. Amaral; M. C. Oliveira; W. Luz; J. Fortes; R. Bonif√°cio; D. Alencar; E. Monteiro; G. Pinto; D. Lo",
      "Author Affiliations": "University of Bras√≠lia, Bras√≠lia, Brazil; Brazilian Ministry of Economy, Bras√≠lia, Brazil; University of Bras√≠lia, Bras√≠lia, Brazil; University of Bras√≠lia, Bras√≠lia, Brazil; University of Bras√≠lia, Bras√≠lia, Brazil; Brazilian Ministry of Economy, Bras√≠lia, Brazil; University of Bras√≠lia, Bras√≠lia, Brazil; Federal University of Par√°, Bel√©m, Brazil; Singapore Management University, Singapore",
      "Publication Title": "2020 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "2-Nov-20",
      "Publication Year": "2020",
      "Start Page": "441",
      "End Page": "452",
      "Abstract": "Context: In a seminal work, Ball et al. [1] investigate if the information available in version control systems could be used to predict defect density, arguing that practitioners and researchers could better understand errors \"if [our] version control system could talk\". In the meanwhile, several research works have reported that conflict merge resolution is a time consuming and error-prone task, while other contributions diverge about the correlation between co-change dependencies and defect density. Problem: The correlation between conflicting merge scenarios and bugs has not been addressed before, whilst the correlation between co-change dependencies and bug density has been only investigated using a small number of case studies-which can compromise the generalization of the results. Goal: To address this gap in the literature, this paper presents the results of a comprehensive study whose goal is to understand whether or not (a) conflicting merge scenarios and (b) co-change dependencies are good predictors for bug density. Method: We first build a curated dataset comprising the source code history of 29 popular Java Apache projects and leverage the SZZ algorithm to collect the sets of bug-fixing and bug-introducing commits. We then combine the SZZ results with the set of past conflicting merge scenarios and co-change dependencies of the projects. Finally, we use exploratory data analysis and machine learning models to understand the strength of the correlation between conflict resolution and co-change dependencies with defect density. Findings: (a) conflicting merge scenarios are not more prone to introduce bugs than regular commits, (b) there is a negligible to a small correlation between co-change dependencies and defect density-contradicting previous studies in the literature.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-7281-5619-4",
      "DOI": "10.1109/ICSME46990.2020.00049",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240688",
      "Author_Keywords": "software defects;software integration;merge conflicts;co-change dependencies",
      "IEEE_Terms": "Software maintenance;Correlation;Machine learning algorithms;Computer bugs;Control systems;Prediction algorithms;Task analysis",
      "Article Citation Count": "1",
      "Reference Count": "52",
      "License": "IEEE",
      "Online Date": "2-Nov-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Wireless Anomaly Detection Based on IEEE 802.11 Behavior Analysis",
      "Authors": "H. Alipour; Y. B. Al-Nashif; P. Satam; S. Hariri",
      "Author Affiliations": "Cloud Identity Services and Security Division, Microsoft, Redmond, WA, USA; Department of Electrical and Computer Engineering, Old Dominion University, Norfolk, VA, USA; Department of Electrical and Computer Engineering, The University of Arizona, Tucson, AZ, USA; Department of Electrical and Computer Engineering, The University of Arizona, Tucson, AZ, USA",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "19-May-17",
      "Publication Year": "2015",
      "Volume": "10",
      "Issue": "10",
      "Start Page": "2158",
      "End Page": "2170",
      "Abstract": "Wireless communication networks are pervading every aspect of our lives due to their fast, easy, and inexpensive deployment. They are becoming ubiquitous and have been widely used to transfer critical information, such as banking accounts, credit cards, e-mails, and social network credentials. The more pervasive the wireless technology is going to be, the more important its security issue will be. Whereas the current security protocols for wireless networks have addressed the privacy and confidentiality issues, there are unaddressed vulnerabilities threatening their availability and integrity (e.g., denial of service, session hijacking, and MAC address spoofing attacks). In this paper, we describe an anomaly based intrusion detection system for the IEEE 802.11 wireless networks based on behavioral analysis to detect deviations from normal behaviors that are triggered by wireless network attacks. Our anomaly behavior analysis of the 802.11 protocols is based on monitoring the n-consecutive transitions of the protocol state machine. We apply sequential machine learning techniques to model the n-transition patterns in the protocol and characterize the probabilities of these transitions being normal. We have implemented several experiments to evaluate our system performance. By cross validating the system over two different wireless channels, we have achieved a low false alarm rate (<;0.1%). We have also evaluated our approach against an attack library of known wireless attacks and has achieved more than 99% detection rate.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2015.2433898",
      "Funding Information": "AFOSR DDDAS(grant numbers:FA95550-12-1-0241); National Science Foundation research projects(grant numbers:NSF IIP-0758579,NCS-0855087,IIP-1127873); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7109166",
      "Author_Keywords": "Anomaly detection;IEEE 802.11 security;Intrusion detection;Wireless Network security;Protocol analysis;Wireless networks;Anomaly detection;IEEE 802.11 security;intrusion detection;wireless network security;protocol analysis;wireless networks",
      "IEEE_Terms": "Protocols;IEEE 802.11 Standards;Intrusion detection;Detectors;Communication system security;Wireless networks",
      "Article Citation Count": "56",
      "Reference Count": "27",
      "License": "IEEE",
      "Online Date": "15-May-15",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Mining Workflows for Anomalous Data Transfers",
      "Authors": "H. Tu; G. Papadimitriou; M. Kiran; C. Wang; A. Mandal; E. Deelman; T. Menzies",
      "Author Affiliations": "Department of Computer Science, North Carolina State University, Raleigh, USA; University of Southern California, Information Sciences Institute, Marina del Rey, CA, USA; Energy Sciences Network (ESnet), Lawrence Berkeley National Labs, CA, USA; RENCI, University of North Carolina, Chapel Hill, NC, USA; RENCI, University of North Carolina, Chapel Hill, NC, USA; University of Southern California, Information Sciences Institute, Marina del Rey, CA, USA; Department of Computer Science, North Carolina State University, Raleigh, USA",
      "Publication Title": "2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "28-Jun-21",
      "Publication Year": "2021",
      "Start Page": "1",
      "End Page": "12",
      "Abstract": "Modern scientific workflows are data-driven and are often executed on distributed, heterogeneous, high-performance computing infrastructures. Anomalies and failures in the work-flow execution cause loss of scientific productivity and inefficient use of the infrastructure. Hence, detecting, diagnosing, and mitigating these anomalies are immensely important for reliable and performant scientific workflows. Since these workflows rely heavily on high-performance network transfers that require strict QoS constraints, accurately detecting anomalous network performance is crucial to ensure reliable and efficient workflow execution. To address this challenge, we have developed X-FLASH, a network anomaly detection tool for faulty TCP workflow transfers. X-FLASH incorporates novel hyperparameter tuning and data mining approaches for improving the performance of the machine learning algorithms to accurately classify the anomalous TCP packets. X-FLASH leverages XGBoost as an ensemble model and couples XGBoost with a sequential optimizer, FLASH, borrowed from search-based Software Engineering to learn the optimal model parameters. X-FLASH found configurations that outperformed the existing approach up to 28%, 29%, and 40% relatively for F-measure, G-score, and recall in less than 30 evaluations. From (1) large improvement and (2) simple tuning, we recommend future research to have additional tuning study as a new standard, at least in the area of scientific workflow anomaly detection.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-7281-8710-5",
      "DOI": "10.1109/MSR52588.2021.00013",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9463120",
      "Author_Keywords": "Scientific Workflow;TCP Signatures;Anomaly Detection;Hyper-Parameter Tuning;Sequential Optimization",
      "IEEE_Terms": "Radio frequency;Tools;Data transfer;Data models;Software;Software reliability;Tuning",
      "Article Citation Count": "7",
      "Reference Count": "69",
      "License": "IEEE",
      "Online Date": "28-Jun-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "AST-SafeSec: Adaptive Stress Testing for Safety and Security Co-Analysis of Cyber-Physical Systems",
      "Authors": "N. Kaloudi; J. Li",
      "Author Affiliations": "Department of Computer Science, Norwegian University of Science and Technology, Trondheim, Norway; Department of Computer Science, Norwegian University of Science and Technology, Trondheim, Norway",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "11-Sep-23",
      "Publication Year": "2023",
      "Volume": "18",
      "Start Page": "5567",
      "End Page": "5579",
      "Abstract": "Cyber-physical systems are becoming more intelligent with the adoption of heterogeneous sensor networks and machine learning capabilities that deal with an increasing amount of input data. While this complexity aims to solve problems in various domains, it adds new challenges for the system assurance. One issue is the rise in the number of abnormal behaviors that affect system performance due to possible sensor faults and attacks. The combination of safety risks, which are usually caused by random sensor faults and security risks that can happen during any random system state, makes the full coverage testing of the cyber-physical system challenging. Existing techniques are inadequate to deal with complex safety and security co-risks against cyber-physical systems. In this paper, we propose AST-SafeSec, an analysis methodology for both safety and security aspects that utilizes reinforcement learning to identify the most likely adversarial paths at various normal or failure states of a cyber-physical system that can influence system behavior through its sensor data. The methodology is evaluated using an autonomous vehicle scenario by incorporating a security attack into the stochastic sensor elements of a vehicle. Evaluation results show that the methodology analyzes the interaction of malicious attacks with random faults and identifies the incident caused by the interactions and the most likely path that leads to the incident.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2023.3309160",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10231138",
      "Author_Keywords": "Co-analysis;cyber-physical systems (CPSs);cybersecurity;safety;stress testing;validation;verification",
      "IEEE_Terms": "Safety;Security;Testing;Complexity theory;Behavioral sciences;Cyber-physical systems;Cyberattack",
      "Reference Count": "57",
      "License": "IEEE",
      "Online Date": "28-Aug-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Person Identification by Keystroke Dynamics Using Pairwise User Coupling",
      "Authors": "S. Mondal; P. Bours",
      "Author Affiliations": "University of Twente (UT), Enschede, AE, The Netherlands; Department of Information Security and Communication Technology, Norwegian University of Science and Technology, NO-2802, Gj√∏vik, Norway",
      "Publication Title": "IEEE Transactions on Information Forensics and Security",
      "Date Added To Xplore": "1-Mar-17",
      "Publication Year": "2017",
      "Volume": "12",
      "Issue": "6",
      "Start Page": "1319",
      "End Page": "1329",
      "Abstract": "Due to the increasing vulnerabilities in cyberspace, security alone is not enough to prevent a breach, but cyber forensics or cyber intelligence is also required to prevent future attacks or to identify the potential attacker. The unobtrusive and covert nature of biometric data collection of keystroke dynamics has a high potential for use in cyber forensics or cyber intelligence. In this paper, we investigate the usefulness of keystroke dynamics to establish the person identity. We propose three schemes for identifying a person when typing on a keyboard. We use various machine learning algorithms in combination with the proposed pairwise user coupling technique and show the performance of each separate technique as well as the performance when combining two or more together. In particular, we show that pairwise user coupling in a bottom-up tree structure scheme gives the best performance, both concerning accuracy and time complexity. The proposed techniques are validated by using keystroke data. However, these techniques could equally well be applied to other pattern identification problems. We have also investigated the optimized feature set for person identification by using keystroke dynamics. Finally, we also examined the performance of the identification system when a user, unlike his normal behaviour, types with only one hand, and we show that performance then is not optimal, as was to be expected.",
      "ISSN": "1556-6021",
      "DOI": "10.1109/TIFS.2017.2658539",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7833085",
      "Author_Keywords": "Pairwise user coupling;keystroke dynamics;person identification;behavioural biometrics;cyber-forensics",
      "IEEE_Terms": "Authentication;Couplings;Support vector machines;Keyboards;Computers;Biological neural networks;Training",
      "Article Citation Count": "33",
      "Reference Count": "33",
      "License": "IEEE",
      "Online Date": "25-Jan-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Early Life Cycle Software Defect Prediction. Why? How?",
      "Authors": "S. N.C.; S. Majumder; T. Menzies",
      "Author Affiliations": "North Carolina State University, USA; Department of Computer Science, North Carolina State University, Raleigh, USA; Department of Computer Science, North Carolina State University, Raleigh, USA",
      "Publication Title": "2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "7-May-21",
      "Publication Year": "2021",
      "Start Page": "448",
      "End Page": "459",
      "Abstract": "Many researchers assume that, for software analytics, \"more data is better.\" We write to show that, at least for learning defect predictors, this may not be true. To demonstrate this, we analyzed hundreds of popular GitHub projects. These projects ran for 84 months and contained 3,728 commits (median values). Across these projects, most of the defects occur very early in their life cycle. Hence, defect predictors learned from the first 150 commits and four months perform just as well as anything else. This means that, at least for the projects studied here, after the first few months, we need not continually update our defect prediction models. We hope these results inspire other researchers to adopt a \"simplicity-first\" approach to their work. Some domains require a complex and data-hungry analysis. But before assuming complexity, it is prudent to check the raw data looking for \"short cuts\" that can simplify the analysis.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-0296-5",
      "DOI": "10.1109/ICSE43902.2021.00050",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9401968",
      "Author_Keywords": "sampling;early;defect prediction;analytics",
      "IEEE_Terms": "Transfer learning;Predictive models;Software;Task analysis;Stress;Software engineering;Software development management",
      "Article Citation Count": "5",
      "Reference Count": "81",
      "License": "IEEE",
      "Online Date": "7-May-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Prioritizing Test Inputs for Deep Neural Networks via Mutation Analysis",
      "Authors": "Z. Wang; H. You; J. Chen; Y. Zhang; X. Dong; W. Zhang",
      "Author Affiliations": "College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; Information and Network Center, Tianjin University, Tianjin, China; Information and Network Center, Tianjin University, Tianjin, China",
      "Publication Title": "2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "7-May-21",
      "Publication Year": "2021",
      "Start Page": "397",
      "End Page": "409",
      "Abstract": "Deep Neural Network (DNN) testing is one of the most widely-used ways to guarantee the quality of DNNs. However, labeling test inputs to check the correctness of DNN prediction is very costly, which could largely affect the efficiency of DNN testing, even the whole process of DNN development. To relieve the labeling-cost problem, we propose a novel test input prioritization approach (called PRIMA) for DNNs via intelligent mutation analysis in order to label more bug-revealing test inputs earlier for a limited time, which facilitates to improve the efficiency of DNN testing. PRIMA is based on the key insight: a test input that is able to kill many mutated models and produce different prediction results with many mutated inputs, is more likely to reveal DNN bugs, and thus it should be prioritized higher. After obtaining a number of mutation results from a series of our designed model and input mutation rules for each test input, PRIMA further incorporates learning-to-rank (a kind of supervised machine learning to solve ranking problems) to intelligently combine these mutation results for effective test input prioritization. We conducted an extensive study based on 36 popular subjects by carefully considering their diversity from five dimensions (i.e., different domains of test inputs, different DNN tasks, different network structures, different types of test inputs, and different training scenarios). Our experimental results demonstrate the effectiveness of PRIMA, significantly outperforming the state-of-the-art approaches (with the average improvement of 8.50%~131.01% in terms of prioritization effectiveness). In particular, we have applied PRIMA to the practical autonomous-vehicle testing in a large motor company, and the results on 4 real-world scene-recognition models in autonomous vehicles further confirm the practicability of PRIMA.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-0296-5",
      "DOI": "10.1109/ICSE43902.2021.00046",
      "Funding Information": "National Natural Science Foundation of China; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9402064",
      "Author_Keywords": "Test Prioritization;Deep Neural Network;Mutation;Label;Deep Learning Testing",
      "IEEE_Terms": "Training;Neural networks;Computer bugs;Companies;Predictive models;Labeling;Testing",
      "Article Citation Count": "41",
      "Reference Count": "81",
      "License": "IEEE",
      "Online Date": "7-May-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Improving Automated Bug Triaging with Specialized Topic Model",
      "Authors": "X. Xia; D. Lo; Y. Ding; J. M. Al-Kofahi; T. N. Nguyen; X. Wang",
      "Author Affiliations": "College of Computer Science and Technology, Zhejiang University, Hangzhou, China; School of Information Systems, Singapore Management University, Singapore, Singapore; School of Information Systems, Singapore Management University, Singapore, Singapore; Electrical and Computer Engineering Department, Iowa State University, Ames, IA, USA; Electrical and Computer Engineering Department, Iowa State University, Ames, IA, USA; College of Computer Science and Technology, Zhejiang University, Hangzhou, China",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "13-Mar-17",
      "Publication Year": "2017",
      "Volume": "43",
      "Issue": "3",
      "Start Page": "272",
      "End Page": "297",
      "Abstract": "Bug triaging refers to the process of assigning a bug to the most appropriate developer to fix. It becomes more and more difficult and complicated as the size of software and the number of developers increase. In this paper, we propose a new framework for bug triaging, which maps the words in the bug reports (i.e., the term space) to their corresponding topics (i.e., the topic space). We propose a specialized topic modeling algorithm named  multi-feature topic model (MTM) which extends Latent Dirichlet Allocation (LDA) for bug triaging. MTM  considers product and component information of bug reports to map the term space to the topic space. Finally, we propose an incremental learning method named TopicMiner which considers the topic distribution of a new bug report to assign an appropriate fixer based on the affinity of the fixer to the topics. We pair  TopicMiner with MTM (TopicMiner$^{MTM}$ ). We have evaluated our solution on 5 large bug report datasets including GCC, OpenOffice, Mozilla, Netbeans, and Eclipse containing a total of 227,278 bug reports. We show that TopicMiner $^{MTM}$  can achieve top-1 and top-5 prediction accuracies of 0.4831-0.6868, and 0.7686-0.9084, respectively. We also compare TopicMiner$^{MTM}$  with Bugzie, LDA-KL, SVM-LDA, LDA-Activity, and Yang et¬†al.'s approach. The results show that TopicMiner $^{MTM}$  on average improves top-1 and top-5 prediction accuracies of Bugzie by 128.48 and 53.22 percent, LDA-KL by 262.91 and 105.97 percent, SVM-LDA by 205.89 and 110.48 percent, LDA-Activity by 377.60 and 176.32 percent, and Yang et¬†al.'s approach by 59.88 and 13.70 percent, respectively.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2016.2576454",
      "Funding Information": "National Basic Research Program of China (the 973 Program)(grant numbers:2015CB352201); NSFC(grant numbers:61572426); National Key Technology R&D Program; Ministry of Science and Technology of China(grant numbers:2015BAH17F01); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7484672",
      "Author_Keywords": "Developer;bug triaging;feature information;topic model",
      "IEEE_Terms": "Software;Resource management;Software algorithms;Support vector machines;Learning systems;Indexes;Computer bugs",
      "Article Citation Count": "120",
      "Reference Count": "46",
      "License": "IEEE",
      "Online Date": "7-Jun-16",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Analyzing reviews and code of mobile apps for better release planning",
      "Authors": "A. Ciurumelea; A. Schaufelb√ºhl; S. Panichella; H. C. Gall",
      "Author Affiliations": "Department of Informatics, University of Zurich, Switzerland; Department of Informatics, University of Zurich, Switzerland; Department of Informatics, University of Zurich, Switzerland; Department of Informatics, University of Zurich, Switzerland",
      "Publication Title": "2017 IEEE 24th International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "23-Mar-17",
      "Publication Year": "2017",
      "Start Page": "91",
      "End Page": "102",
      "Abstract": "The mobile applications industry experiences an unprecedented high growth, developers working in this context face a fierce competition in acquiring and retaining users. They have to quickly implement new features and fix bugs, or risks losing their users to the competition. To achieve this goal they must closely monitor and analyze the user feedback they receive in form of reviews. However, successful apps can receive up to several thousands of reviews per day, manually analysing each of them is a time consuming task. To help developers deal with the large amount of available data, we manually analyzed the text of 1566 user reviews and defined a high and low level taxonomy containing mobile specific categories (e.g. performance, resources, battery, memory, etc.) highly relevant for developers during the planning of maintenance and evolution activities. Then we built the User Request Referencer (URR) prototype, using Machine Learning and Information Retrieval techniques, to automatically classify reviews according to our taxonomy and recommend for a particular review what are the source code files that need to be modified to handle the issue described in the user review. We evaluated our approach through an empirical study involving the reviews and code of 39 mobile applications. Our results show a high precision and recall of URR in organising reviews according to the defined taxonomy.",
      "ISBNs": "978-1-5090-5501-2",
      "DOI": "10.1109/SANER.2017.7884612",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7884612",
      "Author_Keywords": "Mobile Applications;User Reviews;Text Classification;Code Localization",
      "IEEE_Terms": "Taxonomy;Mobile communication;Mobile applications;Computer bugs;Prototypes;Batteries;Maintenance engineering",
      "Article Citation Count": "83",
      "Reference Count": "54",
      "License": "IEEE",
      "Online Date": "23-Mar-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "The Impact of Using Regression Models to Build Defect Classifiers",
      "Authors": "G. K. Rajbahadur; S. Wang; Y. Kamei; A. E. Hassan",
      "Author Affiliations": "Queen's University, Canada; Queen's University, Canada; Kyushu University, Japan; Queen's University, Canada",
      "Publication Title": "2017 IEEE/ACM 14th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "3-Jul-17",
      "Publication Year": "2017",
      "Start Page": "135",
      "End Page": "145",
      "Abstract": "It is common practice to discretize continuous defect counts into defective and non-defective classes and use them as a target variable when building defect classifiers (discretized classifiers). However, this discretization of continuous defect counts leads to information loss that might affect the performance and interpretation of defect classifiers. Another possible approach to build defect classifiers is through the use of regression models then discretizing the predicted defect counts into defective and non-defective classes (regression-based classifiers). In this paper, we compare the performance and interpretation of defect classifiers that are built using both approaches (i.e., discretized classifiers and regression-based classifiers) across six commonly used machine learning classifiers (i.e., linear/logistic regression, random forest, KNN, SVM, CART, and neural networks) and 17 datasets. We find that: i) Random forest based classifiers outperform other classifiers (best AUC) for both classifier building approaches, ii) In contrast to common practice, building a defect classifier using discretized defect counts (i.e., discretized classifiers) does not always lead to better performance. Hence we suggest that future defect classification studies should consider building regression-based classifiers (in particular when the defective ratio of the modeled dataset is low). Moreover, we suggest that both approaches for building defect classifiers should be explored, so the best-performing classifier can be used when determining the most influential features.",
      "ISBNs": "978-1-5386-1544-7",
      "DOI": "10.1109/MSR.2017.4",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7962363",
      "Author_Keywords": "Classification via regression;Random forest;Bug prediction;Discretization;Non-Discretization;Model Interpretation",
      "IEEE_Terms": "Buildings;Correlation;Software;Predictive models;Redundancy;Computational modeling;Data collection",
      "Article Citation Count": "41",
      "Reference Count": "44",
      "License": "IEEE",
      "Online Date": "3-Jul-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Deep Green: Modelling Time-Series of Software Energy Consumption",
      "Authors": "S. Romansky; N. C. Borle; S. Chowdhury; A. Hindle; R. Greiner",
      "Author Affiliations": "Department of Computing Science, University of Alberta Edmonton, Canada; Department of Computing Science, University of Alberta Edmonton, Canada; Department of Computing Science, University of Alberta Edmonton, Canada; Department of Computing Science, University of Alberta Edmonton, Canada; Department of Computing Science, University of Alberta Edmonton, Canada",
      "Publication Title": "2017 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "7-Nov-17",
      "Publication Year": "2017",
      "Start Page": "273",
      "End Page": "283",
      "Abstract": "Inefficient mobile software kills battery life. Yet, developers lack the tools necessary to detect and solve energy bugs in software. In addition, developers are usually tasked with the creation of software features and triaging existing bugs. This means that most developers do not have the time or resources to research, build, or employ energy debugging tools. We present a new method for predicting software energy consumption to help debug software energy issues. Our approach enables developers to align traces of software behavior with traces of software energy consumption. This allows developers to match run-time energy hot spots to the corresponding execution. We accomplish this by applying recent neural network models to predict time series of energy consumption given a software's behavior. We compare our time series models to prior state-of-the-art models that only predict total software energy consumption. We found that machine learning based time series based models, and LSTM based time series based models, can often be more accurate at predicting instantaneous power use and total energy consumption.",
      "ISBNs": "978-1-5386-0992-7",
      "DOI": "10.1109/ICSME.2017.79",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094428",
      "Author_Keywords": "energy;software engineering;online model;profiling;green mining;modelling",
      "IEEE_Terms": "Software;Energy consumption;Predictive models;Tools;Time series analysis;Energy measurement;Hardware",
      "Article Citation Count": "14",
      "Reference Count": "36",
      "License": "IEEE",
      "Online Date": "7-Nov-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Using Developer-Interaction Trails to Triage Change Requests",
      "Authors": "M. B. Zanjani; H. Kagdi; C. Bird",
      "Author Affiliations": "Department of Electrical Engineering and Computer Science, Wichita State University, Wichita, Kansas, USA; Department of Electrical Engineering and Computer Science, Wichita State University, Wichita, Kansas, USA; Microsoft Research, Redmond, WA, USA",
      "Publication Title": "2015 IEEE/ACM 12th Working Conference on Mining Software Repositories",
      "Date Added To Xplore": "6-Aug-15",
      "Publication Year": "2015",
      "Start Page": "88",
      "End Page": "98",
      "Abstract": "The paper presents an approach, namely iHDev, to recommend developers who are most likely to implement incoming change requests. The basic premise of iHDev is that the developers who interacted with the source code relevant to a given change request are most likely to best assist with its resolution. A machine-learning technique is first used to locate source code entities relevant to the textual description of a given change request. Ihdev then mines interaction trails (i.e., Mylyn sessions) associated with these source code entities to recommend a ranked list of developers. Ihdev integrates the interaction trails in a unique way to perform its task, which was not investigated previously. An empirical study on open source systems Mylyn and Eclipse Project was conducted to assess the effectiveness of iHDev. A number of change requests were used in the evaluated bench-mark. Recall for top one to five recommended developers and Mean Reciprocal Rank (MRR) values are reported. Furthermore, a comparative study with two previous approaches that use commit histories and/or the source code authorship information for developer recommendation was performed. Results show that iHDev could provide a recall gain of up to 127.27% with equivalent or improved MRR values by up to 112.5%.",
      "ISSN": "2160-1860",
      "ISBNs": "978-0-7695-5594-2",
      "DOI": "10.1109/MSR.2015.16",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7180070",
      "IEEE_Terms": "History;Computer bugs;Mathematical model;Software;Data mining;XML;Context",
      "Article Citation Count": "6",
      "Patent Citation Count": "1",
      "Reference Count": "38",
      "License": "IEEE",
      "Online Date": "6-Aug-15",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Where Should I Look at? Recommending Lines that Reviewers Should Pay Attention To",
      "Authors": "Y. Hong; C. K. Tantithamthavorn; P. P. Thongtanunam",
      "Author Affiliations": "Monash University, Australia; Monash University, Australia; The University of Melbourne, Australia",
      "Publication Title": "2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "21-Jul-22",
      "Publication Year": "2022",
      "Start Page": "1034",
      "End Page": "1045",
      "Abstract": "Code review is an effective quality assurance practice, yet can be time-consuming since reviewers have to carefully review all new added lines in a patch. Our analysis shows that at the median, patch authors often waited 15‚Äì64 hours to receive initial feedback from reviewers, which accounts for 16%-26% of the whole review time of a patch. Importantly, we also found that large patches tend to receive initial feedback from reviewers slower than smaller patches. Hence, it would be beneficial to reviewers to reduce their effort with an approach to pinpoint the lines that they should pay attention to. In this paper, we proposed REVSPOT-a machine learning-based approach to predict problematic lines (i.e., lines that will receive a comment and lines that will be revised). Through a case study of three open-source projects (i.e., Openstack Nova, Openstack Ironic, and Qt Base), Revspot can accurately predict lines that will receive comments and will be revised (with a Top-10 Accuracy of 81% and 93%, which is 56% and 15% better than the baseline approach), and these correctly predicted problematic lines are related to logic defects, which could impact the functionality of the system. Based on these findings, our Revspot could help reviewers to reduce their reviewing effort by reviewing a smaller set of lines and increasing code review speed and reviewers' productivity.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-6654-3786-8",
      "DOI": "10.1109/SANER53432.2022.00121",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9825760",
      "Author_Keywords": "Software Quality Assurance;Modern Code Review",
      "IEEE_Terms": "Productivity;Codes;Quality assurance;Conferences;Software quality;Open source software",
      "Article Citation Count": "5",
      "Reference Count": "63",
      "License": "IEEE",
      "Online Date": "21-Jul-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "iFeedback: Exploiting User Feedback for Real-Time Issue Detection in Large-Scale Online Service Systems",
      "Authors": "W. Zheng; H. Lu; Y. Zhou; J. Liang; H. Zheng; Y. Deng",
      "Author Affiliations": "School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; School of Computer Science, Fudan University, Shanghai, China; Tencent Inc., Shenzhen, China; Tencent Inc., Shenzhen, China; Tencent Inc., Shenzhen, China",
      "Publication Title": "2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "9-Jan-20",
      "Publication Year": "2019",
      "Start Page": "352",
      "End Page": "363",
      "Abstract": "Large-scale online systems are complex, fast-evolving, and hardly bug-free despite the testing efforts. Backend system monitoring cannot detect many types of issues, such as UI related bugs, bugs with small impact on backend system indicators, or errors from third-party co-operating systems, etc. However, users are good informers of such issues: They will provide their feedback for any types of issues. This experience paper discusses our design of iFeedback, a tool to perform real-time issue detection based on user feedback texts. Unlike traditional approaches that analyze user feedback with computation-intensive natural language processing algorithms, iFeedback is focusing on fast issue detection, which can serve as a system life-condition monitor. In particular, iFeedback extracts word combination-based indicators from feedback texts. This allows iFeedback to perform fast system anomaly detection with sophisticated machine learning algorithms. iFeedback then further summarizes the texts with an aim to effectively present the anomaly to the developers for root cause analysis. We present our representative experiences in successfully applying iFeedback in tens of large-scale production online service systems in ten months.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-7281-2508-4",
      "DOI": "10.1109/ASE.2019.00041",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952229",
      "Author_Keywords": "Bug and vulnerability detection",
      "IEEE_Terms": "Monitoring;Real-time systems;Task analysis;Computer bugs;Runtime;Anomaly detection",
      "Article Citation Count": "5",
      "Reference Count": "42",
      "License": "IEEE",
      "Online Date": "9-Jan-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "BugMiner: Automating Precise Bug Dataset Construction by Code Evolution History Mining",
      "Authors": "X. Song; Y. Wu; J. Cao; B. Chen; Y. Lin; Z. Lu; D. Wang; X. Peng",
      "Author Affiliations": "Fudan University, Shanghai, China; Fudan University, Shanghai, China; Fudan University, Shanghai, China; Fudan University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China; Fudan University, Shanghai, China; Fudan University, Shanghai, China; Fudan University, Shanghai, China",
      "Publication Title": "2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "8-Nov-23",
      "Publication Year": "2023",
      "Start Page": "1919",
      "End Page": "1929",
      "Abstract": "Bugs and their fixes in the code evolution histories are important assets for many software engineering tasks such as deriving new state-of-the-art automatic bug fixing techniques. Existing bug datasets are either manually built which is difficult to grow efficiently to a scale large enough for massive data analysis, or lack of precise information of how bugs are introduced and fixed which is critical for in-depth analysis such as buggy/fixing code identification. Moreover, the types of the bugs are typically missing in the existing bug datasets, limiting the possibility of developing high-precision type-specific approaches for enterprise-level purposes. In this work, we propose BugMiner, an approach to automatically collecting bugs from code repositories by isolating the critical changes of the bugs. We also propose a learning-based approach for automating bug type classification with relatively small manual labels of bug types. We evaluate our approach regarding the precision of bug information and the efficiency of the bug-mining process with 2,082 bugs automatically mined from 100 open-source projects. We demonstrate the improved effectiveness and efficiency in bug-fixing location identification, compared to the SOTA BugBuilder, and high recall and precision in bug-inducing location identification. We also compare our learning-based bug classification approach to traditional baseline method, indicating about 17 % improvement in classification effectiveness under macro-F1.",
      "ISSN": "2643-1572",
      "ISBNs": "979-8-3503-2996-4",
      "DOI": "10.1109/ASE56229.2023.00201",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:62172099); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298435",
      "Author_Keywords": "bug dataset;bug-fixing;bug-inducing;automatic bug mining",
      "IEEE_Terms": "Codes;Limiting;Data analysis;Computer bugs;Manuals;History;Data mining",
      "Reference Count": "54",
      "License": "IEEE",
      "Online Date": "8-Nov-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Faceted Bug Report Search with Topic Model",
      "Authors": "K. Liu; H. B. K. Tan",
      "Author Affiliations": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
      "Publication Title": "2014 IEEE 38th Annual Computer Software and Applications Conference",
      "Date Added To Xplore": "22-Sep-14",
      "Publication Year": "2014",
      "Start Page": "123",
      "End Page": "128",
      "Abstract": "During bug reporting, The same bugs could be repeatedly reported. As a result, extra time could be spent on bug triaging and fixing. In order to reduce redundant effort, it is important to provide bug reporters with the ability to search for previously reported bugs efficiently and accurately. The existing bug tracking systems are using relatively simple ranking functions, which often produce unsatisfactory results. In this paper, we apply Ranking SVM, a Learning to Rank technique to construct a ranking model for accurate bug report search. Based on the search results, a topic model is used to cluster the bug reports into multiple facets. Each facet contains similar bug reports of the same topic. Users and testers can locate relevant bugs more efficiently through a simple query. We perform evaluations on more than 16,340 Eclipse and Mozilla bug reports. The evaluation results show that the proposed approach can achieve better search results than the existing search functions.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-4799-3575-8",
      "DOI": "10.1109/COMPSAC.2014.19",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6899209",
      "Author_Keywords": "bug report search;topic model;clustering;faceted search;ranking SVM",
      "IEEE_Terms": "Training;Vectors;Support vector machines;Feature extraction;Standards;Databases;Computational modeling",
      "Article Citation Count": "1",
      "Reference Count": "19",
      "License": "IEEE",
      "Online Date": "22-Sep-14",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Efficient Bug Triage For Industrial Environments",
      "Authors": "W. Zhang",
      "Author Affiliations": "Adobe Inc., Mclean, VA, USA",
      "Publication Title": "2020 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "2-Nov-20",
      "Publication Year": "2020",
      "Start Page": "727",
      "End Page": "735",
      "Abstract": "Bug triage is an important task for software maintenance, especially in the industrial environment, where timely bug fixing is critical for customer experience. This process is usually done manually and often takes significant time. In this paper, we propose a machine-learning-based solution to address the problem efficiently. We argue that in the industrial environment, it is more suitable to assign bugs to software components (then to responsible developers) than to developers directly. Because developers can change their roles in industry, they may not oversee the same software module as before. We also demonstrate experimentally that assigning bugs to components rather than developers leads to much higher accuracy. Our solution is based on text-projection features extracted from bug descriptions. We use a Deep Neural Network to train the classification model. The proposed solution achieves state-of-the-art performance based on extensive experiments using multiple data sets. Moreover, our solution is computationally efficient and runs in near real-time.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-7281-5619-4",
      "DOI": "10.1109/ICSME46990.2020.00082",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9240673",
      "Author_Keywords": "Automatic bug triage;machine learning;text classification",
      "IEEE_Terms": "Industries;Software maintenance;Computer bugs;Neural networks;Feature extraction;Real-time systems;Task analysis",
      "Article Citation Count": "11",
      "Reference Count": "26",
      "License": "IEEE",
      "Online Date": "2-Nov-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Automatic Identification of Crash-inducing Smart Contracts",
      "Authors": "C. Ni; C. Tian; K. Yang; D. Lo; J. Chen; X. Yang",
      "Author Affiliations": "School of Software Technology, Zhejiang University, China; College of Computer Science and Technology, Zhejiang University, China; College of Computer Science and Technology, Zhejiang University, China; Singapore Management University Singapore; School of Software Engineering, Sun Yat-Sen University, China; College of Computer Science and Technology, Zhejiang University, China",
      "Publication Title": "2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "15-May-23",
      "Publication Year": "2023",
      "Start Page": "108",
      "End Page": "119",
      "Abstract": "Smart contract, a special software code running on and resided in the blockchain, enlarges the general application of blockchain and exchanges assets without dependence of external parties. With blockchain‚Äôs characteristic of immutability, they cannot be modified once deployed. Thus, the contract and the records are persisted on the blockchain forever, including failed transactions that are caused by runtime errors and result in the waste of computation, storage, and fees. In this paper, we refer to smart contracts which will cause runtime errors as crash-inducing smart contracts. However, automatic identification of crash-inducing smart contracts is limited investigated in the literature. The existing approaches to identify crash-inducing smart contracts are either limited in finding vulnerability (e.g., pattern-based static analysis) or very expensive (e.g., program analysis), which is insufficient for Ethereum.To reduce runtime errors on Ethereum, we propose an efficient, generalizable, and machine learning-based crash-inducing smart contract detector, CRASHSCDET, to automatically identify crash-inducing smart contracts. To investigate the effectiveness of CRASHSCDET, we firstly propose 34 static source code metrics from four dimensions (i.e., complexity metrics, count metrics, object-oriented metrics, and Solidity-specific metrics) to characterize smart contracts. Then, we collect a large-scale dataset of verified smart contracts (i.e., 54,739) and label these smart contracts based on their execution traces on Etherscan. We make a comprehensive comparison with three state-of-the-art approaches and the results show that CRASHSCDET can achieve good performance (i.e., 0.937 of F1-measure and 0.980 of AUC on average) and statistically significantly improve the baselines by 0.5%-60.4% in terms of F1-measure and by 41.2%-44.3% in terms of AUC, which indicates the effectiveness of static source code metrics in identifying crash-inducing smart contracts. We further investigate the importance of different types of metrics and find that metrics in different dimensions have varying abilities to depict the characteristic of smart contracts. Especially, metrics belonging to the \"Count\" dimension are the most discriminative ones but combining all metrics can achieve better prediction performance.",
      "ISSN": "2640-7574",
      "ISBNs": "978-1-6654-5278-6",
      "DOI": "10.1109/SANER56733.2023.00020",
      "Funding Information": "Research and Development; National Natural Science Foundation of China; National Science Foundation; Fundamental Research Funds for the Central Universities; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10123502",
      "Author_Keywords": "Crash-inducing Smart Contract;Static Source Code Metric;Quality Assurance;Ethereum;Machine Learning",
      "IEEE_Terms": "Measurement;Runtime;Source coding;Smart contracts;Detectors;Static analysis;Computer crashes",
      "Reference Count": "56",
      "License": "IEEE",
      "Online Date": "15-May-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Developing interpretable models with optimized set reduction for identifying high-risk software components",
      "Authors": "L. C. Briand; V. R. Brasili; C. J. Hetmanski",
      "Author Affiliations": "Institute for Advanced Computer Studies, Computer Science Department, University of Maryland, College Park, MD, USA; Dept. of Comput. Sci., Maryland Univ., College Park, MD, USA; Institute for Advanced Computer Studies, Computer Science Department, University of Maryland, College Park, MD, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "6-Aug-02",
      "Publication Year": "1993",
      "Volume": "19",
      "Issue": "11",
      "Start Page": "1028",
      "End Page": "1044",
      "Abstract": "Applying equal testing and verification effort to all parts of a software system is not very efficient, especially when resources are tight. Therefore, one needs to low/high fault frequency components so that testing/verification effort can be concentrated where needed. Such a strategy is expected to detect more faults and thus improve the resulting reliability of the overall system. The authors present the optimized set reduction approach for constructing such models, which is intended to fulfill specific software engineering needs. The approach to classification is to measure the software system and build multivariate stochastic models for predicting high-risk system components. Experimental results obtained by classifying Ada components into two classes (is, or is not likely to generate faults during system and acceptance rest) are presented. The accuracy of the model and the insights it provides into the error-making process are evaluated.<>",
      "ISSN": "1939-3520",
      "DOI": "10.1109/32.256851",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=256851",
      "IEEE_Terms": "Software engineering;System testing;Software systems;Predictive models;Data analysis;Logistics;Classification tree analysis;Machine learning;Software testing;Frequency",
      "Article Citation Count": "119",
      "Patent Citation Count": "1",
      "Reference Count": "29",
      "License": "IEEE",
      "Online Date": "6-Aug-02",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Revisiting and Improving SZZ Implementations",
      "Authors": "E. C. Neto; D. A. d. Costa; U. Kulesza",
      "Author Affiliations": "Federal Institute of Education, Science and Technology of Rio Grande do Norte, Natal, Brazil; Department of Information Science, University of Otago, Dunedin, New Zealand; Dept. of Informatics and Applied Maths, Federal University of Rio Grande do Norte, Natal, Brazil",
      "Publication Title": "2019 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)",
      "Date Added To Xplore": "17-Oct-19",
      "Publication Year": "2019",
      "Start Page": "1",
      "End Page": "12",
      "Abstract": "Background: The SZZ algorithm was proposed to identify bug-introducing changes, i.e., changes that are likely to induce bugs. Previous studies improved its implementation and evaluated its results.Aims: To address existing limitations of SZZ to improve the maturity of the algorithm. We also aim to verify if the improvements that have been proposed to the SZZ algorithm also hold in different datasets.Method: We re-evaluate two recent SZZ implementations using an adaptation of the Defects4J dataset, which works as a preprocessed dataset that can be used by SZZ. Furthermore, we revisit the limitations of RA-SZZ (refactoring aware SZZ) to improve the precision and recall of the algorithm.Results: We observe that a median of 44% of the lines that are flagged by the improved SZZ are very likely to introduce a bug. We manually analyze the SZZ-generated data and observe that there exist refactoring operations (31.17%) and equivalent changes (13.64%) that are still misidentified by the improved SZZ.Conclusion: By preprocessing the dataset that is used as input by SZZ, the accuracy of SZZ may be considerably improved. For example, we observe that SZZ implementations are approximately 40% more accurate if only valid bug-fix lines are used as the input for SZZ.",
      "ISSN": "1949-3789",
      "ISBNs": "978-1-7281-2968-6",
      "DOI": "10.1109/ESEM.2019.8870178",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8870178",
      "Author_Keywords": "SZZ algorithm;refactoring change;bug-introducing change;bug-fix change",
      "IEEE_Terms": "Computer bugs;Tools;History;Bars;Machine learning algorithms;Prediction algorithms;Software algorithms",
      "Article Citation Count": "20",
      "Reference Count": "49",
      "License": "IEEE",
      "Online Date": "17-Oct-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "How Often Do Single-Statement Bugs Occur? The ManySStuBs4J Dataset",
      "Authors": "R. -M. Karampatsis; C. Sutton",
      "Author Affiliations": "University of Edinburgh, Edinburgh, United Kingdom; Google Research, University of Edinburgh and The Alan Turing Institute, Mountain View, CA, United States",
      "Publication Title": "2020 IEEE/ACM 17th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "20-Jun-23",
      "Publication Year": "2020",
      "Start Page": "573",
      "End Page": "577",
      "Abstract": "Program repair is an important but difficult software engineering problem. One way to achieve acceptable performance is to focus on classes of simple bugs, such as bugs with single statement fixes, or that match a small set of bug templates. However, it is very difficult to estimate the recall of repair techniques for simple bugs, as there are no datasets about how often the associated bugs occur in code. To fill this gap, we provide a dataset of 153,652 single statement bug-fix changes mined from 1,000 popular open-source Java projects, annotated by whether they match any of a set of 16 bug templates, inspired by state-of-the-art program repair techniques. In an initial analysis, we find that about 33% of the simple bug fixes match the templates, indicating that a remarkable number of single-statement bugs can be repaired with a relatively small set of templates. Further, we find that template fitting bugs appear with a frequency of about one bug per 1,600-2,500 lines of code (as measured by the size of the project's latest version). We hope that the dataset will prove a resource for both future work in program repair and studies in empirical software engineering.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-4503-7517-7",
      "DOI": "10.1145/3379597.3387491",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10148782",
      "Author_Keywords": "Program Repair;Mining Software Repositories;Datasets",
      "IEEE_Terms": "Java;Codes;Computer bugs;Machine learning;Maintenance engineering;Size measurement;Software",
      "Article Citation Count": "20",
      "Reference Count": "27",
      "Online Date": "20-Jun-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Constrained feature selection for localizing faults",
      "Authors": "T. -D. B. Le; D. Lo; M. Li",
      "Author Affiliations": "School of Information Systems, Singapore Management University, Singapore; School of Information Systems, Singapore Management University, Singapore; Collaborative Innovation Center of Novel Software Technology and Industrialization, Nanjing University",
      "Publication Title": "2015 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "23-Nov-15",
      "Publication Year": "2015",
      "Start Page": "501",
      "End Page": "505",
      "Abstract": "Developers often take much time and effort to find buggy program elements. To help developers debug, many past studies have proposed spectrum-based fault localization techniques. These techniques compare and contrast correct and faulty execution traces and highlight suspicious program elements. In this work, we propose constrained feature selection algorithms that we use to localize faults. Feature selection algorithms are commonly used to identify important features that are helpful for a classification task. By mapping an execution trace to a classification instance and a program element to a feature, we can transform fault localization to the feature selection problem. Unfortunately, existing feature selection algorithms do not perform too well, and we extend its performance by adding a constraint to the feature selection formulation based on a specific characteristic of the fault localization problem. We have performed experiments on a popular benchmark containing 154 faulty versions from 8 programs and demonstrate that several variants of our approach can outperform many fault localization techniques proposed in the literature. Using Wilcoxon rank-sum test and Cliff's d effect size, we also show that the improvements are both statistically significant and substantial.",
      "ISBNs": "978-1-4673-7532-0",
      "DOI": "10.1109/ICSM.2015.7332502",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7332502",
      "IEEE_Terms": "Standards;Feature extraction;Software;Machine learning algorithms;Benchmark testing;Computer bugs;Information systems",
      "Article Citation Count": "10",
      "Reference Count": "14",
      "License": "IEEE",
      "Online Date": "23-Nov-15",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "You Look so Different: Finding Structural Clones and Subclones in Java Source Code",
      "Authors": "W. Amme; T. S. Heinze; A. Sch√§fer",
      "Author Affiliations": "Institute of Computer Science Friedrich Schiller University Jena, Jena, Germany; Institute of Data Science German Aerospace Center (DLR), Jena, Germany; Institute of Computer Science Friedrich Schiller University Jena, Jena, Germany",
      "Publication Title": "2021 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "24-Nov-21",
      "Publication Year": "2021",
      "Start Page": "70",
      "End Page": "80",
      "Abstract": "Code reuse and copying is a widespread practice in software development. Detecting code clones, i.e., identical or similar fragments of code, is thus an important task with many applications, ranging from code search to bug finding and malware detection. In this paper, we propose a new approach to detect code clones in source code. Instead of analyzing the code tokens or syntax, our technique is based upon control flow analysis and dominator trees. In this way, the technique not only detects exact and syntactically similar near-miss code clones but also two new types of clones, which we characterize as structural code clones and subclones. For implementation and evaluation, we have developed the tool StoneDetector, which finds code clones in Java source code. StoneDetector performs competitive with the state of the art as measured on the BigCloneBench benchmark and finds more structural clones and subclones.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-6654-2882-8",
      "DOI": "10.1109/ICSME52107.2021.00013",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9609181",
      "Author_Keywords": "code clone;clone detection;subclone;structural clone;code duplication",
      "IEEE_Terms": "Java;Software maintenance;Codes;Cloning;Machine learning;Tools;Syntactics",
      "Article Citation Count": "7",
      "Reference Count": "52",
      "License": "IEEE",
      "Online Date": "24-Nov-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Ground-Truth Deficiencies in Software Engineering: When Codifying the Past Can Be Counterproductive",
      "Authors": "E. T√ºz√ºn; H. Erdogmus; M. T. Baldassarre; M. Felderer; R. Feldt; B. Turhan",
      "Author Affiliations": "Bilkent University; Carnegie Mellon University; University of Bari; University of Innsbruck and Blekinge Institute of Technology; Chalmers University of Technology and Blekinge Institute of Technology; University of Oulu and Monash University",
      "Publication Title": "IEEE Software",
      "Date Added To Xplore": "15-Apr-22",
      "Publication Year": "2022",
      "Volume": "39",
      "Issue": "3",
      "Start Page": "85",
      "End Page": "95",
      "Abstract": "In software engineering, the objective function of human decision makers might be influenced by many factors. Relying on historical data as the ground truth may give rise to systems that automate software engineering decisions by mimicking past suboptimal behavior. We describe the problem and offer some strategies.",
      "ISSN": "1937-4194",
      "DOI": "10.1109/MS.2021.3098670",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9491146",
      "IEEE_Terms": "Computer bugs;Software engineering;Software;Data models;Tools;Task analysis;Machine learning",
      "Article Citation Count": "1",
      "Reference Count": "20",
      "License": "IEEE",
      "Online Date": "20-Jul-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Magazines"
    },
    {
      "Document Title": "Identifying Defect-Inducing Changes in Visual Code",
      "Authors": "K. Eng; A. Hindle; A. Senchenko",
      "Author Affiliations": "Quality, Verification & Standards, Electronic Arts, Edmonton, Canada; Department of Computing Science, University of Alberta, Edmonton, Canada; Quality, Verification & Standards, Electronic Arts, Vancouver, Canada",
      "Publication Title": "2023 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "11-Dec-23",
      "Publication Year": "2023",
      "Start Page": "474",
      "End Page": "484",
      "Abstract": "Defects, or bugs, often form during software development. Identifying the root cause of defects is essential to improve code quality, evaluate testing methods, and support defect prediction. Examples of defect-inducing changes can be found using the SZZ algorithm to trace the textual history of defect-fixing changes back to the defect-inducing changes that they fix in line-based code. The line-based approach of the SZZ method is ineffective for visual code that represents source code graphically rather than textually. In this paper we adapt SZZ for visual code and present the SZZ Visual Code (SZZ-VC) algorithm, that finds changes in visual code based on the differences of graphical elements rather than differences of lines to detect defect-inducing changes. We validated the algorithm for an industry-made AAA video game and 20 music visual programming defects across 12 open source projects. Our results show that SZZ-VC is feasible for detecting defects in visual code for 3 different visual programming languages.",
      "ISSN": "2576-3148",
      "ISBNs": "979-8-3503-2783-0",
      "DOI": "10.1109/ICSME58846.2023.00061",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10336342",
      "Author_Keywords": "visual programming;visual code;bugs;defects;version control",
      "IEEE_Terms": "Visualization;Video games;Software maintenance;Codes;Source coding;Software algorithms;Machine learning",
      "Article Citation Count": "1",
      "Reference Count": "51",
      "License": "IEEE",
      "Online Date": "11-Dec-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Functional Programming Model for Embedded Dataflow Applications",
      "Authors": "C. K√ºhbacher; C. Mellwig; F. Haas; T. Ungerer",
      "Author Affiliations": "Department of Computer Science, University of Augsburg, Augsburg, Germany; Department of Computer Science, University of Augsburg, Augsburg, Germany; Department of Computer Science, University of Augsburg, Augsburg, Germany; Department of Computer Science, University of Augsburg, Augsburg, Germany",
      "Publication Title": "2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "9-Jul-19",
      "Publication Year": "2019",
      "Volume": "2",
      "Start Page": "646",
      "End Page": "651",
      "Abstract": "In this paper, we present a functional programming model and a dataflow execution model similar to distributed computing frameworks, like Apache Spark and Flink. Our programming and execution model is suitable for any platform, although its main target are safety-critical embedded systems. Therefore, we emphasize on low overhead, timing analyzability, and potential support for fault tolerance. We implemented our design for the x86 shared memory platform and showed that the performance is comparable to the performance of OpenMP.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-7281-2607-4",
      "DOI": "10.1109/COMPSAC.2019.10281",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8754141",
      "Author_Keywords": "dataflow execution model;functional programming model;embedded systems",
      "IEEE_Terms": "Cluster computing;Computational modeling;Functional programming;Embedded systems;Data models;Machine learning",
      "Reference Count": "9",
      "License": "IEEE",
      "Online Date": "9-Jul-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Detecting Malicious Inputs of Web Application Parameters Using Character Class Sequences",
      "Authors": "Y. Zhong; H. Asakura; H. Takakura; Y. Oshima",
      "Author Affiliations": "NTT Secure Platform Laboratories, Tokyo, JAPAN; NTT Secure Platform Laboratories, Tokyo, JAPAN; Information Technology Center, Nagoya University, Nagoya, JAPAN; NTT Secure Platform Laboratories, Tokyo, JAPAN",
      "Publication Title": "2015 IEEE 39th Annual Computer Software and Applications Conference",
      "Date Added To Xplore": "24-Sep-15",
      "Publication Year": "2015",
      "Volume": "2",
      "Start Page": "525",
      "End Page": "532",
      "Abstract": "Web attacks that exploit vulnerabilities of web applications are still major problems. The number of attacks that maliciously manipulate parameters of web applications such as SQL injections and command injections is increasing nowadays. Anomaly detection is effective for detecting these attacks, particularly in the case of unknown attacks. However, existing anomaly detection methods often raise false alarms with normal requests whose parameters differ slightly from those of learning data because they perform strict feature matching between characters appeared as parameter values and those of normal profiles. We propose a novel anomaly detection method using the abstract structure of parameter values as features of normal profiles in this paper. The results of experiments show that our approach reduced the false positive rate more than existing methods with a comparable detection rate.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-4673-6564-2",
      "DOI": "10.1109/COMPSAC.2015.73",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7273662",
      "Author_Keywords": "Web application;HTTP;Anomaly detection;Attack detection",
      "IEEE_Terms": "Servers;Feature extraction;Training;Accuracy;Training data;Electronic mail;Payloads",
      "Article Citation Count": "2",
      "Reference Count": "14",
      "License": "IEEE",
      "Online Date": "24-Sep-15",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Usability-Oriented Design of Liquid Types for Java",
      "Authors": "C. Gamboa; P. Canelas; C. Timperley; A. Fonseca",
      "Author Affiliations": "School of Computer Science, Carnegie Mellon University, USA; School of Computer Science, Carnegie Mellon University, USA; School of Computer Science, Carnegie Mellon University, USA; LASIGE, Faculdade de Ci√™ncias da, Universidade de Lisboa, Portugal",
      "Publication Title": "2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "14-Jul-23",
      "Publication Year": "2023",
      "Start Page": "1520",
      "End Page": "1532",
      "Abstract": "Developers want to detect bugs as early in the development lifecycle as possible, as the effort and cost to fix them increases with the incremental development of features. Ultimately, bugs that are only found in production can have catastrophic consequences. Type systems are effective at detecting many classes of bugs during development, often providing immediate feedback both at compile-time and while typing due to editor integration. Unfortunately, more powerful static and dynamic analysis tools do not have the same success due to providing false positives, not being immediate, or not being integrated into the language. Liquid Types extend the language type system with predicates, augmenting the classes of bugs that the compiler or IDE can catch compared to the simpler type systems available in mainstream programming languages. However, previous implementations of Liquid Types have not used human-centered methods for designing or evaluating their extensions. Therefore, this paper investigates how Liquid Types can be integrated into a mainstream programming language, Java, by proposing a new design that aims to lower the barriers to entry and adapts to problems that Java developers commonly encounter at runtime. Following a participatory design methodology, we conducted a developer survey to design the syntax of LiquidJava, our prototype. To evaluate if the added effort to writing Liquid Types in Java would convince users to adopt them, we conducted a user study with 30 Java developers. The results show that LiquidJava helped users detect and fix more bugs and that Liquid Types are easy to interpret and learn with few resources. At the end of the study, all users reported interest in adopting LiquidJava for their projects.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-5701-9",
      "DOI": "10.1109/ICSE48619.2023.00132",
      "Funding Information": "Funda√ß√£o para a Ci√™ncia e a Tecnologia(grant numbers:UIDB/00408/2020,UIDP/00408/2020); AFRL(grant numbers:19-PAF00747); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172818",
      "Author_Keywords": "Usability;Java;Refinement Types;Liquid Types",
      "IEEE_Terms": "Surveys;Java;Computer languages;Liquids;Runtime;Program processors;Computer bugs",
      "Reference Count": "49",
      "License": "IEEE",
      "Online Date": "14-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Neural Program Repair with Execution-based Backpropagation",
      "Authors": "H. Ye; M. Martinez; M. Monperrus",
      "Author Affiliations": "KTH Royal Institute of Technology, Sweden; Universit√© Polytechnique, France; KTH Royal Institute of Technology, Sweden",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "1506",
      "End Page": "1518",
      "Abstract": "Neural machine translation (NMT) architectures have achieved promising results for automatic program repair. Yet, they have the limitation of generating low-quality patches (e.g., not compilable patches). This is because the existing works only optimize a purely syntactic loss function based on characters and tokens without incorporating program-specific information during neural network weight optimization. In this paper, we propose a novel program repair model called RewardRepair. The core novelty of RewardRepair is to improve NMT-based program repair with a loss function based on program compilation and test execution information, rewarding the network to produce patches that compile and that do not overfit. We conduct several experiments to evaluate RewardRepair showing that it is feasible and effective to use compilation and test execution results to optimize the underlying neural repair model. RewardRepair correctly repairs 207 bugs over four benchmarks. we report on repair success for 121 bugs that are fixed for the first time in the literature. Also, RewardRepair produces up to 45.3% of compilable patches, an improvement over the 39% by the state-of-the-art.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3510222",
      "Funding Information": "Knut and Alice Wallenberg Foundation; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793856",
      "Author_Keywords": "automated program repair",
      "IEEE_Terms": "Backpropagation;Training;Computer bugs;Semantics;Neural networks;Maintenance engineering;Syntactics",
      "Article Citation Count": "17",
      "Reference Count": "76",
      "License": "CCBY",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Comments on ‚ÄúUsing $k$k-Core Decomposition on Class Dependency Networks to Improve Bug Prediction Model's Practical Performance‚Äù",
      "Authors": "W. Pan; H. Ming; Z. Yang; T. Wang",
      "Author Affiliations": "School of Computer Science and Information Engineering, Zhejiang Gongshang University, Hangzhou, China; School of Engineering and Computer Science, Oakland University, Rochester, MI, USA; School of Computer Science, Xi'an Jiaotong University and GuardStrike Inc., Shaanxi, China; School of Computer Science and Information Engineering, Zhejiang Gongshang University, Hangzhou, China",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "9-Dec-22",
      "Publication Year": "2022",
      "Volume": "48",
      "Issue": "12",
      "Start Page": "5176",
      "End Page": "5187",
      "Abstract": "In a very recent paper by (Qu et al., 2021), the authors propose an effective equation, top-core, to improve the performance of effort-aware bug prediction models. A distinctive feature of top-core is that it takes into account the coreness of a class in a Class Dependency Network (CDN) when calculating the relative risk of a class to be buggy. In this comment, we show that Qu et al.'s paper contains three shortcomings that may influence the performance of top-core or even have the potential to lead to erroneous results. First, we show that the CDN that they use to calculate the coreness of classes is not very accurate, neglecting many important types of dependency relations between classes such as method call relation, access relation, and instantiates relation. Second, they trained a Logistic Regression model using the scikit-learn framework to predict the probability of a specific class to be buggy. It is actually an L2 regularized Logistic Regression model, which is dependent on the scale of the features. But they neglected to normalize the features, making the obtained results erroneous. Finally, the number of execution times (viz. 10 times in the paper of Qu et al.) they used to reduce the bias caused by the randomness (viz. random split of instances and the process to handle class-imbalance problem) in the experiments is too small to ensure that the obtained results converge to stable values; but they failed to signify the precision level of their results for comparison. In this comment, we provide solutions to the problems by using i) an improved CDN (ICDN) to represent the structure of software systems, ii) the z-score method to normalize the features, and iii) an adaptive mechanism to determine the number of execution times. In the experiments, we find that Qu et al.'s approach based on the Logistic Regression model does not perform significantly better than the state-of-the-art approach Ree, which is inconsistent with the conclusion in Qu et al.'s work. We also observe that replacing CDN with ICDN does improve the performance of Qu et al.'s approach.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2022.3140599",
      "Funding Information": "Natural Science Foundation of Zhejiang Province(grant numbers:LY22F020007); National Natural Science Foundation of China(grant numbers:62032010,61832014); Key R&D Program of Zhejiang Province(grant numbers:2019C01004,2019C03123); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9733807",
      "Author_Keywords": "Effort-aware bug prediction;coreness;  $k$   k     -core;class dependency network;complex network",
      "IEEE_Terms": "Computer bugs;Logistics;Predictive models;Mathematical models;Testing;Software systems;Codes",
      "Article Citation Count": "10",
      "Reference Count": "17",
      "License": "IEEE",
      "Online Date": "14-Mar-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Beyond Duplicates: Towards Understanding and Predicting Link Types in Issue Tracking Systems",
      "Authors": "C. M. L√ºders; A. Bouraffa; W. Maalej",
      "Author Affiliations": "University of Hamburg, Hamburg, Germany; University of Hamburg, Hamburg, Germany; University of Hamburg, Hamburg, Germany",
      "Publication Title": "2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "21-Jun-22",
      "Publication Year": "2022",
      "Start Page": "48",
      "End Page": "60",
      "Abstract": "Software projects use Issue Tracking Systems (ITS) like JIRA to track issues and organize the workflows around them. Issues are often inter-connected via different links such as the default JIRA link types Duplicate, Relate, Block, or Subtask. While previous research has mostly focused on analyzing and predicting duplication links, this work aims at understanding the various other link types, their prevalence, and characteristics towards a more reliable link type prediction. For this, we studied 607,208 links connecting 698,790 issues in 15 public JIRA repositories. Besides the default types, the custom types Depend, Incorporate, Split, and Cause were also common. We manually grouped all 75 link types used in the repositories into five general categories: General Relation, Duplication, Composition, Temporal/Causal, and Workflow. Comparing the structures of the corresponding graphs, we observed several trends. For instance, Duplication links tend to represent simpler issue graphs often with two components and Composition links present the highest amount of hierarchical tree structures (97.7%). Surprisingly, General Relation links have a significantly higher transitivity score than Duplication and Temporal/ Causal links. Motivated by the differences between the link types and by their popularity, we evaluated the robustness of two state-of-the-art duplicate detection approaches from the literature on the JIRA dataset. We found that current deep-learning approaches confuse between Duplication and other links in almost all repositories. On average, the classification accuracy dropped by 6% for one approach and 12% for the other. Extending the training sets with other link types seems to partly solve this issue. We discuss our findings and their implications for research and practice.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-4503-9303-4",
      "DOI": "10.1145/3524842.3528457",
      "Funding Information": "European Union(grant numbers:732463); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9796252",
      "Author_Keywords": "Issue Management;Issue Tracking System;Duplicate Detection;Link Type Detection;Dependency Management",
      "IEEE_Terms": "Training;Analytical models;Uncertainty;Semantics;Training data;Organizations;Predictive models",
      "Article Citation Count": "2",
      "Reference Count": "42",
      "Online Date": "21-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Perfce: Performance Debugging on Databases with Chaos Engineering-Enhanced Causality Analysis",
      "Authors": "Z. Ji; P. Ma; S. Wang",
      "Author Affiliations": "The Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology; The Hong Kong University of Science and Technology",
      "Publication Title": "2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "8-Nov-23",
      "Publication Year": "2023",
      "Start Page": "1454",
      "End Page": "1466",
      "Abstract": "Debugging performance anomalies in databases is challenging. Causal inference techniques enable qualitative and quantitative root cause analysis of performance downgrades. Nevertheless, causality analysis is challenging in practice, particularly due to limited observability. Recently, chaos engineering (CE) has been applied to test complex software systems. CE frameworks mutate chaos variables to inject catastrophic events (e.g., network slowdowns) to stress-test these software systems. The systems under chaos stress are then tested (e.g., via differential testing) to check if they retain normal functionality, such as returning correct SQL query outputs even under stress. To date, CE is mainly employed to aid software testing. This paper identifies the novel usage of CE in diagnosing performance anomalies in databases. Our framework, PERFCE, has two phases - offline and online. The offline phase learns statistical models of a database using both passive observations and proactive chaos experiments. The online phase diagnoses the root cause of performance anomalies from both qualitative and quantitative aspects on-the-fly. In evaluation, Perfce outperformed previous works on synthetic datasets and is highly accurate and moderately expensive when analyzing real-world (distributed) databases like MySQL and TiDB.",
      "ISSN": "2643-1572",
      "ISBNs": "979-8-3503-2996-4",
      "DOI": "10.1109/ASE56229.2023.00106",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298374",
      "Author_Keywords": "Performance Debugging;Chaos Engineering;Causality Analysis",
      "IEEE_Terms": "Chaos;Software testing;Root cause analysis;Distributed databases;Debugging;Software systems;Observability",
      "Article Citation Count": "2",
      "Reference Count": "86",
      "License": "IEEE",
      "Online Date": "8-Nov-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Procedure to Continuously Evaluate Predictive Performance of Just-In-Time Software Defect Prediction Models During Software Development",
      "Authors": "L. Song; L. L. Minku",
      "Author Affiliations": "Research Institute of Trustworthy Autonomous Systems, Southern University of Science and Technology, Shenzhen, Guangdong, China; School of Computer Science, University of Birmingham, Birmingham, U.K.",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "14-Feb-23",
      "Publication Year": "2023",
      "Volume": "49",
      "Issue": "2",
      "Start Page": "646",
      "End Page": "666",
      "Abstract": "Just-In-Time Software Defect Prediction (JIT-SDP) uses machine learning to predict whether software changes are defect-inducing or clean. When adopting JIT-SDP, changes in the underlying defect generating process may significantly affect the predictive performance of JIT-SDP models over time. Therefore, being able to continuously track the predictive performance of JIT-SDP models during the software development process is of utmost importance for software companies to decide whether or not to trust the predictions provided by such models over time. However, there has been little discussion on how to continuously evaluate predictive performance in practice, and such evaluation is not straightforward. In particular, labeled software changes that can be used for evaluation arrive over time with a delay, which in part corresponds to the time we have to wait to label software changes as ‚Äòclean‚Äô (waiting time). A clean label assigned based on a given waiting time may not correspond to the true label of the software changes. This can potentially hinder the validity of any continuous predictive performance evaluation procedure for JIT-SDP models. This paper provides the first discussion of how to continuously evaluate predictive performance of JIT-SDP models over time during the software development process, and the first investigation of whether and to what extent waiting time affects the validity of such continuous performance evaluation procedure in JIT-SDP. Based on 13 GitHub projects, we found that waiting time had a significant impact on the validity. Though typically small, the differences in estimated predicted performance were sometimes large, and thus inappropriate choices of waiting time can lead to misleading estimations of predictive performance over time. Such impact did not normally change the ranking between JIT-SDP models, and thus conclusions in terms of which JIT-SDP model performs better are likely reliable independent of the choice of waiting time, especially when considered across projects.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2022.3158831",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:62002148); Engineering and Physical Sciences Research Council(grant numbers:EP/R006660/2); Guangdong Provincial Key Laboratory(grant numbers:2020B121201001); Program for Guangdong Introducing Innovative and Enterpreneurial Teams(grant numbers:2017ZT07X386); Shenzhen Science and Technology Program(grant numbers:KQTD2016112514355531); Research Institute of Trustworthy Autonomous Systems; Southern University of Science and Technology(grant numbers:518055); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9735354",
      "Author_Keywords": "Just-in-time software defect prediction;performance evaluation procedure;concept drift;data stream learning;online learning;verification latency;and label noise",
      "IEEE_Terms": "Software;Performance evaluation;Predictive models;Training;Estimation;Software reliability;Delays",
      "Article Citation Count": "2",
      "Reference Count": "39",
      "License": "IEEE",
      "Online Date": "15-Mar-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Using a Nearest-Neighbour, BERT-Based Approach for Scalable Clone Detection",
      "Authors": "M. Chochlov; G. Aftab Ahmed; J. Vincent Patten; G. Lu; W. Hou; D. Gregg; J. Buckley",
      "Author Affiliations": "Dept. of Computer Science and Information Systems, University of Limerick, Limerick, Ireland; Dept. of Computer Science, Trinity College Dublin, Dublin, Ireland; Dept. of Computer Science and Information Systems, University of Limerick, Limerick, Ireland; WN Digital IPD and Trustworthiness Enabling, Huawei Technologies Co., Ltd., Shanghai, China; Huawei Vulnerability Management Center, Huawei Technologies Co., Ltd., Shenzhen, China; Dept. of Computer Science, Trinity College Dublin, Dublin, Ireland; Dept. of Computer Science and Information Systems, University of Limerick, Limerick, Ireland",
      "Publication Title": "2022 IEEE International Conference on Software Maintenance and Evolution (ICSME)",
      "Date Added To Xplore": "19-Dec-22",
      "Publication Year": "2022",
      "Start Page": "582",
      "End Page": "591",
      "Abstract": "Code clones can detrimentally impact software maintenance and manually detecting them in very large code-bases is impractical. Additionally, automated approaches find detection of Type 3 and Type 4 (inexact) clones very challenging. While the most recent artificial deep neural networks (for ex-ample BERT-based artificial neural networks) seem to be highly effective in detecting such clones, their pairwise comparison of every code pair in the target system(s) is inefficient and scales poorly on large codebases.We therefore introduce SSCD, a BERT-based clone detection approach that targets high recall of Type 3 and Type 4 clones at scale (in line with our industrial partner‚Äôs requirements). It does so by computing a representative embedding for each code fragment and finding similar fragments using a nearest neighbour search. SSCD thus avoids the pairwise-comparison bottleneck of other Neural Network approaches while also using parallel, GPU-accelerated search to tackle scalability.This paper details the approach and an empirical assessment towards configuring and evaluating that approach in industrial setting. The configuration analysis suggests that shorter input lengths and text-only based neural network models demonstrate better efficiency in SSCD, while only slightly decreasing effectiveness. The evaluation results suggest that SSCD is more effective than state-of-the-art approaches like SAGA and SourcererCC. It is also highly efficient: in its optimal setting, SSCD effectively locates clones in the entire 320 million LOC BigCloneBench (a standard clone detection benchmark) in just under three hours.",
      "ISSN": "2576-3148",
      "ISBNs": "978-1-6654-7956-1",
      "DOI": "10.1109/ICSME55016.2022.00080",
      "Funding Information": "Science Foundation Ireland; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9978241",
      "Author_Keywords": "Clone detection;semantic clones;scalable;deep neural networks",
      "IEEE_Terms": "Deep learning;Software maintenance;Analytical models;Codes;Cloning;Artificial neural networks;Benchmark testing",
      "Reference Count": "33",
      "License": "IEEE",
      "Online Date": "19-Dec-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "On the Evaluation of Neural Code Summarization",
      "Authors": "E. Shi; Y. Wang; L. Du; J. Chen; S. Han; H. Zhang; D. Zhang; H. Sun",
      "Author Affiliations": "Xi'an Jiaotong University; Microsoft Research; Microsoft Research; Tianjin University; Microsoft Research; The University of Newcastle; Microsoft Research; Xi'an Jiaotong University",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "1597",
      "End Page": "1608",
      "Abstract": "Source code summaries are important for program comprehension and maintenance. However, there are plenty of programs with missing, outdated, or mismatched summaries. Recently, deep learning techniques have been exploited to automatically generate summaries for given code snippets. To achieve a profound understanding of how far we are from solving this problem and provide suggestions to future research, in this paper, we conduct a systematic and in-depth analysis of 5 state-of-the-art neural code summarization models on 6 widely used BLEU variants, 4 pre-processing operations and their combinations, and 3 widely used datasets. The evaluation results show that some important factors have a great influence on the model evaluation, especially on the performance of models and the ranking among the models. However, these factors might be easily overlooked. Specifically, (1) the BLEU metric widely used in existing work of evaluating code summarization models has many variants. Ignoring the differences among these variants could greatly affect the validity of the claimed results. Besides, we discover and resolve an important and previously unknown bug in BLEU calculation in a commonly-used software package. Furthermore, we conduct human evaluations and find that the metric BLEU-DC is most correlated to human perception; (2) code pre-processing choices can have a large (from ‚àí18% to +25%) impact on the summarization performance and should not be neglected. We also explore the aggregation of pre-processing combinations and boost the performance of models; (3) some important char-acteristics of datasets (corpus sizes, data splitting methods, and duplication ratios) have a significant impact on model evaluation. Based on the experimental results, we give actionable suggestions for evaluating code summarization and choosing the best method in different scenarios. We also build a shared code summarization toolbox to facilitate future research.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3510060",
      "Funding Information": "National Key R&D Program of China(grant numbers:2017YFA0700800); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9794127",
      "Author_Keywords": "Code summarization;Empirical study;Deep learning;Evaluation",
      "IEEE_Terms": "Measurement;Analytical models;Codes;Systematics;Smoothing methods;Software packages;Data models",
      "Article Citation Count": "13",
      "Reference Count": "72",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "CC2Vec: Distributed Representations of Code Changes",
      "Authors": "T. Hoang; H. J. Kang; D. Lo; J. Lawall",
      "Author Affiliations": "Singapore Management University, Singapore; Singapore Management University, Singapore; Singapore Management University, Singapore; Sorbonne University/Inria/LIP6, France",
      "Publication Title": "2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "21-Dec-20",
      "Publication Year": "2020",
      "Start Page": "518",
      "End Page": "529",
      "Abstract": "Existing work on software patches often use features specific to a single task. These works often rely on manually identified features, and human effort is required to identify these features for each task. In this work, we propose CC2Vec, a neural network model that learns a representation of code changes guided by their accompanying log messages, which represent the semantic intent of the code changes. CC2Vec models the hierarchical structure of a code change with the help of the attention mechanism and uses multiple comparison functions to identify the differences between the removed and added code. To evaluate if CC2Vec can produce a distributed representation of code changes that is general and useful for multiple tasks on software patches, we use the vectors produced by CC2Vec for three tasks: log message generation, bug fixing patch identification, and just-in-time defect prediction. In all tasks, the models using CC2Vec outperform the state-of-the-art techniques.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-7121-6",
      "Funding Information": "Singapore National Research Foundation(grant numbers:NRF2016-NRF-ANR003); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284081",
      "Author_Keywords": "code embedding;deep learning;code changes",
      "IEEE_Terms": "Semantics;Neural networks;Tools;Predictive models;Software;Task analysis;Software engineering",
      "Article Citation Count": "8",
      "Reference Count": "62",
      "Online Date": "21-Dec-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Which Crashes Should I Fix First?: Predicting Top Crashes at an Early Stage to Prioritize Debugging Efforts",
      "Authors": "D. Kim; X. Wang; S. Kim; A. Zeller; S. C. Cheung; S. Park",
      "Author Affiliations": "Department of Computer Science and Engineering, Sogang University, Seoul, South Korea; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Computer Science, University of Saarland, Saarbruecken, Germany; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Computer Science and Engineering, Sogang University, Seoul, South Korea",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "27-May-11",
      "Publication Year": "2011",
      "Volume": "37",
      "Issue": "3",
      "Start Page": "430",
      "End Page": "447",
      "Abstract": "Many popular software systems automatically report failures back to the vendors, allowing developers to focus on the most pressing problems. However, it takes a certain period of time to assess which failures occur most frequently. In an empirical investigation of the Firefox and Thunderbird crash report databases, we found that only 10 to 20 crashes account for the large majority of crash reports; predicting these ‚Äútop crashes‚Äù thus could dramatically increase software quality. By training a machine learner on the features of top crashes of past releases, we can effectively predict the top crashes well before a new release. This allows for quick resolution of the most important crashes, leading to improved user experience and better allocation of maintenance efforts.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2011.20",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5711013",
      "Author_Keywords": "Top crash;machine learning;crash reports;social network analysis;data mining.",
      "IEEE_Terms": "Fires;Feature extraction;Software;Testing;Computer bugs;Training",
      "Article Citation Count": "56",
      "Reference Count": "59",
      "License": "IEEE",
      "Online Date": "10-Feb-11",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Data Quality for Software Vulnerability Datasets",
      "Authors": "R. Croft; M. A. Babar; M. M. Kholoosi",
      "Author Affiliations": "School of Computer Science, CREST, University of Adelaide, Australia; School of Computer Science, CREST, University of Adelaide, Australia; School of Computer Science, CREST, University of Adelaide, Australia",
      "Publication Title": "2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "14-Jul-23",
      "Publication Year": "2023",
      "Start Page": "121",
      "End Page": "133",
      "Abstract": "The use of learning-based techniques to achieve automated software vulnerability detection has been of longstanding interest within the software security domain. These data-driven solutions are enabled by large software vulnerability datasets used for training and benchmarking. However, we observe that the quality of the data powering these solutions is currently ill-considered, hindering the reliability and value of produced outcomes. Whilst awareness of software vulnerability data preparation challenges is growing, there has been little investigation into the potential negative impacts of software vulnerability data quality. For instance, we lack confirmation that vulnerability labels are correct or consistent. Our study seeks to address such shortcomings by inspecting five inherent data quality attributes for four state-of-the-art software vulnerability datasets and the subsequent impacts that issues can have on software vulnerability prediction models. Surprisingly, we found that all the analyzed datasets exhibit some data quality problems. In particular, we found 20‚Äì71% of vulnerability labels to be inaccurate in real-world datasets, and 17-99% of data points were duplicated. We observed that these issues could cause significant impacts on downstream models, either preventing effective model training or inflating benchmark performance. We advocate for the need to overcome such challenges. Our findings will enable better consideration and assessment of software vulnerability data quality in the future.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-5701-9",
      "DOI": "10.1109/ICSE48619.2023.00022",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172650",
      "Author_Keywords": "software vulnerability;data quality;machine learning",
      "IEEE_Terms": "Training;Data integrity;Benchmark testing;Predictive models;Software;Data models;Software reliability",
      "Article Citation Count": "11",
      "Reference Count": "73",
      "License": "IEEE",
      "Online Date": "14-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Defect-causal analysis drives down error rates",
      "Authors": "D. N. Card",
      "Author Affiliations": "Computer Science Corporation",
      "Publication Title": "IEEE Software",
      "Date Added To Xplore": "6-Aug-02",
      "Publication Year": "1993",
      "Volume": "10",
      "Issue": "4",
      "Start Page": "98",
      "End Page": "99",
      "Abstract": "Defect-causal analysis (DCA), a low-cost technique for driving down error rates in software, is discussed. The learning method used in DCA is described, and its benefits are discussed. The effect of DCA on maturity (as in the Capability Maturity model) is considered. Possibly pitfalls in using DCA are pointed out.<>",
      "ISSN": "1937-4194",
      "DOI": "10.1109/52.219639",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=219639",
      "IEEE_Terms": "Error analysis;Proposals;Meeting planning;Quality management;Quality control;Software engineering;Capability maturity model;Coordinate measuring machines;Management training;Testing",
      "Article Citation Count": "17",
      "License": "IEEE",
      "Online Date": "6-Aug-02",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Magazines"
    },
    {
      "Document Title": "An Empirical Study of Model-Agnostic Techniques for Defect Prediction Models",
      "Authors": "J. Jiarpakdee; C. K. Tantithamthavorn; H. K. Dam; J. Grundy",
      "Author Affiliations": "Faculty of Information Technology, Monash University, Clayton, VIC, Australia; Faculty of Information Technology, Monash University, Clayton, VIC, Australia; Faculty of Engineering and Information Sciences, School of Computing and Information Technology, University of Wollongong, Wollongong, NSW, Australia; Faculty of Information Technology, Monash University, Clayton, VIC, Australia",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "11-Jan-22",
      "Publication Year": "2022",
      "Volume": "48",
      "Issue": "1",
      "Start Page": "166",
      "End Page": "185",
      "Abstract": "Software analytics have empowered software organisations to support a wide range of improved decision-making and policy-making. However, such predictions made by software analytics to date have not been explained and justified. Specifically, current defect prediction models still fail to explain why models make such a prediction and fail to uphold the privacy laws in terms of the requirement to explain any decision made by an algorithm. In this paper, we empirically evaluate three model-agnostic techniques, i.e., two state-of-the-art Local Interpretability Model-agnostic Explanations technique (LIME) and BreakDown techniques, and our improvement of LIME with Hyper Parameter Optimisation (LIME-HPO). Through a case study of 32 highly-curated defect datasets that span across 9 open-source software systems, we conclude that (1) model-agnostic techniques are needed to explain individual predictions of defect models; (2) instance explanations generated by model-agnostic techniques are mostly overlapping (but not exactly the same) with the global explanation of defect models and reliable when they are re-generated; (3) model-agnostic techniques take less than a minute to generate instance explanations; and (4) more than half of the practitioners perceive that the contrastive explanations are necessary and useful to understand the predictions of defect models. Since the implementation of the studied model-agnostic techniques is available in both Python and R, we recommend model-agnostic techniques be used in the future.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2020.2982385",
      "Funding Information": "Australian Research Council(grant numbers:DE200100941); ARC Laureate Fellowship(grant numbers:FL190100035); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9044387",
      "Author_Keywords": "Explainable software analytics;software quality assurance;defect prediction models;model-agnostic techniques",
      "IEEE_Terms": "Predictive models;Software;Analytical models;Software algorithms;Prediction algorithms;Electric breakdown;Software engineering",
      "Article Citation Count": "66",
      "Reference Count": "113",
      "License": "IEEE",
      "Online Date": "23-Mar-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Practitioners‚Äô Perceptions of the Goals and Visual Explanations of Defect Prediction Models",
      "Authors": "J. Jiarpakdee; C. K. Tantithamthavorn; J. Grundy",
      "Author Affiliations": "Monash University, Melbourne, Australia; Monash University, Melbourne, Australia; Monash University, Melbourne, Australia",
      "Publication Title": "2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "28-Jun-21",
      "Publication Year": "2021",
      "Start Page": "432",
      "End Page": "443",
      "Abstract": "Software defect prediction models are classifiers that are constructed from historical software data. Such software defect prediction models have been proposed to help developers optimize the limited Software Quality Assurance (SQA) resources and help managers develop SQA plans. Prior studies have different goals for their defect prediction models and use different techniques for generating visual explanations of their models. Yet, it is unclear what are the practitioners' perceptions of (1) these defect prediction model goals, and (2) the model-agnostic techniques used to visualize these models. We conducted a qualitative survey to investigate practitioners' perceptions of the goals of defect prediction models and the model-agnostic techniques used to generate visual explanations of defect prediction models. We found that (1) 82%-84% of the respondents perceived that the three goals of defect prediction models are useful; (2) LIME is the most preferred technique for understanding the most important characteristics that contributed to a prediction of a file, while ANOVA/VarImp is the second most preferred technique for understanding the characteristics that are associated with software defects in the past. Our findings highlight the significance of investigating how to improve the understanding of defect prediction models and their predictions. Hence, model-agnostic techniques from explainable AI domain may help practitioners to understand defect prediction models and their predictions.",
      "ISSN": "2574-3864",
      "ISBNs": "978-1-7281-8710-5",
      "DOI": "10.1109/MSR52588.2021.00055",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9463073",
      "Author_Keywords": "Software Quality Assurance;Defect Prediction;Explainable AI;Software Analytics",
      "IEEE_Terms": "Visualization;Analytical models;Privacy;Software quality;Predictive models;Data models;Data mining",
      "Article Citation Count": "34",
      "Reference Count": "54",
      "License": "IEEE",
      "Online Date": "28-Jun-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "ATOM: Commit Message Generation Based on Abstract Syntax Tree and Hybrid Ranking",
      "Authors": "S. Liu; C. Gao; S. Chen; L. Y. Nie; Y. Liu",
      "Author Affiliations": "School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; Chinese University of Hong Kong, Hong Kong, China; School of Computer Science and Engineering, Nanyang Technological University, Singapore",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "16-May-22",
      "Publication Year": "2022",
      "Volume": "48",
      "Issue": "5",
      "Start Page": "1800",
      "End Page": "1817",
      "Abstract": "Commit messages record code changes (e.g., feature modifications and bug repairs) in natural language, and are useful for program comprehension. Due to the frequent updates of software and time cost, developers are generally unmotivated to write commit messages for code changes. Therefore, automating the message writing process is necessitated. Previous studies on commit message generation have been benefited from generation models or retrieval models, but the code structure of changed code, i.e., AST, which can be important for capturing code semantics, has not been explicitly involved. Moreover, although generation models have the advantages of synthesizing commit messages for new code changes, they are not easy to bridge the semantic gap between code and natural languages which could be mitigated by retrieval models. In this paper, we propose a novel commit message generation model, named ATOM, which explicitly incorporates the abstract syntax tree for representing code changes and integrates both retrieved and generated messages through hybrid ranking. Specifically, the hybrid ranking module can prioritize the most accurate message from both retrieved and generated messages regarding one code change. We evaluate the proposed model ATOM on our dataset crawled from 56 popular Java repositories. Experimental results demonstrate that ATOM increases the state-of-the-art models by 30.72 percent in terms of BLEU-4 (an accuracy measure that is widely used to evaluate text generation systems). Qualitative analysis also demonstrates the effectiveness of ATOM in generating accurate code commit messages.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2020.3038681",
      "Funding Information": "Nvidia; Singapore Ministry of Education Academic Research Fund Tier 1(grant numbers:2018-T1-002-069); National Research Foundation, Prime Ministers Office, Singapore; National Cybersecurity R&D Program(grant numbers:NRF2018NCR-NCR005-0001); National Research Foundation Singapore(grant numbers:NRF2018NCR-NSOE003-0001); NRF Investigatorship(grant numbers:NRFI06-2020-0022); National Natural Science Foundation of China(grant numbers:62002084); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9261989",
      "Author_Keywords": "Commit message generation;code changes;abstract syntax tree",
      "IEEE_Terms": "Syntactics;Semantics;Atomic measurements;Hybrid power systems;Benchmark testing;Writing;Java",
      "Article Citation Count": "30",
      "Reference Count": "91",
      "License": "IEEE",
      "Online Date": "17-Nov-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "MalScan: Fast Market-Wide Mobile Malware Scanning by Social-Network Centrality Analysis",
      "Authors": "Y. Wu; X. Li; D. Zou; W. Yang; X. Zhang; H. Jin",
      "Author Affiliations": "Cluster and Grid Computing Lab Services Computing Technology and System Lab, National Engineering Research Center for Big Data Technology and System; University of Texas at Dallas; Cluster and Grid Computing Lab Services Computing Technology and System Lab, National Engineering Research Center for Big Data Technology and System; University of Texas at Dallas; Cluster and Grid Computing Lab Services Computing Technology and System Lab, National Engineering Research Center for Big Data Technology and System; Cluster and Grid Computing Lab Services Computing Technology and System Lab, National Engineering Research Center for Big Data Technology and System",
      "Publication Title": "2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)",
      "Date Added To Xplore": "9-Jan-20",
      "Publication Year": "2019",
      "Start Page": "139",
      "End Page": "150",
      "Abstract": "Malware scanning of an app market is expected to be scalable and effective. However, existing approaches use either syntax-based features which can be evaded by transformation attacks or semantic-based features which are usually extracted by performing expensive program analysis. Therefor, in this paper, we propose a lightweight graph-based approach to perform Android malware detection. Instead of traditional heavyweight static analysis, we treat function call graphs of apps as social networks and perform social-network-based centrality analysis to represent the semantic features of the graphs. Our key insight is that centrality provides a succinct and fault-tolerant representation of graph semantics, especially for graphs with certain amount of inaccurate information (e.g., inaccurate call graphs). We implement a prototype system, MalScan, and evaluate it on datasets of 15,285 benign samples and 15,430 malicious samples. Experimental results show that MalScan is capable of detecting Android malware with up to 98% accuracy under one second which is more than 100 times faster than two state-of-the-art approaches, namely MaMaDroid and Drebin. We also demonstrate the feasibility of MalScan on market-wide malware scanning by performing a statistical study on over 3 million apps. Finally, in a corpus of dataset collected from Google-Play app market, MalScan is able to identify 18 zero-day malware including malware samples that can evade detection of existing tools.",
      "ISSN": "2643-1572",
      "ISBNs": "978-1-7281-2508-4",
      "DOI": "10.1109/ASE.2019.00023",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952382",
      "Author_Keywords": "Lightweight feature, Android Malware, API Centrality, Market-wide",
      "IEEE_Terms": "Malware;Social networking (online);Feature extraction;Semantics;Analysis of variance;Static analysis;Robustness",
      "Article Citation Count": "24",
      "Reference Count": "43",
      "License": "IEEE",
      "Online Date": "9-Jan-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Characterizing Crowds to Better Optimize Worker Recommendation in Crowdsourced Testing",
      "Authors": "J. Wang; S. Wang; J. Chen; T. Menzies; Q. Cui; M. Xie; Q. Wang",
      "Author Affiliations": "Laboratory for Internet Software Technologies, State Key Laboratory of Computer Sciences, Institute of Software Chinese Academy of Sciences, Beijing, China; York University, Toronto, ON, Canada; Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Bytedance Inc., Beijing, China; DAMO Academy of Alibaba Group, Beijing, China; Laboratory for Internet Software Technologies, State Key Laboratory of Computer Sciences, Institute of Software Chinese Academy of Sciences, Beijing, China",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "11-Jun-21",
      "Publication Year": "2021",
      "Volume": "47",
      "Issue": "6",
      "Start Page": "1259",
      "End Page": "1276",
      "Abstract": "Crowdsourced testing is an emerging trend, in which test tasks are entrusted to the online crowd workers. Typically, a crowdsourced test task aims to detect as many bugs as possible within a limited budget. However not all crowd workers are equally skilled at finding bugs; Inappropriate workers may miss bugs, or report duplicate bugs, while hiring them requires nontrivial budget. Therefore, it is of great value to recommend a set of appropriate crowd workers for a test task so that more software bugs can be detected with fewer workers. This paper first presents a new characterization of crowd workers and characterizes them with testing context, capability, and domain knowledge. Based on the characterization, we then propose Multi-Objective Crowd wOrker recoMmendation approach (MOCOM), which aims at recommending a minimum number of crowd workers who could detect the maximum number of bugs for a crowdsourced testing task. Specifically, MOCOM recommends crowd workers by maximizing the bug detection probability of workers, the relevance with the test task, the diversity of workers, and minimizing the test cost. We experimentally evaluate MOCOM on 532 test tasks, and results show that MOCOM significantly outperforms five commonly-used and state-of-the-art baselines. Furthermore, MOCOM can reduce duplicate reports and recommend workers with high relevance and larger bug detection probability; because of this it can find more bugs with fewer workers.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2019.2918520",
      "Funding Information": "National Key Research and Development Program of China(grant numbers:2018YFB1403400); National Natural Science Foundation of China(grant numbers:61602450,61432001); China Scholarship Council; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721154",
      "Author_Keywords": "Crowdsourced testing;crowd worker recommendation;multi-objective optimization",
      "IEEE_Terms": "Task analysis;Computer bugs;Testing;Software;Videos;Software engineering;Optimization",
      "Article Citation Count": "20",
      "Reference Count": "66",
      "License": "IEEE",
      "Online Date": "23-May-19",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "Theoretical and Empirical Analyses of the Effectiveness of Metamorphic Relation Composition",
      "Authors": "K. Qiu; Z. Zheng; T. Y. Chen; P. -L. Poon",
      "Author Affiliations": "School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; Department of Computer Science and Software Engineering, Swinburne University of Technology, Hawthorn, VIC, Australia; School of Engineering and Technology, Central Queensland University, Melbourne, VIC, Australia",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "15-Mar-22",
      "Publication Year": "2022",
      "Volume": "48",
      "Issue": "3",
      "Start Page": "1001",
      "End Page": "1017",
      "Abstract": "Metamorphic Relations (MRs) play a key role in determining the fault detection capability of Metamorphic Testing (MT). As human judgement is required for MR identification, systematic MR generation has long been an important research area in MT. Additionally, due to the extra program executions required for follow-up test cases, some concerns have been raised about MT cost-effectiveness. Consequently, the reduction in testing costs associated with MT has become another important issue to be addressed. MR composition can address both of these problems. This technique can automatically generate new MRs by composing existing ones, thereby reducing the number of follow-up test cases. Despite this advantage, previous studies on MR composition have empirically shown that some composite MRs have lower fault detection capability than their corresponding component MRs. To investigate this issue, we performed theoretical and empirical analyses to identify what characteristics component MRs should possess so that their corresponding composite MR has at least the same fault detection capability as the component MRs do. We have also derived a convenient, but effective guideline so that the fault detection capability of MT will most likely not be reduced after composition.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2020.3009698",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:61772055,61872169); Technical Foundation Project of Ministry of Industry and Information Technology of China(grant numbers:JSZL2016601B003); Equipment Preliminary R&D Project of China(grant numbers:41402020102); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9144441",
      "Author_Keywords": "Metamorphic testing;metamorphic relation;metamorphic relation composition;test oracle;fault detection capability",
      "IEEE_Terms": "Testing;Fault detection;Software;Guidelines;Systematics;Australia;Companies",
      "Article Citation Count": "10",
      "Reference Count": "49",
      "License": "IEEE",
      "Online Date": "20-Jul-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    },
    {
      "Document Title": "VCMatch: A Ranking-based Approach for Automatic Security Patches Localization for OSS Vulnerabilities",
      "Authors": "S. Wang; Y. Zhang; L. Bao; X. Xia; M. Wu",
      "Author Affiliations": "School of Computer and Computing Science, Zhejiang University City College, Hangzhou, China; School of Computer and Computing Science, Zhejiang University City College, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; School of Computer and Computing Science, Zhejiang University City College, Hangzhou, China",
      "Publication Title": "2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "21-Jul-22",
      "Publication Year": "2022",
      "Start Page": "589",
      "End Page": "600",
      "Abstract": "Nowadays, vulnerabilities in open source software (OSS) are constantly emerging, posing a great threat to application security. Security patches are crucial in reducing the risk of OSS vulnerabilities. However, many of the vulnerabilities disclosed by CVE/NVD are not accompanied by security patches. Previous research has shown that the auxiliary information in CVE/NVD can aid in the matching of a vulnerability to appropriate commits. The state-of-art research proposed a rank-based approach based on the multiple dimensions of features extracted from the auxiliary information in CVE/NVD. However, this approach ignores the semantic features in the vulnerability descriptions and commit messages, making the model still have room for improvement. In this paper, we propose a novel ranking-based approach VCMATCH (Vulnerability-Commit Match). In addition to extracting the shallow statistical features between the vulnerability and the patch commit, VCMATCH extracts the deep semantic features of the vulnerability descriptions and commit messages. Besides, VCMATCH applies three classification models (i.e., XGBoost, LightGBM, CNN) and uses a voting-based rank fusion method to combine the results of the three models to generate a better result. We evaluate VCMATCH with 1,669 CVEs from 10 OSS projects. The experiment results show that VCMATCH can effectively identify security patches for OSS vulnerabilities in terms of Recall@K and Manual Effort@K, and outperforms the state-of-art model by a statistically significant margin.",
      "ISSN": "1534-5351",
      "ISBNs": "978-1-6654-3786-8",
      "DOI": "10.1109/SANER53432.2022.00076",
      "Funding Information": "Natural Science Foundation of Zhejiang Province(grant numbers:LQ21F020008); National Science Foundation of China(grant numbers:62141222,U20A20173,6190234); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9825908",
      "Author_Keywords": "Security Patches;Vulnerability Analysis;Mining Software Repository",
      "IEEE_Terms": "Location awareness;Conferences;Semantics;Manuals;Feature extraction;Application security;Security",
      "Article Citation Count": "3",
      "Reference Count": "66",
      "License": "IEEE",
      "Online Date": "21-Jul-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "A Cybersecurity Moonshot",
      "Authors": "H. Okhravi",
      "Author Affiliations": "MIT Lincoln Laboratory, Lexington, Massachusetts, USA",
      "Publication Title": "IEEE Security & Privacy",
      "Date Added To Xplore": "17-May-21",
      "Publication Year": "2021",
      "Volume": "19",
      "Issue": "3",
      "Start Page": "8",
      "End Page": "16",
      "Abstract": "Cybersecurity needs radical rethinking to change its current landscape. This article charts a vision for a cybersecurity moonshot based on radical but feasible technologies that can prevent the largest classes of vulnerabilities in modern systems.",
      "ISSN": "1558-4046",
      "DOI": "10.1109/MSEC.2021.3059438",
      "Funding Information": "Under Secretary of Defense for Research and Engineering(grant numbers:Air Force Contract No. FA8702-15-D-0001); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9374753",
      "IEEE_Terms": "Program processors;Computer security;Computer architecture;Safety;Computer bugs;Semantics",
      "Article Citation Count": "3",
      "Reference Count": "18",
      "License": "IEEE",
      "Online Date": "10-Mar-21",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Magazines"
    },
    {
      "Document Title": "Code Coverage-Based Failure Proximity without Test Oracles",
      "Authors": "J. Tu; X. Xie; B. Xu",
      "Author Affiliations": "Department of Computer Science and Technology, Nanjing University, Nanjing, China; State Key Lab of Software Engineering, Wuhan University, Wuhan, China; Department of Computer Science and Technology, Nanjing University, Nanjing, China",
      "Publication Title": "2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "25-Aug-16",
      "Publication Year": "2016",
      "Volume": "1",
      "Start Page": "133",
      "End Page": "142",
      "Abstract": "Failure indexing technique plays an important role in modern software maintenance. It can facilitate duplicated failure removal, failure assignment, etc. Failure proximity is a crucial part that underpins failure indexing techniques. It is comprised of two components: a fingerprinting function extracting failure signatures from failures and a distance function computing pairwise distances between failures. Failure proximity usually assumes the existence of test oracle. However, in many real-life application domains, test oracles do not always exist. Hence, the applicability of existing failure proximity techniques is limited. In our paper, we focus on investigating how to apply metamorphic testing on code coverage-based failure proximity without test oracles. In our approach, instead of using the testing results of failure, the results of violation or non-violation for metamorphic test groups are used. Specifically, the fingerprinting function extracts signatures from metamorphic slices rather than execution slices and the distance function computes the pairwise distance between violations rather than between failures. Thereby, the applicability of failure proximity is extended to the situations without test oracles. The experimental results on 50 two-fault mutants show that the quality of proximity matrix obtained through our approach is statistical comparable to traditional code coverage-based failure proximity with test oracle.",
      "ISSN": "0730-3157",
      "ISBNs": "978-1-4673-8845-0",
      "DOI": "10.1109/COMPSAC.2016.81",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552001",
      "Author_Keywords": "failure proximity;metamorphic testing;test oracle;metamorphic slice",
      "IEEE_Terms": "Testing;Computer bugs;Indexing;Software;Electronic mail;Data mining;Computer science",
      "Article Citation Count": "2",
      "Reference Count": "25",
      "License": "IEEE",
      "Online Date": "25-Aug-16",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Towards Understanding the Impacts of Textual Dissimilarity on Duplicate Bug Report Detection",
      "Authors": "S. Jahan; M. M. Rahman",
      "Author Affiliations": "Dalhousie University; Dalhousie University",
      "Publication Title": "2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)",
      "Date Added To Xplore": "15-May-23",
      "Publication Year": "2023",
      "Start Page": "25",
      "End Page": "36",
      "Abstract": "About 40% of software bug reports are duplicates of one another, which pose a major overhead during software maintenance. Traditional techniques often focus on detecting duplicate bug reports that are textually similar. However, in bug tracking systems, many duplicate bug reports might not be textually similar, for which the traditional techniques might fall short. In this paper, we conduct a large-scale empirical study to better understand the impacts of textual dissimilarity on the detection of duplicate bug reports. First, we collect a total of 92,854 bug reports from three open-source systems and construct two datasets containing textually similar and textually dissimilar duplicate bug reports. Then we determine the performance of three existing techniques in detecting duplicate bug reports and show that their performance is significantly poor for textually dissimilar duplicate reports. Second, we analyze the two groups of bug reports using a combination of descriptive analysis, word embedding visualization, and manual analysis. We found that textually dissimilar duplicate bug reports often miss important components (e.g., expected behaviors and steps to reproduce), which could lead to their textual differences and poor performance by the existing techniques. Finally, we apply domain-specific embedding to duplicate bug report detection problems, which shows mixed results. All these findings above warrant further investigation and more effective solutions for detecting textually dissimilar duplicate bug reports.",
      "ISSN": "2640-7574",
      "ISBNs": "978-1-6654-5278-6",
      "DOI": "10.1109/SANER56733.2023.00013",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10123457",
      "Author_Keywords": "Software bug;duplicate bug detection;textual dissimilarity;word embedding;t-SNE",
      "IEEE_Terms": "Visualization;Software maintenance;Computer bugs;Behavioral sciences",
      "Article Citation Count": "1",
      "Reference Count": "71",
      "License": "IEEE",
      "Online Date": "15-May-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "FACEE: Framework for Automating CNN Explainability Evaluation",
      "Authors": "A. Rezaei; J. Nau; J. Richter; D. Streitferdt; J. Schambach",
      "Author Affiliations": "Teaching Group Computer Engineering, Technische Universit√§t Ilmenau, Ilmenau, Germany; Teaching Group Computer Engineering, Technische Universit√§t Ilmenau, Ilmenau, Germany; Teaching Group Computer Engineering, Technische Universit√§t Ilmenau, Ilmenau, Germany; Teaching Group Computer Engineering, Technische Universit√§t Ilmenau, Ilmenau, Germany; Produktmanager Industrielle Bildverarbeitung, G√∂pel GmbH, Jena, Germany",
      "Publication Title": "2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)",
      "Date Added To Xplore": "2-Aug-23",
      "Publication Year": "2023",
      "Start Page": "67",
      "End Page": "78",
      "Abstract": "Convolutional Neural Networks (CNNs) are used mainly for image classification because of their high accuracy and fast performance. Due to their complexity, their functionality is like a black box to the human user. Hence, this black box functionality may classify an image based on the wrong features, which can lead to severe consequences in critical applications, such as disease detection. Therefore, explainer methods provide the users with the reasoning behind each classification. However, selecting well-matching pairs of CNN models and explainers is challenging.This paper proposes a framework for automated explainability evaluation in CNN models, which follows a quantitative approach for assessing the model and explainer pairs. The proposed framework supersedes the previous attempts towards an explainability evaluation framework by replacing the time-consuming qualitative measure with a unified quantitative metric. This quantitative approach allows the users to assess several models and explainer pairs and compare the results based on two aspects on the one hand, selecting the most prominent model/explainer pair or, on the other hand, making compromises for better real-time performance. The framework is applied to a defect detection problem for printed circuit board assembly(PCBA) automatic optical inspection (AOI). The results are analyzed for thirteen built-in CNN models and ten built-in explainer methods. The results demonstrate the superiority of the \"CoAtNet0\" and \"Grad-Cam selfmatch\" pair with the 55.38% Explanation Score (ES) metric. The authors also provide a discussion on other criteria in the selection of a prominent pair using the proposed novel FACEE framework.",
      "ISSN": "0730-3157",
      "ISBNs": "979-8-3503-2697-0",
      "DOI": "10.1109/COMPSAC57700.2023.00019",
      "Funding Information": "Th√ºringer Aufbaubank; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10196830",
      "Author_Keywords": "Explainable AI;Explainability Evaluation;PCB AOI;Quantitative Approach",
      "IEEE_Terms": "Measurement;Location awareness;Graphics processing units;Software;Timing;Convolutional neural networks;Time factors",
      "Reference Count": "41",
      "License": "IEEE",
      "Online Date": "2-Aug-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Cold-Start Software Analytics",
      "Authors": "J. Guo; M. Rahimi; J. Cleland-Huang; A. Rasin; J. H. Hayes; M. Vierhauser",
      "Author Affiliations": "School of Computing, DePaul University, Chicago, IL, USA; School of Computing, DePaul University, Chicago, IL, USA; School of Computing, DePaul University, Chicago, IL, USA; School of Computing, DePaul University, Chicago, IL, USA; Computer Science Department, University of Kentucky, USA; CDL MEVSS, Johannes Kepler University, Linz, Austria",
      "Publication Title": "2016 IEEE/ACM 13th Working Conference on Mining Software Repositories (MSR)",
      "Date Added To Xplore": "26-Jan-17",
      "Publication Year": "2016",
      "Start Page": "142",
      "End Page": "153",
      "Abstract": "Software project artifacts such as source code, requirements, and change logs represent a gold-mine of actionable information. As a result, software analytic solutions have been developed to mine repositories and answer questions such as \"who is the expert?,'' \"which classes are fault prone?,'' or even \"who are the domain experts for these fault-prone classes?'' Analytics often require training and configuring in order to maximize performance within the context of each project. A cold-start problem exists when a function is applied within a project context without first configuring the analytic functions on project-specific data. This scenario exists because of the non-trivial effort necessary to instrument a project environment with candidate tools and algorithms and to empirically evaluate alternate configurations. We address the cold-start problem by comparatively evaluating 'best-of-breed' and 'profile-driven' solutions, both of which reuse known configurations in new project contexts. We describe and evaluate our approach against 20 project datasets for the three analytic areas of artifact connectivity, fault-prediction, and finding the expert, and show that the best-of-breed approach outperformed the profile-driven approach in all three areas; however, while it delivered acceptable results for artifact connectivity and find the expert, both techniques underperformed for cold-start fault prediction.",
      "ISBNs": "978-1-4503-4186-8",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7832895",
      "Author_Keywords": "Cold-start;Software Analytics;Configuration",
      "IEEE_Terms": "Software;Measurement;Predictive models;Analytical models;Context;Training;Software engineering",
      "Reference Count": "51",
      "Online Date": "26-Jan-17",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Silent Vulnerable Dependency Alert Prediction with Vulnerability Key Aspect Explanation",
      "Authors": "J. Sun; Z. Xing; Q. Lu; X. Xu; L. Zhu; T. Hoang; D. Zhao",
      "Author Affiliations": "Data61, Eveleigh, CSIRO, Sydney, Australia; Data61, Eveleigh, CSIRO, Sydney, Australia; Data61, Eveleigh, CSIRO, Sydney, Australia; Data61, Eveleigh, CSIRO, Sydney, Australia; Data61, Eveleigh, CSIRO, Sydney, Australia; Data61, Eveleigh, CSIRO, Sydney, Australia; Research School of Computer Science, CECS, Australian National University, Canberra, Australia",
      "Publication Title": "2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "14-Jul-23",
      "Publication Year": "2023",
      "Start Page": "970",
      "End Page": "982",
      "Abstract": "Due to convenience, open-source software is widely used. For beneficial reasons, open-source maintainers often fix the vulnerabilities silently, exposing their users unaware of the updates to threats. Previous works all focus on black-box binary detection of the silent dependency alerts that suffer from high false-positive rates. Open-source software users need to analyze and explain AI prediction themselves. Explainable AI becomes remarkable as a complementary of black-box AI models, providing details in various forms to explain AI decisions. Noticing there is still no technique that can discover silent dependency alert on time, in this work, we propose a framework using an encoder-decoder model with a binary detector to provide explainable silent dependency alert prediction. Our model generates 4 types of vulnerability key aspects including vulnerability type, root cause, attack vector, and impact to enhance the trustworthiness and users' acceptance to alert prediction. By experiments with several models and inputs, we confirm CodeBERT with both commit messages and code changes achieves the best results. Our user study shows that explainable alert predictions can help users find silent dependency alert more easily than black-box predictions. To the best of our knowledge, this is the first research work on the application of Explainable AI in silent dependency alert prediction, which opens the door of the related domains.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-6654-5701-9",
      "DOI": "10.1109/ICSE48619.2023.00089",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10172824",
      "IEEE_Terms": "Codes;Soft sensors;Closed box;Detectors;Predictive models;Generators;Data models",
      "Reference Count": "82",
      "License": "IEEE",
      "Online Date": "14-Jul-23",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "Default: Mutual Information-based Crash Triage for Massive Crashes",
      "Authors": "X. Zhang; J. Chen; C. Feng; R. Li; W. Diao; K. Zhang; J. Lei; C. Tang",
      "Author Affiliations": "National University of Defense Technology; National University of Defense Technology; National University of Defense Technology; National University of Defense Technology; School of Cyber Science and Technology, Shandong University; Chinese University of Hong Kong; National University of Defense Technology; National University of Defense Technology",
      "Publication Title": "2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE)",
      "Date Added To Xplore": "20-Jun-22",
      "Publication Year": "2022",
      "Start Page": "635",
      "End Page": "646",
      "Abstract": "With the considerable success achieved by modern fuzzing in-frastructures, more crashes are produced than ever before. To dig out the root cause, rapid and faithful crash triage for large numbers of crashes has always been attractive. However, hindered by the practical difficulty of reducing analysis imprecision without compromising efficiency, this goal has not been accomplished. In this paper, we present an end-to-end crash triage solution Default, for accurately and quickly pinpointing unique root cause from large numbers of crashes. In particular, we quantify the ‚Äúcrash relevance‚Äù of program entities based on mutual information, which serves as the criterion of unique crash bucketing and allows us to bucket massive crashes without pre-analyzing their root cause. The quantification of ‚Äúcrash relevance‚Äù is also used in the shortening of long crashing traces. On this basis, we use the interpretability of neural networks to precisely pinpoint the root cause in the shortened traces by evaluating each basic block's impact on the crash label. Evaluated with 20 programs with 22216 crashes in total, Default demonstrates remarkable accuracy and performance, which is way beyond what the state-of-the-art techniques can achieve: crash de-duplication was achieved at a super-fast processing speed - 0.017 seconds per crashing trace, without missing any unique bugs. After that, it identifies the root cause of 43 unique crashes with no false negatives and an average false positive rate of 9.2%.",
      "ISSN": "1558-1225",
      "ISBNs": "978-1-4503-9221-1",
      "DOI": "10.1145/3510003.3512760",
      "Funding Information": "National Natural Science Foundation of China(grant numbers:61902148); Qilu Young Scholar Program of Shandong University; ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9793954",
      "Author_Keywords": "Crash Triage;Software Security",
      "IEEE_Terms": "Location awareness;Software algorithms;Neural networks;Computer bugs;Fuzzing;Computer crashes;Security",
      "Reference Count": "53",
      "Online Date": "20-Jun-22",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Conferences"
    },
    {
      "Document Title": "CODIT: Code Editing With Tree-Based Neural Models",
      "Authors": "S. Chakraborty; Y. Ding; M. Allamanis; B. Ray",
      "Author Affiliations": "Department of Computer Science, Columbia University, New York, NY, USA; Department of Computer Science, Columbia University, New York, NY, USA; Microsoft Research, Cambridge, U.K; Department of Computer Science, Columbia University, New York, NY, USA",
      "Publication Title": "IEEE Transactions on Software Engineering",
      "Date Added To Xplore": "15-Apr-22",
      "Publication Year": "2022",
      "Volume": "48",
      "Issue": "4",
      "Start Page": "1385",
      "End Page": "1399",
      "Abstract": "The way developers edit day-to-day code tends to be repetitive, often using existing code elements. Many researchers have tried to automate repetitive code changes by learning from specific change templates which are applied to limited scope. The advancement of deep neural networks and the availability of vast open-source evolutionary data opens up the possibility of automatically learning those templates from the wild. However, deep neural network based modeling for code changes and code in general introduces some specific problems that needs specific attention from research community. For instance, compared to natural language, source code vocabulary can be significantly larger. Further, good changes in code do not break its syntactic structure. Thus, deploying state-of-the-art neural network models without adapting the methods to the source code domain yields sub-optimal results. To this end, we propose a novel tree-based neural network system to model source code changes and learn code change patterns from the wild. Specifically, we propose a tree-based neural machine translation model to learn the probability distribution of changes in code. We realize our model with a change suggestion engine, Codit, and train the model with more than 24k real-world changes and evaluate it on 5k patches. Our evaluation shows the effectiveness of Codit in learning and suggesting patches. Codit can also learn specific bug fix pattern from bug fixing patches and can fix 25 bugs out of 80 bugs in Defects4J.",
      "ISSN": "1939-3520",
      "DOI": "10.1109/TSE.2020.3020502",
      "Funding Information": "National Science Foundation(grant numbers:CCF1845893,CCF 1822965,CNS 1842456); ",
      "PDF Link": "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9181462",
      "Author_Keywords": "Code change;tree-2-tree translation;code synthesis;neural machine translator;empirical software engineering",
      "IEEE_Terms": "Computer bugs;Predictive models;Reactive power;Probability distribution;Syntactics;Neural networks;Adaptation models",
      "Article Citation Count": "30",
      "Reference Count": "99",
      "License": "IEEE",
      "Online Date": "31-Aug-20",
      "Publisher": "IEEE",
      "Document Identifier": "IEEE Journals"
    }
  ]