@inproceedings{10.1145/3377814.3381716,
author = {Miljanovic, Michael A. and Bradbury, Jeremy S.},
title = {GidgetML: an adaptive serious game for enhancing first year programming labs},
year = {2020},
isbn = {9781450371247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377814.3381716},
doi = {10.1145/3377814.3381716},
abstract = {Serious games have become a popular alternative learning tool for computer programming education. Research has shown that serious games provide benefits including the development of problem solving skills and increased engagement in the learning process. Despite the benefits, a major challenge of developing serious games is their ability to accommodate students with different educational backgrounds and levels of competency. Learners with a high-level of competence may find a serious games to be too easy or boring, while learners with low-level competence may be frequently frustrated or find it difficult to progress through the game. One solution to this challenge is to use automated adaptation that can alter game content and adjust game tasks to a level appropriate for the learner. The use of adaptation has been successfully utilized in educational domains outside of Software Engineering, but has not been applied to serious programming games. This paper presents GidgetML, an adaptive version of the Gidget programming game, that uses machine learning to modify game tasks based on assessing and predicting learners' competencies. To assess the benefits of adaptation, we have conducted a study involving 100 students in a first-year university programming course. Our study compared the use of Gidget (non-adaptive) with GidgetML (adaptive) and found that students who played Gidget during lab sessions varied significantly in their performance while this variance was significantly reduced for students who played GidgetML.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering Education and Training},
pages = {184–192},
numpages = {9},
keywords = {software engineering, serious games, programming, machine learning, game-based learning, education, computer science, computer education},
location = {Seoul, South Korea},
series = {ICSE-SEET '20}
}

@inproceedings{10.1145/3416508.3417121,
author = {Villalobos-Arias, Leonardo and Quesada-L\'{o}pez, Christian and Guevara-Coto, Jose and Mart\'{\i}nez, Alexandra and Jenkins, Marcelo},
title = {Evaluating hyper-parameter tuning using random search in support vector machines for software effort estimation},
year = {2020},
isbn = {9781450381277},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416508.3417121},
doi = {10.1145/3416508.3417121},
abstract = {Studies in software effort estimation&nbsp;(SEE) have explored the use of hyper-parameter tuning for machine learning algorithms&nbsp;(MLA) to improve the accuracy of effort estimates. In other contexts random search&nbsp;(RS) has shown similar results to grid search, while being less computationally-expensive. In this paper, we investigate to what extent the random search hyper-parameter tuning approach affects the accuracy and stability of support vector regression&nbsp;(SVR) in SEE. Results were compared to those obtained from ridge regression models and grid search-tuned models. A case study with four data sets extracted from the ISBSG 2018 repository shows that random search exhibits similar performance to grid search, rendering it an attractive alternative technique for hyper-parameter tuning. RS-tuned SVR achieved an increase of 0.227 standardized accuracy&nbsp;(SA) with respect to default hyper-parameters. In addition, random search improved prediction stability of SVR models to a minimum ratio of 0.840. The analysis showed that RS-tuned SVR attained performance equivalent to GS-tuned SVR. Future work includes extending this research to cover other hyper-parameter tuning approaches and machine learning algorithms, as well as using additional data sets.},
booktitle = {Proceedings of the 16th ACM International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {31–40},
numpages = {10},
keywords = {support vector machines, random search, hyper-parameter tuning, grid search, empirical study, Software effort estimation},
location = {Virtual, USA},
series = {PROMISE 2020}
}

@inproceedings{10.1145/3416508.3417114,
author = {Aljamaan, Hamoud and Alazba, Amal},
title = {Software defect prediction using tree-based ensembles},
year = {2020},
isbn = {9781450381277},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416508.3417114},
doi = {10.1145/3416508.3417114},
abstract = {Software defect prediction is an active research area in software engineering. Accurate prediction of software defects assists software engineers in guiding software quality assurance activities. In machine learning, ensemble learning has been proven to improve the prediction performance over individual machine learning models. Recently, many Tree-based ensembles have been proposed in the literature, and their prediction capabilities were not investigated in defect prediction. In this paper, we will empirically investigate the prediction performance of seven Tree-based ensembles in defect prediction. Two ensembles are classified as bagging ensembles: Random Forest and Extra Trees, while the other five ensembles are boosting ensembles: Ada boost, Gradient Boosting, Hist Gradient Boosting, XGBoost and CatBoost. The study utilized 11 publicly available MDP NASA software defect datasets. Empirical results indicate the superiority of Tree-based bagging ensembles: Random Forest and Extra Trees ensembles over other Tree-based boosting ensembles. However, none of the investigated Tree-based ensembles was significantly lower than individual decision trees in prediction performance. Finally, Adaboost ensemble was the worst performing ensemble among all Tree-based ensembles.},
booktitle = {Proceedings of the 16th ACM International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {1–10},
numpages = {10},
keywords = {Software Defect, Prediction, Machine Learning, Ensemble Learning, Classification, Boosting, Bagging},
location = {Virtual, USA},
series = {PROMISE 2020}
}

@inproceedings{10.1145/3597503.3608130,
author = {Arteaga Garcia, Emily Judith and Nicolaci Pimentel, Jo\~{a}o Felipe and Feng, Zixuan and Gerosa, Marco and Steinmacher, Igor and Sarma, Anita},
title = {How to Support ML End-User Programmers through a Conversational Agent},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3608130},
doi = {10.1145/3597503.3608130},
abstract = {Machine Learning (ML) is increasingly gaining significance for enduser programmer (EUP) applications. However, machine learning end-user programmers (ML-EUPs) without the right background face a daunting learning curve and a heightened risk of mistakes and flaws in their models. In this work, we designed a conversational agent named "Newton" as an expert to support ML-EUPs. Newton's design was shaped by a comprehensive review of existing literature, from which we identified six primary challenges faced by ML-EUPs and five strategies to assist them. To evaluate the efficacy of Newton's design, we conducted a Wizard of Oz within-subjects study with 12 ML-EUPs. Our findings indicate that Newton effectively assisted ML-EUPs, addressing the challenges highlighted in the literature. We also proposed six design guidelines for future conversational agents, which can help other EUP applications and software engineering activities.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {53},
numpages = {12},
keywords = {end-user programming, conversational agent, wizard of Oz},
location = {<conf-loc>, <city>Lisbon</city>, <country>Portugal</country>, </conf-loc>},
series = {ICSE '24}
}

@inproceedings{10.1145/3377811.3380378,
author = {Islam, Md Johirul and Pan, Rangeet and Nguyen, Giang and Rajan, Hridesh},
title = {Repairing deep neural networks: fix patterns and challenges},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380378},
doi = {10.1145/3377811.3380378},
abstract = {Significant interest in applying Deep Neural Network (DNN) has fueled the need to support engineering of software that uses DNNs. Repairing software that uses DNNs is one such unmistakable SE need where automated tools could be beneficial; however, we do not fully understand challenges to repairing and patterns that are utilized when manually repairing DNNs. What challenges should automated repair tools address? What are the repair patterns whose automation could help developers? Which repair patterns should be assigned a higher priority for building automated bug repair tools? This work presents a comprehensive study of bug fix patterns to address these questions. We have studied 415 repairs from Stack Overflow and 555 repairs from GitHub for five popular deep learning libraries Caffe, Keras, Tensorflow, Theano, and Torch to understand challenges in repairs and bug repair patterns. Our key findings reveal that DNN bug fix patterns are distinctive compared to traditional bug fix patterns; the most common bug fix patterns are fixing data dimension and neural network connectivity; DNN bug fixes have the potential to introduce adversarial vulnerabilities; DNN bug fixes frequently introduce new bugs; and DNN bug localization, reuse of trained model, and coping with frequent releases are major challenges faced by developers when fixing bugs. We also contribute a benchmark of 667 DNN (bug, repair) instances.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {1135–1146},
numpages = {12},
keywords = {deep neural networks, bugs, bug fix patterns, bug fix},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1145/3377811.3380434,
author = {Zhou, Weijie and Zhao, Yue and Zhang, Guoqiang and Shen, Xipeng},
title = {HARP: holistic analysis for refactoring Python-based analytics programs},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380434},
doi = {10.1145/3377811.3380434},
abstract = {Modern machine learning programs are often written in Python, with the main computations specified through calls to some highly optimized libraries (e.g., TensorFlow, PyTorch). How to maximize the computing efficiency of such programs is essential for many application domains, which has drawn lots of recent attention. This work points out a common limitation in existing efforts: they focus their views only on the static computation graphs specified by library APIs, but leave the influence from the hosting Python code largely unconsidered. The limitation often causes them to miss the big picture and hence many important optimization opportunities. This work proposes a new approach named HARP to address the problem. HARP enables holistic analysis that spans across computation graphs and their hosting Python code. HARP achieves it through a set of novel techniques: analytics-conscious speculative analysis to circumvent Python complexities, a unified representation augmented computation graphs to capture all dimensions of knowledge related with the holistic analysis, and conditioned feedback mechanism to allow risk-controlled aggressive analysis. Refactoring based on HARP gives 1.3--3X and 2.07X average speedups on a set of TensorFlow and PyTorch programs.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {506–517},
numpages = {12},
keywords = {program analysis, machine learning program, dynamic language, computation graph},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1145/3597503.3623333,
author = {Ahmed, Shibbir and Gao, Hongyang and Rajan, Hridesh},
title = {Inferring Data Preconditions from Deep Learning Models for Trustworthy Prediction in Deployment},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3623333},
doi = {10.1145/3597503.3623333},
abstract = {Deep learning models are trained with certain assumptions about the data during the development stage and then used for prediction in the deployment stage. It is important to reason about the trustworthiness of the model's predictions with unseen data during deployment. Existing methods for specifying and verifying traditional software are insufficient for this task, as they cannot handle the complexity of DNN model architecture and expected outcomes. In this work, we propose a novel technique that uses rules derived from neural network computations to infer data preconditions for a DNN model to determine the trustworthiness of its predictions. Our approach, DeepInfer involves introducing a novel abstraction for a trained DNN model that enables weakest precondition reasoning using Dijkstra's Predicate Transformer Semantics. By deriving rules over the inductive type of neural network abstract representation, we can overcome the matrix dimensionality issues that arise from the backward non-linear computation from the output layer to the input layer. We utilize the weakest precondition computation using rules of each kind of activation function to compute layer-wise precondition from the given postcondition on the final output of a deep neural network. We extensively evaluated DeepInfer on 29 real-world DNN models using four different datasets collected from five different sources and demonstrated the utility, effectiveness, and performance improvement over closely related work. DeepInfer efficiently detects correct and incorrect predictions of high-accuracy models with high recall (0.98) and high F-1 score (0.84) and has significantly improved over the prior technique, SelfChecker. The average runtime overhead of DeepInfer is low, 0.22 sec for all the unseen datasets. We also compared runtime overhead using the same hardware settings and found that DeepInfer is 3.27 times faster than SelfChecker, the state-of-the-art in this area.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {38},
numpages = {13},
keywords = {deep neural networks, weakest precondition, trustworthiness},
location = {<conf-loc>, <city>Lisbon</city>, <country>Portugal</country>, </conf-loc>},
series = {ICSE '24}
}

@inproceedings{10.1145/3510454.3516841,
author = {Moin, Armin and Mituca, Andrei and Challenger, Moharram and Badii, Atta and G\"{u}nnemann, Stephan},
title = {ML-quadrat &amp; DriotData: a model-driven engineering tool and a low-code platform for smart IoT services},
year = {2022},
isbn = {9781450392235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510454.3516841},
doi = {10.1145/3510454.3516841},
abstract = {In this paper, we present ML-Quadrat, an open-source research prototype that is based on the Eclipse Modeling Framework (EMF) and the state of the art in the literature of Model-Driven Software Engineering (MDSE) for smart Cyber-Physical Systems (CPS) and the Internet of Things (IoT). Its envisioned users are mostly software developers who might not have deep knowledge and skills in the heterogeneous IoT platforms and the diverse Artificial Intelligence (AI) technologies, specifically regarding Machine Learning (ML). ML-Quadrat is released under the terms of the Apache 2.0 license on Github1. Additionally, we demonstrate an early tool prototype of DriotData, a web-based Low-Code platform targeting citizen data scientists and citizen/end-user software developers. DriotData exploits and adopts ML-Quadrat in the industry by offering an extended version of it as a subscription-based service to companies, mainly Small- and Medium-Sized Enterprises (SME). The current preliminary version of DriotData has three web-based model editors: text-based, tree-/form-based and diagram-based. The latter is designed for domain experts in the problem or use case domains (namely the IoT vertical domains) who might not have knowledge and skills in the field of IT. Finally, a short video demonstrating the tools is available on YouTube: https://youtu.be/VAuz25w0a5k.},
booktitle = {Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings},
pages = {144–148},
numpages = {5},
keywords = {model-driven software engineering, machine learning, low-code, iot, domain-specific modeling},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3510454.3517067,
author = {d'Aloisio, Giordano},
title = {Quality-driven machine learning-based data science pipeline realization: a software engineering approach},
year = {2022},
isbn = {9781450392235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510454.3517067},
doi = {10.1145/3510454.3517067},
abstract = {The recently wide adoption of data science approaches to decision making in several application domains (such as health, business and even education) open new challenges in engineering and implementation of this systems. Considering the big picture of data science, Machine learning is the wider used technique and due to its characteristics, we believe that a better engineering methodology and tools are needed to realize innovative data-driven systems able to satisfy the emerging quality attributes (such as, debias and fariness, explainability, privacy and ethics, sustainability). This research project will explore the following three pillars: i) identify key quality attributes, formalize them in the context of data science pipelines and study their relationships; ii) define a new software engineering approach for data-science systems development that assures compliance with quality requirements; iii) implement tools that guide IT professionals and researchers in the realization of ML-based data science pipelines since the requirement engineering. Moreover, in this paper we also presents some details of the project showing how the feature models and model-driven engineering can be leveraged to realize our project.},
booktitle = {Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings},
pages = {291–293},
numpages = {3},
keywords = {software quality, product-line architecture, pipelines, model-driven, machine learning},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3510454.3517055,
author = {Quaranta, Luigi},
title = {Assessing the quality of computational notebooks for a frictionless transition from exploration to production},
year = {2022},
isbn = {9781450392235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510454.3517055},
doi = {10.1145/3510454.3517055},
abstract = {The massive trend of integrating data-driven AI capabilities into traditional software systems is rising new intriguing challenges. One of such challenges is achieving a smooth transition from the explorative phase of Machine Learning projects - in which data scientists build prototypical models in the lab - to their production phase - in which software engineers translate prototypes into production-ready AI components. To narrow down the gap between these two phases, tools and practices adopted by data scientists might be improved by incorporating consolidated software engineering solutions. In particular, computational notebooks have a prominent role in determining the quality of data science prototypes. In my research project, I address this challenge by studying the best practices for collaboration with computational notebooks and proposing proof-of-concept tools to foster guidelines compliance.},
booktitle = {Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings},
pages = {256–260},
numpages = {5},
keywords = {static analysis tools, software engineering, machine learning, linters, data science, computational notebooks, artificial intelligence},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3580252.3586977,
author = {Sun, Minglong and Jung, Woosub and Koltermann, Kenneth and Zhou, Gang and Watson, Amanda and Blackwell, Ginamari and Helm, Noah and Cloud, Leslie and Pretzer-Aboff, Ingrid},
title = {Parkinson's Disease Action Tremor Detection with Supervised-Leaning Models},
year = {2024},
isbn = {9798400701023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580252.3586977},
doi = {10.1145/3580252.3586977},
abstract = {People with Parkinson's Disease (PD) have multiple symptoms, such as freezing of gait (FoG), hand tremors, speech difficulties, and balance issues, in different stages of the disease. Among these symptoms, hand tremors are present across all stages of the disease. PD hand tremors have critical consequences and negatively impact the quality of PD patients' everyday lives. Researchers have proposed a variety of wearable devices to mitigate PD tremors. However, these devices require accurate tremor detection technology to work effectively while the tremor occurs. This paper introduces a PD action tremor detection method to recognize PD tremors from regular activities. We used a dataset from 30 PD patients wearing accelerometers and gyroscope sensors on their wrists. We selected time-domain and frequency-domain hand-crafted features. Also, we compared our hand-crafted features with existing CNN data-driven features, and our features have more specific boundaries in 2-D feature visualization using the t-SNE tool. We fed our features into multiple supervised machine learning models, including Logistic Regression (LR), K-Nearest Neighbours (KNNs), Support Vector Machines (SVMs), and Convolutional Neural Networks (CNNs), for detecting PD action tremors. These models were evaluated with 30 PD patients' data. The performance of all models using our features has more than 90% of F1 scores in five-fold cross-validations and 88% F1 scores in the leave-one-out evaluation. Specifically, Support Vector Machines (SVMs) perform the best in five-fold cross-validation with over 92% F1 scores. SVMs also show the best performance in the leave-one-out evaluation with over 90% F1 scores.},
booktitle = {Proceedings of the 8th ACM/IEEE International Conference on Connected Health: Applications, Systems and Engineering Technologies},
pages = {1–10},
numpages = {10},
keywords = {parkinson's disease, action tremor detection, wearable device, supervised-learning},
location = {<conf-loc>, <city>Orlando</city>, <state>FL</state>, <country>USA</country>, </conf-loc>},
series = {CHASE '23}
}

@inproceedings{10.1145/3580252.3586972,
author = {Seidi, Navid and Tripathy, Ardhendu and Das, Sajal K.},
title = {Using Geographic Location-Based Public Health Features in Survival Analysis},
year = {2024},
isbn = {9798400701023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580252.3586972},
doi = {10.1145/3580252.3586972},
abstract = {Time elapsed till an event of interest is often modeled using the survival analysis methodology, which estimates a survival score based on the input features. There is a resurgence of interest in developing more accurate prediction models for time-to-event prediction in personalized healthcare using modern tools such as neural networks. Higher quality features and more frequent observations improve the predictions for a patient, however, the impact of including a patient's geographic location-based public health statistics on individual predictions has not been studied. This paper proposes a complementary improvement to survival analysis models by incorporating public health statistics in the input features. We show that including geographic location-based public health information results in a statistically significant improvement in the concordance index evaluated on the Surveillance, Epidemiology, and End Results (SEER) dataset containing nationwide cancer incidence data. The improvement holds for both the standard Cox proportional hazards model and the state-of-the-art Deep Survival Machines model. Our results indicate the utility of geographic location-based public health features in survival analysis.},
booktitle = {Proceedings of the 8th ACM/IEEE International Conference on Connected Health: Applications, Systems and Engineering Technologies},
pages = {80–91},
numpages = {12},
keywords = {survival analysis, machine learning, deep neural networks, smart health, medical cyber-physical system},
location = {<conf-loc>, <city>Orlando</city>, <state>FL</state>, <country>USA</country>, </conf-loc>},
series = {CHASE '23}
}

@inproceedings{10.1145/3617555.3617876,
author = {Menzies, Tim},
title = {Model Review: A PROMISEing Opportunity},
year = {2023},
isbn = {9798400703751},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617555.3617876},
doi = {10.1145/3617555.3617876},
abstract = {To make models more understandable and correctable, I propose  
that the PROMISE community pivots to the problem of model review.  
Over the years, there have been many reports that very simple mod-  
els can perform exceptionally well. Yet, where are the researchers  
asking “say, does that mean that we could make software analytics  
simpler and more comprehensible?” This is an important question,  
since humans often have difficulty accurately assessing complex  
models (leading to unreliable and sometimes dangerous results).  

Prior PROMISE results have shown that data mining can effectively summarizing large models/ data sets into simpler and smaller  
ones. Therefore, the PROMISE community has the skills and experience needed to redefine, simplify, and improve the relationship  
between humans and AI.},
booktitle = {Proceedings of the 19th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {64–68},
numpages = {5},
keywords = {review, optimization, discrimination, data mining, Model},
location = {<conf-loc>, <city>San Francisco</city>, <state>CA</state>, <country>USA</country>, </conf-loc>},
series = {PROMISE 2023}
}

@inproceedings{10.1145/2884781.2884801,
author = {Anish, Preethu Rose and Balasubramaniam, Balaji and Sainani, Abhishek and Cleland-Huang, Jane and Daneva, Maya and Wieringa, Roel J. and Ghaisas, Smita},
title = {Probing for requirements knowledge to stimulate architectural thinking},
year = {2016},
isbn = {9781450339001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2884781.2884801},
doi = {10.1145/2884781.2884801},
abstract = {Software requirements specifications (SRSs) often lack the detail needed to make informed architectural decisions. Architects therefore either make assumptions, which can lead to incorrect decisions, or conduct additional stakeholder interviews, resulting in potential project delays. We previously observed that software architects ask Probing Questions (PQs) to gather information crucial to architectural decision-making. Our goal is to equip Business Analysts with appropriate PQs so that they can ask these questions themselves. We report a new study with over 40 experienced architects to identify reusable PQs for five areas of functionality and organize them into structured flows. These PQ-flows can be used by Business Analysts to elicit and specify architecturally relevant information. Additionally, we leverage machine learning techniques to determine when a PQ-flow is appropriate for use in a project, and to annotate individual PQs with relevant information extracted from the existing SRS. We trained and evaluated our approach on over 8,000 individual requirements from 114 requirements specifications and also conducted a pilot study to validate its usefulness.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering},
pages = {843–854},
numpages = {12},
keywords = {requirements knowledge, functional requirements, automated requirement classification, architecturally significant requirements, Probing Questions (PQs), PQ-flows},
location = {Austin, Texas},
series = {ICSE '16}
}

@inproceedings{10.1145/3510003.3510051,
author = {Pan, Rangeet and Rajan, Hridesh},
title = {Decomposing convolutional neural networks into reusable and replaceable modules},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510051},
doi = {10.1145/3510003.3510051},
abstract = {Training from scratch is the most common way to build a Convolutional Neural Network (CNN) based model. What if we can build new CNN models by reusing parts from previously built CNN models? What if we can improve a CNN model by replacing (possibly faulty) parts with other parts? In both cases, instead of training, can we identify the part responsible for each output class (module) in the model(s) and reuse or replace only the desired output classes to build a model? Prior work has proposed decomposing dense-based networks into modules (one for each output class) to enable reusability and replaceability in various scenarios. However, this work is limited to the dense layers and is based on the one-to-one relationship between the nodes in consecutive layers. Due to the shared architecture in the CNN model, prior work cannot be adapted directly. In this paper, we propose to decompose a CNN model used for image classification problems into modules for each output class. These modules can further be reused or replaced to build a new model. We have evaluated our approach with CIFAR-10, CIFAR-100, and ImageNet tiny datasets with three variations of ResNet models and found that enabling decomposition comes with a small cost (1.77% and 0.85% for top-1 and top-5 accuracy, respectively). Also, building a model by reusing or replacing modules can be done with a 2.3% and 0.5% average loss of accuracy. Furthermore, reusing and replacing these modules reduces CO2e emission by ~37 times compared to training the model from scratch.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {524–535},
numpages = {12},
keywords = {modularity, deep neural network, deep learning, decomposition, cnn},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3510003.3510049,
author = {Ahmed, Toufique and Devanbu, Premkumar},
title = {Multilingual training for software engineering},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510049},
doi = {10.1145/3510003.3510049},
abstract = {Well-trained machine-learning models, which leverage large amounts of open-source software data, have now become an interesting approach to automating many software engineering tasks. Several SE tasks have all been subject to this approach, with performance gradually improving over the past several years with better models and training methods. More, and more diverse, clean, labeled data is better for training; but constructing good-quality datasets is time-consuming and challenging. Ways of augmenting the volume and diversity of clean, labeled data generally have wide applicability. For some languages (e.g., Ruby) labeled data is less abundant; in others (e.g., JavaScript) the available data maybe more focused on some application domains, and thus less diverse. As a way around such data bottlenecks, we present evidence suggesting that human-written code in different languages (which performs the same function), is rather similar, and particularly preserving of identifier naming patterns; we further present evidence suggesting that identifiers are a very important element of training data for software engineering tasks. We leverage this rather fortuitous phenomenon to find evidence that available multilingual training data (across different languages) can be used to amplify performance. We study this for 3 different tasks: code summarization, code retrieval, and function naming. We note that this data-augmenting approach is broadly compatible with different tasks, languages, and machine-learning models.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {1443–1455},
numpages = {13},
keywords = {method name prediction, deep learning, code summarization, code search},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3510003.3510037,
author = {Liu, Changlin and Wang, Hanlin and Liu, Tianming and Gu, Diandian and Ma, Yun and Wang, Haoyu and Xiao, Xusheng},
title = {ProMal: precise window transition graphs for android via synergy of program analysis and machine learning},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510037},
doi = {10.1145/3510003.3510037},
abstract = {Mobile apps have been an integral part in our daily life. As these apps become more complex, it is critical to provide automated analysis techniques to ensure the correctness, security, and performance of these apps. A key component for these automated analysis techniques is to create a graphical user interface (GUI) model of an app, i.e., a window transition graph (WTG), that models windows and transitions among the windows. While existing work has provided both static and dynamic analysis to build the WTG for an app, the constructed WTG misses many transitions or contains many infeasible transitions due to the coverage issues of dynamic analysis and over-approximation of the static analysis. We propose ProMal, a "tribrid" analysis that synergistically combines static analysis, dynamic analysis, and machine learning to construct a precise WTG. Specifically, ProMal first applies static analysis to build a static WTG, and then applies dynamic analysis to verify the transitions in the static WTG. For the unverified transitions, ProMal further provides machine learning techniques that leverage runtime information (i.e., screenshots, UI layouts, and text information) to predict whether they are feasible transitions. Our evaluations on 40 real-world apps demonstrate the superiority of ProMal in building WTGs over static analysis, dynamic analysis, and machine learning techniques when they are applied separately.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {1755–1767},
numpages = {13},
keywords = {window transition graph, static analysis, mobile apps, deep learning},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3510003.3510225,
author = {Dilhara, Malinda and Ketkar, Ameya and Sannidhi, Nikhith and Dig, Danny},
title = {Discovering repetitive code changes in python ML systems},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510225},
doi = {10.1145/3510003.3510225},
abstract = {Over the years, researchers capitalized on the repetitiveness of software changes to automate many software evolution tasks. Despite the extraordinary rise in popularity of Python-based ML systems, they do not benefit from these advances. Without knowing what are the repetitive changes that ML developers make, researchers, tool, and library designers miss opportunities for automation, and ML developers fail to learn and use best coding practices.To fill the knowledge gap and advance the science and tooling in ML software evolution, we conducted the first and most fine-grained study on code change patterns in a diverse corpus of 1000 top-rated ML systems comprising 58 million SLOC. To conduct this study we reuse, adapt, and improve upon the state-of-the-art repetitive change mining techniques. Our novel tool, R-CPatMiner, mines over 4M commits and constructs 350K fine-grained change graphs and detects 28K change patterns. Using thematic analysis, we identified 22 pattern groups and we reveal 4 major trends of how ML developers change their code. We surveyed 650 ML developers to further shed light on these patterns and their applications, and we received a 15% response rate. We present actionable, empirically-justified implications for four audiences: (i) researchers, (ii) tool builders, (iii) ML library vendors, and (iv) developers and educators.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {736–748},
numpages = {13},
keywords = {repetition, refactoring, python, machine learning, code changes},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3510003.3510052,
author = {Nguyen, Giang and Islam, Md Johirul and Pan, Rangeet and Rajan, Hridesh},
title = {Manas: mining software repositories to assist AutoML},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510052},
doi = {10.1145/3510003.3510052},
abstract = {Today deep learning is widely used for building software. A software engineering problem with deep learning is that finding an appropriate convolutional neural network (CNN) model for the task can be a challenge for developers. Recent work on AutoML, more precisely neural architecture search (NAS), embodied by tools like Auto-Keras aims to solve this problem by essentially viewing it as a search problem where the starting point is a default CNN model, and mutation of this CNN model allows exploration of the space of CNN models to find a CNN model that will work best for the problem. These works have had significant success in producing high-accuracy CNN models. There are two problems, however. First, NAS can be very costly, often taking several hours to complete. Second, CNN models produced by NAS can be very complex that makes it harder to understand them and costlier to train them. We propose a novel approach for NAS, where instead of starting from a default CNN model, the initial model is selected from a repository of models extracted from GitHub. The intuition being that developers solving a similar problem may have developed a better starting point compared to the default model. We also analyze common layer patterns of CNN models in the wild to understand changes that the developers make to improve their models. Our approach uses commonly occurring changes as mutation operators in NAS. We have extended Auto-Keras to implement our approach. Our evaluation using 8 top voted problems from Kaggle for tasks including image classification and image regression shows that given the same search time, without loss of accuracy, Manas produces models with 42.9% to 99.6% fewer number of parameters than Auto-Keras' models. Benchmarked on GPU, Manas' models train 30.3% to 641.6% faster than Auto-Keras' models.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {1368–1380},
numpages = {13},
keywords = {mining software repositories, deep learning, MSR, AutoML},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3510003.3510057,
author = {Biswas, Sumon and Wardat, Mohammad and Rajan, Hridesh},
title = {The art and practice of data science pipelines: A comprehensive study of data science pipelines in theory, in-the-small, and in-the-large},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510057},
doi = {10.1145/3510003.3510057},
abstract = {Increasingly larger number of software systems today are including data science components for descriptive, predictive, and prescriptive analytics. The collection of data science stages from acquisition, to cleaning/curation, to modeling, and so on are referred to as data science pipelines. To facilitate research and practice on data science pipelines, it is essential to understand their nature. What are the typical stages of a data science pipeline? How are they connected? Do the pipelines differ in the theoretical representations and that in the practice? Today we do not fully understand these architectural characteristics of data science pipelines. In this work, we present a three-pronged comprehensive study to answer this for the state-of-the-art, data science in-the-small, and data science in-the-large. Our study analyzes three datasets: a collection of 71 proposals for data science pipelines and related concepts in theory, a collection of over 105 implementations of curated data science pipelines from Kaggle competitions to understand data science in-the-small, and a collection of 21 mature data science projects from GitHub to understand data science in-the-large. Our study has led to three representations of data science pipelines that capture the essence of our subjects in theory, in-the-small, and in-the-large.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {2091–2103},
numpages = {13},
keywords = {predictive, descriptive, data science processes, data science pipelines},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3510003.3510221,
author = {Georgiou, Stefanos and Kechagia, Maria and Sharma, Tushar and Sarro, Federica and Zou, Ying},
title = {Green AI: do deep learning frameworks have different costs?},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510221},
doi = {10.1145/3510003.3510221},
abstract = {The use of Artificial Intelligence (ai), and more specifically of Deep Learning (dl), in modern software systems, is nowadays widespread and continues to grow. At the same time, its usage is energy demanding and contributes to the increased CO2 emissions, and has a great financial cost as well. Even though there are many studies that examine the capabilities of dl, only a few focus on its green aspects, such as energy consumption.This paper aims at raising awareness of the costs incurred when using different dl frameworks. To this end, we perform a thorough empirical study to measure and compare the energy consumption and run-time performance of six different dl models written in the two most popular dl frameworks, namely PyTorch and TensorFlow. We use a well-known benchmark of dl models, DeepLearningExamples, created by nvidia, to compare both the training and inference costs of dl. Finally, we manually investigate the functions of these frameworks that took most of the time to execute in our experiments.The results of our empirical study reveal that there is a statistically significant difference between the cost incurred by the two dl frameworks in 94% of the cases studied. While TensorFlow achieves significantly better energy and run-time performance than PyTorch, and with large effect sizes in 100% of the cases for the training phase, PyTorch instead exhibits significantly better energy and run-time performance than TensorFlow in the inference phase for 66% of the cases, always, with large effect sizes. Such a large difference in performance costs does not, however, seem to affect the accuracy of the models produced, as both frameworks achieve comparable scores under the same configurations. Our manual analysis, of the documentation and source code of the functions examined, reveals that such a difference in performance costs is under-documented, in these frameworks. This suggests that developers need to improve the documentation of their dl frameworks, the source code of the functions used in these frameworks, as well as to enhance existing dl algorithms.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {1082–1094},
numpages = {13},
keywords = {run-time performance, energy consumption, deep learning, APIs},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3510003.3510068,
author = {Wan, Chengcheng and Liu, Shicheng and Xie, Sophie and Liu, Yifan and Hoffmann, Henry and Maire, Michael and Lu, Shan},
title = {Automated testing of software that uses machine learning APIs},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510068},
doi = {10.1145/3510003.3510068},
abstract = {An increasing number of software applications incorporate machine learning (ML) solutions for cognitive tasks that statistically mimic human behaviors. To test such software, tremendous human effort is needed to design image/text/audio inputs that are relevant to the software, and to judge whether the software is processing these inputs as most human beings do. Even when misbehavior is exposed, it is often unclear whether the culprit is inside the cognitive ML API or the code using the API.This paper presents Keeper, a new testing tool for software that uses cognitive ML APIs. Keeper designs a pseudo-inverse function for each ML API that reverses the corresponding cognitive task in an empirical way (e.g., an image search engine pseudo-reverses the image-classification API), and incorporates these pseudo-inverse functions into a symbolic execution engine to automatically generate relevant image/text/audio inputs and judge output correctness. Once misbehavior is exposed, Keeper attempts to change how ML APIs are used in software to alleviate the misbehavior. Our evaluation on a variety of open-source applications shows that Keeper greatly improves the branch coverage, while identifying many previously unknown bugs.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {212–224},
numpages = {13},
keywords = {software testing, machine learning API, machine learning},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.5555/2818754.2818821,
author = {Jia, Yue and Cohen, Myra B. and Harman, Mark and Petke, Justyna},
title = {Learning combinatorial interaction test generation strategies using hyperheuristic search},
year = {2015},
isbn = {9781479919345},
publisher = {IEEE Press},
abstract = {The surge of search based software engineering research has been hampered by the need to develop customized search algorithms for different classes of the same problem. For instance, two decades of bespoke Combinatorial Interaction Testing (CIT) algorithm development, our exemplar problem, has left software engineers with a bewildering choice of CIT techniques, each specialized for a particular task. This paper proposes the use of a single hyperheuristic algorithm that learns search strategies across a broad range of problem instances, providing a single generalist approach. We have developed a Hyperheuristic algorithm for CIT, and report experiments that show that our algorithm competes with known best solutions across constrained and unconstrained problems: For all 26 real-world subjects, it equals or outperforms the best result previously reported in the literature. We also present evidence that our algorithm's strong generic performance results from its unsupervised learning. Hyperheuristic search is thus a promising way to relocate CIT design intelligence from human to machine.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 1},
pages = {540–550},
numpages = {11},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.5555/2819009.2819200,
author = {Honsel, Verena},
title = {Statistical learning and software mining for agent based simulation of software evolution},
year = {2015},
publisher = {IEEE Press},
abstract = {In the process of software development it is of high interest for a project manager to gain insights about the ongoing process and possible development trends at several points in time. Substantial factors influencing this process are, e.g., the constellation of the development team, the growth and complexity of the system, and the error-proneness of software entities. For this purpose we build an agent based simulation tool which predicts the future of a project under given circumstances, stored in parameters, which control the simulation process.We estimate these parameters with the help of software mining. Our work exposed the need for a more fine-grained model for the developer behavior. Due to this we create a learning model, which helps us to understand the contribution behavior of developers and, thereby, to determine simulation parameters close to reality. In this paper we present our agent based simulation model for software evolution and describe how methods from statistical learning and data mining serves us to estimate suitable simulation parameters.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 2},
pages = {863–866},
numpages = {4},
keywords = {software process simulation, hidden markov model, developer behavior, agent based modeling},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.5555/2818754.2818781,
author = {Filieri, Antonio and Grunske, Lars and Leva, Alberto},
title = {Lightweight adaptive filtering for efficient learning and updating of probabilistic models},
year = {2015},
isbn = {9781479919345},
publisher = {IEEE Press},
abstract = {Adaptive software systems are designed to cope with unpredictable and evolving usage behaviors and environmental conditions. For these systems reasoning mechanisms are needed to drive evolution, which are usually based on models capturing relevant aspects of the running software. The continuous update of these models in evolving environments requires efficient learning procedures, having low overhead and being robust to changes. Most of the available approaches achieve one of these goals at the price of the other. In this paper we propose a lightweight adaptive filter to accurately learn time-varying transition probabilities of discrete time Markov models, which provides robustness to noise and fast adaptation to changes with a very low overhead. A formal stability, unbiasedness and consistency assessment of the learning approach is provided, as well as an experimental comparison with state-of-the-art alternatives.},
booktitle = {Proceedings of the 37th International Conference on Software Engineering - Volume 1},
pages = {200–211},
numpages = {12},
location = {Florence, Italy},
series = {ICSE '15}
}

@inproceedings{10.1145/3194085.3194087,
author = {Rao, Qing and Frtunikj, Jelena},
title = {Deep learning for self-driving cars: chances and challenges},
year = {2018},
isbn = {9781450357395},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194085.3194087},
doi = {10.1145/3194085.3194087},
abstract = {Artificial Intelligence (AI) is revolutionizing the modern society. In the automotive industry, researchers and developers are actively pushing deep learning based approaches for autonomous driving. However, before a neural network finds its way into series production cars, it has to first undergo strict assessment concerning functional safety. The chances and challenges of incorporating deep learning for self-driving cars are presented in this paper.},
booktitle = {Proceedings of the 1st International Workshop on Software Engineering for AI in Autonomous Systems},
pages = {35–38},
numpages = {4},
keywords = {functional safety, deep learning, automotive},
location = {Gothenburg, Sweden},
series = {SEFAIS '18}
}

@inproceedings{10.1145/3194085.3194086,
author = {Damm, Werner and Galbas, Roland},
title = {Exploiting learning and scenario-based specification languages for the verification and validation of highly automated driving},
year = {2018},
isbn = {9781450357395},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194085.3194086},
doi = {10.1145/3194085.3194086},
abstract = {We propose a series of methods based on learning key structural properties from traffic data-basis and on statistical model checking, ultimately leading to the construction of a scenario catalogue capturing requirements for controlling criticality for highly autonomous vehicles. We sketch underlying mathematical foundations which allow to derive formal confidence levels that vehicles tested by such a scenario catalogue will maintain the required control of criticality in real traffic matching the probability distributions of key parameters of data recorded in the reference data base employed for this process.},
booktitle = {Proceedings of the 1st International Workshop on Software Engineering for AI in Autonomous Systems},
pages = {39–46},
numpages = {8},
keywords = {verification and validation, statistical model-checking, requirement analysis, learning, highly automated driving, formal specification},
location = {Gothenburg, Sweden},
series = {SEFAIS '18}
}

@inproceedings{10.1145/3194085.3194090,
author = {Henriksson, Jens and Borg, Markus and Englund, Cristofer},
title = {Automotive safety and machine learning: initial results from a study on how to adapt the ISO 26262 safety standard},
year = {2018},
isbn = {9781450357395},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194085.3194090},
doi = {10.1145/3194085.3194090},
abstract = {Machine learning (ML) applications generate a continuous stream of success stories from various domains. ML enables many novel applications, also in safety-critical contexts. However, the functional safety standards such as ISO 26262 did not evolve to cover ML. We conduct an exploratory study on which parts of ISO 26262 represent the most critical gaps between safety engineering and ML development. While this paper only reports the first steps toward a larger research endeavor, we report three adaptations that are critically needed to allow ISO 26262 compliant engineering, and related suggestions on how to evolve the standard.},
booktitle = {Proceedings of the 1st International Workshop on Software Engineering for AI in Autonomous Systems},
pages = {47–49},
numpages = {3},
keywords = {safety, machine learning, interview study, automotive software},
location = {Gothenburg, Sweden},
series = {SEFAIS '18}
}

@inproceedings{10.1145/3528227.3528565,
author = {Gopalakrishna, Nikhil Krishna and Anandayuvaraj, Dharun and Detti, Annan and Bland, Forrest Lee and Rahaman, Sazzadur and Davis, James C.},
title = {"If security is required": engineering and security practices for machine learning-based IoT devices},
year = {2023},
isbn = {9781450393324},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3528227.3528565},
doi = {10.1145/3528227.3528565},
abstract = {The latest generation of IoT systems incorporate machine learning (ML) technologies on edge devices. This introduces new engineering challenges to bring ML onto resource-constrained hardware, and complications for ensuring system security and privacy. Existing research prescribes iterative processes for machine learning enabled IoT products to ease development and increase product success. However, these processes mostly focus on existing practices used in other generic software development areas and are not specialized for the purpose of machine learning or IoT devices.This research seeks to characterize engineering processes and security practices for ML-enabled IoT systems through the lens of the engineering lifecycle. We collected data from practitioners through a survey (N=25) and interviews (N=4). We found that security processes and engineering methods vary by company. Respondents emphasized the engineering cost of security analysis and threat modeling, and trade-offs with business needs. Engineers reduce their security investment if it is not an explicit requirement. The threats of IP theft and reverse engineering were a consistent concern among practitioners when deploying ML for IoT devices. Based on our findings, we recommend further research into understanding engineering cost, compliance, and security trade-offs.},
booktitle = {Proceedings of the 4th International Workshop on Software Engineering Research and Practice for the IoT},
pages = {1–8},
numpages = {8},
keywords = {software engineering, security and privacy, machine learning, internet of things, embedded systems, cyber-physical systems},
location = {Pittsburgh, Pennsylvania},
series = {SERP4IoT '22}
}

@inproceedings{10.1145/3387903.3389312,
author = {Zhu, Hong and Bayley, Ian},
title = {Exploratory Datamorphic Testing of Classification Applications},
year = {2020},
isbn = {9781450379571},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387903.3389312},
doi = {10.1145/3387903.3389312},
abstract = {Testing has been widely recognised as difficult for AI applications. This paper proposes a set of testing strategies for testing machine learning applications in the framework of the datamorphism testing methodology. In these strategies, testing aims at exploring the data space of a classification or clustering application to discover the boundaries between classes that the machine learning application defines. This enables the tester to understand precisely the behaviour and function of the software under test. In the paper, three variants of exploratory strategies are presented with the algorithms as implemented in the automated datamorphic testing tool Morphy. The correctness of these algorithms are formally proved. The paper also reports the results of some controlled experiments with Morphy that study the factors that affect the test effectiveness of the strategies.},
booktitle = {Proceedings of the IEEE/ACM 1st International Conference on Automation of Software Test},
pages = {51–60},
numpages = {10},
keywords = {Testing tools, Test strategies, Test method, Software testing, Exploratory testing, Datamorphic testing, Automated software testing, Artificial intelligence},
location = {Seoul, Republic of Korea},
series = {AST '20}
}

@inproceedings{10.1145/3379177.3388898,
author = {Kl\"{u}nder, Jil and Karajic, Dzejlana and Tell, Paolo and Karras, Oliver and M\"{u}nkel, Christian and M\"{u}nch, J\"{u}rgen and MacDonell, Stephen G. and Hebig, Regina and Kuhrmann, Marco},
title = {Determining Context Factors for Hybrid Development Methods with Trained Models},
year = {2020},
isbn = {9781450375122},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379177.3388898},
doi = {10.1145/3379177.3388898},
abstract = {Selecting a suitable development method for a specific project context is one of the most challenging activities in process design. Every project is unique and, thus, many context factors have to be considered. Recent research took some initial steps towards statistically constructing hybrid development methods, yet, paid little attention to the peculiarities of context factors influencing method and practice selection. In this paper, we utilize exploratory factor analysis and logistic regression analysis to learn such context factors and to identify methods that are correlated with these factors. Our analysis is based on 829 data points from the HELENA dataset. We provide five base clusters of methods consisting of up to 10 methods that lay the foundation for devising hybrid development methods. The analysis of the five clusters using trained models reveals only a few context factors, e.g., project/product size and target application domain, that seem to significantly influence the selection of methods. An extended descriptive analysis of these practices in the context of the identified method clusters also suggests a consolidation of the relevant practice sets used in specific project contexts.},
booktitle = {Proceedings of the International Conference on Software and System Processes},
pages = {61–70},
numpages = {10},
keywords = {software process, logistical regression analysis, hybrid development method, exploratory factor analysis, Agile software development},
location = {Seoul, Republic of Korea},
series = {ICSSP '20}
}

@inproceedings{10.1145/3526073.3527589,
author = {Habibullah, Khan Mohammad and Gay, Gregory and Horkoff, Jennifer},
title = {Non-functional requirements for machine learning: an exploration of system scope and interest},
year = {2023},
isbn = {9781450393195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3526073.3527589},
doi = {10.1145/3526073.3527589},
abstract = {Systems that rely on Machine Learning (ML systems) have differing demands on quality---non-functional requirements (NFRs)---compared to traditional systems. NFRs for ML systems may differ in their definition, scope, and importance. Despite the importance of NFRs for ML systems, our understanding of their definitions and scope---and of the extent of existing research---is lacking compared to our understanding in traditional domains.Building on an investigation into importance and treatment of ML system NFRs in industry, we make three contributions towards narrowing this gap: (1) we present clusters of ML system NFRs based on shared characteristics, (2) we use Scopus search results---as well as inter-coder reliability on a sample of NFRs---to estimate the number of relevant studies on a subset of the NFRs, and (3), we use our initial reading of titles and abstracts in each sample to define the scope of NFRs over parts of the system (e.g., training data, ML model). These initial findings form the groundwork for future research in this emerging domain.},
booktitle = {Proceedings of the 1st Workshop on Software Engineering for Responsible AI},
pages = {29–36},
numpages = {8},
keywords = {requirements engineering, non-functional requirements, machine learning systems, machine learning},
location = {Pittsburgh, Pennsylvania},
series = {SE4RAI '22}
}

@inproceedings{10.1145/3526073.3527591,
author = {Matsui, Beatriz M. A. and Goya, Denise H.},
title = {MLOps: a guide to its adoption in the context of responsible AI},
year = {2023},
isbn = {9781450393195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3526073.3527591},
doi = {10.1145/3526073.3527591},
abstract = {DevOps practices have increasingly been applied to software development as well as the machine learning lifecycle, in a process known as MLOps. Currently, many professionals have written about this topic, but still few results can be found in the academic and scientific literature on MLOps and how to to implement it effectively. Considering aspects of responsible AI, this number is even lower, opening up a field of research with many possibilities. This article presents five steps to guide the understanding and adoption of MLOps in the context of responsible AI. The study aims to serve as a reference guide for all those who wish to learn more about the topic and intend to implement MLOps practices to develop their systems, following responsible AI principles.},
booktitle = {Proceedings of the 1st Workshop on Software Engineering for Responsible AI},
pages = {45–49},
numpages = {5},
keywords = {responsible AI, model, machine learning, development, MLOps, DevOps},
location = {Pittsburgh, Pennsylvania},
series = {SE4RAI '22}
}

@inproceedings{10.1145/3526073.3527590,
author = {Lewis, Grace A. and Echeverr\'{\i}a, Sebasti\'{a}n and Pons, Lena and Chrabaszcz, Jeffrey},
title = {Augur: a step towards realistic drift detection in production ML systems},
year = {2023},
isbn = {9781450393195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3526073.3527590},
doi = {10.1145/3526073.3527590},
abstract = {The inference quality of deployed machine learning (ML) models degrades over time due to differences between training and production data, typically referred to as drift. While large organizations rely on periodic training to evade drift, the reality is that not all organizations have the data and the resources required to do so. We propose a process for drift behavior analysis at model development time that determines the set of metrics and thresholds to monitor for runtime drift detection. Better understanding of how models will react to drift before they are deployed, combined with a mechanism for how to detect this drift in production, is an important aspect of Responsible AI. The toolset and experiments reported in this paper provide an initial demonstration of (1) drift behavior analysis as a part of the model development process, (2) metrics and thresholds that need to be monitored for drift detection in production, and (3) libraries for drift detection that can be embedded in production monitoring infrastructures.},
booktitle = {Proceedings of the 1st Workshop on Software Engineering for Responsible AI},
pages = {37–44},
numpages = {8},
keywords = {software engineering, responsible AI, model monitoring, machine learning, drift detection},
location = {Pittsburgh, Pennsylvania},
series = {SE4RAI '22}
}

@inproceedings{10.1145/3526073.3527584,
author = {Kolltveit, Ask Berstad and Li, Jingyue},
title = {Operationalizing machine learning models: a systematic literature review},
year = {2023},
isbn = {9781450393195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3526073.3527584},
doi = {10.1145/3526073.3527584},
abstract = {Deploying machine learning (ML) models to production with the same level of rigor and automation as traditional software systems has shown itself to be a non-trivial task, requiring extra care and infrastructure to deal with the additional challenges. Although many studies focus on adapting ML software engineering (SE) approaches and techniques, few studies have summarized the status and challenges of operationalizing ML models. Model operationalization encompasses all steps after model training and evaluation, including packaging the model in a format appropriate for deployment, publishing to a model registry or storage, integrating the model into a broader software system, serving, and monitoring. This study is the first systematic literature review investigating the techniques, tools, and infrastructures to operationalize ML models. After reviewing 24 primary studies, the results show that there are a number of tools for most use cases to operationalize ML models and cloud deployment in particular. The review also revealed several research opportunities, such as dynamic model-switching, continuous model-monitoring, and efficient edge ML deployments.},
booktitle = {Proceedings of the 1st Workshop on Software Engineering for Responsible AI},
pages = {1–8},
numpages = {8},
keywords = {systematic literature review, operationalization, machine learning, deployment, MLOps},
location = {Pittsburgh, Pennsylvania},
series = {SE4RAI '22}
}

@inproceedings{10.1145/3524842.3528455,
author = {V\'{e}lez, Tatiana Castro and Khatchadourian, Raffi and Bagherzadeh, Mehdi and Raja, Anita},
title = {Challenges in migrating imperative deep learning programs to graph execution: an empirical study},
year = {2022},
isbn = {9781450393034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524842.3528455},
doi = {10.1145/3524842.3528455},
abstract = {Efficiency is essential to support responsiveness w.r.t. ever-growing datasets, especially for Deep Learning (DL) systems. DL frameworks have traditionally embraced deferred execution-style DL code that supports symbolic, graph-based Deep Neural Network (DNN) computation. While scalable, such development tends to produce DL code that is error-prone, non-intuitive, and difficult to debug. Consequently, more natural, less error-prone imperative DL frameworks encouraging eager execution have emerged at the expense of run-time performance. While hybrid approaches aim for the "best of both worlds," the challenges in applying them in the real world are largely unknown. We conduct a data-driven analysis of challenges---and resultant bugs---involved in writing reliable yet performant imperative DL code by studying 250 open-source projects, consisting of 19.7 MLOC, along with 470 and 446 manually examined code patches and bug reports, respectively. The results indicate that hybridization: (i) is prone to API misuse, (ii) can result in performance degradation---the opposite of its intention, and (iii) has limited application due to execution mode incompatibility. We put forth several recommendations, best practices, and anti-patterns for effectively hybridizing imperative DL code, potentially benefiting DL practitioners, API designers, tool developers, and educators.},
booktitle = {Proceedings of the 19th International Conference on Mining Software Repositories},
pages = {469–481},
numpages = {13},
keywords = {software evolution, imperative programs, hybrid programming paradigms, graph-based execution, empirical studies, deep learning},
location = {Pittsburgh, Pennsylvania},
series = {MSR '22}
}

@inproceedings{10.1145/3524610.3527893,
author = {Haryono, Stefanus A. and Kang, Hong Jin and Sharma, Abhishek and Sharma, Asankhaya and Santosa, Andrew and Yi, Ang Ming and Lo, David},
title = {Automated identification of libraries from vulnerability data: can we do better?},
year = {2022},
isbn = {9781450392983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524610.3527893},
doi = {10.1145/3524610.3527893},
abstract = {Software engineers depend heavily on software libraries and have to update their dependencies once vulnerabilities are found in them. Software Composition Analysis (SCA) helps developers identify vulnerable libraries used by an application. A key challenge is the identification of libraries related to a given reported vulnerability in the National Vulnerability Database (NVD), which may not explicitly indicate the affected libraries. Recently, researchers have tried to address the problem of identifying the libraries from an NVD report by treating it as an extreme multi-label learning (XML) problem, characterized by its large number of possible labels and severe data sparsity. As input, the NVD report is provided, and as output, a set of relevant libraries is returned.In this work, we evaluated multiple XML techniques. While previous work only evaluated a traditional XML technique, FastXML, we trained four other traditional XML models (DiSMEC, Parabel, Bonsai, ExtremeText) as well as two deep learning-based models (XML-CNN and LightXML). We compared both their effectiveness and the time cost of training and using the models for predictions. We find that other than DiSMEC and XML-CNN, recent XML models outperform the FastXML model by 3%--10% in terms of F1-scores on Top-k (k=1,2,3) predictions. Furthermore, we observe significant improvements in both the training and prediction time of these XML models, with Bonsai and Parabel model achieving 627x and 589x faster training time and 12x faster prediction time from the FastXML baseline. We discuss the implications of our experimental results and highlight limitations for future work to address.},
booktitle = {Proceedings of the 30th IEEE/ACM International Conference on Program Comprehension},
pages = {178–189},
numpages = {12},
keywords = {vulnerability report, multi-label classification, machine learning},
location = {Virtual Event},
series = {ICPC '22}
}

@inproceedings{10.5555/2820518.2820559,
author = {White, Martin and Vendome, Christopher and Linares-V\'{a}squez, Mario and Poshyvanyk, Denys},
title = {Toward deep learning software repositories},
year = {2015},
isbn = {9780769555942},
publisher = {IEEE Press},
abstract = {Deep learning subsumes algorithms that automatically learn compositional representations. The ability of these models to generalize well has ushered in tremendous advances in many fields such as natural language processing (NLP). Recent research in the software engineering (SE) community has demonstrated the usefulness of applying NLP techniques to software corpora. Hence, we motivate deep learning for software language modeling, highlighting fundamental differences between state-of-the-practice software language models and connectionist models. Our deep learning models are applicable to source code files (since they only require lexically analyzed source code written in any programming language) and other types of artifacts. We show how a particular deep learning model can remember its state to effectively model sequential data, e.g., streaming software tokens, and the state is shown to be much more expressive than discrete tokens in a prefix. Then we instantiate deep learning models and show that deep learning induces high-quality models compared to n-grams and cache-based n-grams on a corpus of Java projects. We experiment with two of the models' hyperparameters, which govern their capacity and the amount of context they use to inform predictions, before building several committees of software language models to aid generalization. Then we apply the deep learning models to code suggestion and demonstrate their effectiveness at a real SE task compared to state-of-the-practice models. Finally, we propose avenues for future work, where deep learning can be brought to bear to support model-based testing, improve software lexicons, and conceptualize software artifacts. Thus, our work serves as the first step toward deep learning software repositories.},
booktitle = {Proceedings of the 12th Working Conference on Mining Software Repositories},
pages = {334–345},
numpages = {12},
keywords = {software repositories, software language models, neural networks, n-grams, machine learning, deep learning},
location = {Florence, Italy},
series = {MSR '15}
}

@inproceedings{10.1145/3194733.3194737,
author = {Eni\c{s}er, Hasan Ferit and Sen, Alper},
title = {Testing service oriented architectures using stateful service visualization via machine learning},
year = {2018},
isbn = {9781450357432},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194733.3194737},
doi = {10.1145/3194733.3194737},
abstract = {Today's enterprise software systems are much complicated than the past. Increasing number of dependent applications, heterogeneous technologies and wide usage of Service Oriented Architectures (SOA), where numerous services communicate with each other, makes testing of such systems challenging. For testing these software systems, the concept of service virtualization is gaining popularity. Service virtualization is an automated technique to mimic the behavior of a given real service. Services can be classified as stateless or stateful services. Many services are stateful in nature. Although there are works in the literature for virtualization of state-less services, no such solution exists for stateful services. To the best of our knowledge, this is the first work for stateful service virtualization. We employ classification based and sequence-to-sequence based machine learning algorithms in developing our solutions. We demonstrate the validity of our approach on two data sets collected from real life services and obtain promising results.},
booktitle = {Proceedings of the 13th International Workshop on Automation of Software Test},
pages = {9–15},
numpages = {7},
keywords = {software testing, service virtualization, machine learning},
location = {Gothenburg, Sweden},
series = {AST '18}
}

